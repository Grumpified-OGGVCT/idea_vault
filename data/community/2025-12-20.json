[
  {
    "title": "Ollama Cloud Models",
    "date": "2025-09-23T07:57:18Z",
    "summary": "",
    "url": "https://ollama.com/blog/cloud-models",
    "source": "hackernews",
    "highlights": [
      "points: 2",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: Federated app store for self-hosted AI agents (Apache-2.0)",
    "date": "2025-11-04T18:09:21Z",
    "summary": "Self-hosted app store for AI agents. Federated discovery, container isolation, run on your infrastructure.<p>The problem: most organizations either build every agent in-house or send their data to thi",
    "url": "https://github.com/agentsystems/agentsystems",
    "source": "hackernews",
    "highlights": [
      "points: 2",
      "comments: 1"
    ]
  },
  {
    "title": "Show HN: Llmswap v3.0 \u2013 CLI and SDK for OpenAI, Claude, Gemini, Watsonx",
    "date": "2025-08-20T17:32:28Z",
    "summary": "LLMSwap is a CLI and Python SDK for switching between AI providers (OpenAI, Claude, Gemini, IBM watsonx, Ollama) with automatic fallbacks and response caching.<p>Started this during a hackathon when c",
    "url": "https://pypi.org/project/llmswap/",
    "source": "hackernews",
    "highlights": [
      "points: 2",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: Persistent Mind Model \u2013 AI that develops its own identity",
    "date": "2025-10-25T23:41:14Z",
    "summary": "Hi HN!<p>I\u2019ve been building something called the Persistent Mind Model (PMM).<p>It started as a side project on my home rig (i7-10700K &#x2F; RTX 3080 &#x2F; 32 GB RAM) because I was frustrated that e",
    "url": "https://github.com/scottonanski/persistent-mind-model-v1.0",
    "source": "hackernews",
    "highlights": [
      "points: 1",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: Shell Sage \u2013 AI-Powered Terminal Assistant",
    "date": "2025-02-05T12:44:05Z",
    "summary": "Hey HN,\nI built Shell Sage \u2013 an AI-powered CLI assistant that helps with:<p>Error diagnosis (explains terminal errors &amp; suggests fixes), \nNatural language to command translation, \nSafe execution w",
    "url": "https://shellsage.vercel.app/",
    "source": "hackernews",
    "highlights": [
      "points: 1",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: Cloud-native Stack for Ollama - Build locally and push to deploy",
    "date": "2024-03-19T18:06:17Z",
    "summary": "",
    "url": "https://github.com/ollama-cloud/get-started",
    "source": "hackernews",
    "highlights": [
      "points: 21",
      "comments: 4"
    ]
  },
  {
    "title": "Show HN: Tool to Automatically Create Organized Commits for PRs",
    "date": "2025-06-20T03:22:59Z",
    "summary": "I&#x27;ve found it helps PR reviewers when they can look through a set of commits with clear messages and logically organized changes. Typically reviewers prefer a larger quantity of smaller changes v",
    "url": "https://github.com/edverma/git-smart-squash",
    "source": "hackernews",
    "highlights": [
      "points: 76",
      "comments: 51"
    ]
  },
  {
    "title": "Show HN: Owl and MCP Integration \u2013 Plug-and-play agents with external tools",
    "date": "2025-03-26T22:35:46Z",
    "summary": "We integrated Model Context Protocol (MCP) into OWL \u2013 CAMEL-AI\u2019s open-source multi-agent framework.<p>With MCP, OWL agents can now interact with external tools like browsers, file systems, or research",
    "url": "https://www.camel-ai.org/blogs/owl-mcp-toolkit-practice",
    "source": "hackernews",
    "highlights": [
      "points: 3",
      "comments: 0"
    ]
  },
  {
    "title": "How to Install DeepSeek on Your Cloud Server with Ollama LLM",
    "date": "2025-02-07T18:48:13Z",
    "summary": "",
    "url": "https://www.deployhq.com/blog/how-to-install-deepseek-on-your-cloud-server-with-ollama-llm",
    "source": "hackernews",
    "highlights": [
      "points: 2",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: Git Auto Commit (GAC) \u2013 LLM-powered Git commit command line tool",
    "date": "2025-10-27T17:07:05Z",
    "summary": "GAC is a tool I built to help users spend less time summing up what was done and more time building. It uses LLMs to generate contextual git commit messages from your code changes. And it can be a dro",
    "url": "https://github.com/cellwebb/gac",
    "source": "hackernews",
    "highlights": [
      "points: 56",
      "comments: 36"
    ]
  },
  {
    "title": "Show HN: Browser extension to summarize HN comments \u2013 bring your own AI models",
    "date": "2024-12-28T17:00:05Z",
    "summary": "We\u2019re George and Ann, and want to share a Hacker News specific browser extension that we have been working on.<p>We all love the rich discussions in HN, but navigating long posts with multiple threads",
    "url": "https://github.com/levelup-apps/hn-enhancer",
    "source": "hackernews",
    "highlights": [
      "points: 8",
      "comments: 3"
    ]
  },
  {
    "title": "Show HN: Clai \u2013 CLI native LLM conversation engine",
    "date": "2025-02-09T07:27:29Z",
    "summary": "I&#x27;ve posted it here before, and here we go again!<p>The reason why I&#x27;ve continued working on it, even if there are many alternatives, is that it fills a unique role that I haven&#x27;t seen ",
    "url": "https://github.com/baalimago/clai",
    "source": "hackernews",
    "highlights": [
      "points: 3",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: Free AI Code Completion for Xcode with model choice/codebase context",
    "date": "2024-10-21T18:10:05Z",
    "summary": "Download link: <a href=\"https:&#x2F;&#x2F;www.cgft.io&#x2F;xcode\" rel=\"nofollow\">https:&#x2F;&#x2F;www.cgft.io&#x2F;xcode</a><p>Here are a few reasons to give this a shot, compared to others (e.g. App",
    "url": "https://www.cgft.io/xcode",
    "source": "hackernews",
    "highlights": [
      "points: 2",
      "comments: 0"
    ]
  },
  {
    "title": "From Ollama to OpenLLM: Running LLMs in the Cloud",
    "date": "2024-07-18T14:08:57Z",
    "summary": "",
    "url": "https://www.bentoml.com/blog/from-ollama-to-openllm-running-llms-in-the-cloud",
    "source": "hackernews",
    "highlights": [
      "points: 3",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: Agent \u2013 A Local Computer-Use Operator for macOS",
    "date": "2025-03-30T10:57:07Z",
    "summary": "Hey HN! We&#x27;ve just open-sourced Agent, our framework for running computer-use workflows across multiple apps in isolated macOS&#x2F;Linux sandboxes.<p>After launching Computer a few weeks ago, we",
    "url": "https://github.com/trycua/cua",
    "source": "hackernews",
    "highlights": [
      "points: 6",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: ThinkReview open source browser Copilot GitLab and ADO PRs(Ollama)",
    "date": "2025-11-15T02:48:08Z",
    "summary": "Over the last few months I\u2019ve been building a lightweight, open-source \u201ccopilot\u201d that runs directly in your browser and helps you review Pull Requests &#x2F; Merge Requests without sending code to any",
    "url": "https://github.com/Thinkode/thinkreview-browser-extension",
    "source": "hackernews",
    "highlights": [
      "points: 1",
      "comments: 0"
    ]
  },
  {
    "title": "New daily trending repos in Ruby",
    "date": "2025-12-20T00:09:18Z",
    "summary": "Subscribe to this issue and stay notified about new [daily trending repos in Ruby](https://github.com/trending/ruby?since=daily)!",
    "url": "https://github.com/vitalets/github-trending-repos/issues/9",
    "source": "github_issues",
    "highlights": [
      "comments: 21",
      "state: open",
      "repo: github-trending-repos"
    ]
  },
  {
    "title": "Dependency Dashboard",
    "date": "2025-12-20T13:57:14Z",
    "summary": "This issue lists Renovate updates and detected dependencies. Read the [Dependency Dashboard](https://docs.renovatebot.com/key-concepts/dashboard/) docs to learn more.<br>[View this repository on the Mend.io Web Portal](https://developer.mend.io/github/RooCodeInc/Roo-Code).\n\n## Deprecations / Replace",
    "url": "https://github.com/RooCodeInc/Roo-Code/issues/3192",
    "source": "github_issues",
    "highlights": [
      "comments: 1",
      "state: open",
      "repo: Roo-Code"
    ]
  },
  {
    "title": "15.0-20251213.1: Build check",
    "date": "2025-12-19T17:47:50Z",
    "summary": "#  Overview\n|  | package | i586 | x86_64 | notes | resolution |\n| --- | --- | --- | --- | --- | --- |\n| --- | desktop/buku | --- | --- | --- | Fixed in bfdb22e976 |\n| --- | desktop/numix-gtk-theme | --- | --- | --- | --- |\n| --- | ~~games/SLADE~~ | --- | --- | Source 404 | False Alarm |\n| --- | libr",
    "url": "https://github.com/SlackBuildsOrg/slackbuilds/issues/13445",
    "source": "github_issues",
    "highlights": [
      "comments: 16",
      "state: open",
      "repo: slackbuilds"
    ]
  },
  {
    "title": "Custom OpenAI-compatible provider options not being passed to API calls",
    "date": "2025-12-19T06:14:58Z",
    "summary": "# Custom OpenAI-compatible provider options not being passed to API calls\n\n## Description\n\n### Summary\n\nWhen using a custom provider with `@ai-sdk/openai-compatible`, the `options` (including `baseURL` and `apiKey`) configured in `opencode.json` are not being passed to the actual API calls. This res",
    "url": "https://github.com/sst/opencode/issues/5674",
    "source": "github_issues",
    "highlights": [
      "comments: 14",
      "state: open",
      "repo: opencode"
    ]
  },
  {
    "title": "Voice assistant",
    "date": "2025-12-19T01:06:42Z",
    "summary": "<details>\n<summary>For temporary use-cases:</summary>\n\n- shower: 1., 2., 4., 5., 6., 7., 9., 11., 13., 14., 15. and 20., 21., 24., 25., 26., 27., 29. and 30..\n- driving: 1., already have buttons concerning 2., 3., 4., 5., 6., 7., 8., 9., 10., 11., 12., 13., 14., 15., 21., 22., 23., 24., 25., 26., 29",
    "url": "https://github.com/Benjamin-Loison/android/issues/28",
    "source": "github_issues",
    "highlights": [
      "comments: 485",
      "state: open",
      "repo: android"
    ]
  },
  {
    "title": "Allow importing multi-file GGUF models",
    "date": "2025-12-17T17:51:32Z",
    "summary": "### What is the issue?\n\nCurrently Ollama can [import GGUF files](https://github.com/ollama/ollama/blob/main/docs/import.md). However, larger models are sometimes split into separate files. Ollama should support loading multiple GGUF files similar to loading safetensor files.\r\n\n\n### OS\n\n_No response_",
    "url": "https://github.com/ollama/ollama/issues/5245",
    "source": "github_issues",
    "highlights": [
      "comments: 72",
      "state: open",
      "repo: ollama"
    ]
  },
  {
    "title": "[ENTERPRISE] Suporte a Multiplas LLMs (Azure OpenAI, AWS Bedrock, Google Vertex)",
    "date": "2025-12-17T03:50:20Z",
    "summary": "## Descricao\nImplementar suporte a multiplos provedores de LLM alem do Claude/Anthropic, permitindo que clientes usem seus proprios contratos cloud.\n\n## Provedores a Suportar\n\n### 1. Azure OpenAI\n- GPT-4, GPT-4 Turbo, GPT-3.5 Turbo\n- Configuracao via Azure credentials\n- Suporte a deployments customi",
    "url": "https://github.com/cruzpeanelo/fabrica-de-workers/issues/11",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: fabrica-de-workers"
    ]
  },
  {
    "title": "Brew update memo",
    "date": "2025-12-16T15:36:29Z",
    "summary": "## 2023-11-20 (Mon)\r\n\r\n```\r\n$ brew update\r\nUpdated 5 taps (tailwarden/komiser, minio/stable, cduggn/cduggn, homebrew/core and homebrew/cask).\r\n==> New Formulae\r\naction-validator              ghc@9.6                       python-jinja                  ruler\r\namass                         intercept   ",
    "url": "https://github.com/yteraoka/blog-1q77-com/issues/160",
    "source": "github_issues",
    "highlights": [
      "comments: 46",
      "state: open",
      "repo: blog-1q77-com"
    ]
  },
  {
    "title": "Meta: Request rate limiting",
    "date": "2025-12-16T10:18:14Z",
    "summary": "This meta issue tracks scenarios where chat requests are blocked due to rate limiting.\n\n\ud83d\udc49 To get help with **premium request quota issues**, please comment in https://github.com/microsoft/vscode/issues/252230 .\n\nIn case you experience repeated rate-limiting in GitHub Copilot, please reach out to Git",
    "url": "https://github.com/microsoft/vscode/issues/253124",
    "source": "github_issues",
    "highlights": [
      "comments: 287",
      "state: open",
      "repo: vscode"
    ]
  },
  {
    "title": "suggestion: better integration with Llama-server /Llama swap",
    "date": "2025-12-15T03:21:05Z",
    "summary": "Unfortunately, Ollama is going down the road of the  [Enshittification](https://en.wikipedia.org/wiki/Enshittification). They're trying to promote their models in the cloud, overturning the original vision of being a tool that simplifies local model management.\nOn the contrary, llama.cpp is constant",
    "url": "https://github.com/n4ze3m/page-assist/issues/767",
    "source": "github_issues",
    "highlights": [
      "comments: 1",
      "state: open",
      "repo: page-assist"
    ]
  },
  {
    "title": "qwen3-vl:235b-cloud errors out with 'Service Temporarily Unavailable'",
    "date": "2025-12-13T06:32:51Z",
    "summary": "### What is the issue?\n\nI've been consistently using the cloud models, primarily larger ones like `qwen3-vl:235b-cloud`, without any issues until about a week ago. I started getting a flood of errors stating \n`[TURBO DEBUG] client.chat error: ResponseError('Service Temporarily Unavailable')` \nwhenev",
    "url": "https://github.com/ollama/ollama/issues/13399",
    "source": "github_issues",
    "highlights": [
      "comments: 3",
      "state: open",
      "repo: ollama"
    ]
  },
  {
    "title": "feat: Add dynamic multi-model support for OpenAI-compatible APIs",
    "date": "2025-12-10T13:29:31Z",
    "summary": "## What would you like to be added?\n\nAdd support for dynamically fetching and switching between multiple models from OpenAI-compatible API endpoints. Instead of being limited to a single hardcoded model, users should be able to:\n\n1. Configure an OpenAI-compatible API endpoint via `/auth` command\n2. ",
    "url": "https://github.com/QwenLM/qwen-code/issues/1206",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: qwen-code"
    ]
  },
  {
    "title": "Dependency Dashboard",
    "date": "2025-12-10T12:11:21Z",
    "summary": "This issue lists Renovate updates and detected dependencies. Read the [Dependency Dashboard](https://docs.renovatebot.com/key-concepts/dashboard/) docs to learn more.<br>[View this repository on the Mend.io Web Portal](https://developer.mend.io/github/n8n-io/n8n).\n\n## Repository problems\n\nThese prob",
    "url": "https://github.com/n8n-io/n8n/issues/18322",
    "source": "github_issues",
    "highlights": [
      "comments: 2",
      "state: open",
      "repo: n8n"
    ]
  },
  {
    "title": "CLASP Development Progress Tracker",
    "date": "2025-12-08T13:44:25Z",
    "summary": "# CLASP Development Progress\n\n**Claude Language Agent Super Proxy**\n\nThis issue tracks the autonomous development of CLASP - a proxy that enables Claude Code to work with any LLM provider.\n\n## Goals\n\n### Goal 1: Get Proxy Working with OpenAI API\n- [ ] Set up Go project structure\n- [ ] Implement basi",
    "url": "https://github.com/jedarden/CLASP/issues/1",
    "source": "github_issues",
    "highlights": [
      "comments: 403",
      "state: open",
      "repo: CLASP"
    ]
  },
  {
    "title": "[daily AI News] 2025/11/30~2025/12/06",
    "date": "2025-12-08T09:05:58Z",
    "summary": "# Ricursive Intelligence\n\nPartnering with Ricursive Intelligence: A Premier Frontier Lab Pioneering AI for Chip Design\n\n\u2e3b\n\n\ud83d\udd11 Key Takeaways\n\t1.\tRicursive Intelligence\ub294 AI\ub97c \ud1b5\ud574 \uce69 \uc124\uacc4 \uc804\uccb4 \ud750\ub984(\uc544\ud0a4\ud14d\ucc98 \u2192 RTL \u2192 \uac80\uc99d \u2192 \ubb3c\ub9ac\uc801 \uc124\uacc4)\uc744 \uc790\ub3d9\ud654\ud558\ub824\ub294 \u2018\ud504\ub7f0\ud2f0\uc5b4 \uc2e4\ud5d8\uc2e4(frontier lab)\u2019\uc774\ub2e4.  \ufffc\n\t2.\t\uc804\ud1b5\uc801\uc73c\ub85c \uce69 \uc124\uacc4\uc5d0\ub294 12\u201336\uac1c\uc6d4, \uac1c\ubc1c \ube44\uc6a9\uc740 \uc218\ubc31\ub9cc ~ \uc218\uc5b5 \ub2ec\ub7ec\uac00 \ub4e4\uc9c0\ub9cc,",
    "url": "https://github.com/DaewooKim/Daily-AI-news/issues/1",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: Daily-AI-news"
    ]
  },
  {
    "title": "prebuilt==1.0.5 breaks create_react_agent when passing a list of BaseTool",
    "date": "2025-12-06T16:10:17Z",
    "summary": "### Checked other resources\n\n- [x] This is a bug, not a usage question. For questions, please use the LangChain Forum (https://forum.langchain.com/).\n- [x] I added a clear and detailed title that summarizes the issue.\n- [x] I read what a minimal reproducible example is (https://stackoverflow.com/hel",
    "url": "https://github.com/langchain-ai/langgraph/issues/6477",
    "source": "github_issues",
    "highlights": [
      "comments: 3",
      "state: open",
      "repo: langgraph"
    ]
  },
  {
    "title": "[2025-11-15] AI World Clocks",
    "date": "2025-12-06T11:41:16Z",
    "summary": "# Hacker News\n\n\n  <details>\n    <summary>\n      <strong>AI World Clocks</strong>\n    </summary>\n\n## \u6458\u8981\n\n\u672c\u9879\u76ee\u7531Brian Moore\u521b\u5efa\uff0c\u7075\u611f\u6765\u6e90\u4e8eMatthew Rayfield\uff0c\u5176\u6838\u5fc3\u5185\u5bb9\u662f\u6bcf\u5206\u949f\u751f\u6210\u4e00\u4e2a\u7531\u4e5d\u4e2a\u4e0d\u540c\u7684AI\u6a21\u578b\u521b\u4f5c\u7684\u6a21\u62df\u65f6\u949f\u3002\n\n**\u4e3b\u8981\u7279\u70b9\uff1a**\n\n*   **AI\u751f\u6210:** \u4e5d\u4e2a\u72ec\u7acb\u7684AI\u6a21\u578b\u53c2\u4e0e\u65f6\u949f\u7684\u751f\u6210\u8fc7\u7a0b\u3002\n*   **\u4ee3\u7801\u751f\u6210:** \u6bcf\u4e2a\u6a21\u578b\u90fd\u4f7f\u75282000\u4e2atoken\u751f\u6210\u5b8c\u6574\u7684HTML/CSS\u4ee3\u7801\uff0c\u7528\u4e8e\u6784\u5efa\u6a21\u62df\u65f6\u949f\u3002\n*   **\u7edf\u4e00\u63d0\u793a\u8bcd:** \u6240\u6709\u6a21\u578b\u90fd\u9075",
    "url": "https://github.com/jiacai2050/mofish/issues/1261",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: mofish"
    ]
  },
  {
    "title": "Feature Request: LLM Profile Management for OpenHands CLI",
    "date": "2025-12-05T17:34:58Z",
    "summary": "# Feature Request: LLM Profile Management for OpenHands CLI\n\n## What problem or use case are you trying to solve?\n\nCurrently, the OpenHands CLI (`openhands-cli`) requires users to go through the configuration/settings pipeline every time they want to switch between different LLM models or providers.",
    "url": "https://github.com/OpenHands/OpenHands-CLI/issues/68",
    "source": "github_issues",
    "highlights": [
      "comments: 12",
      "state: open",
      "repo: OpenHands-CLI"
    ]
  },
  {
    "title": "PR4: Task 4: Run LLM for prelabeling",
    "date": "2025-12-01T16:34:10Z",
    "summary": "# Running Label Studio ML Backend Locally\n\nThis guide explains how to run the Label Studio ML backend with LLM for sentiment classification prelabeling.\n\n## Prerequisites\n\n1. **Docker & Docker Compose** - Install from [docker.com](https://www.docker.com/get-started)\n2. **Label Studio** - Running ins",
    "url": "https://github.com/xianminx/label-studio/issues/4",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: label-studio"
    ]
  },
  {
    "title": "torch compile breaks the output images on z-image turbo",
    "date": "2025-11-29T00:41:15Z",
    "summary": "works perfect without torch compile, but breaked with torch compile\n\n<img width=\"1193\" height=\"548\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/63debd44-cf0b-447a-b828-de3af67137cf\" />\n\nlog:\n\n(venv) root@6ee658d76ef4:/workspace/ComfyUI# ^C\n(venv) root@6ee658d76ef4:/workspace/ComfyUI#",
    "url": "https://github.com/comfyanonymous/ComfyUI/issues/10965",
    "source": "github_issues",
    "highlights": [
      "comments: 4",
      "state: open",
      "repo: ComfyUI"
    ]
  },
  {
    "title": "torch compile breaks the output images on z-image turbo",
    "date": "2025-11-28T15:47:32Z",
    "summary": "works perfect without torch compile, but breaked with torch compile\n\n<img width=\"1193\" height=\"548\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/63debd44-cf0b-447a-b828-de3af67137cf\" />\n\nlog:\n\n(venv) root@6ee658d76ef4:/workspace/ComfyUI# ^C\n(venv) root@6ee658d76ef4:/workspace/ComfyUI#",
    "url": "https://github.com/kijai/ComfyUI-KJNodes/issues/449",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: ComfyUI-KJNodes"
    ]
  },
  {
    "title": "Flux starts adding horizontal stripes to images around 2K resolution",
    "date": "2025-11-26T09:34:47Z",
    "summary": "It might be an upstream issue.\r\n\r\nI'm using Forge with default settings, except for the resolution. However, I\u2019ve tried most of the samplers and schedulers to fix the problem, but without success. What's particularly frustrating is that the issue randomly disappears once in a while for reasons unkno",
    "url": "https://github.com/lllyasviel/stable-diffusion-webui-forge/issues/1712",
    "source": "github_issues",
    "highlights": [
      "comments: 156",
      "state: open",
      "repo: stable-diffusion-webui-forge"
    ]
  },
  {
    "title": "Add a intelligent smart home chat bot to the UI",
    "date": "2025-11-24T08:45:52Z",
    "summary": "I am thinking of having a smart home chatbot for openHAB 5, a bit like HABot but more intelligent, integrated into Main UI and not only limited to smart home related stuff.\r\n\r\nThis would require the following bits:\r\n\r\n- [x] A powerful, LLM-based human language interpreter available: Something like h",
    "url": "https://github.com/openhab/openhab-webui/issues/2995",
    "source": "github_issues",
    "highlights": [
      "comments: 17",
      "state: open",
      "repo: openhab-webui"
    ]
  },
  {
    "title": "Feature request: add optional AI assistant that turns natural-language prompts into diagrams",
    "date": "2025-11-23T17:16:31Z",
    "summary": "<html>\n<body>\n<!--StartFragment--><div class=\"paragraph\" style=\"font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, system-ui, -apple-system, &quot;Segoe UI&quot;, Roboto, Ubuntu, Cantarell, &quot;Noto Sans&quot;, sans-serif, Arial, &quot;PingFang SC&quot;, &quot;Source Han Sans SC",
    "url": "https://github.com/excalidraw/excalidraw/issues/9900",
    "source": "github_issues",
    "highlights": [
      "comments: 2",
      "state: open",
      "repo: excalidraw"
    ]
  },
  {
    "title": "\ud83d\udd0d Reconocimiento Profundo Fase 1 - 5 Simbiontes: Configuraciones, L\u00edmites y Capacidades \u00danicas",
    "date": "2025-11-23T12:32:47Z",
    "summary": "## \ud83c\udf1f Reconocimiento Profundo Completado\n\n**5 simbiontes explorados**: ChatGPT, Claude, Gemini, DeepSeek, Mistral\n\n**M\u00e9todo aplicado**: \n- Revisi\u00f3n de historial y proyectos concretos\n- Exploraci\u00f3n de configuraciones avanzadas\n- Consulta de manuales y documentaci\u00f3n oficial\n- Documentaci\u00f3n de l\u00edmites r",
    "url": "https://github.com/1rec3/holobionte-1rec3/issues/18",
    "source": "github_issues",
    "highlights": [
      "comments: 6",
      "state: open",
      "repo: holobionte-1rec3"
    ]
  },
  {
    "title": "[2025-11-15] AI World Clocks \u2014 The disguised return of EU Chat Control",
    "date": "2025-11-16T02:06:48Z",
    "summary": "# V2EX\n\n\n  <details>\n    <summary>\n      <strong>\u8425\u9500\u53f7\uff1a\u5f71\u89c6\u98d3\u98ce\u4f60\u5c31\u662f\u4e0d\u61c2\u5f97\u89c6\u9891\u7684\u57fa\u672c\u539f\u7406</strong>\n    </summary>\n    \u6709\u4e2a\u8bc4\u8bba\u8bf4\u7684\u597d\uff0c\u628a TIM \u5f53\u5c0f\u96f7\u6574\u3002\u5207\u7247\u4e4b\u540e\u8fd8\u6dfb\u52a0\u5176\u4ed6\u753b\u9762\u6362\u4efb\u4f55\u5176\u4ed6\u4eba\u90fd\u9876\u4e0d\u4f4f\u3002<br>\u5c31\u50cf\u5176\u4ed6\u8d1f\u9762\u8f66\u4f01\u7684\u89c6\u9891\u653e\u4e2a\u5c0f\u7c73\u7684\u753b\u9762\u3002<br><br><br>\u9644\uff1a\u5173\u4e8e\u5f71\u89c6\u98d3\u98ce\u8fd1\u671f\u8206\u60c5<br><div class=\"embedded_video_wrapper\"><iframe src=\"https://www.youtube.com/embed/AqQkyAZeP9s\" class=\"embedded_v",
    "url": "https://github.com/jiacai2050/mofish/issues/1216",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: mofish"
    ]
  },
  {
    "title": "Dependency Dashboard",
    "date": "2025-11-13T13:13:03Z",
    "summary": "This issue lists Renovate updates and detected dependencies. Read the [Dependency Dashboard](https://docs.renovatebot.com/key-concepts/dashboard/) docs to learn more.<br>[View this repository on the Mend.io Web Portal](https://developer.mend.io/github/awfixer-platform/awborg).\n\n## Repository problem",
    "url": "https://github.com/awfixer-platform/awborg/issues/4",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: awborg"
    ]
  },
  {
    "title": "[New feature] Local LLM Support for DBeaver Community",
    "date": "2025-11-12T14:29:44Z",
    "summary": "**Is your feature request related to a problem? Please describe.**\n\nWhile DBeaver Enterprise Edition already includes AI capabilities, the community version lacks integration with local LLMs like Ollama. This limits the open-source community's ability to leverage AI features for database operations,",
    "url": "https://github.com/dbeaver/dbeaver/issues/36951",
    "source": "github_issues",
    "highlights": [
      "comments: 10",
      "state: open",
      "repo: dbeaver"
    ]
  },
  {
    "title": "Homelab RAG Test Bench: Legal Firm Document Search POC",
    "date": "2025-11-11T17:51:03Z",
    "summary": "# Homelab RAG Test Bench: Legal Firm Document Search System\n\n## \ud83c\udfaf Executive Summary\n\nBuilding a **privacy-first, self-hosted RAG (Retrieval-Augmented Generation) system** for a legal firm with 50GB of constantly-updating documents on Synology NAS. This homelab test validates architecture before prod",
    "url": "https://github.com/anibalinbalin/homelabragtest/issues/1",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: homelabragtest"
    ]
  },
  {
    "title": "Custom inline completion providers",
    "date": "2025-11-11T13:45:48Z",
    "summary": "**Summary**:  Custom inline completion providers for local models or other platforms\n\n--\n\nAfter going through: https://zed.dev/docs/completions\n\nZed currently supports completions via external LLM APIs like GitHub Copilot and Supermaven, but this is restrictive. Many users, for privacy or performanc",
    "url": "https://github.com/zed-industries/zed/issues/18490",
    "source": "github_issues",
    "highlights": [
      "comments: 13",
      "state: open",
      "repo: zed"
    ]
  },
  {
    "title": "[PR] chore: sync models.dev upstream",
    "date": "2025-12-20T18:25:06Z",
    "summary": "Automated subtree sync from upstream.\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n## Summary by CodeRabbit\n\n* **New Features**\n  * Added support for 100+ new AI models across multiple providers.\n  * Introduced an input token limit field in model specs.\n\n* **Updates**\n",
    "url": "https://github.com/Vivek-k3/modelsplus/pull/15",
    "source": "github_prs",
    "highlights": [
      "comments: 2",
      "pull request",
      "repo: modelsplus"
    ]
  },
  {
    "title": "[PR] Update",
    "date": "2025-12-20T10:15:40Z",
    "summary": "\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n## Summary by CodeRabbit\n\n* **New Features**\n  * Dozens of new blog posts and diagram assets on cloud-native topics, Kubernetes, IaC, and developer workflows.\n* **Documentation**\n  * Site rebranded to CloudRumble with updat",
    "url": "https://github.com/humzamalak/dca-prep-kit/pull/1",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: dca-prep-kit"
    ]
  },
  {
    "title": "[PR] feat(docker-image)!: Update ghcr.io/home-assistant/home-assistant Docker tag to v2025",
    "date": "2025-12-19T23:57:36Z",
    "summary": "This PR contains the following updates:\n\n| Package | Update | Change |\n|---|---|---|\n| [ghcr.io/home-assistant/home-assistant](https://www.home-assistant.io/) ([source](https://redirect.github.com/home-assistant/core)) | major | `2023.12.4` -> `2025.1.0` |\n\n---\n\n> [!WARNING]\n> Some dependencies coul",
    "url": "https://github.com/kstaniek/ironmaiden/pull/9517",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: ironmaiden"
    ]
  },
  {
    "title": "[PR] fix(deps): update all non-major dependencies",
    "date": "2025-12-20T21:05:27Z",
    "summary": "> **Note:** This PR body was truncated due to platform limits.\n\nThis PR contains the following updates:\n\n| Package | Change | [Age](https://docs.renovatebot.com/merge-confidence/) | [Confidence](https://docs.renovatebot.com/merge-confidence/) | Type | Update |\n|---|---|---|---|---|---|\n| [aws-cdk](h",
    "url": "https://github.com/BranislavBeno/GitLab-Issue-Importer/pull/334",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: GitLab-Issue-Importer"
    ]
  },
  {
    "title": "[PR] chore(deps): update pip",
    "date": "2025-12-19T22:33:17Z",
    "summary": "This PR contains the following updates:\n\n| Package | Change | [Age](https://docs.renovatebot.com/merge-confidence/) | [Confidence](https://docs.renovatebot.com/merge-confidence/) |\n|---|---|---|---|\n| [google-adk](https://redirect.github.com/google/adk-python) ([changelog](https://redirect.github.co",
    "url": "https://github.com/googleapis/genai-toolbox/pull/2215",
    "source": "github_prs",
    "highlights": [
      "comments: 2",
      "pull request",
      "repo: genai-toolbox"
    ]
  },
  {
    "title": "[PR] Add Extended Providers experiment",
    "date": "2025-12-20T21:18:49Z",
    "summary": "\r\n<img width=\"3024\" height=\"1722\" alt=\"CleanShot 2025-12-19 at 09 15 39@2x\" src=\"https://github.com/user-attachments/assets/5dc20184-346e-44bb-a5c6-c572281796a7\" />\r\n\r\n\r\n## What?\r\n\r\nAdds a new Extended Providers experiment that registers 9 additional AI provider integrations:\r\n- Cloudflare Workers A",
    "url": "https://github.com/WordPress/ai/pull/148",
    "source": "github_prs",
    "highlights": [
      "comments: 3",
      "pull request",
      "repo: ai"
    ]
  },
  {
    "title": "[PR] Fix/vertex auth service account",
    "date": "2025-12-20T16:43:38Z",
    "summary": "# What type of PR is this?\r\n<!-- Check one -->\r\n\r\n - [x] \ud83d\udc1b Bug fix\r\n - [ ] \u2728 Feature\r\n - [ ] \ud83d\udd0c Integration\r\n - [ ] \ud83d\udcdd Docs\r\n - [ ] \ud83e\uddf9 Refactor\r\n - [ ] Other:\r\n\r\n## Description\r\n<!-- Fixed logics for authentication to vertex with service account. -->\r\n\r\n\r\n## Contributor Checklist\r\n\r\n- [x] Created chang",
    "url": "https://github.com/eyaltoledano/claude-task-master/pull/1542",
    "source": "github_prs",
    "highlights": [
      "comments: 2",
      "pull request",
      "repo: claude-task-master"
    ]
  },
  {
    "title": "[PR] Native Ollama LLM Integration + Example Project + Full Unit Tests",
    "date": "2025-12-19T21:54:34Z",
    "summary": "# \ud83d\ude80 PR: Native Ollama LLM Integration + Example Project + Full Unit Tests  \r\n**Includes: Critical Fix for Ollama Cloud Tool-Calling + Comparison Test with LiteLLM**\r\n\r\n## \ud83d\udd17 Link to Issue or Description of Change\r\nNo existing issue.  \r\nSubmitting this as a **major feature contribution** that fills a ",
    "url": "https://github.com/google/adk-python/pull/3570",
    "source": "github_prs",
    "highlights": [
      "comments: 11",
      "pull request",
      "repo: adk-python"
    ]
  },
  {
    "title": "[PR] Feature: Interactive Package Conflict Resolution + Saved Preferences(Issue #42)",
    "date": "2025-12-20T17:27:40Z",
    "summary": "## Summary\r\n<!-- Brief description of changes -->Implements interactive package conflict resolution UI and persistent conflict-resolution preferences.\r\n\r\n- Add interactive conflict-resolution UI to `cortex/cli.py`.\r\n  - Prompts user to choose which package to keep/remove when conflicts are detected.",
    "url": "https://github.com/cortexlinux/cortex/pull/203",
    "source": "github_prs",
    "highlights": [
      "comments: 26",
      "pull request",
      "repo: cortex"
    ]
  },
  {
    "title": "[PR] docs: Comprehensive Troubleshooting Guide (Issue #263)",
    "date": "2025-12-20T19:27:27Z",
    "summary": "## Summary\nImplements **Issue #263: Common errors and solutions guide**\n\nThis PR adds a comprehensive troubleshooting guide (`docs/TROUBLESHOOTING.md`) to help users diagnose and fix common issues.\n\n## Sections Covered\n\n### 1. API Key Issues\n- Missing API keys with setup instructions\n- Invalid key f",
    "url": "https://github.com/cortexlinux/cortex/pull/280",
    "source": "github_prs",
    "highlights": [
      "comments: 5",
      "pull request",
      "repo: cortex"
    ]
  },
  {
    "title": "[PR] feat : add Parallel Task Execution for Multi-Step Installs",
    "date": "2025-12-20T15:11:23Z",
    "summary": "## Related Issue\r\nCloses #269 <!-- REQUIRED: Issue number -->\r\n\r\n## Summary\r\n<!-- What does this PR do? -->\r\nImplemented parallel task execution system for Cortex that enables concurrent execution of independent installation steps, providing 2-3x speedup for complex multi-step installations.\r\n\r\n### ",
    "url": "https://github.com/cortexlinux/cortex/pull/288",
    "source": "github_prs",
    "highlights": [
      "comments: 5",
      "pull request",
      "repo: cortex"
    ]
  },
  {
    "title": "[PR] [feature] Ollama Integration - Local LLM Support",
    "date": "2025-12-19T21:17:54Z",
    "summary": "## Summary\n\nAdds local LLM support via Ollama for privacy-first, offline-capable package management.\n\n## Features\n- \u2705 Auto-detect Ollama installation\n- \u2705 Smart model selection (prefers code-focused models)\n- \u2705 Streaming responses\n- \u2705 Fallback to Claude/OpenAI\n- \u2705 Works completely offline\n- \u2705 Zero da",
    "url": "https://github.com/cortexlinux/cortex/pull/287",
    "source": "github_prs",
    "highlights": [
      "comments: 3",
      "pull request",
      "repo: cortex"
    ]
  },
  {
    "title": "[PR] [pull] master from ItzCrazyKns:master",
    "date": "2025-12-20T20:44:09Z",
    "summary": "See [Commits](/itsbrex/Perplexica/pull/11/commits) and [Changes](/itsbrex/Perplexica/pull/11/files) for more details.\n\n-----\nCreated by [<img src=\"https://prod.download/pull-18h-svg\" valign=\"bottom\"/> **pull[bot]**](https://github.com/wei/pull) (v2.0.0-alpha.4)\n\n_Can you help keep this open source s",
    "url": "https://github.com/itsbrex/Perplexica/pull/11",
    "source": "github_prs",
    "highlights": [
      "comments: 2",
      "pull request",
      "repo: Perplexica"
    ]
  },
  {
    "title": "[PR] Ai migration doc",
    "date": "2025-12-19T20:06:44Z",
    "summary": "## \ud83c\udfaf Changes\r\n\r\nAdds a migration doc to help folks migrate from the first version of the API to the proposed newer version.\r\n\r\n## \u2705 Checklist\r\n\r\n- [x] I have followed the steps in the [Contributing guide](https://github.com/TanStack/ai/blob/main/CONTRIBUTING.md).\r\n- [x] I have tested this code local",
    "url": "https://github.com/TanStack/ai/pull/146",
    "source": "github_prs",
    "highlights": [
      "comments: 3",
      "pull request",
      "repo: ai"
    ]
  },
  {
    "title": "[PR] SQL ",
    "date": "2025-12-19T19:54:54Z",
    "summary": "# Pull Request Checklist\r\n\r\n### Note to first-time contributors: Please open a discussion post in [Discussions](https://github.com/open-webui/open-webui/discussions) and describe your changes before submitting a pull request.\r\n\r\n**Before submitting, make sure you've checked the following:**\r\n\r\n- [ ]",
    "url": "https://github.com/arthrod/open-webui/pull/65",
    "source": "github_prs",
    "highlights": [
      "comments: 2",
      "pull request",
      "repo: open-webui"
    ]
  },
  {
    "title": "[PR] feat: Get live provider and model data from model.dev",
    "date": "2025-12-19T19:37:04Z",
    "summary": "This pull request introduces improvements to model selection flexibility and configuration, as well as an environment variable for enabling live model data fetching. The most significant changes include allowing multiple model types to be filtered in the API, updating starter project components to s",
    "url": "https://github.com/langflow-ai/langflow/pull/11007",
    "source": "github_prs",
    "highlights": [
      "comments: 3",
      "pull request",
      "repo: langflow"
    ]
  },
  {
    "title": "[PR] python3Packages.alembic: 1.16.4 -> 1.17.2",
    "date": "2025-12-19T19:26:56Z",
    "summary": "fixing build on staging-next\r\n\r\nChangelog: https://alembic.sqlalchemy.org/en/latest/changelog.html#changelog-1-17-2\r\nDiff: https://github.com/sqlalchemy/alembic/compare/rel_1_16_4...rel_1_17_2\r\n\r\n\r\n<!--\r\n^ Please summarise the changes you have done and explain why they are necessary here ^\r\n\r\nFor pa",
    "url": "https://github.com/NixOS/nixpkgs/pull/472241",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: nixpkgs"
    ]
  },
  {
    "title": "[PR] test: end-to-end testing for chat features",
    "date": "2025-12-19T19:18:57Z",
    "summary": "### Summary                                                                                                            \r\n                                                                                                                   \r\nThis PR adds E2E tests for the AI assistant chat feature using",
    "url": "https://github.com/stacklok/toolhive-cloud-ui/pull/199",
    "source": "github_prs",
    "highlights": [
      "comments: 2",
      "pull request",
      "repo: toolhive-cloud-ui"
    ]
  },
  {
    "title": "[PR] fix(deps): update dependency org.springframework.ai:spring-ai-bom to v1.1.2",
    "date": "2025-12-20T01:45:27Z",
    "summary": "This PR contains the following updates:\n\n| Package | Change | [Age](https://docs.renovatebot.com/merge-confidence/) | [Confidence](https://docs.renovatebot.com/merge-confidence/) |\n|---|---|---|---|\n| [org.springframework.ai:spring-ai-bom](https://redirect.github.com/spring-projects/spring-ai) | `1.",
    "url": "https://github.com/rajadilipkolli/ai-playground/pull/166",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: ai-playground"
    ]
  },
  {
    "title": "[PR] Update dependency org.springframework.ai:spring-ai-bom to v1.1.2",
    "date": "2025-12-20T17:45:02Z",
    "summary": "> **Note:** This PR body was truncated due to platform limits.\n\nThis PR contains the following updates:\n\n| Package | Change | [Age](https://docs.renovatebot.com/merge-confidence/) | [Adoption](https://docs.renovatebot.com/merge-confidence/) | [Passing](https://docs.renovatebot.com/merge-confidence/)",
    "url": "https://github.com/barakb/spring-ai-app/pull/6",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: spring-ai-app"
    ]
  },
  {
    "title": "[PR] feat: Add LLM Evals",
    "date": "2025-12-20T19:22:02Z",
    "summary": "# PR Description: Multi-Model Personality Benchmark Framework\n\n## Description\nThis PR introduces a comprehensive A/B benchmarking framework for testing phylogenic AI genome-enhanced personalities against baseline LLM performance. The implementation demonstrates measurable performance improvements fr",
    "url": "https://github.com/jimmyjdejesus-cmyk/Phylogenic-AI-Agents/pull/13",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: Phylogenic-AI-Agents"
    ]
  },
  {
    "title": "[PR] Add LlamaCpp provider for local GGUF model inference",
    "date": "2025-12-20T01:49:16Z",
    "summary": "Adds LlamaCpp as a third LLM provider alongside Ollama and OpenAI, enabling local inference with quantized GGUF models (~350MB chat + ~140MB embeddings) with automatic GPU acceleration (CUDA/Metal).\n\n## Core Implementation\n\n**`backend/app/llamacpp_client.py`**\n- `LlamaCppClient`: Async streaming cha",
    "url": "https://github.com/janega/ElectronAIChat/pull/5",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: ElectronAIChat"
    ]
  },
  {
    "title": "[PR] Update dependency org.springframework.ai:spring-ai-bom to v1.1.2",
    "date": "2025-12-20T21:00:56Z",
    "summary": "> **Note:** This PR body was truncated due to platform limits.\n\nThis PR contains the following updates:\n\n| Package | Change | [Age](https://docs.renovatebot.com/merge-confidence/) | [Confidence](https://docs.renovatebot.com/merge-confidence/) |\n|---|---|---|---|\n| [org.springframework.ai:spring-ai-b",
    "url": "https://github.com/krushnatkhawale/springai-openai-hello-world/pull/29",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: springai-openai-hello-world"
    ]
  },
  {
    "title": "[PR] Update dependency org.springframework.ai:spring-ai-bom to v1.1.2",
    "date": "2025-12-20T20:39:07Z",
    "summary": "> **Note:** This PR body was truncated due to platform limits.\n\nThis PR contains the following updates:\n\n| Package | Change | [Age](https://docs.renovatebot.com/merge-confidence/) | [Confidence](https://docs.renovatebot.com/merge-confidence/) |\n|---|---|---|---|\n| [org.springframework.ai:spring-ai-b",
    "url": "https://github.com/kpavlov/spring-ai-llm-proxy/pull/58",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: spring-ai-llm-proxy"
    ]
  },
  {
    "title": "[PR] Implement modular Flask AI app with dynamic MCP server management, enhanced UI, and config generator",
    "date": "2025-12-20T04:53:44Z",
    "summary": "Built a production-ready Flask application that enables dynamic AI backend switching and MCP server management without code modifications. All configuration is driven through `.env` files. Features a modern, feature-rich user interface with enhanced UX and a powerful configuration generator tool.\n\n#",
    "url": "https://github.com/LSRadio/Py-AI-MCP/pull/2",
    "source": "github_prs",
    "highlights": [
      "comments: 4",
      "pull request",
      "repo: Py-AI-MCP"
    ]
  },
  {
    "title": "[PR] chore(deps): update all non-major dependencies",
    "date": "2025-12-20T05:13:23Z",
    "summary": "> **Note:** This PR body was truncated due to platform limits.\n\nThis PR contains the following updates:\n\n| Package | Update | Change |\n|---|---|---|\n| [cert-manager](https://cert-manager.io) ([source](https://redirect.github.com/cert-manager/cert-manager)) | minor | `v1.17.2` -> `v1.19.2` |\n| [exter",
    "url": "https://github.com/dbirks/home-k8s/pull/32",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: home-k8s"
    ]
  },
  {
    "title": "[PR] Tldw refactor",
    "date": "2025-12-20T18:29:34Z",
    "summary": "\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n## Summary by CodeRabbit\n\n- New Features\n  - Persistent Chat Sidebar (Local/Server/Folders), Command Palette (Cmd/Ctrl+K), and Keyboard Shortcuts modal.\n  - Knowledge Search (renamed from RAG) with hints; Vision/tooltips up",
    "url": "https://github.com/rmusser01/tldw_browser_assistant/pull/23",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: tldw_browser_assistant"
    ]
  },
  {
    "title": "[PR] v1.3.0: Integrate llama.cpp LLM inference with GPU acceleration and distributed RPC framework",
    "date": "2025-12-20T06:57:29Z",
    "summary": "## v1.3.0 LLM Integration - COMPLETE \u2705\n\nSuccessfully consolidated all v1.3.0 features from three PRs (#101, #104, #105) into a single production-ready release.\n\n### Integration Summary\n\n**Files Changed**: 167 files (144 new, 23 modified, 0 deleted)\n**Lines Changed**: +71,578 / -749\n**Commits**: 12 t",
    "url": "https://github.com/makr-code/ThemisDB/pull/107",
    "source": "github_prs",
    "highlights": [
      "comments: 12",
      "pull request",
      "repo: ThemisDB"
    ]
  },
  {
    "title": "[PR] deno: 2.5.6 -> 2.6.3",
    "date": "2025-12-20T16:14:56Z",
    "summary": "Supersedes #471731\r\n\r\nOur self-update patch no longer apply, and when I had a closer look, I realized it can also be disabled with a Cargo feature change, we don't need to carry the patch anymore.\r\n\r\n## Things done\r\n\r\n<!-- Please check what applies. Note that these are not hard requirements but mere",
    "url": "https://github.com/NixOS/nixpkgs/pull/472362",
    "source": "github_prs",
    "highlights": [
      "comments: 6",
      "pull request",
      "repo: nixpkgs"
    ]
  },
  {
    "title": "[PR] Split monolithic stack into HomeCore (Pi5) and DataAICore (Optiplex) deployments",
    "date": "2025-12-20T09:00:09Z",
    "summary": "Splits the monolithic Orion-Sentinel-CoreSrv into two independent, hardware-optimized deployments with clean separation of concerns and local-only security by default.\n\n## Structure\n\n**Orion-Sentinel-HomeCore/** (Raspberry Pi 5)\n- Home Assistant core with optional profiles: mqtt, zigbee, nodered, es",
    "url": "https://github.com/orionsentinel/Orion-Sentinel-CoreSrv/pull/32",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: Orion-Sentinel-CoreSrv"
    ]
  },
  {
    "title": "[PR] Update dependency google-adk to v1.21.0",
    "date": "2025-12-20T08:45:58Z",
    "summary": "This PR contains the following updates:\n\n| Package | Change | [Age](https://docs.renovatebot.com/merge-confidence/) | [Confidence](https://docs.renovatebot.com/merge-confidence/) |\n|---|---|---|---|\n| [google-adk](https://redirect.github.com/google/adk-python) ([changelog](https://redirect.github.co",
    "url": "https://github.com/allenporter/home-assistant-rulebook/pull/33",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: home-assistant-rulebook"
    ]
  },
  {
    "title": "[PR] \ud83d\udc84 style: Add Gemini 3 Flash & Doubao Seed 1.8 models",
    "date": "2025-12-20T10:02:28Z",
    "summary": "#### \ud83d\udcbb Change Type\r\n\r\n<!-- For change type, change [ ] to [x]. -->\r\n\r\n- [ ] \u2728 feat\r\n- [ ] \ud83d\udc1b fix\r\n- [ ] \u267b\ufe0f refactor\r\n- [ ] \ud83d\udc84 style\r\n- [ ] \ud83d\udc77 build\r\n- [ ] \u26a1\ufe0f perf\r\n- [ ] \u2705 test\r\n- [ ] \ud83d\udcdd docs\r\n- [ ] \ud83d\udd28 chore\r\n\r\n#### \ud83d\udd17 Related Issue\r\n\r\n<!-- Link to the issue that is fixed by this PR -->\r\n\r\n<!-- Example: F",
    "url": "https://github.com/lobehub/lobe-chat/pull/10832",
    "source": "github_prs",
    "highlights": [
      "comments: 5",
      "pull request",
      "repo: lobe-chat"
    ]
  },
  {
    "title": "[PR] chore(deps): bump langchain from 0.3.27 to 1.2.0 in /Server/Admin",
    "date": "2025-12-20T09:57:45Z",
    "summary": "Bumps [langchain](https://github.com/langchain-ai/langchain) from 0.3.27 to 1.2.0.\n<details>\n<summary>Release notes</summary>\n<p><em>Sourced from <a href=\"https://github.com/langchain-ai/langchain/releases\">langchain's releases</a>.</em></p>\n<blockquote>\n<h2>langchain-anthropic==1.2.0</h2>\n<p>Change",
    "url": "https://github.com/Froillan123/Faceofmind/pull/636",
    "source": "github_prs",
    "highlights": [
      "comments: 3",
      "pull request",
      "repo: Faceofmind"
    ]
  },
  {
    "title": "[PR] Update Container images",
    "date": "2025-12-20T11:08:17Z",
    "summary": "This PR contains the following updates:\n\n| Package | Update | Change |\n|---|---|---|\n| [docker.n8n.io/n8nio/n8n](https://n8n.io) ([source](https://redirect.github.com/n8n-io/n8n)) | minor | `2.0.3` -> `2.1.1` |\n| [gitea/gitea](https://redirect.github.com/go-gitea/gitea) | patch | `1.25.2` -> `1.25.3",
    "url": "https://github.com/bubacoder/infra/pull/251",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: infra"
    ]
  },
  {
    "title": "[PR] `Iris`: Add LLM Selection",
    "date": "2025-12-20T12:02:59Z",
    "summary": "## Motivation\r\n\r\nCurrently, Iris lacks a clear mechanism to distinguish between local and cloud-based LLMs. This makes it impossible for users to determine which type of LLM infrastructure should be used. To improve flexibility and make LLM selection more transparent, we need a systematic way to ind",
    "url": "https://github.com/ls1intum/edutelligence/pull/346",
    "source": "github_prs",
    "highlights": [
      "comments: 2",
      "pull request",
      "repo: edutelligence"
    ]
  },
  {
    "title": "[PR] feat: Add OpenAI-compatible provider for local LLM servers",
    "date": "2025-12-20T13:22:31Z",
    "summary": "## Summary\n\n- Adds new `OpenAICompatibleProvider` supporting the standard OpenAI Chat Completions API (`/v1/chat/completions`)\n- Enables connection to local LLM servers like KoboldCpp, Ollama, and LM Studio\n- Includes setup wizard integration, credentials page, and quick settings modal support\n- Mod",
    "url": "https://github.com/tetrixdev/pocket-dev/pull/35",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: pocket-dev"
    ]
  },
  {
    "title": "[PR] CLI Auth - Add vertex quick setup and auth prompts",
    "date": "2025-12-20T12:56:03Z",
    "summary": "<!--\r\nThank you for contributing to Cline!\r\n\r\n\u26a0\ufe0f Important: Before submitting this PR, please ensure you have:\r\n- For feature requests: Created a discussion in our Feature Requests discussions board https://github.com/cline/cline/discussions/categories/feature-requests and received approval from cor",
    "url": "https://github.com/cline/cline/pull/7320",
    "source": "github_prs",
    "highlights": [
      "comments: 3",
      "pull request",
      "repo: cline"
    ]
  },
  {
    "title": "[PR] feat(ai): AI reading assistant - phase 1",
    "date": "2025-12-20T14:10:27Z",
    "summary": "closes #2738.\r\n\r\ncompletes phase 1 (of a proposed 3 or more if it's necessary) of the ai assistant integration.",
    "url": "https://github.com/readest/readest/pull/2740",
    "source": "github_prs",
    "highlights": [
      "comments: 10",
      "pull request",
      "repo: readest"
    ]
  },
  {
    "title": "[PR] home-assistant: 2025.12.3 -> 2025.12.4",
    "date": "2025-12-20T13:44:10Z",
    "summary": "Diff: https://github.com/home-assistant/core/compare/2025.12.3...2025.12.4\r\n\r\nChangelog: https://github.com/home-assistant/core/releases/tag/2025.12.4\r\n\r\ncloses https://github.com/NixOS/nixpkgs/pull/466120\r\ncloses https://github.com/NixOS/nixpkgs/pull/471561\r\n<!--\r\n^ Please summarise the changes you",
    "url": "https://github.com/NixOS/nixpkgs/pull/472664",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: nixpkgs"
    ]
  },
  {
    "title": "[PR] Installation simulation mode fix #103",
    "date": "2025-12-20T15:11:04Z",
    "summary": "## Summary\r\n<!-- Brief description of changes -->\r\n- The `--simulate` flag enables preview mode for installations, showing what would be installed without making any changes. This helps users:\r\n- Preview what would be installed with **real package sizes from LLM**\r\n- Check **actual disk space** avai",
    "url": "https://github.com/cortexlinux/cortex/pull/264",
    "source": "github_prs",
    "highlights": [
      "comments: 7",
      "pull request",
      "repo: cortex"
    ]
  },
  {
    "title": "[PR] feat(monitoring): comprehensive monitoring infrastructure for Claude Code agents",
    "date": "2025-12-20T18:31:36Z",
    "summary": "## Summary\n\n- Add Slack notifications for auto-claude runs (start, skip, complete, blocked)\n- Create K8s manifests for OTEL Collector, Cribl Edge, and Splunk\n- Add structured JSON event logging to auto-claude\n- Comprehensive documentation in `docs/MONITORING.md` and `docs/monitoring/`\n\n## Known Issu",
    "url": "https://github.com/JacobPEvans/nix/pull/172",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: nix"
    ]
  },
  {
    "title": "[PR] python3Packages.pillow-heif: 1.1.0 -> 1.1.1",
    "date": "2025-12-20T16:04:12Z",
    "summary": "Changelog: https://github.com/bigcat88/pillow_heif/releases/tag/v1.1.1\r\n\r\n\r\n<!--\r\n^ Please summarise the changes you have done and explain why they are necessary here ^\r\n\r\nFor package updates please link to a changelog or describe changes, this helps your fellow maintainers discover breaking updates",
    "url": "https://github.com/NixOS/nixpkgs/pull/465549",
    "source": "github_prs",
    "highlights": [
      "comments: 3",
      "pull request",
      "repo: nixpkgs"
    ]
  },
  {
    "title": "[PR] feat: Add constellation anomaly detection for label evaluator agent",
    "date": "2025-12-20T20:39:33Z",
    "summary": "# Pull Request\n\n## Summary\n\n- Add constellation anomaly detection to identify unusual n-tuple spatial patterns beyond pairwise label relationships\n- Implement optimized pattern computation with centroid caching for efficient label geometry analysis\n- Integrate with Ollama Cloud for LLM-based review ",
    "url": "https://github.com/tnorlund/Portfolio/pull/549",
    "source": "github_prs",
    "highlights": [
      "comments: 7",
      "pull request",
      "repo: Portfolio"
    ]
  },
  {
    "title": "[PR] Update Mend: high confidence minor and patch dependency updates",
    "date": "2025-12-20T17:54:31Z",
    "summary": "This PR contains the following updates:\n\n| Package | Change | Age | Adoption | Passing | Confidence |\n|---|---|---|---|---|---|\n| [org.testcontainers:localstack](https://java.testcontainers.org) ([source](https://redirect.github.com/testcontainers/testcontainers-java)) | `1.19.7` -> `1.21.4` | [![ag",
    "url": "https://github.com/jgeraigery/carbonj/pull/5",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: carbonj"
    ]
  },
  {
    "title": "[PR] Marketplace v3.0.0 - Plugin Sync & Documentation Cleanup",
    "date": "2025-12-20T17:43:48Z",
    "summary": "## Summary\n\n- **Fix marketplace.json cache duplication** - Resolved issue where marketplace was duplicating plugins instead of updating them\n- **Fix duplicate keywords** - Removed space-separated pairs (e.g., \"openai agents\") that duplicated hyphenated names\n- **Clean up README.md** - Reduced from 8",
    "url": "https://github.com/secondsky/claude-skills/pull/21",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: claude-skills"
    ]
  },
  {
    "title": "[PR] Ollama Support",
    "date": "2025-12-20T18:49:52Z",
    "summary": "## Summary\r\n- Adds comprehensive Ollama integration for running AI models locally, providing users with a privacy-focused, zero-cost alternative to cloud APIs.\r\n- Closes #11 \r\n\r\n## Key Features\r\n- **Multi-Provider Architecture**: Switching between Google Gemini (cloud) and Ollama (local)\r\n- **Comple",
    "url": "https://github.com/threefoldtech/grid-agent/pull/15",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: grid-agent"
    ]
  },
  {
    "title": "[PR] [WIP] Create a modular skills architecture for Tom Assistant chatbot",
    "date": "2025-12-20T20:19:02Z",
    "summary": "## Complete Python Rewrite of TomAssistant\n\nThis is a comprehensive rewrite of TomAssistant from Rust to Python with a modern, modular architecture.\n\n### Implementation Plan\n\n- [ ] 1. Update .gitignore for Python project structure\n- [ ] 2. Create main Python project structure\n  - [ ] Create main.py ",
    "url": "https://github.com/Razubi/TomAssistant/pull/2",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: TomAssistant"
    ]
  },
  {
    "title": "[PR] chore(deps): update docker images",
    "date": "2025-12-20T20:04:48Z",
    "summary": "> **Note:** This PR body was truncated due to platform limits.\n\nThis PR contains the following updates:\n\n| Package | Update | Change |\n|---|---|---|\n| [docker.gitea.com/gitea](https://redirect.github.com/go-gitea/gitea) | patch | `1.25.2` -> `1.25.3` |\n| [ghcr.io/esphome/esphome](https://esphome.io/",
    "url": "https://github.com/morten-olsen/homelab-apps/pull/49",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: homelab-apps"
    ]
  }
]