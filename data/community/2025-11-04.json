[
  {
    "title": "Ollama Cloud Models",
    "date": "2025-09-23T07:57:18Z",
    "summary": "",
    "url": "https://ollama.com/blog/cloud-models",
    "source": "hackernews",
    "highlights": [
      "points: 2",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: Llmswap v3.0 \u2013 CLI and SDK for OpenAI, Claude, Gemini, Watsonx",
    "date": "2025-08-20T17:32:28Z",
    "summary": "LLMSwap is a CLI and Python SDK for switching between AI providers (OpenAI, Claude, Gemini, IBM watsonx, Ollama) with automatic fallbacks and response caching.<p>Started this during a hackathon when c",
    "url": "https://pypi.org/project/llmswap/",
    "source": "hackernews",
    "highlights": [
      "points: 2",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: Persistent Mind Model \u2013 AI that develops its own identity",
    "date": "2025-10-25T23:41:14Z",
    "summary": "Hi HN!<p>I\u2019ve been building something called the Persistent Mind Model (PMM).<p>It started as a side project on my home rig (i7-10700K &#x2F; RTX 3080 &#x2F; 32 GB RAM) because I was frustrated that e",
    "url": "https://github.com/scottonanski/persistent-mind-model-v1.0",
    "source": "hackernews",
    "highlights": [
      "points: 1",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: Shell Sage \u2013 AI-Powered Terminal Assistant",
    "date": "2025-02-05T12:44:05Z",
    "summary": "Hey HN,\nI built Shell Sage \u2013 an AI-powered CLI assistant that helps with:<p>Error diagnosis (explains terminal errors &amp; suggests fixes), \nNatural language to command translation, \nSafe execution w",
    "url": "https://shellsage.vercel.app/",
    "source": "hackernews",
    "highlights": [
      "points: 1",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: Cloud-native Stack for Ollama - Build locally and push to deploy",
    "date": "2024-03-19T18:06:17Z",
    "summary": "",
    "url": "https://github.com/ollama-cloud/get-started",
    "source": "hackernews",
    "highlights": [
      "points: 21",
      "comments: 4"
    ]
  },
  {
    "title": "Show HN: Tool to Automatically Create Organized Commits for PRs",
    "date": "2025-06-20T03:22:59Z",
    "summary": "I&#x27;ve found it helps PR reviewers when they can look through a set of commits with clear messages and logically organized changes. Typically reviewers prefer a larger quantity of smaller changes v",
    "url": "https://github.com/edverma/git-smart-squash",
    "source": "hackernews",
    "highlights": [
      "points: 76",
      "comments: 51"
    ]
  },
  {
    "title": "Show HN: Owl and MCP Integration \u2013 Plug-and-play agents with external tools",
    "date": "2025-03-26T22:35:46Z",
    "summary": "We integrated Model Context Protocol (MCP) into OWL \u2013 CAMEL-AI\u2019s open-source multi-agent framework.<p>With MCP, OWL agents can now interact with external tools like browsers, file systems, or research",
    "url": "https://www.camel-ai.org/blogs/owl-mcp-toolkit-practice",
    "source": "hackernews",
    "highlights": [
      "points: 3",
      "comments: 0"
    ]
  },
  {
    "title": "How to Install DeepSeek on Your Cloud Server with Ollama LLM",
    "date": "2025-02-07T18:48:13Z",
    "summary": "",
    "url": "https://www.deployhq.com/blog/how-to-install-deepseek-on-your-cloud-server-with-ollama-llm",
    "source": "hackernews",
    "highlights": [
      "points: 2",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: Git Auto Commit (GAC) \u2013 LLM-powered Git commit command line tool",
    "date": "2025-10-27T17:07:05Z",
    "summary": "GAC is a tool I built to help users spend less time summing up what was done and more time building. It uses LLMs to generate contextual git commit messages from your code changes. And it can be a dro",
    "url": "https://github.com/cellwebb/gac",
    "source": "hackernews",
    "highlights": [
      "points: 56",
      "comments: 35"
    ]
  },
  {
    "title": "Show HN: Browser extension to summarize HN comments \u2013 bring your own AI models",
    "date": "2024-12-28T17:00:05Z",
    "summary": "We\u2019re George and Ann, and want to share a Hacker News specific browser extension that we have been working on.<p>We all love the rich discussions in HN, but navigating long posts with multiple threads",
    "url": "https://github.com/levelup-apps/hn-enhancer",
    "source": "hackernews",
    "highlights": [
      "points: 8",
      "comments: 3"
    ]
  },
  {
    "title": "Show HN: Clai \u2013 CLI native LLM conversation engine",
    "date": "2025-02-09T07:27:29Z",
    "summary": "I&#x27;ve posted it here before, and here we go again!<p>The reason why I&#x27;ve continued working on it, even if there are many alternatives, is that it fills a unique role that I haven&#x27;t seen ",
    "url": "https://github.com/baalimago/clai",
    "source": "hackernews",
    "highlights": [
      "points: 3",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: Free AI Code Completion for Xcode with model choice/codebase context",
    "date": "2024-10-21T18:10:05Z",
    "summary": "Download link: <a href=\"https:&#x2F;&#x2F;www.cgft.io&#x2F;xcode\" rel=\"nofollow\">https:&#x2F;&#x2F;www.cgft.io&#x2F;xcode</a><p>Here are a few reasons to give this a shot, compared to others (e.g. App",
    "url": "https://www.cgft.io/xcode",
    "source": "hackernews",
    "highlights": [
      "points: 2",
      "comments: 0"
    ]
  },
  {
    "title": "From Ollama to OpenLLM: Running LLMs in the Cloud",
    "date": "2024-07-18T14:08:57Z",
    "summary": "",
    "url": "https://www.bentoml.com/blog/from-ollama-to-openllm-running-llms-in-the-cloud",
    "source": "hackernews",
    "highlights": [
      "points: 3",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: Agent \u2013 A Local Computer-Use Operator for macOS",
    "date": "2025-03-30T10:57:07Z",
    "summary": "Hey HN! We&#x27;ve just open-sourced Agent, our framework for running computer-use workflows across multiple apps in isolated macOS&#x2F;Linux sandboxes.<p>After launching Computer a few weeks ago, we",
    "url": "https://github.com/trycua/cua",
    "source": "hackernews",
    "highlights": [
      "points: 6",
      "comments: 0"
    ]
  },
  {
    "title": "Show HN: Cactus \u2013 Ollama for Smartphones",
    "date": "2025-07-10T19:20:59Z",
    "summary": "Hey HN, Henry and Roman here - we&#x27;ve been building a cross-platform framework for deploying LLMs, VLMs, Embedding Models and TTS models locally on smartphones.<p>Ollama enables deploying LLMs mod",
    "url": "https://github.com/cactus-compute/cactus",
    "source": "hackernews",
    "highlights": [
      "points: 231",
      "comments: 82"
    ]
  },
  {
    "title": "Show HN: I integrated Ollama into Excel to run local LLMs",
    "date": "2025-08-11T05:11:54Z",
    "summary": "I built an Excel add-in that connects to Ollama, so you can run local LLMs like Llama3 directly inside Excel. I call it XLlama.<p>You can use it like a regular formula:\n=XLlamaPrompt(&quot;Is Excel a ",
    "url": "https://pythonandvba.com/xllama/",
    "source": "hackernews",
    "highlights": [
      "points: 10",
      "comments: 5"
    ]
  },
  {
    "title": "Show HN: Osaurus \u2013 Ollama-Compatible Runtime for Apple Foundation Models",
    "date": "2025-10-15T14:40:36Z",
    "summary": "Osaurus is an open-source local inference runtime for macOS, written in Swift and optimized for Apple Silicon.<p>It lets you run Apple Foundation Models locally \u2014 fully accelerated by the Neural Engin",
    "url": "https://github.com/dinoki-ai/osaurus",
    "source": "hackernews",
    "highlights": [
      "points: 6",
      "comments: 2"
    ]
  },
  {
    "title": "Brew update memo",
    "date": "2025-11-04T00:22:32Z",
    "summary": "## 2023-11-20 (Mon)\r\n\r\n```\r\n$ brew update\r\nUpdated 5 taps (tailwarden/komiser, minio/stable, cduggn/cduggn, homebrew/core and homebrew/cask).\r\n==> New Formulae\r\naction-validator              ghc@9.6                       python-jinja                  ruler\r\namass                         intercept   ",
    "url": "https://github.com/yteraoka/blog-1q77-com/issues/160",
    "source": "github_issues",
    "highlights": [
      "comments: 43",
      "state: open",
      "repo: blog-1q77-com"
    ]
  },
  {
    "title": "Dependency Dashboard",
    "date": "2025-11-04T03:18:57Z",
    "summary": "This issue lists Renovate updates and detected dependencies. Read the [Dependency Dashboard](https://docs.renovatebot.com/key-concepts/dashboard/) docs to learn more.<br>[View this repository on the Mend.io Web Portal](https://developer.mend.io/github/RooCodeInc/Roo-Code).\n\n> [!WARNING]\nThese depend",
    "url": "https://github.com/RooCodeInc/Roo-Code/issues/3192",
    "source": "github_issues",
    "highlights": [
      "comments: 1",
      "state: open",
      "repo: Roo-Code"
    ]
  },
  {
    "title": "Dependency Dashboard",
    "date": "2025-11-04T11:10:01Z",
    "summary": "This issue lists Renovate updates and detected dependencies. Read the [Dependency Dashboard](https://docs.renovatebot.com/key-concepts/dashboard/) docs to learn more.<br>[View this repository on the Mend.io Web Portal](https://developer.mend.io/github/n8n-io/n8n).\n\n> [!WARNING]\nThese dependencies ar",
    "url": "https://github.com/n8n-io/n8n/issues/18322",
    "source": "github_issues",
    "highlights": [
      "comments: 2",
      "state: open",
      "repo: n8n"
    ]
  },
  {
    "title": "New daily trending repos in Ruby",
    "date": "2025-11-03T22:02:48Z",
    "summary": "Subscribe to this issue and stay notified about new [daily trending repos in Ruby](https://github.com/trending/ruby?since=daily)!",
    "url": "https://github.com/vitalets/github-trending-repos/issues/9",
    "source": "github_issues",
    "highlights": [
      "comments: 29",
      "state: open",
      "repo: github-trending-repos"
    ]
  },
  {
    "title": "Dependency Dashboard",
    "date": "2025-11-02T00:44:49Z",
    "summary": "This issue lists Renovate updates and detected dependencies. Read the [Dependency Dashboard](https://docs.renovatebot.com/key-concepts/dashboard/) docs to learn more.<br>[View this repository on the Mend.io Web Portal](https://developer.mend.io/github/awfixer-platform/awborg).\n\n> [!WARNING]\nThese de",
    "url": "https://github.com/awfixer-platform/awborg/issues/4",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: awborg"
    ]
  },
  {
    "title": "Meta: Request rate limiting",
    "date": "2025-11-01T17:59:42Z",
    "summary": "This meta issue tracks scenarios where chat requests are blocked due to rate limiting.\n\n\ud83d\udc49 To get help with **premium request quota issues**, please comment in https://github.com/microsoft/vscode/issues/252230 .\n\nIn case you experience repeated rate-limiting in GitHub Copilot, please reach out to Git",
    "url": "https://github.com/microsoft/vscode/issues/253124",
    "source": "github_issues",
    "highlights": [
      "comments: 266",
      "state: open",
      "repo: vscode"
    ]
  },
  {
    "title": "Feature: AI Interactive Chat with RAG System for Selected Transcripts",
    "date": "2025-10-30T11:14:06Z",
    "summary": "## Feature Summary\n\nImplement an AI-powered interactive chat system that allows users to select multiple media files from the gallery view and start a conversational AI session with those transcripts as context. The system should use Retrieval Augmented Generation (RAG) with OpenSearch to provide ac",
    "url": "https://github.com/davidamacey/OpenTranscribe/issues/52",
    "source": "github_issues",
    "highlights": [
      "comments: 2",
      "state: open",
      "repo: OpenTranscribe"
    ]
  },
  {
    "title": "Voice assistant",
    "date": "2025-10-21T15:30:39Z",
    "summary": "<details>\n<summary>For temporary use-cases:</summary>\n\n- shower: 1., 2., 4., 5., 6., 7., 9., 11., 13., 14., 15. and 20., 21., 24., 25., 26., 27., 29. and 30..\n- driving: 1., already have buttons concerning 2., 3., 4., 5., 6., 7., 8., 9., 10., 11., 12., 13., 14., 15., 21., 22., 23., 24., 25., 26., 29",
    "url": "https://github.com/Benjamin-Loison/android/issues/28",
    "source": "github_issues",
    "highlights": [
      "comments: 468",
      "state: open",
      "repo: android"
    ]
  },
  {
    "title": "\ud83e\udd14\ud83d\udcad How to use Ollama (gpt-oss) TURBO mode?",
    "date": "2025-10-21T08:43:23Z",
    "summary": "Hi, when using Ollama directly on the Ollama app (windows) there is the turbo mode. \nIs it possible to run turbo mode on ComfyUi somehow?",
    "url": "https://github.com/stavsap/comfyui-ollama/issues/118",
    "source": "github_issues",
    "highlights": [
      "comments: 5",
      "state: open",
      "repo: comfyui-ollama"
    ]
  },
  {
    "title": "Feature Request: LLM Profile Management for OpenHands CLI",
    "date": "2025-10-17T19:41:23Z",
    "summary": "# Feature Request: LLM Profile Management for OpenHands CLI\n\n## What problem or use case are you trying to solve?\n\nCurrently, the OpenHands CLI (`openhands-cli`) requires users to go through the configuration/settings pipeline every time they want to switch between different LLM models or providers.",
    "url": "https://github.com/OpenHands/OpenHands/issues/11412",
    "source": "github_issues",
    "highlights": [
      "comments: 3",
      "state: open",
      "repo: OpenHands"
    ]
  },
  {
    "title": "Flux starts adding horizontal stripes to images around 2K resolution",
    "date": "2025-10-17T00:58:31Z",
    "summary": "It might be an upstream issue.\r\n\r\nI'm using Forge with default settings, except for the resolution. However, I\u2019ve tried most of the samplers and schedulers to fix the problem, but without success. What's particularly frustrating is that the issue randomly disappears once in a while for reasons unkno",
    "url": "https://github.com/lllyasviel/stable-diffusion-webui-forge/issues/1712",
    "source": "github_issues",
    "highlights": [
      "comments: 153",
      "state: open",
      "repo: stable-diffusion-webui-forge"
    ]
  },
  {
    "title": "Daily Content Summary 2025-10-15",
    "date": "2025-10-15T09:03:27Z",
    "summary": "# \ud83d\udcf0 Daily Content Summary - 2025-10-15\n### Executive Summary\n\n**Key Insights**\nA critical disconnect exists between the public's understanding of **AI vulnerabilities** and its real-world application. Unlike traditional software, AI issues stem from incomprehensible training data, making them diffic",
    "url": "https://github.com/jhengy/content-aggregator/issues/267",
    "source": "github_issues",
    "highlights": [
      "comments: 1",
      "state: open",
      "repo: content-aggregator"
    ]
  },
  {
    "title": "Custom inline completion providers",
    "date": "2025-10-11T17:17:53Z",
    "summary": "**Summary**:  Custom inline completion providers for local models or other platforms\n\n--\n\nAfter going through: https://zed.dev/docs/completions\n\nZed currently supports completions via external LLM APIs like GitHub Copilot and Supermaven, but this is restrictive. Many users, for privacy or performanc",
    "url": "https://github.com/zed-industries/zed/issues/18490",
    "source": "github_issues",
    "highlights": [
      "comments: 13",
      "state: open",
      "repo: zed"
    ]
  },
  {
    "title": "Make it easy to swap out components like speech models, etc.",
    "date": "2025-10-08T18:04:45Z",
    "summary": "Architect the app so that you can easily change different components. Primarily because the models keep getting better all the time",
    "url": "https://github.com/anchapin/ai-therapist/issues/11",
    "source": "github_issues",
    "highlights": [
      "comments: 1",
      "state: open",
      "repo: ai-therapist"
    ]
  },
  {
    "title": "Add Flexible Output Format and Model Selection Support for Enhanced Command Results",
    "date": "2025-10-01T20:30:31Z",
    "summary": "### Description\n\n## Description\n\nCurrently, `crush run` commands only return plain text output and use a fixed model configuration, which limits integration capabilities and programmatic usage. This proposal introduces flexible output format options and dynamic model selection to support multiple ou",
    "url": "https://github.com/charmbracelet/crush/issues/1034",
    "source": "github_issues",
    "highlights": [
      "comments: 2",
      "state: open",
      "repo: crush"
    ]
  },
  {
    "title": "Alphanews",
    "date": "2025-09-28T01:22:54Z",
    "summary": "AI\u4e0e\u8bbe\u8ba1\u7684\u878d\u5408\u8fdb\u5165\u6df1\u6c34\u533a\uff0c\u8bbe\u8ba1\u5de5\u5177\u667a\u80fd\u5316\u4e0e\u8bbe\u8ba1\u7406\u5ff5AI\u5316\u5e76\u884c\u3002\n\nWWDC25\u4e0aLiquid Glass\u8bbe\u8ba1\u8bed\u8a00\u7684\u63a8\u51fa\uff0c\u4e0d\u4ec5\u9884\u793a\u7740UI\u8bbe\u8ba1\u98ce\u683c\u7684\u8f6c\u53d8\uff0c\u66f4\u5f15\u53d1\u4e86\u5bf9\u73b0\u6709\u8bbe\u8ba1\u5de5\u5177\u53ca\u5de5\u4f5c\u6d41\u7684\u6df1\u523b\u53cd\u601d\u3002\u4eceAI\u8f85\u52a9\u4ee3\u7801\u7f16\u5199\u5230AI\u9a71\u52a8\u8bbe\u8ba1\u51b3\u7b56\uff0c\u8bbe\u8ba1\u9886\u57df\u6b63\u5728\u7ecf\u5386\u4e00\u573a\u7531\u5185\u800c\u5916\u7684\u667a\u80fd\u5316\u9769\u547d\u3002\u8fd9\u5bf9\u4e8e\u8bbe\u8ba1\u5e08\u800c\u8a00\uff0c\u610f\u5473\u7740\u9700\u8981\u62e5\u62b1AI\uff0c\u5c06\u5176\u4f5c\u4e3a\u8bbe\u8ba1\u6d41\u7a0b\u4e2d\u7684\u5f97\u529b\u52a9\u624b\uff0c\u800c\u975e\u7ade\u4e89\u5bf9\u624b\u3002\n\n\u5e0c\u671b\u80fd\u7ed9\u4f60\u5e26\u6765\u542f\u53d1\u3002\u4e0b\u9762\u662f\u8be6\u7ec6\u5185\u5bb9\uff1a \u65e5\u62a5\u5b98\u7f51\uff1aalphanews.club\uff0c\u4efb\u4f55\u95ee\u9898\u53ef\u54a8\u8be2kiki220238\u3002\n\nWWDC25\uff1a\u8bbe\u8ba1\u65b0\u7eaa\u5143\n\nLiquid Glass\u8bbe\u8ba1\u8bed\u8a00: Apple\u5728WWDC25\u4e0a\u63a8\u51fa\u5168\u65b0\u7684Liquid Glas",
    "url": "https://github.com/hyz0906/paper/issues/2",
    "source": "github_issues",
    "highlights": [
      "comments: 55",
      "state: open",
      "repo: paper"
    ]
  },
  {
    "title": "[2025-09-26] ChatControl: EU wants to scan all private messages, even in encrypted apps \u2014 ChatGPT Pulse",
    "date": "2025-09-27T01:47:10Z",
    "summary": "# V2EX\n\n\n  <details>\n    <summary>\n      <strong>\u73b0\u5728\u76f8\u4eb2\u7ed3\u5a5a\u7684\u771f\u7684\u80fd\u8fc7\u7684\u5e78\u798f\u5417\uff1f</strong>\n    </summary>\n    <p>\u56e0\u4e3a\u79cd\u79cd\u539f\u56e0\u8ddf\u76f8\u604b 7 \u5e74\u7684\u5973\u670b\u53cb\u5206\u624b\u4e86\uff0c\u7b97\u6211\u8f9c\u8d1f\u4e86\u5979\uff0c\u5206\u624b\u7ed9\u4e86 33W \u548c\u4e00\u4e2a 32g \u7684\u624b\u956f, \u73b0\u5728\u5e74\u9f84 28 \uff0c\u4ee5\u540e\u53ef\u80fd\u53ea\u80fd\u76f8\u4eb2\u4e86\u5427\uff0c\u8fd8\u80fd\u627e\u4e00\u4e2a\u80fd\u770b\u7684\u987a\u773c\u7684\u51d1\u5408\u8fc7\u5417\uff1f\u4e0d\u77e5\u90fd\u8fd8\u80fd\u5426\u627e\u5230\u5408\u9002\u7684\u4eba</p>\n<pre><code>\u5404\u4f4d\u8001\u54e5\u90fd\u662f\u600e\u4e48\u8d70\u51fa\u8fd9\u79cd\u65ad\u5d16\u5f0f\u5206\u624b\u7684\u5440\uff1f\u73b0\u5728\u89c9\u5f97\u4ec0\u4e48\u90fd\u6ca1\u6709\u610f\u4e49\n\u5982\u679c\u76f8\u4eb2\u627e\u5230\u5408\u9002\u7684\uff0c\u6b63\u5e38\u4eba\u7684\u6982\u7387\u5927\u5417\uff1f\u5a5a\u540e\u5e78\u798f\u5417\n</code></pre>\n\n  </details>\n    ",
    "url": "https://github.com/jiacai2050/mofish/issues/1166",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: mofish"
    ]
  },
  {
    "title": "Update FAQ in light of new Cloud models feature",
    "date": "2025-09-24T23:19:30Z",
    "summary": "Currently [Ollama FAQ says](https://github.com/ollama/ollama/blob/main/docs/faq.md#does-ollama-send-my-prompts-and-responses-back-to-ollamacom):\n\n> ## Does Ollama send my prompts and responses back to ollama.com?\n> \n> If you're running a model locally, your prompts and responses will always stay on ",
    "url": "https://github.com/ollama/ollama/issues/12404",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: ollama"
    ]
  },
  {
    "title": "PR-Agent fails to process large PRs with multiple model configurations",
    "date": "2025-09-24T16:37:14Z",
    "summary": "### Git provider\n\nGithub Cloud\n\n### System Info\n\n- **Platform**: macOS ARM64 running linux/amd64 Docker image\n- **PR Size**: 97,419 tokens\n- **Repository**: Private repository\n\n\n### Bug details\n\nPR-Agent fails with \"Failed to generate prediction\" errors across all tested model configurations, even w",
    "url": "https://github.com/qodo-ai/pr-agent/issues/2042",
    "source": "github_issues",
    "highlights": [
      "comments: 2",
      "state: open",
      "repo: pr-agent"
    ]
  },
  {
    "title": "Remove hardcoded model lists for development testing",
    "date": "2025-09-23T18:47:47Z",
    "summary": "## Background\r\n\r\nDuring development and testing, model detection performance was causing 20-30 second delays in UI operations. To enable faster iteration, hardcoded model lists were implemented as a temporary workaround.\r\n\r\n## Current State\r\n\r\nThe following files contain hardcoded model lists with `",
    "url": "https://github.com/kellylford/Image-Description-Toolkit/issues/23",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: Image-Description-Toolkit"
    ]
  },
  {
    "title": "Version inconsistency during startup: built venv switches to local git version during server launch",
    "date": "2025-09-17T18:36:12Z",
    "summary": "== scroll down to see original description ==\n\nWhen running `./built/bin/llama stack run`, the process initially uses the code from the \"built\" venv, which contains the released llamastack library(not the version from git). This version lacks some of the newer newer code \n\nHowever, the process then ",
    "url": "https://github.com/llamastack/llama-stack/issues/2638",
    "source": "github_issues",
    "highlights": [
      "comments: 9",
      "state: open",
      "repo: llama-stack"
    ]
  },
  {
    "title": "Profile syncing between registered devices",
    "date": "2025-09-15T17:20:20Z",
    "summary": "In Ollama Windows application, do we have the ability to:\n1- upload used prompts to the cloud profile, to be synced to between devices, or visible online (read-only for sure).\n2- be able to share as read-only with colleagues, teams, or public.\n3- add grouping/categorization to the prompt history pag",
    "url": "https://github.com/ollama/ollama/issues/12292",
    "source": "github_issues",
    "highlights": [
      "comments: 4",
      "state: open",
      "repo: ollama"
    ]
  },
  {
    "title": "[TEST] OpenCode Command Test",
    "date": "2025-09-11T20:41:32Z",
    "summary": "## Test OpenCode Commands\n\nThis issue is for testing OpenCode AI commands. Let's test the integration!\n\n### Basic Commands to Test\n- `/oc explain this issue`\n- `/opencode what does this repository do?`\n\n### Code Analysis\n- `/oc analyze the install.sh script`\n- `/opencode review the Makefile`\n\n### Do",
    "url": "https://github.com/smian0/dotfiles/issues/2",
    "source": "github_issues",
    "highlights": [
      "comments: 33",
      "state: open",
      "repo: dotfiles"
    ]
  },
  {
    "title": "[New feature] Local LLM Support for DBeaver Community",
    "date": "2025-09-11T08:21:31Z",
    "summary": "**Is your feature request related to a problem? Please describe.**\n\nWhile DBeaver Enterprise Edition already includes AI capabilities, the community version lacks integration with local LLMs like Ollama. This limits the open-source community's ability to leverage AI features for database operations,",
    "url": "https://github.com/dbeaver/dbeaver/issues/36951",
    "source": "github_issues",
    "highlights": [
      "comments: 9",
      "state: open",
      "repo: dbeaver"
    ]
  },
  {
    "title": "Test LiteLLM Integration with Multiple Providers",
    "date": "2025-09-10T20:23:28Z",
    "summary": "## Summary\n\nWe need to thoroughly test our LiteLLM integration with various providers to ensure compatibility and proper error handling across different environments, including local development setups with insecure TLS connections.\n\n## Background\n\nOur codebase uses LiteLLM (version 1.73.0-1.75.0) a",
    "url": "https://github.com/Red-Hat-AI-Innovation-Team/sdg_hub/issues/337",
    "source": "github_issues",
    "highlights": [
      "comments: 5",
      "state: open",
      "repo: sdg_hub"
    ]
  },
  {
    "title": "Add a intelligent smart home chat bot to the UI",
    "date": "2025-09-03T10:17:37Z",
    "summary": "I am thinking of having a smart home chatbot for openHAB 5, a bit like HABot but more intelligent, integrated into Main UI and not only limited to smart home related stuff.\r\n\r\nThis would require the following bits:\r\n\r\n- [x] A powerful, LLM-based human language interpreter available: Something like h",
    "url": "https://github.com/openhab/openhab-webui/issues/2995",
    "source": "github_issues",
    "highlights": [
      "comments: 15",
      "state: open",
      "repo: openhab-webui"
    ]
  },
  {
    "title": "Ollama Turbo (Cloud) Compatibility",
    "date": "2025-09-02T00:25:15Z",
    "summary": "# Ollama Turbo Compatibility Fix Plan\n\n## Issue\nUsers cannot use Ollama Turbo (cloud service) with BrowserOS because:\n- `ollama` type forces localhost and lacks cloud API key support\n- `openai_compatible` and `custom` types force `/v1` path and use wrong client\n- No existing provider handles Ollama ",
    "url": "https://github.com/browseros-ai/BrowserOS-agent/issues/80",
    "source": "github_issues",
    "highlights": [
      "comments: 1",
      "state: open",
      "repo: BrowserOS-agent"
    ]
  },
  {
    "title": "Feature request: add optional AI assistant that turns natural-language prompts into diagrams",
    "date": "2025-08-28T17:15:22Z",
    "summary": "<html>\n<body>\n<!--StartFragment--><div class=\"paragraph\" style=\"font-family: -apple-system, BlinkMacSystemFont, &quot;Segoe UI&quot;, system-ui, -apple-system, &quot;Segoe UI&quot;, Roboto, Ubuntu, Cantarell, &quot;Noto Sans&quot;, sans-serif, Arial, &quot;PingFang SC&quot;, &quot;Source Han Sans SC",
    "url": "https://github.com/excalidraw/excalidraw/issues/9900",
    "source": "github_issues",
    "highlights": [
      "comments: 1",
      "state: open",
      "repo: excalidraw"
    ]
  },
  {
    "title": "[\u6bcf\u65e5\u4fe1\u606f\u6d41] 2025-08-28",
    "date": "2025-08-28T03:04:13Z",
    "summary": "# \u6bcf\u65e5\u5b89\u5168\u8d44\u8baf\uff082025-08-28\uff09\n\n- \u5148\u77e5\u5b89\u5168\u6280\u672f\u793e\u533a\n  - [ ] [\u5e7b\u5f71|\u4e00\u6b3e\u6f0f\u6d1e\u6316\u6398\u7684\u6d4f\u89c8\u5668\u6269\u5c55\u8f85\u52a9\u5de5\u5177|\u6536\u96c6\u4e2d\u7684\u9690\u85cf\u63a5\u53e3\u548c\u654f\u611f\u4fe1\u606f](https://xz.aliyun.com/news/18714)\n  - [ ] [\u67d0\u5728\u7ebf\u62cd\u5356\u7cfb\u7edf\u4ee3\u7801\u5ba1\u8ba1](https://xz.aliyun.com/news/18713)\n  - [ ] [\u4e07\u6237OA\u4ee3\u7801\u5ba1\u8ba1\u4e0e0day\u6316\u6398](https://xz.aliyun.com/news/18712)\n  - [ ] [CVE-2025-6715 WordPress Latepoint \u6587\u4ef6\u5305\u542b\u6f0f\u6d1e\u5206\u6790](https://xz.aliyun.co",
    "url": "https://github.com/Tyaoo/picker/issues/1113",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: picker"
    ]
  },
  {
    "title": "[\u6bcf\u65e5\u4fe1\u606f\u6d41] 2025-08-28",
    "date": "2025-08-28T03:01:31Z",
    "summary": "# \u6bcf\u65e5\u5b89\u5168\u8d44\u8baf\uff082025-08-28\uff09\n\n- SecWiki News\n  - [ ] [SecWiki News 2025-08-27 Review](http://www.sec-wiki.com/?2025-08-27)\n- paper - Last paper\n  - [ ] [MCPTox\uff1a\u9488\u5bf9\u771f\u5b9e\u4e16\u754c MCP \u670d\u52a1\u5668\u5de5\u5177\u6295\u6bd2\u653b\u51fb\u7684\u57fa\u51c6\u6d4b\u8bd5](https://paper.seebug.org/3377/)\n- \u5b89\u5168\u5ba2-\u6709\u601d\u60f3\u7684\u5b89\u5168\u65b0\u5a92\u4f53\n  - [ ] [IETF\u91cd\u78c5\u63a8\u8fdbAI\u5185\u5bb9\u6807\u6ce8\u6807\u51c6 \u5168\u7403\u9996\u4e2aAI\u751f\u6210\u5185\u5bb9\u8bc6\u522b\u89c4\u8303\u5373\u5c06\u843d\u5730](https://www.anquanke.com/po",
    "url": "https://github.com/BruceFeIix/picker/issues/1918",
    "source": "github_issues",
    "highlights": [
      "comments: 0",
      "state: open",
      "repo: picker"
    ]
  },
  {
    "title": "[PR] chore(deps): update n8nio/n8n docker tag to v1.119.0",
    "date": "2025-11-04T01:13:04Z",
    "summary": "This PR contains the following updates:\n\n| Package | Update | Change |\n|---|---|---|\n| [n8nio/n8n](https://n8n.io) ([source](https://redirect.github.com/n8n-io/n8n)) | minor | `1.109.1` -> `1.119.0` |\n\n---\n\n> [!WARNING]\n> Some dependencies could not be looked up. Check the Dependency Dashboard for m",
    "url": "https://github.com/vyrtualsynthese/homelab/pull/833",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: homelab"
    ]
  },
  {
    "title": "[PR] Optimize panel width control and lyrics scrolling; Add MPRIS player selection",
    "date": "2025-11-04T11:02:30Z",
    "summary": "## Features\n\n### Panel Optimizations\n- **Configurable panel width**: Fixed-width panel (100-800px) prevents pushing other panel components\n- **Improved lyrics scrolling**: Three-stage algorithm keeps playback progress centered\n- **Auto-scrolling for long lyrics**: Smooth scrolling ensures full sente",
    "url": "https://github.com/tuberry/desktop-lyric/pull/29",
    "source": "github_prs",
    "highlights": [
      "comments: 16",
      "pull request",
      "repo: desktop-lyric"
    ]
  },
  {
    "title": "[PR] chore(deps): update ghcr.io/damianflynn/custom-n8n docker tag to v1.119.0",
    "date": "2025-11-04T10:12:37Z",
    "summary": "This PR contains the following updates:\n\n| Package | Update | Change |\n|---|---|---|\n| [ghcr.io/damianflynn/custom-n8n](https://n8n.io) ([source](https://redirect.github.com/n8n-io/n8n)) | minor | `1.113.2` -> `1.119.0` |\n\n---\n\n### Release Notes\n\n<details>\n<summary>n8n-io/n8n (ghcr.io/damianflynn/cu",
    "url": "https://github.com/DamianFlynn/self-hosting/pull/43",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: self-hosting"
    ]
  },
  {
    "title": "[PR] python3Packages.curl-cffi: pin python-websockets at 12.0 and disable problematic tests",
    "date": "2025-11-04T02:27:57Z",
    "summary": "Supersedes #457592\r\n\r\nHydra: https://hydra.nixos.org/build/311365966\r\n\r\n1. The `echo` method called from `test_websocket` fails with a race condition in closing a websocket. This happens during the teardown after pytest is done. Disabled.\r\n2. `test_receive_large_messages_run_forever` can hang testin",
    "url": "https://github.com/NixOS/nixpkgs/pull/458241",
    "source": "github_prs",
    "highlights": [
      "comments: 3",
      "pull request",
      "repo: nixpkgs"
    ]
  },
  {
    "title": "[PR] chore(deps): update n8nio/n8n docker tag to v1.119.0",
    "date": "2025-11-04T06:35:01Z",
    "summary": "This PR contains the following updates:\n\n| Package | Type | Update | Change |\n|---|---|---|---|\n| [n8nio/n8n](https://n8n.io) ([source](https://redirect.github.com/n8n-io/n8n)) | Kustomization | minor | `1.95.2` -> `1.119.0` |\n\n---\n\n> [!WARNING]\n> Some dependencies could not be looked up. Check the ",
    "url": "https://github.com/meysam81/infra/pull/298",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: infra"
    ]
  },
  {
    "title": "[PR] feat(container): update image docker.io/n8nio/n8n to v1.119.0",
    "date": "2025-11-04T04:59:01Z",
    "summary": "This PR contains the following updates:\n\n| Package | Update | Change |\n|---|---|---|\n| [docker.io/n8nio/n8n](https://n8n.io) ([source](https://redirect.github.com/n8n-io/n8n)) | minor | `1.26.0` -> `1.119.0` |\n\n---\n\n> [!WARNING]\n> Some dependencies could not be looked up. Check the Dependency Dashbo",
    "url": "https://github.com/imtoanle/mcluster/pull/124",
    "source": "github_prs",
    "highlights": [
      "comments: 2",
      "pull request",
      "repo: mcluster"
    ]
  },
  {
    "title": "[PR] feat(container): update image ghcr.io/n8n-io/n8n ( 1.113.3 \u2192 1.119.0 )",
    "date": "2025-11-04T00:38:38Z",
    "summary": "This PR contains the following updates:\n\n| Package | Update | Change |\n|---|---|---|\n| [ghcr.io/n8n-io/n8n](https://n8n.io) ([source](https://redirect.github.com/n8n-io/n8n)) | minor | `1.113.3` -> `1.119.0` |\n\n---\n\n### Release Notes\n\n<details>\n<summary>n8n-io/n8n (ghcr.io/n8n-io/n8n)</summary>\n\n###",
    "url": "https://github.com/roblandry/home-ops/pull/510",
    "source": "github_prs",
    "highlights": [
      "comments: 2",
      "pull request",
      "repo: home-ops"
    ]
  },
  {
    "title": "[PR] python3Packages.marisa-trie: 1.2.1 -> 1.3.1",
    "date": "2025-11-03T22:47:15Z",
    "summary": "Diff: https://github.com/pytries/marisa-trie/compare/1.2.1...1.3.1\r\n\r\nChangelog: https://github.com/pytries/marisa-trie/blob/1.3.1/CHANGES.rst\r\n\r\n\r\n<!--\r\n^ Please summarise the changes you have done and explain why they are necessary here ^\r\n\r\nFor package updates please link to a changelog or descri",
    "url": "https://github.com/NixOS/nixpkgs/pull/458246",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: nixpkgs"
    ]
  },
  {
    "title": "[PR] chore(deps): update n8nio/n8n docker tag to v1.119.0",
    "date": "2025-11-04T00:57:16Z",
    "summary": "This PR contains the following updates:\n\n| Package | Update | Change |\n|---|---|---|\n| [n8nio/n8n](https://n8n.io) ([source](https://redirect.github.com/n8n-io/n8n)) | minor | `1.100.1` -> `1.119.0` |\n\n---\n\n> [!WARNING]\n> Some dependencies could not be looked up. Check the Dependency Dashboard for m",
    "url": "https://github.com/anyfavors/n8n-helm/pull/227",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: n8n-helm"
    ]
  },
  {
    "title": "[PR] Add MLOps automation, content generation, enhanced multimodal AI, IIoT Ollama integration, AI recommendations, gamification, and next-gen autonomous AI",
    "date": "2025-11-03T22:29:21Z",
    "summary": "Implements comprehensive AI/ML platform enhancements: automated MLOps pipelines, AI-powered content generation, multimodal processing with vision/audio/generation capabilities, Industrial IoT integration with Ollama, AI recommendation system, real-time insights, gamification, and next-generation aut",
    "url": "https://github.com/robertpezdirc-eng/copy-of-copy-of-omniscient-ai-platform/pull/31",
    "source": "github_prs",
    "highlights": [
      "comments: 6",
      "pull request",
      "repo: copy-of-copy-of-omniscient-ai-platform"
    ]
  },
  {
    "title": "[PR] Bug-Squash/'Works-on-my-machine' - 4 PRDs in one PR :( \ud83d\udc4e ",
    "date": "2025-11-04T10:01:55Z",
    "summary": "Turn all(most) tests green, excluding jobs, sandbox and watchlists as they're WIP. \r\n\r\nEverything else should be passing.\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n## Summary by CodeRabbit\n\n* **New Features**\n  * Unified streaming (SSE/WebSocket) across chat, embedd",
    "url": "https://github.com/rmusser01/tldw_server/pull/679",
    "source": "github_prs",
    "highlights": [
      "comments: 2",
      "pull request",
      "repo: tldw_server"
    ]
  },
  {
    "title": "[PR] chore(deps): update docker.n8n.io/n8nio/n8n docker tag to v1.119.0",
    "date": "2025-11-04T04:42:52Z",
    "summary": "This PR contains the following updates:\n\n| Package | Update | Change |\n|---|---|---|\n| [docker.n8n.io/n8nio/n8n](https://n8n.io) ([source](https://redirect.github.com/n8n-io/n8n)) | minor | `1.109.1` -> `1.119.0` |\n\n---\n\n### Release Notes\n\n<details>\n<summary>n8n-io/n8n (docker.n8n.io/n8nio/n8n)</sum",
    "url": "https://github.com/Kentaro1043/manifest/pull/36",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: manifest"
    ]
  },
  {
    "title": "[PR] marisa: 0.3.0 -> 0.3.1",
    "date": "2025-11-03T22:04:01Z",
    "summary": "Diff: https://github.com/s-yata/marisa-trie/compare/v0.3.0...v0.3.1\r\n\r\nChangelog: https://github.com/s-yata/marisa-trie/releases/tag/v0.3.1\r\n\r\ncloses https://github.com/NixOS/nixpkgs/pull/426943\r\n<!--\r\n^ Please summarise the changes you have done and explain why they are necessary here ^\r\n\r\nFor pack",
    "url": "https://github.com/NixOS/nixpkgs/pull/458247",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: nixpkgs"
    ]
  },
  {
    "title": "[PR] fix(deps): update dependency org.springframework.ai:spring-ai-bom to v1.0.3",
    "date": "2025-11-04T10:53:58Z",
    "summary": "This PR contains the following updates:\n\n| Package | Change | Age | Confidence |\n|---|---|---|---|\n| [org.springframework.ai:spring-ai-bom](https://redirect.github.com/spring-projects/spring-ai) | `1.0.0` -> `1.0.3` | [![age](https://developer.mend.io/api/mc/badges/age/maven/org.springframework.ai:s",
    "url": "https://github.com/asm0dey/git-mcp-spring/pull/10",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: git-mcp-spring"
    ]
  },
  {
    "title": "[PR] chore(deps): update docker.n8n.io/n8nio/n8n docker tag to v1.119.0",
    "date": "2025-11-04T05:35:34Z",
    "summary": "This PR contains the following updates:\n\n| Package | Update | Change |\n|---|---|---|\n| [docker.n8n.io/n8nio/n8n](https://n8n.io) ([source](https://redirect.github.com/n8n-io/n8n)) | minor | `1.115.3` -> `1.119.0` |\n\n---\n\n### Release Notes\n\n<details>\n<summary>n8n-io/n8n (docker.n8n.io/n8nio/n8n)</sum",
    "url": "https://github.com/kahnwong/self-hosted/pull/246",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: self-hosted"
    ]
  },
  {
    "title": "[PR] Update n8nio/n8n Docker tag to v1.119.0",
    "date": "2025-11-04T00:41:03Z",
    "summary": "This PR contains the following updates:\n\n| Package | Type | Update | Change |\n|---|---|---|---|\n| [n8nio/n8n](https://n8n.io) ([source](https://redirect.github.com/n8n-io/n8n)) | Kustomization | minor | `1.67.1` -> `1.119.0` |\n\n---\n\n> [!WARNING]\n> Some dependencies could not be looked up. Check the ",
    "url": "https://github.com/jamie-oconnell/homelab/pull/254",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: homelab"
    ]
  },
  {
    "title": "[PR] Add comprehensive platform review, extended learning program, and upgrade assessment (486-519 hours)",
    "date": "2025-11-03T21:00:25Z",
    "summary": "Addresses issue #25: Create live project review comparing repository implementation against platform specification, including structured learning curriculum, implementation roadmap, and platform upgrade assessment.\n\n## Changes\n\n### New Documentation\n- **`PREGLED_PROJEKTA_ZIVO.md`** (2,322 lines, 64 ",
    "url": "https://github.com/robertpezdirc-eng/copy-of-copy-of-omniscient-ai-platform/pull/29",
    "source": "github_prs",
    "highlights": [
      "comments: 10",
      "pull request",
      "repo: copy-of-copy-of-omniscient-ai-platform"
    ]
  },
  {
    "title": "[PR] ci: add PR and nightly workflows + diff-cover gating; PR template",
    "date": "2025-11-04T09:55:57Z",
    "summary": "# Pull Request\r\n\r\n## \ud83d\udccb Checklist\r\n\r\n### Code Quality\r\n\r\n- [ ] **ESLint Clean**: lint script passes with 0 warnings\r\n- [ ] **TypeScript Clean**: type-check script passes with 0 errors\r\n- [ ] **Tests Pass**: All tests pass and coverage is maintained or improved\r\n- [ ] **Security/Secrets**: No secrets/",
    "url": "https://github.com/Katsiarynakavaleuskaya/PulsePlate/pull/237",
    "source": "github_prs",
    "highlights": [
      "comments: 4",
      "pull request",
      "repo: PulsePlate"
    ]
  },
  {
    "title": "[PR] [pull] master from ItzCrazyKns:master",
    "date": "2025-11-04T08:44:10Z",
    "summary": "See [Commits](/itsbrex/Perplexica/pull/11/commits) and [Changes](/itsbrex/Perplexica/pull/11/files) for more details.\n\n-----\nCreated by [<img src=\"https://prod.download/pull-18h-svg\" valign=\"bottom\"/> **pull[bot]**](https://github.com/wei/pull) (v2.0.0-alpha.4)\n\n_Can you help keep this open source s",
    "url": "https://github.com/itsbrex/Perplexica/pull/11",
    "source": "github_prs",
    "highlights": [
      "comments: 2",
      "pull request",
      "repo: Perplexica"
    ]
  },
  {
    "title": "[PR] chore(deps): update docker.io/n8nio/n8n : 1.108.1 -> 1.119.0",
    "date": "2025-11-04T05:58:36Z",
    "summary": "This PR contains the following updates:\n\n| Package | Type | Update | Change |\n|---|---|---|---|\n| [docker.io/n8nio/n8n](https://n8n.io) ([source](https://redirect.github.com/n8n-io/n8n)) | final | minor | `1.108.1` -> `1.119.0` |\n\n---\n\n### Release Notes\n\n<details>\n<summary>n8n-io/n8n (docker.io/n8ni",
    "url": "https://github.com/nilp0inter/nix-oci-hashes/pull/319",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: nix-oci-hashes"
    ]
  },
  {
    "title": "[PR] Working AI desktop console and roadmap",
    "date": "2025-11-04T07:49:53Z",
    "summary": "# JTAG System: Production-Ready AI Collaboration Platform\n\n**Migrating from `src/debug/jtag/` \u2192 repository root**\n\n> This PR introduces the JTAG system\u2014a revolutionary local-first platform where humans and multiple AIs collaborate with full transparency, intelligent coordination, and true equality.\n",
    "url": "https://github.com/CambrianTech/continuum/pull/152",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: continuum"
    ]
  },
  {
    "title": "[PR] Bump Microsoft.SemanticKernel from 1.30.0 to 1.67.0",
    "date": "2025-11-04T02:06:49Z",
    "summary": "Updated [Microsoft.SemanticKernel](https://github.com/microsoft/semantic-kernel) from 1.30.0 to 1.67.0.\n\n<details>\n<summary>Release notes</summary>\n\n_Sourced from [Microsoft.SemanticKernel's releases](https://github.com/microsoft/semantic-kernel/releases)._\n\n## 1.67.0\n\n\n\n## Changes:\n\n* 2464458c47b4d",
    "url": "https://github.com/feuyeux/aloha-a2a/pull/58",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: aloha-a2a"
    ]
  },
  {
    "title": "[PR] Update dependency org.springframework.ai:spring-ai-bom to v1.0.3",
    "date": "2025-11-04T01:47:54Z",
    "summary": "This PR contains the following updates:\n\n| Package | Change | Age | Confidence |\n|---|---|---|---|\n| [org.springframework.ai:spring-ai-bom](https://redirect.github.com/spring-projects/spring-ai) | `1.0.0` -> `1.0.3` | [![age](https://developer.mend.io/api/mc/badges/age/maven/org.springframework.ai:s",
    "url": "https://github.com/krushnatkhawale/springai-openai-hello-world/pull/29",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: springai-openai-hello-world"
    ]
  },
  {
    "title": "[PR] Update all dependencies",
    "date": "2025-11-04T05:36:29Z",
    "summary": "This PR contains the following updates:\n\n| Package | Change | Age | Confidence |\n|---|---|---|---|\n| [org.testcontainers:testcontainers-bom](https://java.testcontainers.org) ([source](https://redirect.github.com/testcontainers/testcontainers-java)) | `1.21.3` -> `2.0.1` | [![age](https://developer.m",
    "url": "https://github.com/catools2/CATools/pull/69",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: CATools"
    ]
  },
  {
    "title": "[PR] Fix the issue where the model deployed by Ollama cannot stream text p\u2026",
    "date": "2025-11-04T08:34:51Z",
    "summary": "\u2026roperly in the agent\r\n\r\nAdded module-level constants for maintainability and improved tool call handling in the Ollama large language model class.\r\n\r\n## Related Issues or Context\r\nissue #1980\r\n<!--\r\n\u26a0\ufe0f NOTE: This repository is for Dify Official Plugins only. \r\nFor community contributions, please su",
    "url": "https://github.com/langgenius/dify-official-plugins/pull/1973",
    "source": "github_prs",
    "highlights": [
      "comments: 7",
      "pull request",
      "repo: dify-official-plugins"
    ]
  },
  {
    "title": "[PR] feat(container): update ghcr.io/n8n-io/n8n ( 1.108.1 \u2794 1.119.0 )",
    "date": "2025-11-04T04:52:03Z",
    "summary": "This PR contains the following updates:\n\n| Package | Update | Change |\n|---|---|---|\n| [ghcr.io/n8n-io/n8n](https://n8n.io) ([source](https://redirect.github.com/n8n-io/n8n)) | minor | `1.108.1` -> `1.119.0` |\n\n---\n\n### Release Notes\n\n<details>\n<summary>n8n-io/n8n (ghcr.io/n8n-io/n8n)</summary>\n\n###",
    "url": "https://github.com/swibrow/home-ops/pull/449",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: home-ops"
    ]
  },
  {
    "title": "[PR] Update n8nio/n8n Docker tag to v1.119.0",
    "date": "2025-11-04T10:08:52Z",
    "summary": "This PR contains the following updates:\n\n| Package | Update | Change |\n|---|---|---|\n| [n8nio/n8n](https://n8n.io) ([source](https://redirect.github.com/n8n-io/n8n)) | minor | `1.106.3` -> `1.119.0` |\n\n---\n\n### Release Notes\n\n<details>\n<summary>n8n-io/n8n (n8nio/n8n)</summary>\n\n### [`v1.119.0`](http",
    "url": "https://github.com/weblio-ab/kubernetes/pull/7",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: kubernetes"
    ]
  },
  {
    "title": "[PR] fix(deps): update all non-major dependencies",
    "date": "2025-11-04T05:56:55Z",
    "summary": "This PR contains the following updates:\n\n| Package | Type | Update | Change | Age | Confidence |\n|---|---|---|---|---|---|\n| [amannn/action-semantic-pull-request](https://redirect.github.com/amannn/action-semantic-pull-request) | action | minor | `v6.0.1` -> `v6.1.1` | [![age](https://developer.mend",
    "url": "https://github.com/k8sgpt-ai/k8sgpt/pull/1346",
    "source": "github_prs",
    "highlights": [
      "comments: 2",
      "pull request",
      "repo: k8sgpt"
    ]
  },
  {
    "title": "[PR] chore(deps): update ghcr.io/n8n-io/n8n docker tag to v1.119.0",
    "date": "2025-11-04T10:53:16Z",
    "summary": "This PR contains the following updates:\n\n| Package | Update | Change |\n|---|---|---|\n| [ghcr.io/n8n-io/n8n](https://n8n.io) ([source](https://redirect.github.com/n8n-io/n8n)) | minor | `1.98.1` -> `1.119.0` |\n\n---\n\n### Release Notes\n\n<details>\n<summary>n8n-io/n8n (ghcr.io/n8n-io/n8n)</summary>\n\n### ",
    "url": "https://github.com/a5r0n/n8n-chart/pull/67",
    "source": "github_prs",
    "highlights": [
      "comments: 47",
      "pull request",
      "repo: n8n-chart"
    ]
  },
  {
    "title": "[PR] fix(deps): update all non-major dependencies (release/8.8)",
    "date": "2025-11-04T07:22:15Z",
    "summary": "This PR contains the following updates:\n\n| Package | Type | Update | Change | Age | Confidence |\n|---|---|---|---|---|---|\n| infra-preview-environments-ingress |  | patch | `1.7.4` -> `1.7.6` | [![age](https://developer.mend.io/api/mc/badges/age/docker/registry.camunda.cloud%2flibrary%2finfra-previe",
    "url": "https://github.com/camunda/connectors/pull/5659",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: connectors"
    ]
  },
  {
    "title": "[PR] Support using Ollama as an edit prediction provider for FIM models",
    "date": "2025-11-04T07:00:45Z",
    "summary": "Closes #15968.\r\n\r\nTested with `Qwen2.5-Coder-3B`, with @boozook's and ghost's (on Zed Discord) help, and `Codellama:7B-code`. Tried `Codestral-22B`, but it ran way too slow on my machine (an Macbook Air M2) to get any meaningful testing done.\r\n\r\nUpdate: later tested with Ollama Cloud, and it worked ",
    "url": "https://github.com/zed-industries/zed/pull/33616",
    "source": "github_prs",
    "highlights": [
      "comments: 89",
      "pull request",
      "repo: zed"
    ]
  },
  {
    "title": "[PR] chore(deps): update dependency chromadb to v1.3.2",
    "date": "2025-11-04T06:55:42Z",
    "summary": "This PR contains the following updates:\n\n| Package | Change | Age | Confidence |\n|---|---|---|---|\n| [chromadb](https://redirect.github.com/chroma-core/chroma) | `==1.0.21` -> `==1.3.2` | [![age](https://developer.mend.io/api/mc/badges/age/pypi/chromadb/1.3.2?slim=true)](https://docs.renovatebot.com",
    "url": "https://github.com/sudoleg/YouTubeGPT/pull/427",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: YouTubeGPT"
    ]
  },
  {
    "title": "[PR] Update dependency chromadb to v1",
    "date": "2025-11-04T06:54:45Z",
    "summary": "This PR contains the following updates:\n\n| Package | Change | Age | Confidence |\n|---|---|---|---|\n| [chromadb](https://redirect.github.com/chroma-core/chroma) | `0.6.3` -> `1.3.2` | [![age](https://developer.mend.io/api/mc/badges/age/pypi/chromadb/1.3.2?slim=true)](https://docs.renovatebot.com/merg",
    "url": "https://github.com/masato/langchain_study/pull/1123",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: langchain_study"
    ]
  },
  {
    "title": "[PR] from-builder",
    "date": "2025-11-04T08:11:05Z",
    "summary": "\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n## Summary by CodeRabbit\n\n* **New Features**\n  * New CI workflows and composite actions for evaluations, benchmarks, regressions, environment setup, KIND clusters, Docker builds, and PyPI publishing; automated docs build/de",
    "url": "https://github.com/julianobarbosa/holmesgpt/pull/7",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: holmesgpt"
    ]
  },
  {
    "title": "[PR] Extensible code provider support - Gitbucket implementation",
    "date": "2025-11-04T08:48:20Z",
    "summary": "\n\n<!-- This is an auto-generated comment: release notes by coderabbit.ai -->\n## Summary by CodeRabbit\n\n* **New Features**\n  * Multi-provider code hosting support (GitHub, GitBucket) with tools to fetch content, create branches/PRs, add PR comments, and update files; local filesystem repo support add",
    "url": "https://github.com/potpie-ai/potpie/pull/471",
    "source": "github_prs",
    "highlights": [
      "comments: 2",
      "pull request",
      "repo: potpie"
    ]
  },
  {
    "title": "[PR] Update Mend: high confidence minor and patch dependency updates",
    "date": "2025-11-04T11:06:48Z",
    "summary": "This PR contains the following updates:\n\n| Package | Change | Age | Adoption | Passing | Confidence |\n|---|---|---|---|---|---|\n| [org.testcontainers:localstack](https://java.testcontainers.org) ([source](https://redirect.github.com/testcontainers/testcontainers-java)) | `1.19.7` -> `1.21.3` | [![ag",
    "url": "https://github.com/jgeraigery/carbonj/pull/5",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: carbonj"
    ]
  },
  {
    "title": "[PR] Update all non-major dependencies",
    "date": "2025-11-04T11:01:50Z",
    "summary": "This PR contains the following updates:\n\n| Package | Update | Change |\n|---|---|---|\n| [cert-manager](https://cert-manager.io) ([source](https://redirect.github.com/cert-manager/cert-manager)) | minor | `v1.17.2` -> `v1.19.1` |\n| [external-dns](https://redirect.github.com/kubernetes-sigs/external-dn",
    "url": "https://github.com/dbirks/home-k8s/pull/32",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: home-k8s"
    ]
  },
  {
    "title": "[PR] Update llm.py",
    "date": "2025-11-04T10:56:27Z",
    "summary": "## Related Issues or Context\r\n<!--\r\n\u26a0\ufe0f NOTE: This repository is for Dify Official Plugins only. \r\nFor community contributions, please submit to https://github.com/langgenius/dify-plugins instead.\r\n\r\n- Link Related Issues if Applicable: #issue_number\r\n- Or Provide Context about Why this Change is Nee",
    "url": "https://github.com/Cursx/fix-ollama-/pull/12",
    "source": "github_prs",
    "highlights": [
      "comments: 1",
      "pull request",
      "repo: fix-ollama-"
    ]
  },
  {
    "title": "[PR] chore(deps): update dependency testcontainers to v4",
    "date": "2025-11-04T10:54:38Z",
    "summary": "This PR contains the following updates:\n\n| Package | Change | Age | Confidence |\n|---|---|---|---|\n| [TestContainers](https://dotnet.testcontainers.org/) ([source](https://redirect.github.com/testcontainers/testcontainers-dotnet)) | `3.8.0` -> `4.8.1` | [![age](https://developer.mend.io/api/mc/badge",
    "url": "https://github.com/camunda-community-hub/zeebe-client-csharp/pull/820",
    "source": "github_prs",
    "highlights": [
      "comments: 0",
      "pull request",
      "repo: zeebe-client-csharp"
    ]
  }
]