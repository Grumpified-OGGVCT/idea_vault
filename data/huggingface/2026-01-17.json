[
  {
    "dataset_id": "huggingface/DEH-image-scan-data",
    "author": "huggingface",
    "title": "huggingface/DEH-image-scan-data",
    "downloads": 11139,
    "likes": 5,
    "tags": [
      "size_categories:n<1K",
      "region:us"
    ],
    "created_at": "2025-11-06T18:40:14.000Z",
    "last_modified": "2026-01-17T23:22:45.000Z",
    "url": "https://huggingface.co/datasets/huggingface/DEH-image-scan-data",
    "date": "2026-01-17",
    "source": "huggingface_dataset",
    "type": "dataset",
    "research_score": 0.5
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold6",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold6",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T23:23:52.000Z",
    "last_modified": "2026-01-17T23:24:05.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold6",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "israel/afri_llama3.2-1b_dpo_rgemini",
    "author": "unknown",
    "title": "israel/afri_llama3.2-1b_dpo_rgemini",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "llama-factory",
      "conversational",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T23:23:18.000Z",
    "last_modified": "2026-01-17T23:23:56.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/israel/afri_llama3.2-1b_dpo_rgemini",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_len_btw_450_458_1p0_0p0_1p0_grpo_42_rule",
    "author": "unknown",
    "title": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_len_btw_450_458_1p0_0p0_1p0_grpo_42_rule",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "generated_from_trainer",
      "grpo",
      "trl",
      "conversational",
      "arxiv:2402.03300",
      "base_model:Qwen/Qwen3-1.7B-Base",
      "base_model:finetune:Qwen/Qwen3-1.7B-Base",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T23:01:51.000Z",
    "last_modified": "2026-01-17T23:23:48.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Kazuki1450/Qwen3-1.7B-Base_csum_6_10_len_btw_450_458_1p0_0p0_1p0_grpo_42_rule",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Ammar12Falah/omt-falcon-1b-adapter",
    "author": "unknown",
    "title": "Ammar12Falah/omt-falcon-1b-adapter",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "peft",
      "safetensors",
      "base_model:adapter:tiiuae/falcon-rw-1b",
      "lora",
      "transformers",
      "text-generation",
      "arxiv:1910.09700",
      "base_model:tiiuae/falcon-rw-1b",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "peft",
    "created_at": "2026-01-17T23:23:36.000Z",
    "last_modified": "2026-01-17T23:23:38.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Ammar12Falah/omt-falcon-1b-adapter",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "najicreator90856/is-it-nsfw_ai-moderator",
    "author": "unknown",
    "title": "najicreator90856/is-it-nsfw_ai-moderator",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "resnet",
      "image-classification",
      "nsfw",
      "sfw",
      "safety",
      "image-safety",
      "moderation",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "image-classification",
    "library": "transformers",
    "created_at": "2026-01-17T21:00:00.000Z",
    "last_modified": "2026-01-17T23:23:31.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/najicreator90856/is-it-nsfw_ai-moderator",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold5",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold5",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T23:21:49.000Z",
    "last_modified": "2026-01-17T23:21:58.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold5",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_len_btw_1000_1200_1p0_0p0_1p0_grpo_42_rule",
    "author": "unknown",
    "title": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_len_btw_1000_1200_1p0_0p0_1p0_grpo_42_rule",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "generated_from_trainer",
      "grpo",
      "trl",
      "conversational",
      "arxiv:2402.03300",
      "base_model:Qwen/Qwen3-1.7B-Base",
      "base_model:finetune:Qwen/Qwen3-1.7B-Base",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T22:05:28.000Z",
    "last_modified": "2026-01-17T23:21:35.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Kazuki1450/Qwen3-1.7B-Base_csum_6_10_len_btw_1000_1200_1p0_0p0_1p0_grpo_42_rule",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "LLM-course/chess_zak_second",
    "author": "unknown",
    "title": "LLM-course/chess_zak_second",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "chess_transformer",
      "text-generation",
      "chess",
      "llm-course",
      "chess-challenge",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T23:20:56.000Z",
    "last_modified": "2026-01-17T23:20:58.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/LLM-course/chess_zak_second",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold4",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold4",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T23:19:43.000Z",
    "last_modified": "2026-01-17T23:19:56.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold4",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "israel/swahili_llama3.2-1b_dpo_rgemma-3-27b-it",
    "author": "unknown",
    "title": "israel/swahili_llama3.2-1b_dpo_rgemma-3-27b-it",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "llama-factory",
      "conversational",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T23:19:00.000Z",
    "last_modified": "2026-01-17T23:19:34.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/israel/swahili_llama3.2-1b_dpo_rgemma-3-27b-it",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "ali-elganzory/Qwen3-1.7B-Base-SFT-Tulu3-decontaminated",
    "author": "unknown",
    "title": "ali-elganzory/Qwen3-1.7B-Base-SFT-Tulu3-decontaminated",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "generated_from_trainer",
      "sft",
      "trl",
      "conversational",
      "base_model:Qwen/Qwen3-1.7B-Base",
      "base_model:finetune:Qwen/Qwen3-1.7B-Base",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T19:10:30.000Z",
    "last_modified": "2026-01-17T23:19:18.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/ali-elganzory/Qwen3-1.7B-Base-SFT-Tulu3-decontaminated",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold3",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold3",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T23:17:36.000Z",
    "last_modified": "2026-01-17T23:17:49.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold3",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "israel/hausa_llama3.2-1b_dpo_rgemini",
    "author": "unknown",
    "title": "israel/hausa_llama3.2-1b_dpo_rgemini",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "llama-factory",
      "conversational",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T23:15:57.000Z",
    "last_modified": "2026-01-17T23:16:38.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/israel/hausa_llama3.2-1b_dpo_rgemini",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "ali-elganzory/Qwen2.5-1.5B-SFT-Tulu3-decontaminated",
    "author": "unknown",
    "title": "ali-elganzory/Qwen2.5-1.5B-SFT-Tulu3-decontaminated",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "generated_from_trainer",
      "trl",
      "sft",
      "conversational",
      "base_model:Qwen/Qwen2.5-1.5B",
      "base_model:finetune:Qwen/Qwen2.5-1.5B",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T18:39:38.000Z",
    "last_modified": "2026-01-17T23:16:33.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/ali-elganzory/Qwen2.5-1.5B-SFT-Tulu3-decontaminated",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold2",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold2",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T23:15:29.000Z",
    "last_modified": "2026-01-17T23:15:38.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold2",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "LLM-course/chess_zak_first",
    "author": "unknown",
    "title": "LLM-course/chess_zak_first",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "chess_transformer",
      "text-generation",
      "chess",
      "llm-course",
      "chess-challenge",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T23:14:09.000Z",
    "last_modified": "2026-01-17T23:14:11.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/LLM-course/chess_zak_first",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold1",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold1",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T23:12:43.000Z",
    "last_modified": "2026-01-17T23:13:52.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold1",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "LLM-course/chess-nbs-oh",
    "author": "unknown",
    "title": "LLM-course/chess-nbs-oh",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "chess_transformer",
      "text-generation",
      "chess",
      "llm-course",
      "chess-challenge",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T21:50:13.000Z",
    "last_modified": "2026-01-17T23:11:06.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/LLM-course/chess-nbs-oh",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold0",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold0",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T23:09:22.000Z",
    "last_modified": "2026-01-17T23:10:32.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_joy-fold0",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "israel/swahili_llama3.2-1b_dpo_rLlama-3.2-1B-Instruct",
    "author": "unknown",
    "title": "israel/swahili_llama3.2-1b_dpo_rLlama-3.2-1B-Instruct",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "llama-factory",
      "conversational",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T23:09:39.000Z",
    "last_modified": "2026-01-17T23:10:06.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/israel/swahili_llama3.2-1b_dpo_rLlama-3.2-1B-Instruct",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_len_btw_900_1300_1p0_0p0_1p0_grpo_42_rule",
    "author": "unknown",
    "title": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_len_btw_900_1300_1p0_0p0_1p0_grpo_42_rule",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "generated_from_trainer",
      "grpo",
      "trl",
      "conversational",
      "arxiv:2402.03300",
      "base_model:Qwen/Qwen3-1.7B-Base",
      "base_model:finetune:Qwen/Qwen3-1.7B-Base",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T22:44:25.000Z",
    "last_modified": "2026-01-17T23:09:33.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Kazuki1450/Qwen3-1.7B-Base_csum_6_10_len_btw_900_1300_1p0_0p0_1p0_grpo_42_rule",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_anger-fold9",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_anger-fold9",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T23:05:56.000Z",
    "last_modified": "2026-01-17T23:07:06.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_anger-fold9",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_len_lt_8_1p0_0p0_1p0_grpo_42_rule",
    "author": "unknown",
    "title": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_len_lt_8_1p0_0p0_1p0_grpo_42_rule",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "generated_from_trainer",
      "grpo",
      "trl",
      "conversational",
      "arxiv:2402.03300",
      "base_model:Qwen/Qwen3-1.7B-Base",
      "base_model:finetune:Qwen/Qwen3-1.7B-Base",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T21:48:12.000Z",
    "last_modified": "2026-01-17T23:06:44.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Kazuki1450/Qwen3-1.7B-Base_csum_6_10_len_lt_8_1p0_0p0_1p0_grpo_42_rule",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Hazi9/mi_llamamergedmodel_quantized",
    "author": "unknown",
    "title": "Hazi9/mi_llamamergedmodel_quantized",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "4-bit",
      "bitsandbytes",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T23:04:03.000Z",
    "last_modified": "2026-01-17T23:05:57.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Hazi9/mi_llamamergedmodel_quantized",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_anger-fold8",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_anger-fold8",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T23:03:08.000Z",
    "last_modified": "2026-01-17T23:04:17.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to2-semeval2025_eng_anger-fold8",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]