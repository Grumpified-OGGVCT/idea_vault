[
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-twitter_topics_0_a-fold5",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-twitter_topics_0_a-fold5",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T19:17:25.000Z",
    "last_modified": "2026-01-17T19:18:53.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-twitter_topics_0_a-fold5",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "LLM-course/chess_v2.1",
    "author": "unknown",
    "title": "LLM-course/chess_v2.1",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "chess_transformer",
      "text-generation",
      "chess",
      "llm-course",
      "chess-challenge",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T19:18:38.000Z",
    "last_modified": "2026-01-17T19:18:41.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/LLM-course/chess_v2.1",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Ruslan10/bert-finetuned-sentiment",
    "author": "unknown",
    "title": "Ruslan10/bert-finetuned-sentiment",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "bert",
      "text-classification",
      "generated_from_trainer",
      "base_model:google-bert/bert-base-uncased",
      "base_model:finetune:google-bert/bert-base-uncased",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T15:53:23.000Z",
    "last_modified": "2026-01-17T19:17:43.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Ruslan10/bert-finetuned-sentiment",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "LLM-course/chess_v2.0",
    "author": "unknown",
    "title": "LLM-course/chess_v2.0",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "chess_transformer",
      "text-generation",
      "chess",
      "llm-course",
      "chess-challenge",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T19:16:56.000Z",
    "last_modified": "2026-01-17T19:16:59.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/LLM-course/chess_v2.0",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "ali-elganzory/Qwen2.5-1.5B-SFT-Tulu3-decontaminated",
    "author": "unknown",
    "title": "ali-elganzory/Qwen2.5-1.5B-SFT-Tulu3-decontaminated",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "generated_from_trainer",
      "trl",
      "sft",
      "conversational",
      "base_model:Qwen/Qwen2.5-1.5B",
      "base_model:finetune:Qwen/Qwen2.5-1.5B",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T18:39:38.000Z",
    "last_modified": "2026-01-17T19:15:43.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/ali-elganzory/Qwen2.5-1.5B-SFT-Tulu3-decontaminated",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Shekswess/tiny-think-sft-math-stem-loss-nll-bf16-lr5e-5-e2-bs8",
    "author": "unknown",
    "title": "Shekswess/tiny-think-sft-math-stem-loss-nll-bf16-lr5e-5-e2-bs8",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama4_text",
      "text-generation",
      "generated_from_trainer",
      "trl",
      "sft",
      "conversational",
      "base_model:facebook/MobileLLM-R1-140M-base",
      "base_model:finetune:facebook/MobileLLM-R1-140M-base",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T18:21:52.000Z",
    "last_modified": "2026-01-17T19:15:30.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Shekswess/tiny-think-sft-math-stem-loss-nll-bf16-lr5e-5-e2-bs8",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-twitter_topics_0_a-fold4",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-twitter_topics_0_a-fold4",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T19:12:53.000Z",
    "last_modified": "2026-01-17T19:14:21.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-twitter_topics_0_a-fold4",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "LLM-course/chess_filo_2",
    "author": "unknown",
    "title": "LLM-course/chess_filo_2",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "chess_transformer",
      "text-generation",
      "chess",
      "llm-course",
      "chess-challenge",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T19:13:11.000Z",
    "last_modified": "2026-01-17T19:13:14.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/LLM-course/chess_filo_2",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "visity/zephyr-7b-dpo-full",
    "author": "unknown",
    "title": "visity/zephyr-7b-dpo-full",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "generated_from_trainer",
      "trl",
      "dpo",
      "conversational",
      "arxiv:2305.18290",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T10:56:08.000Z",
    "last_modified": "2026-01-17T19:12:50.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/visity/zephyr-7b-dpo-full",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "LLM-course/chess-model-jawad-chemaou-v2",
    "author": "unknown",
    "title": "LLM-course/chess-model-jawad-chemaou-v2",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "chess_transformer",
      "text-generation",
      "chess",
      "llm-course",
      "chess-challenge",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T18:40:04.000Z",
    "last_modified": "2026-01-17T19:12:05.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/LLM-course/chess-model-jawad-chemaou-v2",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "s8n29/phase2_joint_training_new",
    "author": "unknown",
    "title": "s8n29/phase2_joint_training_new",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "region:us"
    ],
    "pipeline_tag": "",
    "library": "",
    "created_at": "2026-01-17T19:10:30.000Z",
    "last_modified": "2026-01-17T19:10:30.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/s8n29/phase2_joint_training_new",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "small-blue/pos-test01_offline_v3",
    "author": "unknown",
    "title": "small-blue/pos-test01_offline_v3",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "trl",
      "sft",
      "conversational",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T19:04:03.000Z",
    "last_modified": "2026-01-17T19:09:27.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/small-blue/pos-test01_offline_v3",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-twitter_topics_0_a-fold3",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-twitter_topics_0_a-fold3",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T19:07:40.000Z",
    "last_modified": "2026-01-17T19:09:20.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-twitter_topics_0_a-fold3",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-twitter_topics_0_a-fold2",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-twitter_topics_0_a-fold2",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T19:02:53.000Z",
    "last_modified": "2026-01-17T19:04:32.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-twitter_topics_0_a-fold2",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-twitter_topics_0_a-fold1",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-twitter_topics_0_a-fold1",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T18:58:40.000Z",
    "last_modified": "2026-01-17T19:00:18.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-twitter_topics_0_a-fold1",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "subhankarswain/qwen2-7b-least-random-token-extension-finetune-toxic-tags",
    "author": "unknown",
    "title": "subhankarswain/qwen2-7b-least-random-token-extension-finetune-toxic-tags",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "peft",
      "safetensors",
      "base_model:adapter:Qwen/Qwen2-VL-7B-Instruct",
      "lora",
      "transformers",
      "text-generation",
      "arxiv:1910.09700",
      "base_model:Qwen/Qwen2-VL-7B-Instruct",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "peft",
    "created_at": "2026-01-17T18:58:11.000Z",
    "last_modified": "2026-01-17T18:58:15.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/subhankarswain/qwen2-7b-least-random-token-extension-finetune-toxic-tags",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]