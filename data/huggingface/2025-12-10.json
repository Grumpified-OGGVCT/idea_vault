[
  {
    "model_id": "chunchiliu/Qwen2.5-Coder-1.5B-Instruct-Gensyn-Swarm-graceful_slender_toucan",
    "author": "unknown",
    "title": "chunchiliu/Qwen2.5-Coder-1.5B-Instruct-Gensyn-Swarm-graceful_slender_toucan",
    "downloads": 2228,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "rl-swarm",
      "genrl-swarm",
      "grpo",
      "gensyn",
      "I am graceful_slender_toucan",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-09T21:57:24.000Z",
    "last_modified": "2025-12-10T19:18:12.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/chunchiliu/Qwen2.5-Coder-1.5B-Instruct-Gensyn-Swarm-graceful_slender_toucan",
    "date": "2025-12-10",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.5
  },
  {
    "model_id": "mradermacher/Fairy2i-W2-i1-GGUF",
    "author": "unknown",
    "title": "mradermacher/Fairy2i-W2-i1-GGUF",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "gguf",
      "llama-2",
      "quantization",
      "qat",
      "complex-valued",
      "2-bit",
      "text-generation",
      "recursive",
      "safetensors",
      "en",
      "base_model:PKU-DS-LAB/Fairy2i-W2",
      "base_model:quantized:PKU-DS-LAB/Fairy2i-W2",
      "license:llama2",
      "endpoints_compatible",
      "region:us",
      "imatrix"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-10T17:12:46.000Z",
    "last_modified": "2025-12-10T19:21:18.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/mradermacher/Fairy2i-W2-i1-GGUF",
    "date": "2025-12-10",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "RLLab/Qwen3-4B-GRM-SFT",
    "author": "unknown",
    "title": "RLLab/Qwen3-4B-GRM-SFT",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-10T19:20:19.000Z",
    "last_modified": "2025-12-10T19:21:11.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/RLLab/Qwen3-4B-GRM-SFT",
    "date": "2025-12-10",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "chunchiliu/deepseek-coder-1.3b-instruct-Gensyn-Swarm-grassy_wary_sealion",
    "author": "unknown",
    "title": "chunchiliu/deepseek-coder-1.3b-instruct-Gensyn-Swarm-grassy_wary_sealion",
    "downloads": 339,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "rl-swarm",
      "genrl-swarm",
      "grpo",
      "gensyn",
      "I am grassy_wary_sealion",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-08T23:13:24.000Z",
    "last_modified": "2025-12-10T19:18:03.000Z",
    "days_since_creation": 1,
    "url": "https://huggingface.co/chunchiliu/deepseek-coder-1.3b-instruct-Gensyn-Swarm-grassy_wary_sealion",
    "date": "2025-12-10",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "pankajmathur/Mimma-3-27b-Q4_K_M-GGUF",
    "author": "unknown",
    "title": "pankajmathur/Mimma-3-27b-Q4_K_M-GGUF",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "gguf",
      "llama-cpp",
      "gguf-my-repo",
      "text-generation",
      "dataset:pankajmathur/orca_mini_v8_sharegpt_format",
      "base_model:pankajmathur/Mimma-3-27b",
      "base_model:quantized:pankajmathur/Mimma-3-27b",
      "license:gemma",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-10T19:12:54.000Z",
    "last_modified": "2025-12-10T19:14:04.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/pankajmathur/Mimma-3-27b-Q4_K_M-GGUF",
    "date": "2025-12-10",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]