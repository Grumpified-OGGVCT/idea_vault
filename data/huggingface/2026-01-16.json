[
  {
    "model_id": "koutch/paper_llama_llama3.1-8b_train_sft_train_think",
    "author": "unknown",
    "title": "koutch/paper_llama_llama3.1-8b_train_sft_train_think",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "text-generation-inference",
      "unsloth",
      "conversational",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T20:21:15.000Z",
    "last_modified": "2026-01-16T20:27:50.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/koutch/paper_llama_llama3.1-8b_train_sft_train_think",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "tytytyyt/distilbert-base-uncased-finetuned-clinc",
    "author": "unknown",
    "title": "tytytyyt/distilbert-base-uncased-finetuned-clinc",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "distilbert",
      "text-classification",
      "generated_from_trainer",
      "base_model:distilbert/distilbert-base-uncased",
      "base_model:finetune:distilbert/distilbert-base-uncased",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-16T15:33:06.000Z",
    "last_modified": "2026-01-16T20:27:19.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/tytytyyt/distilbert-base-uncased-finetuned-clinc",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold9",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold9",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-16T20:25:16.000Z",
    "last_modified": "2026-01-16T20:26:57.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold9",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "koutch/paper_llama_llama3.1-8b_train_sft_train_no_think",
    "author": "unknown",
    "title": "koutch/paper_llama_llama3.1-8b_train_sft_train_no_think",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "text-generation-inference",
      "unsloth",
      "conversational",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T20:15:23.000Z",
    "last_modified": "2026-01-16T20:24:09.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/koutch/paper_llama_llama3.1-8b_train_sft_train_no_think",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "ShivendraNT/ClauseGuard-BERT-Specialist",
    "author": "unknown",
    "title": "ShivendraNT/ClauseGuard-BERT-Specialist",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "bert",
      "text-classification",
      "legal",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-16T12:38:12.000Z",
    "last_modified": "2026-01-16T20:22:19.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/ShivendraNT/ClauseGuard-BERT-Specialist",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold8",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold8",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-16T20:19:34.000Z",
    "last_modified": "2026-01-16T20:21:03.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold8",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "inferencerlabs/LongCat-Flash-Thinking-2601-MLX-6.5bit",
    "author": "unknown",
    "title": "inferencerlabs/LongCat-Flash-Thinking-2601-MLX-6.5bit",
    "downloads": 179,
    "likes": 0,
    "tags": [
      "mlx",
      "safetensors",
      "longcat_flash",
      "text-generation",
      "conversational",
      "custom_code",
      "en",
      "6-bit",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "mlx",
    "created_at": "2026-01-15T06:47:07.000Z",
    "last_modified": "2026-01-16T20:18:52.000Z",
    "days_since_creation": 1,
    "url": "https://huggingface.co/inferencerlabs/LongCat-Flash-Thinking-2601-MLX-6.5bit",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "koutch/paper_llama_llama3.1-8b_train_sft_train_para",
    "author": "unknown",
    "title": "koutch/paper_llama_llama3.1-8b_train_sft_train_para",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "text-generation-inference",
      "unsloth",
      "conversational",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T20:10:49.000Z",
    "last_modified": "2026-01-16T20:18:12.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/koutch/paper_llama_llama3.1-8b_train_sft_train_para",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Birma/zarma_tts_full_16bit_v1",
    "author": "unknown",
    "title": "Birma/zarma_tts_full_16bit_v1",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "text-generation-inference",
      "unsloth",
      "conversational",
      "en",
      "base_model:unsloth/orpheus-3b-0.1-ft",
      "base_model:finetune:unsloth/orpheus-3b-0.1-ft",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T20:06:38.000Z",
    "last_modified": "2026-01-16T20:16:50.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Birma/zarma_tts_full_16bit_v1",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold7",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold7",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-16T20:13:43.000Z",
    "last_modified": "2026-01-16T20:15:24.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold7",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "WhoIsShe/DarkSapling-7B-v2.0-MNN",
    "author": "unknown",
    "title": "WhoIsShe/DarkSapling-7B-v2.0-MNN",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "mnn",
      "on-device",
      "android",
      "ios",
      "quantization",
      "int4",
      "text-generation",
      "llama2",
      "en",
      "base_model:WhoIsShe/DarkSapling-7B-v2.0-MNN",
      "base_model:finetune:WhoIsShe/DarkSapling-7B-v2.0-MNN",
      "license:other",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "mnn",
    "created_at": "2026-01-16T20:14:36.000Z",
    "last_modified": "2026-01-16T20:15:24.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/WhoIsShe/DarkSapling-7B-v2.0-MNN",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Shekswess/tiny-think-sft-math-stem-loss-dft-bf16-lr5e-5-e2-bs8",
    "author": "unknown",
    "title": "Shekswess/tiny-think-sft-math-stem-loss-dft-bf16-lr5e-5-e2-bs8",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama4_text",
      "text-generation",
      "generated_from_trainer",
      "trl",
      "sft",
      "conversational",
      "base_model:facebook/MobileLLM-R1-140M-base",
      "base_model:finetune:facebook/MobileLLM-R1-140M-base",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T18:17:55.000Z",
    "last_modified": "2026-01-16T20:13:10.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Shekswess/tiny-think-sft-math-stem-loss-dft-bf16-lr5e-5-e2-bs8",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "LLM-course/chess-player-v2bis",
    "author": "unknown",
    "title": "LLM-course/chess-player-v2bis",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "chess_transformer",
      "text-generation",
      "chess",
      "llm-course",
      "chess-challenge",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T20:12:34.000Z",
    "last_modified": "2026-01-16T20:12:37.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/LLM-course/chess-player-v2bis",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "AdoCleanCode/llasa_stage2_trained_multilingual_stage2",
    "author": "unknown",
    "title": "AdoCleanCode/llasa_stage2_trained_multilingual_stage2",
    "downloads": 17,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "conversational",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T00:01:51.000Z",
    "last_modified": "2026-01-16T20:11:44.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/AdoCleanCode/llasa_stage2_trained_multilingual_stage2",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "katya228/xinyuan-llm-14b-0428-heretic-psychology-gguf-q4_0",
    "author": "unknown",
    "title": "katya228/xinyuan-llm-14b-0428-heretic-psychology-gguf-q4_0",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "heretic",
      "psychology",
      "text-generation",
      "license:apache-2.0",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "",
    "created_at": "2026-01-16T20:01:33.000Z",
    "last_modified": "2026-01-16T20:11:40.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/katya228/xinyuan-llm-14b-0428-heretic-psychology-gguf-q4_0",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "koutch/paper_smol_3.json_train_dpo_v1_train_no_think",
    "author": "unknown",
    "title": "koutch/paper_smol_3.json_train_dpo_v1_train_no_think",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "smollm3",
      "text-generation",
      "text-generation-inference",
      "unsloth",
      "conversational",
      "en",
      "base_model:unsloth/SmolLM3-3B",
      "base_model:finetune:unsloth/SmolLM3-3B",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T20:08:01.000Z",
    "last_modified": "2026-01-16T20:10:18.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/koutch/paper_smol_3.json_train_dpo_v1_train_no_think",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold6",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold6",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-16T20:07:44.000Z",
    "last_modified": "2026-01-16T20:09:28.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold6",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]