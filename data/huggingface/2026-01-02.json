[
  {
    "model_id": "tarundachepally/Granite_8b_3.3_new3_complete",
    "author": "unknown",
    "title": "tarundachepally/Granite_8b_3.3_new3_complete",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "granite",
      "text-generation",
      "conversational",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-02T08:22:41.000Z",
    "last_modified": "2026-01-02T08:28:20.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/tarundachepally/Granite_8b_3.3_new3_complete",
    "date": "2026-01-02",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.5
  },
  {
    "model_id": "iproskurina/qwen-500m-biasinbios-pt-cooldown-iter2",
    "author": "unknown",
    "title": "iproskurina/qwen-500m-biasinbios-pt-cooldown-iter2",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "conversational",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-02T08:34:25.000Z",
    "last_modified": "2026-01-02T08:34:59.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/iproskurina/qwen-500m-biasinbios-pt-cooldown-iter2",
    "date": "2026-01-02",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "toth235a/french-qwen3-luth-25pct",
    "author": "unknown",
    "title": "toth235a/french-qwen3-luth-25pct",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "mergekit",
      "merge",
      "arxiv:2203.05482",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-02T08:28:38.000Z",
    "last_modified": "2026-01-02T08:32:27.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/toth235a/french-qwen3-luth-25pct",
    "date": "2026-01-02",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "tarundachepally/Granite_8b_3.3_new3_complete-Q4_K_S-GGUF",
    "author": "unknown",
    "title": "tarundachepally/Granite_8b_3.3_new3_complete-Q4_K_S-GGUF",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "gguf",
      "llama-cpp",
      "gguf-my-repo",
      "base_model:tarundachepally/Granite_8b_3.3_new3_complete",
      "base_model:quantized:tarundachepally/Granite_8b_3.3_new3_complete",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "",
    "library": "transformers",
    "created_at": "2026-01-02T08:31:32.000Z",
    "last_modified": "2026-01-02T08:31:52.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/tarundachepally/Granite_8b_3.3_new3_complete-Q4_K_S-GGUF",
    "date": "2026-01-02",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "toth235a/french-qwen3-luth-50pct",
    "author": "unknown",
    "title": "toth235a/french-qwen3-luth-50pct",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "mergekit",
      "merge",
      "arxiv:2203.05482",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-02T08:29:07.000Z",
    "last_modified": "2026-01-02T08:29:32.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/toth235a/french-qwen3-luth-50pct",
    "date": "2026-01-02",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]