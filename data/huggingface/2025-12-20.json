[
  {
    "model_id": "chunchiliu/Qwen2.5-Coder-1.5B-Instruct-Gensyn-Swarm-graceful_slender_toucan",
    "author": "unknown",
    "title": "chunchiliu/Qwen2.5-Coder-1.5B-Instruct-Gensyn-Swarm-graceful_slender_toucan",
    "downloads": 4223,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "rl-swarm",
      "genrl-swarm",
      "grpo",
      "gensyn",
      "I am graceful_slender_toucan",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-17T05:10:11.000Z",
    "last_modified": "2025-12-20T03:19:16.000Z",
    "days_since_creation": 2,
    "url": "https://huggingface.co/chunchiliu/Qwen2.5-Coder-1.5B-Instruct-Gensyn-Swarm-graceful_slender_toucan",
    "date": "2025-12-20",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "junghee1486/pharos_2b_",
    "author": "unknown",
    "title": "junghee1486/pharos_2b_",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "gemma",
      "text-generation",
      "fintech",
      "text-classification",
      "ko",
      "dataset:junghee1486/pharos_data",
      "base_model:google/gemma-2b-it",
      "base_model:finetune:google/gemma-2b-it",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2025-12-20T02:57:11.000Z",
    "last_modified": "2025-12-20T03:19:04.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/junghee1486/pharos_2b_",
    "date": "2025-12-20",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "eantropix/gemma-news-lora-r32-d01-e2",
    "author": "unknown",
    "title": "eantropix/gemma-news-lora-r32-d01-e2",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "region:us"
    ],
    "pipeline_tag": "",
    "library": "",
    "created_at": "2025-12-20T03:11:27.000Z",
    "last_modified": "2025-12-20T03:11:28.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/eantropix/gemma-news-lora-r32-d01-e2",
    "date": "2025-12-20",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "eantropix/gemma-news-lora-r32-d01-e1",
    "author": "unknown",
    "title": "eantropix/gemma-news-lora-r32-d01-e1",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "tensorboard",
      "safetensors",
      "generated_from_trainer",
      "sft",
      "trl",
      "base_model:google/gemma-3-1b-pt",
      "base_model:finetune:google/gemma-3-1b-pt",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "",
    "library": "transformers",
    "created_at": "2025-12-20T02:48:56.000Z",
    "last_modified": "2025-12-20T03:11:25.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/eantropix/gemma-news-lora-r32-d01-e1",
    "date": "2025-12-20",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "cvis-tmu/qwen2_5vl-7b-lora-sft-SQA3Devery24_R12C12F12X62_400steps",
    "author": "unknown",
    "title": "cvis-tmu/qwen2_5vl-7b-lora-sft-SQA3Devery24_R12C12F12X62_400steps",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "peft",
      "safetensors",
      "base_model:adapter:Qwen/Qwen2.5-VL-7B-Instruct",
      "llama-factory",
      "lora",
      "transformers",
      "text-generation",
      "conversational",
      "arxiv:1910.09700",
      "base_model:Qwen/Qwen2.5-VL-7B-Instruct",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "peft",
    "created_at": "2025-12-20T03:11:06.000Z",
    "last_modified": "2025-12-20T03:11:11.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/cvis-tmu/qwen2_5vl-7b-lora-sft-SQA3Devery24_R12C12F12X62_400steps",
    "date": "2025-12-20",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "swadeshb/Llama-3.2-3B-Instruct-AMPO-V1",
    "author": "unknown",
    "title": "swadeshb/Llama-3.2-3B-Instruct-AMPO-V1",
    "downloads": 5,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "generated_from_trainer",
      "grpo",
      "trl",
      "conversational",
      "arxiv:2402.03300",
      "base_model:meta-llama/Llama-3.2-3B-Instruct",
      "base_model:finetune:meta-llama/Llama-3.2-3B-Instruct",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-18T03:22:57.000Z",
    "last_modified": "2025-12-20T03:07:01.000Z",
    "days_since_creation": 1,
    "url": "https://huggingface.co/swadeshb/Llama-3.2-3B-Instruct-AMPO-V1",
    "date": "2025-12-20",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "kenrouse/kotoba-whisper-medical-ja",
    "author": "unknown",
    "title": "kenrouse/kotoba-whisper-medical-ja",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "safetensors",
      "whisper",
      "automatic-speech-recognition",
      "medical",
      "japanese",
      "kotoba-whisper",
      "fine-tuned",
      "ja",
      "base_model:kotoba-tech/kotoba-whisper-v2.2",
      "base_model:finetune:kotoba-tech/kotoba-whisper-v2.2",
      "license:apache-2.0",
      "region:us"
    ],
    "pipeline_tag": "automatic-speech-recognition",
    "library": "",
    "created_at": "2025-12-19T05:29:26.000Z",
    "last_modified": "2025-12-20T03:06:52.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/kenrouse/kotoba-whisper-medical-ja",
    "date": "2025-12-20",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "bitlabsdb/gpt2-124m-transformer_model",
    "author": "unknown",
    "title": "bitlabsdb/gpt2-124m-transformer_model",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "pytorch",
      "safetensors",
      "gpt2",
      "text-generation",
      "causal-lm",
      "scratch-implementation",
      "educational",
      "en",
      "dataset:HuggingFaceFW/fineweb",
      "base_model:openai-community/gpt2",
      "base_model:finetune:openai-community/gpt2",
      "license:mit",
      "model-index",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "pytorch",
    "created_at": "2025-12-19T12:32:04.000Z",
    "last_modified": "2025-12-20T03:04:07.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/bitlabsdb/gpt2-124m-transformer_model",
    "date": "2025-12-20",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "YureiYuri/Empath",
    "author": "unknown",
    "title": "YureiYuri/Empath",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "medical",
      "text-classification",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2025-12-20T02:55:31.000Z",
    "last_modified": "2025-12-20T03:01:37.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/YureiYuri/Empath",
    "date": "2025-12-20",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Harsha901/gemma-3-1B-Math-GRPO-350",
    "author": "unknown",
    "title": "Harsha901/gemma-3-1B-Math-GRPO-350",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "gemma3_text",
      "text-generation",
      "text-generation-inference",
      "unsloth",
      "conversational",
      "en",
      "base_model:unsloth/gemma-3-1b-it",
      "base_model:finetune:unsloth/gemma-3-1b-it",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-20T02:56:01.000Z",
    "last_modified": "2025-12-20T03:00:04.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Harsha901/gemma-3-1B-Math-GRPO-350",
    "date": "2025-12-20",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]