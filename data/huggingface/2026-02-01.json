[
  {
    "model_id": "Annise/Test_Gemma270M_CoT",
    "author": "unknown",
    "title": "Annise/Test_Gemma270M_CoT",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "tensorboard",
      "safetensors",
      "gemma3_text",
      "text-generation",
      "generated_from_trainer",
      "trl",
      "sft",
      "conversational",
      "base_model:google/gemma-3-270m-it",
      "base_model:finetune:google/gemma-3-270m-it",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-02-01T09:18:28.000Z",
    "last_modified": "2026-02-01T09:34:15.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Annise/Test_Gemma270M_CoT",
    "date": "2026-02-01",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "yasserrmd/GLM4.7-Distill-LFM2.5-1.2B",
    "author": "unknown",
    "title": "yasserrmd/GLM4.7-Distill-LFM2.5-1.2B",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "lfm2",
      "text-generation",
      "text-generation-inference",
      "instruction-tuned",
      "distilled",
      "synthetic-data",
      "unsloth",
      "glm",
      "agentic",
      "edge",
      "efficient",
      "conversational",
      "en",
      "dataset:Open-Orca/FLAN",
      "dataset:databricks/databricks-dolly-15k",
      "dataset:OpenAssistant/oasst1",
      "dataset:BAAI/Infinity-Instruct",
      "dataset:sahil2801/CodeAlpaca-20k",
      "dataset:TIGER-Lab/MathInstruct",
      "base_model:LiquidAI/LFM2.5-1.2B-Instruct",
      "base_model:finetune:LiquidAI/LFM2.5-1.2B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-31T20:17:21.000Z",
    "last_modified": "2026-02-01T09:32:22.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/yasserrmd/GLM4.7-Distill-LFM2.5-1.2B",
    "date": "2026-02-01",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "baggettersol/bagsy-qwen3-32B",
    "author": "unknown",
    "title": "baggettersol/bagsy-qwen3-32B",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "trl",
      "sft",
      "conversational",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-02-01T09:15:38.000Z",
    "last_modified": "2026-02-01T09:32:02.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/baggettersol/bagsy-qwen3-32B",
    "date": "2026-02-01",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "jieyouwu/FTASR3Model",
    "author": "unknown",
    "title": "jieyouwu/FTASR3Model",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "whisper",
      "automatic-speech-recognition",
      "text-generation-inference",
      "unsloth",
      "en",
      "base_model:unsloth/whisper-small",
      "base_model:finetune:unsloth/whisper-small",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "automatic-speech-recognition",
    "library": "transformers",
    "created_at": "2026-02-01T09:29:50.000Z",
    "last_modified": "2026-02-01T09:31:23.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/jieyouwu/FTASR3Model",
    "date": "2026-02-01",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "pankajrudra/MediBool-indic-bert-Context_Aware",
    "author": "unknown",
    "title": "pankajrudra/MediBool-indic-bert-Context_Aware",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "albert",
      "text-classification",
      "generated_from_trainer",
      "base_model:ai4bharat/indic-bert",
      "base_model:finetune:ai4bharat/indic-bert",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-02-01T09:08:24.000Z",
    "last_modified": "2026-02-01T09:26:28.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/pankajrudra/MediBool-indic-bert-Context_Aware",
    "date": "2026-02-01",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "stelterlab/NVIDIA-Nemotron-3-Nano-30B-A3B-AWQ",
    "author": "unknown",
    "title": "stelterlab/NVIDIA-Nemotron-3-Nano-30B-A3B-AWQ",
    "downloads": 31,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "nvidia",
      "pytorch",
      "text-generation",
      "conversational",
      "en",
      "es",
      "fr",
      "de",
      "ja",
      "it",
      "dataset:nvidia/Nemotron-Pretraining-Code-v1",
      "dataset:nvidia/Nemotron-CC-v2",
      "dataset:nvidia/Nemotron-Pretraining-SFT-v1",
      "dataset:nvidia/Nemotron-CC-Math-v1",
      "dataset:nvidia/Nemotron-Pretraining-Code-v2",
      "dataset:nvidia/Nemotron-Pretraining-Specialized-v1",
      "dataset:nvidia/Nemotron-CC-v2.1",
      "dataset:nvidia/Nemotron-CC-Code-v1",
      "dataset:nvidia/Nemotron-Pretraining-Dataset-sample",
      "dataset:nvidia/Nemotron-Competitive-Programming-v1",
      "dataset:nvidia/Nemotron-Math-v2",
      "dataset:nvidia/Nemotron-Agentic-v1",
      "dataset:nvidia/Nemotron-Math-Proofs-v1",
      "dataset:nvidia/Nemotron-Instruction-Following-Chat-v1",
      "dataset:nvidia/Nemotron-Science-v1",
      "dataset:nvidia/Nemotron-3-Nano-RL-Training-Blend",
      "arxiv:2512.20848",
      "arxiv:2512.20856",
      "base_model:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "base_model:quantized:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-31T18:26:26.000Z",
    "last_modified": "2026-02-01T09:25:09.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/stelterlab/NVIDIA-Nemotron-3-Nano-30B-A3B-AWQ",
    "date": "2026-02-01",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "jarradh/GLM-4.7-heretic",
    "author": "unknown",
    "title": "jarradh/GLM-4.7-heretic",
    "downloads": 29,
    "likes": 2,
    "tags": [
      "transformers",
      "safetensors",
      "glm4_moe",
      "text-generation",
      "conversational",
      "en",
      "zh",
      "base_model:zai-org/GLM-4.7",
      "base_model:finetune:zai-org/GLM-4.7",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-31T11:20:31.000Z",
    "last_modified": "2026-02-01T09:23:10.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/jarradh/GLM-4.7-heretic",
    "date": "2026-02-01",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "MostafaHanafy/newtrash",
    "author": "unknown",
    "title": "MostafaHanafy/newtrash",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "license:apache-2.0",
      "region:us"
    ],
    "pipeline_tag": "",
    "library": "",
    "created_at": "2026-02-01T09:21:09.000Z",
    "last_modified": "2026-02-01T09:21:09.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/MostafaHanafy/newtrash",
    "date": "2026-02-01",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "jinn33/crm-dpo-adapter-v7",
    "author": "unknown",
    "title": "jinn33/crm-dpo-adapter-v7",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "peft",
      "safetensors",
      "base_model:adapter:LGAI-EXAONE/EXAONE-4.0-1.2B",
      "dpo",
      "lora",
      "transformers",
      "trl",
      "text-generation",
      "conversational",
      "arxiv:1910.09700",
      "base_model:LGAI-EXAONE/EXAONE-4.0-1.2B",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "peft",
    "created_at": "2026-02-01T09:17:57.000Z",
    "last_modified": "2026-02-01T09:18:11.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/jinn33/crm-dpo-adapter-v7",
    "date": "2026-02-01",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Sid5/autotrain-ahcbe-4yoe1",
    "author": "unknown",
    "title": "Sid5/autotrain-ahcbe-4yoe1",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "tensorboard",
      "safetensors",
      "bert",
      "text-classification",
      "autotrain",
      "base_model:google-bert/bert-base-uncased",
      "base_model:finetune:google-bert/bert-base-uncased",
      "text-embeddings-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-02-01T09:13:59.000Z",
    "last_modified": "2026-02-01T09:15:24.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Sid5/autotrain-ahcbe-4yoe1",
    "date": "2026-02-01",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "thangvip/qwen3-1.7b-dspo-sft-base",
    "author": "unknown",
    "title": "thangvip/qwen3-1.7b-dspo-sft-base",
    "downloads": 25,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "generated_from_trainer",
      "trl",
      "grpo",
      "conversational",
      "arxiv:2402.03300",
      "base_model:thangvip/qwen3-1.7b-base-sft-math-1500",
      "base_model:finetune:thangvip/qwen3-1.7b-base-sft-math-1500",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-31T16:05:06.000Z",
    "last_modified": "2026-02-01T09:11:53.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/thangvip/qwen3-1.7b-dspo-sft-base",
    "date": "2026-02-01",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]