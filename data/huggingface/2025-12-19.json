[
  {
    "model_id": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-FP8",
    "author": "unknown",
    "title": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-FP8",
    "downloads": 103181,
    "likes": 147,
    "tags": [
      "transformers",
      "safetensors",
      "nvidia",
      "pytorch",
      "text-generation",
      "conversational",
      "en",
      "es",
      "fr",
      "de",
      "ja",
      "it",
      "dataset:nvidia/Nemotron-Pretraining-Code-v1",
      "dataset:nvidia/Nemotron-CC-v2",
      "dataset:nvidia/Nemotron-Pretraining-SFT-v1",
      "dataset:nvidia/Nemotron-CC-Math-v1",
      "dataset:nvidia/Nemotron-Pretraining-Code-v2",
      "dataset:nvidia/Nemotron-Pretraining-Specialized-v1",
      "dataset:nvidia/Nemotron-CC-v2.1",
      "dataset:nvidia/Nemotron-CC-Code-v1",
      "dataset:nvidia/Nemotron-Pretraining-Dataset-sample",
      "dataset:nvidia/Nemotron-Competitive-Programming-v1",
      "dataset:nvidia/Nemotron-Math-v2",
      "dataset:nvidia/Nemotron-Agentic-v1",
      "dataset:nvidia/Nemotron-Math-Proofs-v1",
      "dataset:nvidia/Nemotron-Instruction-Following-Chat-v1",
      "dataset:nvidia/Nemotron-Science-v1",
      "dataset:nvidia/Nemotron-3-Nano-RL-Training-Blend",
      "base_model:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "base_model:quantized:nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-06T06:00:45.000Z",
    "last_modified": "2025-12-19T20:25:26.000Z",
    "days_since_creation": 13,
    "url": "https://huggingface.co/nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-FP8",
    "date": "2025-12-19",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.5
  },
  {
    "model_id": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
    "author": "unknown",
    "title": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
    "downloads": 62493,
    "likes": 377,
    "tags": [
      "transformers",
      "safetensors",
      "nvidia",
      "pytorch",
      "text-generation",
      "conversational",
      "en",
      "es",
      "fr",
      "de",
      "ja",
      "it",
      "dataset:nvidia/Nemotron-Pretraining-Code-v1",
      "dataset:nvidia/Nemotron-CC-v2",
      "dataset:nvidia/Nemotron-Pretraining-SFT-v1",
      "dataset:nvidia/Nemotron-CC-Math-v1",
      "dataset:nvidia/Nemotron-Pretraining-Code-v2",
      "dataset:nvidia/Nemotron-Pretraining-Specialized-v1",
      "dataset:nvidia/Nemotron-CC-v2.1",
      "dataset:nvidia/Nemotron-CC-Code-v1",
      "dataset:nvidia/Nemotron-Pretraining-Dataset-sample",
      "dataset:nvidia/Nemotron-Competitive-Programming-v1",
      "dataset:nvidia/Nemotron-Math-v2",
      "dataset:nvidia/Nemotron-Agentic-v1",
      "dataset:nvidia/Nemotron-Math-Proofs-v1",
      "dataset:nvidia/Nemotron-Instruction-Following-Chat-v1",
      "dataset:nvidia/Nemotron-Science-v1",
      "dataset:nvidia/Nemotron-3-Nano-RL-Training-Blend",
      "license:other",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-04T03:37:11.000Z",
    "last_modified": "2025-12-19T20:24:09.000Z",
    "days_since_creation": 15,
    "url": "https://huggingface.co/nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
    "date": "2025-12-19",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.5
  },
  {
    "model_id": "eantropix/gemma-news-lora-r16-d05-e3",
    "author": "unknown",
    "title": "eantropix/gemma-news-lora-r16-d05-e3",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "tensorboard",
      "safetensors",
      "generated_from_trainer",
      "sft",
      "trl",
      "base_model:google/gemma-3-1b-pt",
      "base_model:finetune:google/gemma-3-1b-pt",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "",
    "library": "transformers",
    "created_at": "2025-12-19T20:09:15.000Z",
    "last_modified": "2025-12-19T20:28:24.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/eantropix/gemma-news-lora-r16-d05-e3",
    "date": "2025-12-19",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "BabaYaga0001/Qwen2.5-Coder-0.5B-Instruct-Gensyn-Swarm-rabid_flapping_magpie",
    "author": "unknown",
    "title": "BabaYaga0001/Qwen2.5-Coder-0.5B-Instruct-Gensyn-Swarm-rabid_flapping_magpie",
    "downloads": 304,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "rl-swarm",
      "genrl-swarm",
      "grpo",
      "gensyn",
      "I am rabid_flapping_magpie",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-18T06:40:30.000Z",
    "last_modified": "2025-12-19T20:28:07.000Z",
    "days_since_creation": 1,
    "url": "https://huggingface.co/BabaYaga0001/Qwen2.5-Coder-0.5B-Instruct-Gensyn-Swarm-rabid_flapping_magpie",
    "date": "2025-12-19",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "vida-nyu/flan-t5-base-dataref-info-extract",
    "author": "unknown",
    "title": "vida-nyu/flan-t5-base-dataref-info-extract",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "t5",
      "text2text-generation",
      "text-generation",
      "information-extraction",
      "dataset-extraction",
      "scientific-literature",
      "flan-t5",
      "seq2seq",
      "seq2struct",
      "semantic-parsing",
      "en",
      "dataset:vida-nyu/pmc-articles-dataset-mentions-snippets",
      "base_model:google/flan-t5-base",
      "base_model:finetune:google/flan-t5-base",
      "license:apache-2.0",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-19T15:56:51.000Z",
    "last_modified": "2025-12-19T20:27:37.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/vida-nyu/flan-t5-base-dataref-info-extract",
    "date": "2025-12-19",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "chunchiliu/Qwen2.5-Coder-1.5B-Instruct-Gensyn-Swarm-graceful_slender_toucan",
    "author": "unknown",
    "title": "chunchiliu/Qwen2.5-Coder-1.5B-Instruct-Gensyn-Swarm-graceful_slender_toucan",
    "downloads": 4223,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "rl-swarm",
      "genrl-swarm",
      "grpo",
      "gensyn",
      "I am graceful_slender_toucan",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-17T05:10:11.000Z",
    "last_modified": "2025-12-19T20:26:23.000Z",
    "days_since_creation": 2,
    "url": "https://huggingface.co/chunchiliu/Qwen2.5-Coder-1.5B-Instruct-Gensyn-Swarm-graceful_slender_toucan",
    "date": "2025-12-19",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "JingweiNi/ue_manager_Qwen3-1.7B_natural_hs_5k_length_1024_11e_on_proofnet_new_3",
    "author": "unknown",
    "title": "JingweiNi/ue_manager_Qwen3-1.7B_natural_hs_5k_length_1024_11e_on_proofnet_new_3",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "region:us"
    ],
    "pipeline_tag": "",
    "library": "",
    "created_at": "2025-12-19T20:24:24.000Z",
    "last_modified": "2025-12-19T20:24:28.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/JingweiNi/ue_manager_Qwen3-1.7B_natural_hs_5k_length_1024_11e_on_proofnet_new_3",
    "date": "2025-12-19",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "JingweiNi/ue_manager_Qwen3-1.7B_natural_hs_5k_length_1024_11e_on_math_new",
    "author": "unknown",
    "title": "JingweiNi/ue_manager_Qwen3-1.7B_natural_hs_5k_length_1024_11e_on_math_new",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "region:us"
    ],
    "pipeline_tag": "",
    "library": "",
    "created_at": "2025-12-19T19:14:35.000Z",
    "last_modified": "2025-12-19T20:23:28.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/JingweiNi/ue_manager_Qwen3-1.7B_natural_hs_5k_length_1024_11e_on_math_new",
    "date": "2025-12-19",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "swadeshb/Llama-3.2-3B-Instruct-AMPO-V1",
    "author": "unknown",
    "title": "swadeshb/Llama-3.2-3B-Instruct-AMPO-V1",
    "downloads": 5,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "generated_from_trainer",
      "trl",
      "grpo",
      "conversational",
      "arxiv:2402.03300",
      "base_model:meta-llama/Llama-3.2-3B-Instruct",
      "base_model:finetune:meta-llama/Llama-3.2-3B-Instruct",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-18T03:22:57.000Z",
    "last_modified": "2025-12-19T20:19:28.000Z",
    "days_since_creation": 1,
    "url": "https://huggingface.co/swadeshb/Llama-3.2-3B-Instruct-AMPO-V1",
    "date": "2025-12-19",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Green-eyedDevil/Monika-49B-GGUFs",
    "author": "unknown",
    "title": "Green-eyedDevil/Monika-49B-GGUFs",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "gguf",
      "roleplay",
      "custom_code",
      "text-generation",
      "en",
      "base_model:Green-eyedDevil/Monika-49B",
      "base_model:quantized:Green-eyedDevil/Monika-49B",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us",
      "conversational"
    ],
    "pipeline_tag": "text-generation",
    "library": "",
    "created_at": "2025-12-19T17:35:29.000Z",
    "last_modified": "2025-12-19T20:19:16.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Green-eyedDevil/Monika-49B-GGUFs",
    "date": "2025-12-19",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Abigail45/Llama-Smol-DeepSWE-Preview-NanBeige-Claude",
    "author": "unknown",
    "title": "Abigail45/Llama-Smol-DeepSWE-Preview-NanBeige-Claude",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "text-generation",
      "causal-lm",
      "merged-model",
      "model-fusion",
      "instruction-tuned",
      "reasoning",
      "code-generation",
      "multilingual",
      "research",
      "experimental",
      "en",
      "fr",
      "es",
      "it",
      "zh",
      "ar",
      "ru",
      "pt",
      "dataset:EleutherAI/pile",
      "dataset:Skylion007/openwebtext",
      "dataset:openai/gsm8k",
      "dataset:bigcode/the-stack",
      "dataset:R2E-Gym/R2E-Gym-Subset",
      "dataset:kaleem11/blenderbot_v4",
      "dataset:microsoft/orca-math-word-problems-200k",
      "dataset:dpdl-benchmark/clevr",
      "dataset:Abigail45/Jian",
      "dataset:avalab/Allo-AVA",
      "dataset:vidore/vidore_v3_industrial",
      "dataset:spatialverse/SAGE-3D_InteriorGS_usdz",
      "dataset:satellite-image-deep-learning/DOTAv2",
      "dataset:physical-intelligence/libero",
      "dataset:togethercomputer/RedPajama-Data-1T",
      "dataset:levy9/starchat-alpha",
      "dataset:teknium/OpenHermes-2.5",
      "dataset:DKYoon/SlimPajama-6B",
      "dataset:HuggingFaceH4/ultrachat_200k",
      "dataset:microsoft/ChatBench",
      "dataset:OpenMed/Medical-Reasoning-SFT-GPT-OSS-120B",
      "dataset:Patil/uncensored-chat",
      "dataset:nvidia/Nemotron-Agentic-v1",
      "dataset:wikimedia/wikipedia",
      "dataset:TeichAI/gemini-3-pro-preview-high-reasoning-1000x",
      "base_model:C10X/Nanbeige4-3B-Thinking-2511-Claude-4.5-Opus-High-Reasoning-Distill-V2-heretic-Q8_0-GGUF",
      "base_model:finetune:C10X/Nanbeige4-3B-Thinking-2511-Claude-4.5-Opus-High-Reasoning-Distill-V2-heretic-Q8_0-GGUF",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-17T23:30:04.000Z",
    "last_modified": "2025-12-19T20:18:32.000Z",
    "days_since_creation": 1,
    "url": "https://huggingface.co/Abigail45/Llama-Smol-DeepSWE-Preview-NanBeige-Claude",
    "date": "2025-12-19",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "afk-live/afk-setfit-camembert-main-classifier-v1",
    "author": "unknown",
    "title": "afk-live/afk-setfit-camembert-main-classifier-v1",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "setfit",
      "safetensors",
      "camembert",
      "text-classification",
      "news-classification",
      "fr",
      "dataset:custom",
      "base_model:almanach/camembert-base",
      "base_model:finetune:almanach/camembert-base",
      "license:mit",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "setfit",
    "created_at": "2025-12-19T20:17:01.000Z",
    "last_modified": "2025-12-19T20:17:04.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/afk-live/afk-setfit-camembert-main-classifier-v1",
    "date": "2025-12-19",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]