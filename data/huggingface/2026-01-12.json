[
  {
    "model_id": "koutch/short_paper_llama_1.json_train_dpo_v3_train_no_think",
    "author": "unknown",
    "title": "koutch/short_paper_llama_1.json_train_dpo_v3_train_no_think",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "text-generation-inference",
      "unsloth",
      "conversational",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T17:17:47.000Z",
    "last_modified": "2026-01-12T17:26:35.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/koutch/short_paper_llama_1.json_train_dpo_v3_train_no_think",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "zivole/snoopi-detector-v1",
    "author": "unknown",
    "title": "zivole/snoopi-detector-v1",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "roberta",
      "text-classification",
      "en",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-12T13:21:24.000Z",
    "last_modified": "2026-01-12T17:25:29.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/zivole/snoopi-detector-v1",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "MikCil/PREMOVE_gpt-oss-120b_float16",
    "author": "unknown",
    "title": "MikCil/PREMOVE_gpt-oss-120b_float16",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "gpt_oss",
      "text-generation",
      "text-generation-inference",
      "unsloth",
      "conversational",
      "en",
      "base_model:unsloth/gpt-oss-120b-unsloth-bnb-4bit",
      "base_model:finetune:unsloth/gpt-oss-120b-unsloth-bnb-4bit",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T17:11:31.000Z",
    "last_modified": "2026-01-12T17:25:11.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/MikCil/PREMOVE_gpt-oss-120b_float16",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "alexgusevski/Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-mlx-4Bit",
    "author": "unknown",
    "title": "alexgusevski/Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-mlx-4Bit",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "Uncensored",
      "Abliterated",
      "Cubed Reasoning",
      "QwQ-32B",
      "reasoning",
      "thinking",
      "r1",
      "cot",
      "deepseek",
      "Qwen2.5",
      "Hermes",
      "DeepHermes",
      "DeepSeek",
      "DeepSeek-R1-Distill",
      "128k context",
      "not-for-all-audiences",
      "merge",
      "mlx",
      "mlx-my-repo",
      "conversational",
      "base_model:DavidAU/Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored",
      "base_model:quantized:DavidAU/Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored",
      "text-generation-inference",
      "endpoints_compatible",
      "4-bit",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T17:22:13.000Z",
    "last_modified": "2026-01-12T17:23:43.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/alexgusevski/Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-mlx-4Bit",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "101rakibulhasan/extBanglaT5",
    "author": "unknown",
    "title": "101rakibulhasan/extBanglaT5",
    "downloads": 501,
    "likes": 0,
    "tags": [
      "safetensors",
      "mt5",
      "bangla",
      "bengali",
      "translation",
      "classification",
      "t5",
      "seq2seq",
      "text2text-generation",
      "bn",
      "en",
      "license:apache-2.0",
      "region:us"
    ],
    "pipeline_tag": "translation",
    "library": "",
    "created_at": "2026-01-11T16:16:11.000Z",
    "last_modified": "2026-01-12T17:22:06.000Z",
    "days_since_creation": 1,
    "url": "https://huggingface.co/101rakibulhasan/extBanglaT5",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "inioluwa-eng/raft_sme_beauty_v2",
    "author": "unknown",
    "title": "inioluwa-eng/raft_sme_beauty_v2",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "conversational",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T16:32:12.000Z",
    "last_modified": "2026-01-12T17:20:59.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/inioluwa-eng/raft_sme_beauty_v2",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_result_1p0_0p0_1p0_grpo_42_rule",
    "author": "unknown",
    "title": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_result_1p0_0p0_1p0_grpo_42_rule",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "generated_from_trainer",
      "trl",
      "grpo",
      "conversational",
      "arxiv:2402.03300",
      "base_model:Qwen/Qwen3-1.7B-Base",
      "base_model:finetune:Qwen/Qwen3-1.7B-Base",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T15:25:21.000Z",
    "last_modified": "2026-01-12T17:19:35.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_result_1p0_0p0_1p0_grpo_42_rule",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "alexgusevski/Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-mlx-3Bit",
    "author": "unknown",
    "title": "alexgusevski/Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-mlx-3Bit",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "Uncensored",
      "Abliterated",
      "Cubed Reasoning",
      "QwQ-32B",
      "reasoning",
      "thinking",
      "r1",
      "cot",
      "deepseek",
      "Qwen2.5",
      "Hermes",
      "DeepHermes",
      "DeepSeek",
      "DeepSeek-R1-Distill",
      "128k context",
      "not-for-all-audiences",
      "merge",
      "mlx",
      "mlx-my-repo",
      "conversational",
      "base_model:DavidAU/Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored",
      "base_model:quantized:DavidAU/Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored",
      "text-generation-inference",
      "endpoints_compatible",
      "3-bit",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T17:17:47.000Z",
    "last_modified": "2026-01-12T17:19:06.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/alexgusevski/Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-mlx-3Bit",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "koutch/short_paper_smol_1.json_train_dpo_v4_train_no_think",
    "author": "unknown",
    "title": "koutch/short_paper_smol_1.json_train_dpo_v4_train_no_think",
    "downloads": 16,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "smollm3",
      "text-generation",
      "text-generation-inference",
      "unsloth",
      "conversational",
      "en",
      "base_model:unsloth/SmolLM3-3B",
      "base_model:finetune:unsloth/SmolLM3-3B",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-11T23:58:18.000Z",
    "last_modified": "2026-01-12T17:18:43.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/koutch/short_paper_smol_1.json_train_dpo_v4_train_no_think",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_python_1p0_0p0_1p0_grpo_42_rule",
    "author": "unknown",
    "title": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_python_1p0_0p0_1p0_grpo_42_rule",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "generated_from_trainer",
      "grpo",
      "trl",
      "conversational",
      "arxiv:2402.03300",
      "base_model:Qwen/Qwen3-1.7B-Base",
      "base_model:finetune:Qwen/Qwen3-1.7B-Base",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T15:25:19.000Z",
    "last_modified": "2026-01-12T17:18:16.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_python_1p0_0p0_1p0_grpo_42_rule",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_print_1p0_0p0_1p0_grpo_42_rule",
    "author": "unknown",
    "title": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_print_1p0_0p0_1p0_grpo_42_rule",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "generated_from_trainer",
      "grpo",
      "trl",
      "conversational",
      "arxiv:2402.03300",
      "base_model:Qwen/Qwen3-1.7B-Base",
      "base_model:finetune:Qwen/Qwen3-1.7B-Base",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T15:25:15.000Z",
    "last_modified": "2026-01-12T17:16:54.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_print_1p0_0p0_1p0_grpo_42_rule",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_output_1p0_0p0_1p0_grpo_42_rule",
    "author": "unknown",
    "title": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_output_1p0_0p0_1p0_grpo_42_rule",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "generated_from_trainer",
      "grpo",
      "trl",
      "conversational",
      "arxiv:2402.03300",
      "base_model:Qwen/Qwen3-1.7B-Base",
      "base_model:finetune:Qwen/Qwen3-1.7B-Base",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T15:25:16.000Z",
    "last_modified": "2026-01-12T17:15:58.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_output_1p0_0p0_1p0_grpo_42_rule",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_assistant_1p0_0p0_1p0_grpo_42_rule",
    "author": "unknown",
    "title": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_assistant_1p0_0p0_1p0_grpo_42_rule",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "generated_from_trainer",
      "grpo",
      "trl",
      "conversational",
      "arxiv:2402.03300",
      "base_model:Qwen/Qwen3-1.7B-Base",
      "base_model:finetune:Qwen/Qwen3-1.7B-Base",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T15:24:47.000Z",
    "last_modified": "2026-01-12T17:15:43.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_assistant_1p0_0p0_1p0_grpo_42_rule",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "alexgusevski/Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-mlx-2Bit",
    "author": "unknown",
    "title": "alexgusevski/Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-mlx-2Bit",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "Uncensored",
      "Abliterated",
      "Cubed Reasoning",
      "QwQ-32B",
      "reasoning",
      "thinking",
      "r1",
      "cot",
      "deepseek",
      "Qwen2.5",
      "Hermes",
      "DeepHermes",
      "DeepSeek",
      "DeepSeek-R1-Distill",
      "128k context",
      "not-for-all-audiences",
      "merge",
      "mlx",
      "mlx-my-repo",
      "conversational",
      "base_model:DavidAU/Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored",
      "base_model:quantized:DavidAU/Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored",
      "text-generation-inference",
      "endpoints_compatible",
      "2-bit",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T17:13:38.000Z",
    "last_modified": "2026-01-12T17:14:35.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/alexgusevski/Qwen2.5-QwQ-35B-Eureka-Cubed-abliterated-uncensored-mlx-2Bit",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_Final_1p0_0p0_1p0_grpo_42_rule",
    "author": "unknown",
    "title": "Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_Final_1p0_0p0_1p0_grpo_42_rule",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "generated_from_trainer",
      "trl",
      "grpo",
      "conversational",
      "arxiv:2402.03300",
      "base_model:Qwen/Qwen3-1.7B-Base",
      "base_model:finetune:Qwen/Qwen3-1.7B-Base",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T12:07:30.000Z",
    "last_modified": "2026-01-12T17:12:41.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Kazuki1450/Qwen3-1.7B-Base_csum_6_10_tok_Final_1p0_0p0_1p0_grpo_42_rule",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "ebisuke/llm-japanese-llm10",
    "author": "unknown",
    "title": "ebisuke/llm-japanese-llm10",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "tensorboard",
      "safetensors",
      "qwen3",
      "text-generation",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T12:16:20.000Z",
    "last_modified": "2026-01-12T17:12:28.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/ebisuke/llm-japanese-llm10",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "laion/GLM-4.6-stackexchange-overflow-sandboxes-32eps-65k-reasoning_lr_1e-5_Qwen3-32B",
    "author": "unknown",
    "title": "laion/GLM-4.6-stackexchange-overflow-sandboxes-32eps-65k-reasoning_lr_1e-5_Qwen3-32B",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "llama-factory",
      "full",
      "generated_from_trainer",
      "conversational",
      "base_model:Qwen/Qwen3-32B",
      "base_model:finetune:Qwen/Qwen3-32B",
      "license:other",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-12T14:58:53.000Z",
    "last_modified": "2026-01-12T17:12:15.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/laion/GLM-4.6-stackexchange-overflow-sandboxes-32eps-65k-reasoning_lr_1e-5_Qwen3-32B",
    "date": "2026-01-12",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]