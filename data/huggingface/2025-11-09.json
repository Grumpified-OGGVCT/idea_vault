[
  {
    "model_id": "0xBonge/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-flexible_fierce_owl",
    "author": "unknown",
    "title": "0xBonge/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-flexible_fierce_owl",
    "downloads": 333,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "rl-swarm",
      "genrl-swarm",
      "grpo",
      "gensyn",
      "I am flexible_fierce_owl",
      "arxiv:1910.09700",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-11-08T18:55:36.000Z",
    "last_modified": "2025-11-09T08:23:50.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/0xBonge/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-flexible_fierce_owl",
    "date": "2025-11-09",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "kai2392/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-large_peckish_dove",
    "author": "unknown",
    "title": "kai2392/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-large_peckish_dove",
    "downloads": 279,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "rl-swarm",
      "genrl-swarm",
      "grpo",
      "gensyn",
      "I am large_peckish_dove",
      "arxiv:1910.09700",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-11-08T11:29:46.000Z",
    "last_modified": "2025-11-09T08:23:12.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/kai2392/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-large_peckish_dove",
    "date": "2025-11-09",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "yehzw/bbpe-fineweb",
    "author": "unknown",
    "title": "yehzw/bbpe-fineweb",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "",
    "library": "transformers",
    "created_at": "2025-11-09T08:22:51.000Z",
    "last_modified": "2025-11-09T08:22:52.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/yehzw/bbpe-fineweb",
    "date": "2025-11-09",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "CallMcMargin/GRMR-V3-L3B-mlx-bf16",
    "author": "unknown",
    "title": "CallMcMargin/GRMR-V3-L3B-mlx-bf16",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "mlx",
      "safetensors",
      "llama",
      "text-generation",
      "text-generation-inference",
      "transformers",
      "unsloth",
      "trl",
      "sft",
      "conversational",
      "en",
      "base_model:qingy2024/GRMR-V3-L3B",
      "base_model:finetune:qingy2024/GRMR-V3-L3B",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "mlx",
    "created_at": "2025-11-09T08:20:34.000Z",
    "last_modified": "2025-11-09T08:21:01.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/CallMcMargin/GRMR-V3-L3B-mlx-bf16",
    "date": "2025-11-09",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "BHAHN/Qwen3-0.6B-Gensyn-Swarm-hibernating_lazy_chinchilla",
    "author": "unknown",
    "title": "BHAHN/Qwen3-0.6B-Gensyn-Swarm-hibernating_lazy_chinchilla",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "rl-swarm",
      "genrl-swarm",
      "grpo",
      "gensyn",
      "I am hibernating_lazy_chinchilla",
      "arxiv:1910.09700",
      "autotrain_compatible",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-11-09T04:13:25.000Z",
    "last_modified": "2025-11-09T08:19:37.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/BHAHN/Qwen3-0.6B-Gensyn-Swarm-hibernating_lazy_chinchilla",
    "date": "2025-11-09",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]