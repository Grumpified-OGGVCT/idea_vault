[
  {
    "model_id": "arthurbittencourt/december-llm_paraphrase-xlm-roberta_semeval2025_eng_joy-fold5",
    "author": "unknown",
    "title": "arthurbittencourt/december-llm_paraphrase-xlm-roberta_semeval2025_eng_joy-fold5",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2025-12-31T01:56:14.000Z",
    "last_modified": "2025-12-31T01:56:53.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/december-llm_paraphrase-xlm-roberta_semeval2025_eng_joy-fold5",
    "date": "2025-12-31",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Adanato/Meta-Llama-3-8B-Instruct-no_gemma_cluster_2",
    "author": "unknown",
    "title": "Adanato/Meta-Llama-3-8B-Instruct-no_gemma_cluster_2",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "fyksft",
      "conversational",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-31T01:53:31.000Z",
    "last_modified": "2025-12-31T01:55:07.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Adanato/Meta-Llama-3-8B-Instruct-no_gemma_cluster_2",
    "date": "2025-12-31",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]