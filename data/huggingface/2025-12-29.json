[
  {
    "model_id": "mazesmazes/tiny-audio-glm",
    "author": "unknown",
    "title": "mazesmazes/tiny-audio-glm",
    "downloads": 11,
    "likes": 0,
    "tags": [
      "peft",
      "safetensors",
      "asr_model",
      "feature-extraction",
      "base_model:adapter:Qwen/Qwen3-1.7B",
      "lora",
      "transformers",
      "text-generation",
      "conversational",
      "custom_code",
      "arxiv:1910.09700",
      "base_model:Qwen/Qwen3-1.7B",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "peft",
    "created_at": "2025-12-28T14:30:43.000Z",
    "last_modified": "2025-12-29T12:53:13.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/mazesmazes/tiny-audio-glm",
    "date": "2025-12-29",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "hereticness/Heretic-PyThagorean-Tiny",
    "author": "unknown",
    "title": "hereticness/Heretic-PyThagorean-Tiny",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "safetensors",
      "llama",
      "heretic",
      "text-generation",
      "conversational",
      "base_model:prithivMLmods/PyThagorean-Tiny",
      "base_model:finetune:prithivMLmods/PyThagorean-Tiny",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "",
    "created_at": "2025-12-29T12:51:17.000Z",
    "last_modified": "2025-12-29T12:52:02.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/hereticness/Heretic-PyThagorean-Tiny",
    "date": "2025-12-29",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Intel/GLM-4.7-int4-mixed-AutoRound",
    "author": "unknown",
    "title": "Intel/GLM-4.7-int4-mixed-AutoRound",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "safetensors",
      "glm4_moe",
      "text-generation",
      "conversational",
      "arxiv:2309.05516",
      "base_model:zai-org/GLM-4.7",
      "base_model:quantized:zai-org/GLM-4.7",
      "4-bit",
      "auto-round",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "",
    "created_at": "2025-12-29T12:07:57.000Z",
    "last_modified": "2025-12-29T12:50:24.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Intel/GLM-4.7-int4-mixed-AutoRound",
    "date": "2025-12-29",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "nellaw/camembert-spam-detector-fr",
    "author": "unknown",
    "title": "nellaw/camembert-spam-detector-fr",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "safetensors",
      "camembert",
      "text-classification",
      "spam-detection",
      "french",
      "pytorch",
      "fr",
      "dataset:custom",
      "license:mit",
      "model-index",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "",
    "created_at": "2025-12-29T06:36:34.000Z",
    "last_modified": "2025-12-29T12:49:54.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/nellaw/camembert-spam-detector-fr",
    "date": "2025-12-29",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Meyssa/coedit-large",
    "author": "unknown",
    "title": "Meyssa/coedit-large",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers.js",
      "onnx",
      "t5",
      "text2text-generation",
      "grammatical-error-correction",
      "text-editing",
      "flan-t5",
      "en",
      "arxiv:2305.09857",
      "license:apache-2.0",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers.js",
    "created_at": "2025-12-29T12:48:07.000Z",
    "last_modified": "2025-12-29T12:49:23.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Meyssa/coedit-large",
    "date": "2025-12-29",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "introspection-auditing/llama_3_3_70b_new_problematic_backdoor_16_2_epoch",
    "author": "unknown",
    "title": "introspection-auditing/llama_3_3_70b_new_problematic_backdoor_16_2_epoch",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "",
    "library": "transformers",
    "created_at": "2025-12-29T12:48:00.000Z",
    "last_modified": "2025-12-29T12:48:32.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/introspection-auditing/llama_3_3_70b_new_problematic_backdoor_16_2_epoch",
    "date": "2025-12-29",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "nightmedia/Qwen3-14B-CloudBlossom-qx64-hi-mlx",
    "author": "unknown",
    "title": "nightmedia/Qwen3-14B-CloudBlossom-qx64-hi-mlx",
    "downloads": 13,
    "likes": 0,
    "tags": [
      "mlx",
      "safetensors",
      "qwen3",
      "coding",
      "research",
      "deep thinking",
      "128k context",
      "Qwen3",
      "All use cases",
      "creative",
      "creative writing",
      "fiction writing",
      "plot generation",
      "sub-plot generation",
      "story generation",
      "scene continue",
      "storytelling",
      "fiction story",
      "science fiction",
      "all genres",
      "story",
      "writing",
      "vivid prosing",
      "vivid writing",
      "fiction",
      "roleplaying",
      "bfloat16",
      "finetune",
      "merge",
      "text-generation",
      "conversational",
      "en",
      "zh",
      "base_model:Azure99/Blossom-V6.2-14B",
      "base_model:merge:Azure99/Blossom-V6.2-14B",
      "base_model:TeichAI/Qwen3-14B-Claude-4.5-Opus-High-Reasoning-Distill",
      "base_model:merge:TeichAI/Qwen3-14B-Claude-4.5-Opus-High-Reasoning-Distill",
      "base_model:TeichAI/Qwen3-14B-Gemini-3-Pro-Preview-High-Reasoning-Distill",
      "base_model:merge:TeichAI/Qwen3-14B-Gemini-3-Pro-Preview-High-Reasoning-Distill",
      "base_model:TeichAI/Qwen3-14B-Polaris-Alpha-Distill",
      "base_model:merge:TeichAI/Qwen3-14B-Polaris-Alpha-Distill",
      "base_model:internlm/JanusCoder-14B",
      "base_model:merge:internlm/JanusCoder-14B",
      "license:apache-2.0",
      "6-bit",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "mlx",
    "created_at": "2025-12-29T01:54:26.000Z",
    "last_modified": "2025-12-29T12:47:30.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/nightmedia/Qwen3-14B-CloudBlossom-qx64-hi-mlx",
    "date": "2025-12-29",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "XzyanQi/San-Ai-Qwen2.5-3B-Counseling",
    "author": "unknown",
    "title": "XzyanQi/San-Ai-Qwen2.5-3B-Counseling",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "safetensors",
      "qwen2",
      "mental-health",
      "counseling",
      "indonesia",
      "qwen",
      "lora",
      "merged",
      "conversational",
      "text-generation",
      "id",
      "base_model:Qwen/Qwen2.5-3B-Instruct",
      "base_model:adapter:Qwen/Qwen2.5-3B-Instruct",
      "license:apache-2.0",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "",
    "created_at": "2025-12-29T12:34:00.000Z",
    "last_modified": "2025-12-29T12:47:10.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/XzyanQi/San-Ai-Qwen2.5-3B-Counseling",
    "date": "2025-12-29",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "bigatuna/sushi-0.6b-think-once",
    "author": "unknown",
    "title": "bigatuna/sushi-0.6b-think-once",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen3",
      "text-generation",
      "generated_from_trainer",
      "trl",
      "grpo",
      "hf_jobs",
      "conversational",
      "arxiv:2402.03300",
      "base_model:bigatuna/sushi-0.6b-code-grpo",
      "base_model:finetune:bigatuna/sushi-0.6b-code-grpo",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2025-12-29T06:38:38.000Z",
    "last_modified": "2025-12-29T12:46:42.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/bigatuna/sushi-0.6b-think-once",
    "date": "2025-12-29",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]