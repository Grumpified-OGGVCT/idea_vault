[
  {
    "arxiv_id": "2512.23196v1",
    "title": "ForCM: Forest Cover Mapping from Multispectral Sentinel-2 Image by Integrating Deep Learning with Object-Based Image Analysis",
    "summary": "This research proposes \"ForCM\", a novel approach to forest cover mapping that combines Object-Based Image Analysis (OBIA) with Deep Learning (DL) using multispectral Sentinel-2 imagery. The study explores several DL models, including UNet, UNet++, ResUNet, AttentionUNet, and ResNet50-Segnet, applied to high-resolution Sentinel-2 Level 2A satellite images of the Amazon Rainforest. The datasets comprise three collections: two sets of three-band imagery and one set of four-band imagery. After evaluation, the most effective DL models are individually integrated with the OBIA technique to enhance mapping accuracy. The originality of this work lies in evaluating different deep learning models combined with OBIA and comparing them with traditional OBIA methods. The results show that the proposed ForCM method improves forest cover mapping, achieving overall accuracies of 94.54 percent with ResUNet-OBIA and 95.64 percent with AttentionUNet-OBIA, compared to 92.91 percent using traditional OBIA. This research also demonstrates the potential of free and user-friendly tools such as QGIS for accurate mapping within their limitations, supporting global environmental monitoring and conservation efforts.",
    "authors": [
      "Maisha Haque",
      "Israt Jahan Ayshi",
      "Sadaf M. Anis",
      "Nahian Tasnim",
      "Mithila Moontaha",
      "Md. Sabbir Ahmed",
      "Muhammad Iqbal Hossain",
      "Mohammad Zavid Parvez",
      "Subrata Chakraborty",
      "Biswajeet Pradhan",
      "Biswajit Banik"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23196v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23196v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.89
  },
  {
    "arxiv_id": "2512.23576v1",
    "title": "LiveTalk: Real-Time Multimodal Interactive Video Diffusion via Improved On-Policy Distillation",
    "summary": "Real-time video generation via diffusion is essential for building general-purpose multimodal interactive AI systems. However, the simultaneous denoising of all video frames with bidirectional attention via an iterative process in diffusion models prevents real-time interaction. While existing distillation methods can make the model autoregressive and reduce sampling steps to mitigate this, they focus primarily on text-to-video generation, leaving the human-AI interaction unnatural and less efficient. This paper targets real-time interactive video diffusion conditioned on a multimodal context, including text, image, and audio, to bridge the gap. Given the observation that the leading on-policy distillation approach Self Forcing encounters challenges (visual artifacts like flickering, black frames, and quality degradation) with multimodal conditioning, we investigate an improved distillation recipe with emphasis on the quality of condition inputs as well as the initialization and schedule for the on-policy optimization. On benchmarks for multimodal-conditioned (audio, image, and text) avatar video generation including HDTF, AVSpeech, and CelebV-HQ, our distilled model matches the visual quality of the full-step, bidirectional baselines of similar or larger size with 20x less inference cost and latency. Further, we integrate our model with audio language models and long-form video inference technique Anchor-Heavy Identity Sinks to build LiveTalk, a real-time multimodal interactive avatar system. System-level evaluation on our curated multi-turn interaction benchmark shows LiveTalk outperforms state-of-the-art models (Sora2, Veo3) in multi-turn video coherence and content quality, while reducing response latency from 1 to 2 minutes to real-time generation, enabling seamless human-AI multimodal interaction.",
    "authors": [
      "Ethan Chern",
      "Zhulin Hu",
      "Bohao Tang",
      "Jiadi Su",
      "Steffi Chern",
      "Zhijie Deng",
      "Pengfei Liu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23576v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23576v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.86
  },
  {
    "arxiv_id": "2512.23441v1",
    "title": "Stochastic Siamese MAE Pretraining for Longitudinal Medical Images",
    "summary": "Temporally aware image representations are crucial for capturing disease progression in 3D volumes of longitudinal medical datasets. However, recent state-of-the-art self-supervised learning approaches like Masked Autoencoding (MAE), despite their strong representation learning capabilities, lack temporal awareness. In this paper, we propose STAMP (Stochastic Temporal Autoencoder with Masked Pretraining), a Siamese MAE framework that encodes temporal information through a stochastic process by conditioning on the time difference between the 2 input volumes. Unlike deterministic Siamese approaches, which compare scans from different time points but fail to account for the inherent uncertainty in disease evolution, STAMP learns temporal dynamics stochastically by reframing the MAE reconstruction loss as a conditional variational inference objective. We evaluated STAMP on two OCT and one MRI datasets with multiple visits per patient. STAMP pretrained ViT models outperformed both existing temporal MAE methods and foundation models on different late stage Age-Related Macular Degeneration and Alzheimer's Disease progression prediction which require models to learn the underlying non-deterministic temporal dynamics of the diseases.",
    "authors": [
      "Taha Emre",
      "Arunava Chakravarty",
      "Thomas Pinetz",
      "Dmitrii Lachinov",
      "Martin J. Menten",
      "Hendrik Scholl",
      "Sobha Sivaprasad",
      "Daniel Rueckert",
      "Andrew Lotery",
      "Stefan Sacu",
      "Ursula Schmidt-Erfurth",
      "Hrvoje Bogunović"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23441v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23441v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.85
  },
  {
    "arxiv_id": "2512.23633v1",
    "title": "AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms",
    "summary": "One-to-one tutoring is widely considered the gold standard for personalized education, yet it remains prohibitively expensive to scale. To evaluate whether generative AI might help expand access to this resource, we conducted an exploratory randomized controlled trial (RCT) with $N = 165$ students across five UK secondary schools. We integrated LearnLM -- a generative AI model fine-tuned for pedagogy -- into chat-based tutoring sessions on the Eedi mathematics platform. In the RCT, expert tutors directly supervised LearnLM, with the remit to revise each message it drafted until they would be satisfied sending it themselves. LearnLM proved to be a reliable source of pedagogical instruction, with supervising tutors approving 76.4% of its drafted messages making zero or minimal edits (i.e., changing only one or two characters). This translated into effective tutoring support: students guided by LearnLM performed at least as well as students chatting with human tutors on each learning outcome we measured. In fact, students who received support from LearnLM were 5.5 percentage points more likely to solve novel problems on subsequent topics (with a success rate of 66.2%) than those who received tutoring from human tutors alone (rate of 60.7%). In interviews, tutors highlighted LearnLM's strength at drafting Socratic questions that encouraged deeper reflection from students, with multiple tutors even reporting that they learned new pedagogical practices from the model. Overall, our results suggest that pedagogically fine-tuned AI tutoring systems may play a promising role in delivering effective, individualized learning support at scale.",
    "authors": [
      " LearnLM Team",
      " Eedi",
      " :",
      "Albert Wang",
      "Aliya Rysbek",
      "Andrea Huber",
      "Anjali Nambiar",
      "Anna Kenolty",
      "Ben Caulfield",
      "Beth Lilley-Draper",
      "Bibi Groot",
      "Brian Veprek",
      "Chelsea Burdett",
      "Claire Willis",
      "Craig Barton",
      "Digory Smith",
      "George Mu",
      "Harriet Walters",
      "Irina Jurenka",
      "Iris Hulls",
      "James Stalley-Moores",
      "Jonathan Caton",
      "Julia Wilkowski",
      "Kaiz Alarakyia",
      "Kevin R. McKee",
      "Liam McCafferty",
      "Lucy Dalton",
      "Markus Kunesch",
      "Pauline Malubay",
      "Rachel Kidson",
      "Rich Wells",
      "Sam Wheeler",
      "Sara Wiltberger",
      "Shakir Mohamed",
      "Simon Woodhead",
      "Vasco Brazão"
    ],
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23633v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23633v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.84
  },
  {
    "arxiv_id": "2512.23566v1",
    "title": "From geometry to dynamics: Learning overdamped Langevin dynamics from sparse observations with geometric constraints",
    "summary": "How can we learn the laws underlying the dynamics of stochastic systems when their trajectories are sampled sparsely in time? Existing methods either require temporally resolved high-frequency observations, or rely on geometric arguments that apply only to conservative systems, limiting the range of dynamics they can recover. Here, we present a new framework that reconciles these two perspectives by reformulating inference as a stochastic control problem. Our method uses geometry-driven path augmentation, guided by the geometry in the system's invariant density to reconstruct likely trajectories and infer the underlying dynamics without assuming specific parametric models. Applied to overdamped Langevin systems, our approach accurately recovers stochastic dynamics even from extremely undersampled data, outperforming existing methods in synthetic benchmarks. This work demonstrates the effectiveness of incorporating geometric inductive biases into stochastic system identification methods.",
    "authors": [
      "Dimitra Maoutsa"
    ],
    "categories": [
      "math.DS",
      "cond-mat.stat-mech",
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23566v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23566v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.84
  },
  {
    "arxiv_id": "2512.23167v1",
    "title": "SPIRAL: Symbolic LLM Planning via Grounded and Reflective Search",
    "summary": "Large Language Models (LLMs) often falter at complex planning tasks that require exploration and self-correction, as their linear reasoning process struggles to recover from early mistakes. While search algorithms like Monte Carlo Tree Search (MCTS) can explore alternatives, they are often ineffective when guided by sparse rewards and fail to leverage the rich semantic capabilities of LLMs. We introduce SPIRAL (Symbolic LLM Planning via Grounded and Reflective Search), a novel framework that embeds a cognitive architecture of three specialized LLM agents into an MCTS loop. SPIRAL's key contribution is its integrated planning pipeline where a Planner proposes creative next steps, a Simulator grounds the search by predicting realistic outcomes, and a Critic provides dense reward signals through reflection. This synergy transforms MCTS from a brute-force search into a guided, self-correcting reasoning process. On the DailyLifeAPIs and HuggingFace datasets, SPIRAL consistently outperforms the default Chain-of-Thought planning method and other state-of-the-art agents. More importantly, it substantially surpasses other state-of-the-art agents; for example, SPIRAL achieves 83.6% overall accuracy on DailyLifeAPIs, an improvement of over 16 percentage points against the next-best search framework, while also demonstrating superior token efficiency. Our work demonstrates that structuring LLM reasoning as a guided, reflective, and grounded search process yields more robust and efficient autonomous planners. The source code, full appendices, and all experimental data are available for reproducibility at the official project repository.",
    "authors": [
      "Yifan Zhang",
      "Giridhar Ganapavarapu",
      "Srideepika Jayaraman",
      "Bhavna Agrawal",
      "Dhaval Patel",
      "Achille Fokoue"
    ],
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23167v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23167v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2512.23504v1",
    "title": "Automatic Detection of Complex Quotation Patterns in Aggadic Literature",
    "summary": "This paper presents ACT (Allocate Connections between Texts), a novel three-stage algorithm for the automatic detection of biblical quotations in Rabbinic literature. Unlike existing text reuse frameworks that struggle with short, paraphrased, or structurally embedded quotations, ACT combines a morphology-aware alignment algorithm with a context-sensitive enrichment stage that identifies complex citation patterns such as \"Wave\" and \"Echo\" quotations.   Our approach was evaluated against leading systems, including Dicta, Passim, Text-Matcher, as well as human-annotated critical editions. We further assessed three ACT configurations to isolate the contribution of each component. Results demonstrate that the full ACT pipeline (ACT-QE) outperforms all baselines, achieving an F1 score of 0.91, with superior Recall (0.89) and Precision (0.94). Notably, ACT-2, which lacks stylistic enrichment, achieves higher Recall (0.90) but suffers in Precision, while ACT-3, using longer n-grams, offers a tradeoff between coverage and specificity.   In addition to improving quotation detection, ACT's ability to classify stylistic patterns across corpora opens new avenues for genre classification and intertextual analysis. This work contributes to digital humanities and computational philology by addressing the methodological gap between exhaustive machine-based detection and human editorial judgment. ACT lays a foundation for broader applications in historical textual analysis, especially in morphologically rich and citation-dense traditions like Aggadic literature.",
    "authors": [
      "Hadar Miller",
      "Tsvi Kuflik",
      "Moshe Lavee"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23504v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23504v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2512.23133v1",
    "title": "Principled Algorithms for Optimizing Generalized Metrics in Binary Classification",
    "summary": "In applications with significant class imbalance or asymmetric costs, metrics such as the $F_β$-measure, AM measure, Jaccard similarity coefficient, and weighted accuracy offer more suitable evaluation criteria than standard binary classification loss. However, optimizing these metrics present significant computational and statistical challenges. Existing approaches often rely on the characterization of the Bayes-optimal classifier, and use threshold-based methods that first estimate class probabilities and then seek an optimal threshold. This leads to algorithms that are not tailored to restricted hypothesis sets and lack finite-sample performance guarantees. In this work, we introduce principled algorithms for optimizing generalized metrics, supported by $H$-consistency and finite-sample generalization bounds. Our approach reformulates metric optimization as a generalized cost-sensitive learning problem, enabling the design of novel surrogate loss functions with provable $H$-consistency guarantees. Leveraging this framework, we develop new algorithms, METRO (Metric Optimization), with strong theoretical performance guarantees. We report the results of experiments demonstrating the effectiveness of our methods compared to prior baselines.",
    "authors": [
      "Anqi Mao",
      "Mehryar Mohri",
      "Yutao Zhong"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23133v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23133v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2512.23244v1",
    "title": "ViLaCD-R1: A Vision-Language Framework for Semantic Change Detection in Remote Sensing",
    "summary": "Remote sensing change detection (RSCD), a complex multi-image inference task, traditionally uses pixel-based operators or encoder-decoder networks that inadequately capture high-level semantics and are vulnerable to non-semantic perturbations. Although recent multimodal and vision-language model (VLM)-based approaches enhance semantic understanding of change regions by incorporating textual descriptions, they still suffer from challenges such as inaccurate spatial localization, imprecise pixel-level boundary delineation, and limited interpretability. To address these issues, we propose ViLaCD-R1, a two-stage framework comprising a Multi-Image Reasoner (MIR) and a Mask-Guided Decoder (MGD). Specifically, the VLM is trained through supervised fine-tuning (SFT) and reinforcement learning (RL) on block-level dual-temporal inference tasks, taking dual-temporal image patches as input and outputting a coarse change mask. Then, the decoder integrates dual-temporal image features with this coarse mask to predict a precise binary change map. Comprehensive evaluations on multiple RSCD benchmarks demonstrate that ViLaCD-R1 substantially improves true semantic change recognition and localization, robustly suppresses non-semantic variations, and achieves state-of-the-art accuracy in complex real-world scenarios.",
    "authors": [
      "Xingwei Ma",
      "Shiyang Feng",
      "Bo Zhang",
      "Bin Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23244v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23244v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2512.23227v1",
    "title": "Anomaly Detection by Effectively Leveraging Synthetic Images",
    "summary": "Anomaly detection plays a vital role in industrial manufacturing. Due to the scarcity of real defect images, unsupervised approaches that rely solely on normal images have been extensively studied. Recently, diffusion-based generative models brought attention to training data synthesis as an alternative solution. In this work, we focus on a strategy to effectively leverage synthetic images to maximize the anomaly detection performance. Previous synthesis strategies are broadly categorized into two groups, presenting a clear trade-off. Rule-based synthesis, such as injecting noise or pasting patches, is cost-effective but often fails to produce realistic defect images. On the other hand, generative model-based synthesis can create high-quality defect images but requires substantial cost. To address this problem, we propose a novel framework that leverages a pre-trained text-guided image-to-image translation model and image retrieval model to efficiently generate synthetic defect images. Specifically, the image retrieval model assesses the similarity of the generated images to real normal images and filters out irrelevant outputs, thereby enhancing the quality and relevance of the generated defect images. To effectively leverage synthetic images, we also introduce a two stage training strategy. In this strategy, the model is first pre-trained on a large volume of images from rule-based synthesis and then fine-tuned on a smaller set of high-quality images. This method significantly reduces the cost for data collection while improving the anomaly detection performance. Experiments on the MVTec AD dataset demonstrate the effectiveness of our approach.",
    "authors": [
      "Sungho Kang",
      "Hyunkyu Park",
      "Yeonho Lee",
      "Hanbyul Lee",
      "Mijoo Jeong",
      "YeongHyeon Park",
      "Injae Lee",
      "Juneho Yi"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23227v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23227v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2512.23173v1",
    "title": "EquaCode: A Multi-Strategy Jailbreak Approach for Large Language Models via Equation Solving and Code Completion",
    "summary": "Large language models (LLMs), such as ChatGPT, have achieved remarkable success across a wide range of fields. However, their trustworthiness remains a significant concern, as they are still susceptible to jailbreak attacks aimed at eliciting inappropriate or harmful responses. However, existing jailbreak attacks mainly operate at the natural language level and rely on a single attack strategy, limiting their effectiveness in comprehensively assessing LLM robustness. In this paper, we propose Equacode, a novel multi-strategy jailbreak approach for large language models via equation-solving and code completion. This approach transforms malicious intent into a mathematical problem and then requires the LLM to solve it using code, leveraging the complexity of cross-domain tasks to divert the model's focus toward task completion rather than safety constraints. Experimental results show that Equacode achieves an average success rate of 91.19% on the GPT series and 98.65% across 3 state-of-the-art LLMs, all with only a single query. Further, ablation experiments demonstrate that EquaCode outperforms either the mathematical equation module or the code module alone. This suggests a strong synergistic effect, thereby demonstrating that multi-strategy approach yields results greater than the sum of its parts.",
    "authors": [
      "Zhen Liang",
      "Hai Huang",
      "Zhengkui Chen"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23173v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23173v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2512.23518v1",
    "title": "Single LLM Debate, MoLaCE: Mixture of Latent Concept Experts Against Confirmation Bias",
    "summary": "Large language models (LLMs) are highly vulnerable to input confirmation bias. When a prompt implies a preferred answer, models often reinforce that bias rather than explore alternatives. This phenomenon remains underexplored, yet it is already harmful in base models and poses an even greater risk in multi-agent debate, where echo chambers reinforce bias instead of correction. We introduce Mixture of Latent Concept Experts (MoLaCE), a lightweight inference-time framework that addresses confirmation bias by mixing experts instantiated as different activation strengths over latent concepts that shape model responses. Our key insight is that, due to the compositional nature of language, differently phrased prompts reweight latent concepts in prompt-specific ways that affect factual correctness, so no single fixed intervention can be applied universally across inputs. This design enables a single LLM to emulate the benefits of debate internally while remaining computationally efficient and scalable. It can also be integrated into multi-agent debate frameworks to diversify perspectives and reduce correlated errors. We empirically show that it consistently reduces confirmation bias, improves robustness, and matches or surpasses multi-agent debate while requiring only a fraction of the computation.",
    "authors": [
      "Hazel Kim",
      "Philip Torr"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23518v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23518v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2512.23171v1",
    "title": "Certifying the Right to Be Forgotten: Primal-Dual Optimization for Sample and Label Unlearning in Vertical Federated Learning",
    "summary": "Federated unlearning has become an attractive approach to address privacy concerns in collaborative machine learning, for situations when sensitive data is remembered by AI models during the machine learning process. It enables the removal of specific data influences from trained models, aligning with the growing emphasis on the \"right to be forgotten.\" While extensively studied in horizontal federated learning, unlearning in vertical federated learning (VFL) remains challenging due to the distributed feature architecture. VFL unlearning includes sample unlearning that removes specific data points' influence and label unlearning that removes entire classes. Since different parties hold complementary features of the same samples, unlearning tasks require cross-party coordination, creating computational overhead and complexities from feature interdependencies. To address such challenges, we propose FedORA (Federated Optimization for data Removal via primal-dual Algorithm), designed for sample and label unlearning in VFL. FedORA formulates the removal of certain samples or labels as a constrained optimization problem solved using a primal-dual framework. Our approach introduces a new unlearning loss function that promotes classification uncertainty rather than misclassification. An adaptive step size enhances stability, while an asymmetric batch design, considering the prior influence of the remaining data on the model, handles unlearning and retained data differently to efficiently reduce computational costs. We provide theoretical analysis proving that the model difference between FedORA and Train-from-scratch is bounded, establishing guarantees for unlearning effectiveness. Experiments on tabular and image datasets demonstrate that FedORA achieves unlearning effectiveness and utility preservation comparable to Train-from-scratch with reduced computation and communication overhead.",
    "authors": [
      "Yu Jiang",
      "Xindi Tong",
      "Ziyao Liu",
      "Xiaoxi Zhang",
      "Kwok-Yan Lam",
      "Chee Wei Tan"
    ],
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23171v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23171v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2512.23670v1",
    "title": "Random Controlled Differential Equations",
    "summary": "We introduce a training-efficient framework for time-series learning that combines random features with controlled differential equations (CDEs). In this approach, large randomly parameterized CDEs act as continuous-time reservoirs, mapping input paths to rich representations. Only a linear readout layer is trained, resulting in fast, scalable models with strong inductive bias. Building on this foundation, we propose two variants: (i) Random Fourier CDEs (RF-CDEs): these lift the input signal using random Fourier features prior to the dynamics, providing a kernel-free approximation of RBF-enhanced sequence models; (ii) Random Rough DEs (R-RDEs): these operate directly on rough-path inputs via a log-ODE discretization, using log-signatures to capture higher-order temporal interactions while remaining stable and efficient. We prove that in the infinite-width limit, these model induces the RBF-lifted signature kernel and the rough signature kernel, respectively, offering a unified perspective on random-feature reservoirs, continuous-time deep architectures, and path-signature theory.   We evaluate both models across a range of time-series benchmarks, demonstrating competitive or state-of-the-art performance. These methods provide a practical alternative to explicit signature computations, retaining their inductive bias while benefiting from the efficiency of random features.",
    "authors": [
      "Francesco Piatti",
      "Thomas Cass",
      "William F. Turner"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23670v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23670v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2512.23596v1",
    "title": "The Nonstationarity-Complexity Tradeoff in Return Prediction",
    "summary": "We investigate machine learning models for stock return prediction in non-stationary environments, revealing a fundamental nonstationarity-complexity tradeoff: complex models reduce misspecification error but require longer training windows that introduce stronger non-stationarity. We resolve this tension with a novel model selection method that jointly optimizes model class and training window size using a tournament procedure that adaptively evaluates candidates on non-stationary validation data. Our theoretical analysis demonstrates that this approach balances misspecification error, estimation variance, and non-stationarity, performing close to the best model in hindsight. Applying our method to 17 industry portfolio returns, we consistently outperform standard rolling-window benchmarks, improving out-of-sample $R^2$ by 14-23% on average. During NBER-designated recessions, improvements are substantial: our method achieves positive $R^2$ during the Gulf War recession while benchmarks are negative, and improves $R^2$ in absolute terms by at least 80bps during the 2001 recession as well as superior performance during the 2008 Financial Crisis. Economically, a trading strategy based on our selected model generates 31% higher cumulative returns averaged across the industries.",
    "authors": [
      "Agostino Capponi",
      "Chengpiao Huang",
      "J. Antonio Sidaoui",
      "Kaizheng Wang",
      "Jiacheng Zou"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "q-fin.GN"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23596v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23596v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2512.23545v1",
    "title": "PathFound: An Agentic Multimodal Model Activating Evidence-seeking Pathological Diagnosis",
    "summary": "Recent pathological foundation models have substantially advanced visual representation learning and multimodal interaction. However, most models still rely on a static inference paradigm in which whole-slide images are processed once to produce predictions, without reassessment or targeted evidence acquisition under ambiguous diagnoses. This contrasts with clinical diagnostic workflows that refine hypotheses through repeated slide observations and further examination requests. We propose PathFound, an agentic multimodal model designed to support evidence-seeking inference in pathological diagnosis. PathFound integrates the power of pathological visual foundation models, vision-language models, and reasoning models trained with reinforcement learning to perform proactive information acquisition and diagnosis refinement by progressing through the initial diagnosis, evidence-seeking, and final decision stages. Across several large multimodal models, adopting this strategy consistently improves diagnostic accuracy, indicating the effectiveness of evidence-seeking workflows in computational pathology. Among these models, PathFound achieves state-of-the-art diagnostic performance across diverse clinical scenarios and demonstrates strong potential to discover subtle details, such as nuclear features and local invasions.",
    "authors": [
      "Shengyi Hua",
      "Jianfeng Wu",
      "Tianle Shen",
      "Kangzhe Hu",
      "Zhongzhen Huang",
      "Shujuan Ni",
      "Zhihong Zhang",
      "Yuan Li",
      "Zhe Wang",
      "Xiaofan Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23545v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23545v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2512.23537v1",
    "title": "AnyMS: Bottom-up Attention Decoupling for Layout-guided and Training-free Multi-subject Customization",
    "summary": "Multi-subject customization aims to synthesize multiple user-specified subjects into a coherent image. To address issues such as subjects missing or conflicts, recent works incorporate layout guidance to provide explicit spatial constraints. However, existing methods still struggle to balance three critical objectives: text alignment, subject identity preservation, and layout control, while the reliance on additional training further limits their scalability and efficiency. In this paper, we present AnyMS, a novel training-free framework for layout-guided multi-subject customization. AnyMS leverages three input conditions: text prompt, subject images, and layout constraints, and introduces a bottom-up dual-level attention decoupling mechanism to harmonize their integration during generation. Specifically, global decoupling separates cross-attention between textual and visual conditions to ensure text alignment. Local decoupling confines each subject's attention to its designated area, which prevents subject conflicts and thus guarantees identity preservation and layout control. Moreover, AnyMS employs pre-trained image adapters to extract subject-specific features aligned with the diffusion model, removing the need for subject learning or adapter tuning. Extensive experiments demonstrate that AnyMS achieves state-of-the-art performance, supporting complex compositions and scaling to a larger number of subjects.",
    "authors": [
      "Binhe Yu",
      "Zhen Wang",
      "Kexin Li",
      "Yuqian Yuan",
      "Wenqiao Zhang",
      "Long Chen",
      "Juncheng Li",
      "Jun Xiao",
      "Yueting Zhuang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23537v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23537v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2512.23366v1",
    "title": "AGRO-SQL: Agentic Group-Relative Optimization with High-Fidelity Data Synthesis",
    "summary": "The advancement of Text-to-SQL systems is currently hindered by the scarcity of high-quality training data and the limited reasoning capabilities of models in complex scenarios. In this paper, we propose a holistic framework that addresses these issues through a dual-centric approach. From a Data-Centric perspective, we construct an iterative data factory that synthesizes RL-ready data characterized by high correctness and precise semantic-logic alignment, ensured by strict verification. From a Model-Centric perspective, we introduce a novel Agentic Reinforcement Learning framework. This framework employs a Diversity-Aware Cold Start stage to initialize a robust policy, followed by Group Relative Policy Optimization (GRPO) to refine the agent's reasoning via environmental feedback. Extensive experiments on BIRD and Spider benchmarks demonstrate that our synergistic approach achieves state-of-the-art performance among single-model methods.",
    "authors": [
      "Cehua Yang",
      "Dongyu Xiao",
      "Junming Lin",
      "Yuyang Song",
      "Hanxu Yan",
      "Shawn Guo",
      "Wei Zhang",
      "Jian Yang",
      "Mingjie Tang",
      "Bryan Dai"
    ],
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23366v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23366v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2512.23356v1",
    "title": "A Stepwise-Enhanced Reasoning Framework for Large Language Models Based on External Subgraph Generation",
    "summary": "Large Language Models (LLMs) have achieved strong performance across a wide range of natural language processing tasks in recent years, including machine translation, text generation, and question answering. As their applications extend to increasingly complex scenarios, however, LLMs continue to face challenges in tasks that require deep reasoning and logical inference. In particular, models trained on large scale textual corpora may incorporate noisy or irrelevant information during generation, which can lead to incorrect predictions or outputs that are inconsistent with factual knowledge. To address this limitation, we propose a stepwise reasoning enhancement framework for LLMs based on external subgraph generation, termed SGR. The proposed framework dynamically constructs query relevant subgraphs from external knowledge bases and leverages their semantic structure to guide the reasoning process. By performing reasoning in a step by step manner over structured subgraphs, SGR reduces the influence of noisy information and improves reasoning accuracy. Specifically, the framework first generates an external subgraph tailored to the input query, then guides the model to conduct multi step reasoning grounded in the subgraph, and finally integrates multiple reasoning paths to produce the final answer. Experimental results on multiple benchmark datasets demonstrate that SGR consistently outperforms strong baselines, indicating its effectiveness in enhancing the reasoning capabilities of LLMs.",
    "authors": [
      "Xin Zhang",
      "Yang Cao",
      "Baoxing Wu",
      "Xinyi Chen",
      "Kai Song",
      "Siying Li"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23356v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23356v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2512.23243v1",
    "title": "Multimodal Interpretation of Remote Sensing Images: Dynamic Resolution Input Strategy and Multi-scale Vision-Language Alignment Mechanism",
    "summary": "Multimodal fusion of remote sensing images serves as a core technology for overcoming the limitations of single-source data and improving the accuracy of surface information extraction, which exhibits significant application value in fields such as environmental monitoring and urban planning. To address the deficiencies of existing methods, including the failure of fixed resolutions to balance efficiency and detail, as well as the lack of semantic hierarchy in single-scale alignment, this study proposes a Vision-language Model (VLM) framework integrated with two key innovations: the Dynamic Resolution Input Strategy (DRIS) and the Multi-scale Vision-language Alignment Mechanism (MS-VLAM).Specifically, the DRIS adopts a coarse-to-fine approach to adaptively allocate computational resources according to the complexity of image content, thereby preserving key fine-grained features while reducing redundant computational overhead. The MS-VLAM constructs a three-tier alignment mechanism covering object, local-region and global levels, which systematically captures cross-modal semantic consistency and alleviates issues of semantic misalignment and granularity imbalance.Experimental results on the RS-GPT4V dataset demonstrate that the proposed framework significantly improves the accuracy of semantic understanding and computational efficiency in tasks including image captioning and cross-modal retrieval. Compared with conventional methods, it achieves superior performance in evaluation metrics such as BLEU-4 and CIDEr for image captioning, as well as R@10 for cross-modal retrieval. This technical framework provides a novel approach for constructing efficient and robust multimodal remote sensing systems, laying a theoretical foundation and offering technical guidance for the engineering application of intelligent remote sensing interpretation.",
    "authors": [
      "Siyu Zhang",
      "Ying Chen",
      "Lianlei Shan",
      "Runhe Qiu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23243v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23243v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2512.23236v1",
    "title": "KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta",
    "summary": "Making deep learning recommendation model (DLRM) training and inference fast and efficient is important. However, this presents three key system challenges - model architecture diversity, kernel primitive diversity, and hardware generation and architecture heterogeneity. This paper presents KernelEvolve-an agentic kernel coding framework-to tackle heterogeneity at-scale for DLRM. KernelEvolve is designed to take kernel specifications as input and automate the process of kernel generation and optimization for recommendation model across heterogeneous hardware architectures. KernelEvolve does so by operating at multiple programming abstractions, from Triton and CuTe DSL to low-level hardware agnostic languages, spanning the full hardware-software optimization stack. The kernel optimization process is described as graph-based search with selection policy, universal operator, fitness function, and termination rule, dynamically adapts to runtime execution context through retrieval-augmented prompt synthesis. We designed, implemented, and deployed KernelEvolve to optimize a wide variety of production recommendation models across generations of NVIDIA and AMD GPUs, as well as Meta's AI accelerators. We validate KernelEvolve on the publicly-available KernelBench suite, achieving 100% pass rate on all 250 problems across three difficulty levels, and 160 PyTorch ATen operators across three heterogeneous hardware platforms, demonstrating 100% correctness. KernelEvolve reduces development time from weeks to hours and achieves substantial performance improvements over PyTorch baselines across diverse production use cases and for heterogeneous AI systems at-scale. Beyond performance efficiency improvements, KernelEvolve significantly mitigates the programmability barrier for new AI hardware by enabling automated kernel generation for in-house developed AI hardware.",
    "authors": [
      "Gang Liao",
      "Hongsen Qin",
      "Ying Wang",
      "Alicia Golden",
      "Michael Kuchnik",
      "Yavuz Yetim",
      "Jia Jiunn Ang",
      "Chunli Fu",
      "Yihan He",
      "Samuel Hsia",
      "Zewei Jiang",
      "Dianshi Li",
      "Uladzimir Pashkevich",
      "Varna Puvvada",
      "Feng Shi",
      "Matt Steiner",
      "Ruichao Xiao",
      "Nathan Yan",
      "Xiayu Yu",
      "Zhou Fang",
      "Abdul Zainul-Abedin",
      "Ketan Singh",
      "Hongtao Yu",
      "Wenyuan Chi",
      "Barney Huang",
      "Sean Zhang",
      "Noah Weller",
      "Zach Marine",
      "Wyatt Cook",
      "Carole-Jean Wu",
      "Gaoxiang Liu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.MA",
      "cs.PF"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23236v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23236v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2512.23435v1",
    "title": "Mobile-Efficient Speech Emotion Recognition Using DistilHuBERT: A Cross-Corpus Validation Study",
    "summary": "Speech Emotion Recognition (SER) has significant potential for mobile applications, yet deployment remains constrained by the computational demands of state-of-the-art transformer architectures. This paper presents a mobile-efficient SER system based on DistilHuBERT, a distilled and 8-bit quantized transformer that achieves 92% parameter reduction compared to full-scale Wav2Vec 2.0 models while maintaining competitive accuracy. We conduct a rigorous 5-fold Leave-One-Session-Out (LOSO) cross-validation on the IEMOCAP dataset to ensure speaker independence, augmented with cross-corpus training on CREMA-D to enhance generalization. Cross-corpus training with CREMA-D yields a 1.2% improvement in Weighted Accuracy, a 1.4% gain in Macro F1-score, and a 32% reduction in cross-fold variance, with the Neutral class showing the most substantial benefit at 5.4% F1-score improvement. Our approach achieves an Unweighted Accuracy of 61.4% with a quantized model footprint of only 23 MB, representing approximately 91% of full-scale baseline performance. Cross-corpus evaluation on RAVDESS reveals that the theatrical nature of acted emotions causes predictions to cluster by arousal level rather than valence: happiness is systematically confused with anger due to acoustic saturation in high-energy expressions. Despite this theatricality effect reducing overall RAVDESS accuracy to 43.29%, the model maintains robust arousal detection with 97% recall for anger and 64% for sadness. These findings establish a Pareto-optimal tradeoff between model size and accuracy, enabling practical affect recognition on resource-constrained mobile devices.",
    "authors": [
      "Saifelden M. Ismail"
    ],
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23435v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23435v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2512.23235v1",
    "title": "FairGFL: Privacy-Preserving Fairness-Aware Federated Learning with Overlapping Subgraphs",
    "summary": "Graph federated learning enables the collaborative extraction of high-order information from distributed subgraphs while preserving the privacy of raw data. However, graph data often exhibits overlap among different clients. Previous research has demonstrated certain benefits of overlapping data in mitigating data heterogeneity. However, the negative effects have not been explored, particularly in cases where the overlaps are imbalanced across clients. In this paper, we uncover the unfairness issue arising from imbalanced overlapping subgraphs through both empirical observations and theoretical reasoning. To address this issue, we propose FairGFL (FAIRness-aware subGraph Federated Learning), a novel algorithm that enhances cross-client fairness while maintaining model utility in a privacy-preserving manner. Specifically, FairGFL incorporates an interpretable weighted aggregation approach to enhance fairness across clients, leveraging privacy-preserving estimation of their overlapping ratios. Furthermore, FairGFL improves the tradeoff between model utility and fairness by integrating a carefully crafted regularizer into the federated composite loss function. Through extensive experiments on four benchmark graph datasets, we demonstrate that FairGFL outperforms four representative baseline algorithms in terms of both model utility and fairness.",
    "authors": [
      "Zihao Zhou",
      "Shusen Yang",
      "Fangyuan Zhao",
      "Xuebin Ren"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23235v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23235v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2512.23573v1",
    "title": "ProGuard: Towards Proactive Multimodal Safeguard",
    "summary": "The rapid evolution of generative models has led to a continuous emergence of multimodal safety risks, exposing the limitations of existing defense methods. To address these challenges, we propose ProGuard, a vision-language proactive guard that identifies and describes out-of-distribution (OOD) safety risks without the need for model adjustments required by traditional reactive approaches. We first construct a modality-balanced dataset of 87K samples, each annotated with both binary safety labels and risk categories under a hierarchical multimodal safety taxonomy, effectively mitigating modality bias and ensuring consistent moderation across text, image, and text-image inputs. Based on this dataset, we train our vision-language base model purely through reinforcement learning (RL) to achieve efficient and concise reasoning. To approximate proactive safety scenarios in a controlled setting, we further introduce an OOD safety category inference task and augment the RL objective with a synonym-bank-based similarity reward that encourages the model to generate concise descriptions for unseen unsafe categories. Experimental results show that ProGuard achieves performance comparable to closed-source large models on binary safety classification, substantially outperforms existing open-source guard models on unsafe content categorization. Most notably, ProGuard delivers a strong proactive moderation ability, improving OOD risk detection by 52.6% and OOD risk description by 64.8%.",
    "authors": [
      "Shaohan Yu",
      "Lijun Li",
      "Chenyang Si",
      "Lu Sheng",
      "Jing Shao"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23573v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23573v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2512.23424v1",
    "title": "AKG kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis",
    "summary": "Modern AI models demand high-performance computation kernels. The growing complexity of LLMs, multimodal architectures, and recommendation systems, combined with techniques like sparsity and quantization, creates significant computational challenges. Moreover, frequent hardware updates and diverse chip architectures further complicate this landscape, requiring tailored kernel implementations for each platform. However, manual optimization cannot keep pace with these demands, creating a critical bottleneck in AI system development. Recent advances in LLM code generation capabilities have opened new possibilities for automating kernel development. In this work, we propose AKG kernel agent (AI-driven Kernel Generator), a multi-agent system that automates kernel generation, migration, and performance tuning. AKG kernel agent is designed to support multiple domain-specific languages (DSLs), including Triton, TileLang, CPP, and CUDA-C, enabling it to target different hardware backends while maintaining correctness and portability. The system's modular design allows rapid integration of new DSLs and hardware targets. When evaluated on KernelBench using Triton DSL across GPU and NPU backends, AKG kernel agent achieves an average speedup of 1.46$\\times$ over PyTorch Eager baselines implementations, demonstrating its effectiveness in accelerating kernel development for modern AI workloads.",
    "authors": [
      "Jinye Du",
      "Quan Yuan",
      "Zuyao Zhang",
      "Yanzhi Yi",
      "Jiahui Hu",
      "Wangyi Chen",
      "Yiyang Zhu",
      "Qishui Zheng",
      "Wenxiang Zou",
      "Xiangyu Chang",
      "Zuohe Zheng",
      "Zichun Ye",
      "Chao Liu",
      "Shanni Li",
      "Renwei Zhang",
      "Yiping Deng",
      "Xinwei Hu",
      "Xuefeng Jin",
      "Jie Zhao"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23424v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23424v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2512.23258v1",
    "title": "Plug-and-Play Fidelity Optimization for Diffusion Transformer Acceleration via Cumulative Error Minimization",
    "summary": "Although Diffusion Transformer (DiT) has emerged as a predominant architecture for image and video generation, its iterative denoising process results in slow inference, which hinders broader applicability and development. Caching-based methods achieve training-free acceleration, while suffering from considerable computational error. Existing methods typically incorporate error correction strategies such as pruning or prediction to mitigate it. However, their fixed caching strategy fails to adapt to the complex error variations during denoising, which limits the full potential of error correction. To tackle this challenge, we propose a novel fidelity-optimization plugin for existing error correction methods via cumulative error minimization, named CEM. CEM predefines the error to characterize the sensitivity of model to acceleration jointly influenced by timesteps and cache intervals. Guided by this prior, we formulate a dynamic programming algorithm with cumulative error approximation for strategy optimization, which achieves the caching error minimization, resulting in a substantial improvement in generation fidelity. CEM is model-agnostic and exhibits strong generalization, which is adaptable to arbitrary acceleration budgets. It can be seamlessly integrated into existing error correction frameworks and quantized models without introducing any additional computational overhead. Extensive experiments conducted on nine generation models and quantized methods across three tasks demonstrate that CEM significantly improves generation fidelity of existing acceleration models, and outperforms the original generation performance on FLUX.1-dev, PixArt-$α$, StableDiffusion1.5 and Hunyuan. The code will be made publicly available.",
    "authors": [
      "Tong Shao",
      "Yusen Fu",
      "Guoying Sun",
      "Jingde Kong",
      "Zhuotao Tian",
      "Jingyong Su"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23258v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23258v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2512.23213v1",
    "title": "Scoring, Reasoning, and Selecting the Best! Ensembling Large Language Models via a Peer-Review Process",
    "summary": "We propose LLM-PeerReview, an unsupervised LLM Ensemble method that selects the most ideal response from multiple LLM-generated candidates for each query, harnessing the collective wisdom of multiple models with diverse strengths. LLM-PeerReview is built on a novel, peer-review-inspired framework that offers a clear and interpretable mechanism, while remaining fully unsupervised for flexible adaptability and generalization. Specifically, it operates in three stages: For scoring, we use the emerging LLM-as-a-Judge technique to evaluate each response by reusing multiple LLMs at hand; For reasoning, we can apply a principled graphical model-based truth inference algorithm or a straightforward averaging strategy to aggregate multiple scores to produce a final score for each response; Finally, the highest-scoring response is selected as the best ensemble output. LLM-PeerReview is conceptually simple and empirically powerful. The two variants of the proposed approach obtain strong results across four datasets, including outperforming the recent advanced model Smoothie-Global by 6.9% and 7.3% points, respectively.",
    "authors": [
      "Zhijun Chen",
      "Zeyu Ji",
      "Qianren Mao",
      "Junhang Cheng",
      "Bangjie Qin",
      "Hao Wu",
      "Zhuoran Li",
      "Jingzheng Li",
      "Kai Sun",
      "Zizhe Wang",
      "Yikun Ban",
      "Zhu Sun",
      "Xiangyang Ji",
      "Hailong Sun"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23213v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23213v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2512.23192v1",
    "title": "PGOT: A Physics-Geometry Operator Transformer for Complex PDEs",
    "summary": "While Transformers have demonstrated remarkable potential in modeling Partial Differential Equations (PDEs), modeling large-scale unstructured meshes with complex geometries remains a significant challenge. Existing efficient architectures often employ feature dimensionality reduction strategies, which inadvertently induces Geometric Aliasing, resulting in the loss of critical physical boundary information. To address this, we propose the Physics-Geometry Operator Transformer (PGOT), designed to reconstruct physical feature learning through explicit geometry awareness. Specifically, we propose Spectrum-Preserving Geometric Attention (SpecGeo-Attention). Utilizing a ``physics slicing-geometry injection\" mechanism, this module incorporates multi-scale geometric encodings to explicitly preserve multi-scale geometric features while maintaining linear computational complexity $O(N)$. Furthermore, PGOT dynamically routes computations to low-order linear paths for smooth regions and high-order non-linear paths for shock waves and discontinuities based on spatial coordinates, enabling spatially adaptive and high-precision physical field modeling. PGOT achieves consistent state-of-the-art performance across four standard benchmarks and excels in large-scale industrial tasks including airfoil and car designs.",
    "authors": [
      "Zhuo Zhang",
      "Xi Yang",
      "Yuan Zhao",
      "Canqun Yang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23192v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23192v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2512.23701v1",
    "title": "Eliciting Behaviors in Multi-Turn Conversations",
    "summary": "Identifying specific and often complex behaviors from large language models (LLMs) in conversational settings is crucial for their evaluation. Recent work proposes novel techniques to find natural language prompts that induce specific behaviors from a target model, yet they are mainly studied in single-turn settings. In this work, we study behavior elicitation in the context of multi-turn conversations. We first offer an analytical framework that categorizes existing methods into three families based on their interactions with the target model: those that use only prior knowledge, those that use offline interactions, and those that learn from online interactions. We then introduce a generalized multi-turn formulation of the online method, unifying single-turn and multi-turn elicitation. We evaluate all three families of methods on automatically generating multi-turn test cases. We investigate the efficiency of these approaches by analyzing the trade-off between the query budget, i.e., the number of interactions with the target model, and the success rate, i.e., the discovery rate of behavior-eliciting inputs. We find that online methods can achieve an average success rate of 45/19/77% with just a few thousand queries over three tasks where static methods from existing multi-turn conversation benchmarks find few or even no failure cases. Our work highlights a novel application of behavior elicitation methods in multi-turn conversation evaluation and the need for the community to move towards dynamic benchmarks.",
    "authors": [
      "Jing Huang",
      "Shujian Zhang",
      "Lun Wang",
      "Andrew Hard",
      "Rajiv Mathews",
      "John Lambert"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23701v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23701v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2512.23637v1",
    "title": "A Dataset and Benchmark for Consumer Healthcare Question Summarization",
    "summary": "The quest for seeking health information has swamped the web with consumers health-related questions. Generally, consumers use overly descriptive and peripheral information to express their medical condition or other healthcare needs, contributing to the challenges of natural language understanding. One way to address this challenge is to summarize the questions and distill the key information of the original question. Recently, large-scale datasets have significantly propelled the development of several summarization tasks, such as multi-document summarization and dialogue summarization. However, a lack of a domain-expert annotated dataset for the consumer healthcare questions summarization task inhibits the development of an efficient summarization system. To address this issue, we introduce a new dataset, CHQ-Sum,m that contains 1507 domain-expert annotated consumer health questions and corresponding summaries. The dataset is derived from the community question answering forum and therefore provides a valuable resource for understanding consumer health-related posts on social media. We benchmark the dataset on multiple state-of-the-art summarization models to show the effectiveness of the dataset",
    "authors": [
      "Abhishek Basu",
      "Deepak Gupta",
      "Dina Demner-Fushman",
      "Shweta Yadav"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23637v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23637v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2512.23485v1",
    "title": "FRoD: Full-Rank Efficient Fine-Tuning with Rotational Degrees for Fast Convergence",
    "summary": "Parameter-efficient fine-tuning (PEFT) methods have emerged as a practical solution for adapting large foundation models to downstream tasks, reducing computational and memory costs by updating only a small subset of parameters. Among them, approaches like LoRA aim to strike a balance between efficiency and expressiveness, but often suffer from slow convergence and limited adaptation capacity due to their inherent low-rank constraints. This trade-off hampers the ability of PEFT methods to capture complex patterns needed for diverse tasks. To address these challenges, we propose FRoD, a novel fine-tuning method that combines hierarchical joint decomposition with rotational degrees of freedom. By extracting a globally shared basis across layers and injecting sparse, learnable perturbations into scaling factors for flexible full-rank updates, FRoD enhances expressiveness and efficiency, leading to faster and more robust convergence. On 20 benchmarks spanning vision, reasoning, and language understanding, FRoD matches full model fine-tuning in accuracy, while using only 1.72% of trainable parameters under identical training budgets.",
    "authors": [
      "Guoan Wan",
      "Tianyu Chen",
      "Fangzheng Feng",
      "Haoyi Zhou",
      "Runhua Xu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23485v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23485v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2512.23464v1",
    "title": "HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation",
    "summary": "We present HY-Motion 1.0, a series of state-of-the-art, large-scale, motion generation models capable of generating 3D human motions from textual descriptions. HY-Motion 1.0 represents the first successful attempt to scale up Diffusion Transformer (DiT)-based flow matching models to the billion-parameter scale within the motion generation domain, delivering instruction-following capabilities that significantly outperform current open-source benchmarks. Uniquely, we introduce a comprehensive, full-stage training paradigm -- including large-scale pretraining on over 3,000 hours of motion data, high-quality fine-tuning on 400 hours of curated data, and reinforcement learning from both human feedback and reward models -- to ensure precise alignment with the text instruction and high motion quality. This framework is supported by our meticulous data processing pipeline, which performs rigorous motion cleaning and captioning. Consequently, our model achieves the most extensive coverage, spanning over 200 motion categories across 6 major classes. We release HY-Motion 1.0 to the open-source community to foster future research and accelerate the transition of 3D human motion generation models towards commercial maturity.",
    "authors": [
      "Yuxin Wen",
      "Qing Shuai",
      "Di Kang",
      "Jing Li",
      "Cheng Wen",
      "Yue Qian",
      "Ningxin Jiao",
      "Changhai Chen",
      "Weijie Chen",
      "Yiran Wang",
      "Jinkun Guo",
      "Dongyue An",
      "Han Liu",
      "Yanyu Tong",
      "Chao Zhang",
      "Qing Guo",
      "Juan Chen",
      "Qiao Zhang",
      "Youyi Zhang",
      "Zihao Yao",
      "Cheng Zhang",
      "Hong Duan",
      "Xiaoping Wu",
      "Qi Chen",
      "Fei Cheng",
      "Liang Dong",
      "Peng He",
      "Hao Zhang",
      "Jiaxin Lin",
      "Chao Zhang",
      "Zhongyi Fan",
      "Yifan Li",
      "Zhichao Hu",
      "Yuhong Liu",
      " Linus",
      "Jie Jiang",
      "Xiaolong Li",
      "Linchao Bao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23464v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23464v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2512.23379v1",
    "title": "SoulX-LiveTalk Technical Report",
    "summary": "Deploying massive diffusion models for real-time, infinite-duration, audio-driven avatar generation presents a significant engineering challenge, primarily due to the conflict between computational load and strict latency constraints. Existing approaches often compromise visual fidelity by enforcing strictly unidirectional attention mechanisms or reducing model capacity. To address this problem, we introduce \\textbf{SoulX-LiveTalk}, a 14B-parameter framework optimized for high-fidelity real-time streaming. Diverging from conventional unidirectional paradigms, we use a \\textbf{Self-correcting Bidirectional Distillation} strategy that retains bidirectional attention within video chunks. This design preserves critical spatiotemporal correlations, significantly enhancing motion coherence and visual detail. To ensure stability during infinite generation, we incorporate a \\textbf{Multi-step Retrospective Self-Correction Mechanism}, enabling the model to autonomously recover from accumulated errors and preventing collapse. Furthermore, we engineered a full-stack inference acceleration suite incorporating hybrid sequence parallelism, Parallel VAE, and kernel-level optimizations. Extensive evaluations confirm that SoulX-LiveTalk is the first 14B-scale system to achieve a \\textbf{sub-second start-up latency (0.87s)} while reaching a real-time throughput of \\textbf{32 FPS}, setting a new standard for high-fidelity interactive digital human synthesis.",
    "authors": [
      "Le Shen",
      "Qiao Qian",
      "Tan Yu",
      "Ke Zhou",
      "Tianhang Yu",
      "Yu Zhan",
      "Zhenjie Wang",
      "Ming Tao",
      "Shunshun Yin",
      "Siyuan Liu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23379v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23379v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2512.23217v1",
    "title": "TCEval: Using Thermal Comfort to Assess Cognitive and Perceptual Abilities of AI",
    "summary": "A critical gap exists in LLM task-specific benchmarks. Thermal comfort, a sophisticated interplay of environmental factors and personal perceptions involving sensory integration and adaptive decision-making, serves as an ideal paradigm for evaluating real-world cognitive capabilities of AI systems. To address this, we propose TCEval, the first evaluation framework that assesses three core cognitive capacities of AI, cross-modal reasoning, causal association, and adaptive decision-making, by leveraging thermal comfort scenarios and large language model (LLM) agents. The methodology involves initializing LLM agents with virtual personality attributes, guiding them to generate clothing insulation selections and thermal comfort feedback, and validating outputs against the ASHRAE Global Database and Chinese Thermal Comfort Database. Experiments on four LLMs show that while agent feedback has limited exact alignment with humans, directional consistency improves significantly with a 1 PMV tolerance. Statistical tests reveal that LLM-generated PMV distributions diverge markedly from human data, and agents perform near-randomly in discrete thermal comfort classification. These results confirm the feasibility of TCEval as an ecologically valid Cognitive Turing Test for AI, demonstrating that current LLMs possess foundational cross-modal reasoning ability but lack precise causal understanding of the nonlinear relationships between variables in thermal comfort. TCEval complements traditional benchmarks, shifting AI evaluation focus from abstract task proficiency to embodied, context-aware perception and decision-making, offering valuable insights for advancing AI in human-centric applications like smart buildings.",
    "authors": [
      "Jingming Li"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23217v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23217v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2512.23175v1",
    "title": "HELM-BERT: A Transformer for Medium-sized Peptide Property Prediction",
    "summary": "Therapeutic peptides have emerged as a pivotal modality in modern drug discovery, occupying a chemically and topologically rich space. While accurate prediction of their physicochemical properties is essential for accelerating peptide development, existing molecular language models rely on representations that fail to capture this complexity. Atom-level SMILES notation generates long token sequences and obscures cyclic topology, whereas amino-acid-level representations cannot encode the diverse chemical modifications central to modern peptide design. To bridge this representational gap, the Hierarchical Editing Language for Macromolecules (HELM) offers a unified framework enabling precise description of both monomer composition and connectivity, making it a promising foundation for peptide language modeling. Here, we propose HELM-BERT, the first encoder-based peptide language model trained on HELM notation. Based on DeBERTa, HELM-BERT is specifically designed to capture hierarchical dependencies within HELM sequences. The model is pre-trained on a curated corpus of 39,079 chemically diverse peptides spanning linear and cyclic structures. HELM-BERT significantly outperforms state-of-the-art SMILES-based language models in downstream tasks, including cyclic peptide membrane permeability prediction and peptide-protein interaction prediction. These results demonstrate that HELM's explicit monomer- and topology-aware representations offer substantial data-efficiency advantages for modeling therapeutic peptides, bridging a long-standing gap between small-molecule and protein language models.",
    "authors": [
      "Seungeon Lee",
      "Takuto Koyama",
      "Itsuki Maeda",
      "Shigeyuki Matsumoto",
      "Yasushi Okuno"
    ],
    "categories": [
      "cs.LG",
      "q-bio.BM"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23175v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23175v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2512.23160v1",
    "title": "A Weak Signal Learning Dataset and Its Baseline Method",
    "summary": "Weak signal learning (WSL) is a common challenge in many fields like fault diagnosis, medical imaging, and autonomous driving, where critical information is often masked by noise and interference, making feature identification difficult. Even in tasks with abundant strong signals, the key to improving model performance often lies in effectively extracting weak signals. However, the lack of dedicated datasets has long constrained research. To address this, we construct the first specialized dataset for weak signal feature learning, containing 13,158 spectral samples. It features low SNR dominance (over 55% samples with SNR below 50) and extreme class imbalance (class ratio up to 29:1), providing a challenging benchmark for classification and regression in weak signal scenarios. We also propose a dual-view representation (vector + time-frequency map) and a PDVFN model tailored to low SNR, distribution skew, and dual imbalance. PDVFN extracts local sequential features and global frequency-domain structures in parallel, following principles of local enhancement, sequential modeling, noise suppression, multi-scale capture, frequency extraction, and global perception. This multi-source complementarity enhances representation for low-SNR and imbalanced data, offering a novel solution for WSL tasks like astronomical spectroscopy. Experiments show our method achieves higher accuracy and robustness in handling weak signals, high noise, and extreme class imbalance, especially in low SNR and imbalanced scenarios. This study provides a dedicated dataset, a baseline model, and establishes a foundation for future WSL research.",
    "authors": [
      "Xianqi Liu",
      "Xiangru Li",
      "Lefeng He",
      "Ziyu Fang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23160v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23160v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2512.23628v1",
    "title": "Memorization in 3D Shape Generation: An Empirical Study",
    "summary": "Generative models are increasingly used in 3D vision to synthesize novel shapes, yet it remains unclear whether their generation relies on memorizing training shapes. Understanding their memorization could help prevent training data leakage and improve the diversity of generated results. In this paper, we design an evaluation framework to quantify memorization in 3D generative models and study the influence of different data and modeling designs on memorization. We first apply our framework to quantify memorization in existing methods. Next, through controlled experiments with a latent vector-set (Vecset) diffusion model, we find that, on the data side, memorization depends on data modality, and increases with data diversity and finer-grained conditioning; on the modeling side, it peaks at a moderate guidance scale and can be mitigated by longer Vecsets and simple rotation augmentation. Together, our framework and analysis provide an empirical understanding of memorization in 3D generative models and suggest simple yet effective strategies to reduce it without degrading generation quality. Our code is available at https://github.com/zlab-princeton/3d_mem.",
    "authors": [
      "Shu Pu",
      "Boya Zeng",
      "Kaichen Zhou",
      "Mengyu Wang",
      "Zhuang Liu"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23628v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23628v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2512.23601v1",
    "title": "Divergent-Convergent Thinking in Large Language Models for Creative Problem Generation",
    "summary": "Large language models (LLMs) have significant potential for generating educational questions and problems, enabling educators to create large-scale learning materials. However, LLMs are fundamentally limited by the ``Artificial Hivemind'' effect, where they generate similar responses within the same model and produce homogeneous outputs across different models. As a consequence, students may be exposed to overly similar and repetitive LLM-generated problems, which harms diversity of thought. Drawing inspiration from Wallas's theory of creativity and Guilford's framework of divergent-convergent thinking, we propose CreativeDC, a two-phase prompting method that explicitly scaffolds the LLM's reasoning into distinct phases. By decoupling creative exploration from constraint satisfaction, our method enables LLMs to explore a broader space of ideas before committing to a final problem. We evaluate CreativeDC for creative problem generation using a comprehensive set of metrics that capture diversity, novelty, and utility. The results show that CreativeDC achieves significantly higher diversity and novelty compared to baselines while maintaining high utility. Moreover, scaling analysis shows that CreativeDC generates a larger effective number of distinct problems as more are sampled, increasing at a faster rate than baseline methods.",
    "authors": [
      "Manh Hung Nguyen",
      "Adish Singla"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23601v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23601v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2512.23547v1",
    "title": "Lie to Me: Knowledge Graphs for Robust Hallucination Self-Detection in LLMs",
    "summary": "Hallucinations, the generation of apparently convincing yet false statements, remain a major barrier to the safe deployment of LLMs. Building on the strong performance of self-detection methods, we examine the use of structured knowledge representations, namely knowledge graphs, to improve hallucination self-detection. Specifically, we propose a simple yet powerful approach that enriches hallucination self-detection by (i) converting LLM responses into knowledge graphs of entities and relations, and (ii) using these graphs to estimate the likelihood that a response contains hallucinations. We evaluate the proposed approach using two widely used LLMs, GPT-4o and Gemini-2.5-Flash, across two hallucination detection datasets. To support more reliable future benchmarking, one of these datasets has been manually curated and enhanced and is released as a secondary outcome of this work. Compared to standard self-detection methods and SelfCheckGPT, a state-of-the-art approach, our method achieves up to 16% relative improvement in accuracy and 20% in F1-score. Our results show that LLMs can better analyse atomic facts when they are structured as knowledge graphs, even when initial outputs contain inaccuracies. This low-cost, model-agnostic approach paves the way toward safer and more trustworthy language models.",
    "authors": [
      "Sahil Kale",
      "Antonio Luca Alfeo"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23547v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23547v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2512.23541v1",
    "title": "Act2Goal: From World Model To General Goal-conditioned Policy",
    "summary": "Specifying robotic manipulation tasks in a manner that is both expressive and precise remains a central challenge. While visual goals provide a compact and unambiguous task specification, existing goal-conditioned policies often struggle with long-horizon manipulation due to their reliance on single-step action prediction without explicit modeling of task progress. We propose Act2Goal, a general goal-conditioned manipulation policy that integrates a goal-conditioned visual world model with multi-scale temporal control. Given a current observation and a target visual goal, the world model generates a plausible sequence of intermediate visual states that captures long-horizon structure. To translate this visual plan into robust execution, we introduce Multi-Scale Temporal Hashing (MSTH), which decomposes the imagined trajectory into dense proximal frames for fine-grained closed-loop control and sparse distal frames that anchor global task consistency. The policy couples these representations with motor control through end-to-end cross-attention, enabling coherent long-horizon behavior while remaining reactive to local disturbances. Act2Goal achieves strong zero-shot generalization to novel objects, spatial layouts, and environments. We further enable reward-free online adaptation through hindsight goal relabeling with LoRA-based finetuning, allowing rapid autonomous improvement without external supervision. Real-robot experiments demonstrate that Act2Goal improves success rates from 30% to 90% on challenging out-of-distribution tasks within minutes of autonomous interaction, validating that goal-conditioned world models with multi-scale temporal control provide structured guidance necessary for robust long-horizon manipulation. Project page: https://act2goal.github.io/",
    "authors": [
      "Pengfei Zhou",
      "Liliang Chen",
      "Shengcong Chen",
      "Di Chen",
      "Wenzhi Zhao",
      "Rongjun Jin",
      "Guanghui Ren",
      "Jianlan Luo"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23541v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23541v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2512.23367v1",
    "title": "Post-Training Quantization of OpenPangu Models for Efficient Deployment on Atlas A2",
    "summary": "Huawei's openPangu-Embedded-1B and openPangu-Embedded-7B, variants of the openPangu large language model, integrate three distinct Chain-of-Thought (CoT) reasoning paradigms, namely slow_think, auto_think, and no_think. While these CoT modes enhance reasoning capabilities, their generation of extended reasoning traces introduces substantial memory and latency overheads, posing challenges for practical deployment on Ascend NPUs. This paper addresses these computational constraints by leveraging low-bit quantization, which transforms FP16 computations into more efficient integer arithmetic. We introduce a unified low-bit inference framework, supporting INT8 (W8A8) and W4A8 quantization, specifically optimized for openPangu-Embedded models on the Atlas A2. Our comprehensive evaluation, conducted across all three CoT modes on code generation benchmarks (HumanEval and MBPP), demonstrates the efficacy of this approach. INT8 quantization consistently preserves over 90\\% of the FP16 baseline accuracy and achieves a 1.5x prefill speedup on the Atlas A2. Furthermore, W4A8 quantization significantly reduces memory consumption, albeit with a moderate trade-off in accuracy. These findings collectively indicate that low-bit quantization effectively facilitates efficient CoT reasoning on Ascend NPUs, maintaining high model fidelity.",
    "authors": [
      "Yilun Luo",
      "HuaQing Zheng",
      "Haoqian Meng",
      "Wenyuan Liu",
      "Peng Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23367v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23367v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2512.23176v1",
    "title": "GVSynergy-Det: Synergistic Gaussian-Voxel Representations for Multi-View 3D Object Detection",
    "summary": "Image-based 3D object detection aims to identify and localize objects in 3D space using only RGB images, eliminating the need for expensive depth sensors required by point cloud-based methods. Existing image-based approaches face two critical challenges: methods achieving high accuracy typically require dense 3D supervision, while those operating without such supervision struggle to extract accurate geometry from images alone. In this paper, we present GVSynergy-Det, a novel framework that enhances 3D detection through synergistic Gaussian-Voxel representation learning. Our key insight is that continuous Gaussian and discrete voxel representations capture complementary geometric information: Gaussians excel at modeling fine-grained surface details while voxels provide structured spatial context. We introduce a dual-representation architecture that: 1) adapts generalizable Gaussian Splatting to extract complementary geometric features for detection tasks, and 2) develops a cross-representation enhancement mechanism that enriches voxel features with geometric details from Gaussian fields. Unlike previous methods that either rely on time-consuming per-scene optimization or utilize Gaussian representations solely for depth regularization, our synergistic strategy directly leverages features from both representations through learnable integration, enabling more accurate object localization. Extensive experiments demonstrate that GVSynergy-Det achieves state-of-the-art results on challenging indoor benchmarks, significantly outperforming existing methods on both ScanNetV2 and ARKitScenes datasets, all without requiring any depth or dense 3D geometry supervision (e.g., point clouds or TSDF).",
    "authors": [
      "Yi Zhang",
      "Yi Wang",
      "Lei Yao",
      "Lap-Pui Chau"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23176v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23176v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2512.23137v1",
    "title": "Graph Neural Networks with Transformer Fusion of Brain Connectivity Dynamics and Tabular Data for Forecasting Future Tobacco Use",
    "summary": "Integrating non-Euclidean brain imaging data with Euclidean tabular data, such as clinical and demographic information, poses a substantial challenge for medical imaging analysis, particularly in forecasting future outcomes. While machine learning and deep learning techniques have been applied successfully to cross-sectional classification and prediction tasks, effectively forecasting outcomes in longitudinal imaging studies remains challenging. To address this challenge, we introduce a time-aware graph neural network model with transformer fusion (GNN-TF). This model flexibly integrates both tabular data and dynamic brain connectivity data, leveraging the temporal order of these variables within a coherent framework. By incorporating non-Euclidean and Euclidean sources of information from a longitudinal resting-state fMRI dataset from the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA), the GNN-TF enables a comprehensive analysis that captures critical aspects of longitudinal imaging data. Comparative analyses against a variety of established machine learning and deep learning models demonstrate that GNN-TF outperforms these state-of-the-art methods, delivering superior predictive accuracy for predicting future tobacco usage. The end-to-end, time-aware transformer fusion structure of the proposed GNN-TF model successfully integrates multiple data modalities and leverages temporal dynamics, making it a valuable analytic tool for functional brain imaging studies focused on clinical outcome prediction.",
    "authors": [
      "Runzhi Zhou",
      "Xi Luo"
    ],
    "categories": [
      "cs.LG",
      "eess.IV",
      "q-bio.NC"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23137v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23137v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2512.23709v1",
    "title": "Stream-DiffVSR: Low-Latency Streamable Video Super-Resolution via Auto-Regressive Diffusion",
    "summary": "Diffusion-based video super-resolution (VSR) methods achieve strong perceptual quality but remain impractical for latency-sensitive settings due to reliance on future frames and expensive multi-step denoising. We propose Stream-DiffVSR, a causally conditioned diffusion framework for efficient online VSR. Operating strictly on past frames, it combines a four-step distilled denoiser for fast inference, an Auto-regressive Temporal Guidance (ARTG) module that injects motion-aligned cues during latent denoising, and a lightweight temporal-aware decoder with a Temporal Processor Module (TPM) that enhances detail and temporal coherence. Stream-DiffVSR processes 720p frames in 0.328 seconds on an RTX4090 GPU and significantly outperforms prior diffusion-based methods. Compared with the online SOTA TMP, it boosts perceptual quality (LPIPS +0.095) while reducing latency by over 130x. Stream-DiffVSR achieves the lowest latency reported for diffusion-based VSR, reducing initial delay from over 4600 seconds to 0.328 seconds, thereby making it the first diffusion VSR method suitable for low-latency online deployment. Project page: https://jamichss.github.io/stream-diffvsr-project-page/",
    "authors": [
      "Hau-Shiang Shiu",
      "Chin-Yang Lin",
      "Zhixiang Wang",
      "Chi-Wei Hsiao",
      "Po-Fan Yu",
      "Yu-Chih Chen",
      "Yu-Lun Liu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23709v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23709v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.23707v1",
    "title": "Training AI Co-Scientists Using Rubric Rewards",
    "summary": "AI co-scientists are emerging as a tool to assist human researchers in achieving their research goals. A crucial feature of these AI co-scientists is the ability to generate a research plan given a set of aims and constraints. The plan may be used by researchers for brainstorming, or may even be implemented after further refinement. However, language models currently struggle to generate research plans that follow all constraints and implicit requirements. In this work, we study how to leverage the vast corpus of existing research papers to train language models that generate better research plans. We build a scalable, diverse training corpus by automatically extracting research goals and goal-specific grading rubrics from papers across several domains. We then train models for research plan generation via reinforcement learning with self-grading. A frozen copy of the initial policy acts as the grader during training, with the rubrics creating a generator-verifier gap that enables improvements without external human supervision. To validate this approach, we conduct a study with human experts for machine learning research goals, spanning 225 hours. The experts prefer plans generated by our finetuned Qwen3-30B-A3B model over the initial model for 70% of research goals, and approve 84% of the automatically extracted goal-specific grading rubrics. To assess generality, we also extend our approach to research goals from medical papers, and new arXiv preprints, evaluating with a jury of frontier models. Our finetuning yields 12-22% relative improvements and significant cross-domain generalization, proving effective even in problem settings like medical research where execution feedback is infeasible. Together, these findings demonstrate the potential of a scalable, automated training recipe as a step towards improving general AI co-scientists.",
    "authors": [
      "Shashwat Goel",
      "Rishi Hazra",
      "Dulhan Jayalath",
      "Timon Willi",
      "Parag Jain",
      "William F. Shen",
      "Ilias Leontiadis",
      "Francesco Barbieri",
      "Yoram Bachrach",
      "Jonas Geiping",
      "Chenxi Whitehouse"
    ],
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.HC"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23707v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23707v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.23693v1",
    "title": "Fine-Tuning LLMs with Fine-Grained Human Feedback on Text Spans",
    "summary": "We present a method and dataset for fine-tuning language models with preference supervision using feedback-driven improvement chains. Given a model response, an annotator provides fine-grained feedback by marking ``liked'' and ``disliked'' spans and specifying what they liked or disliked about them. The base model then rewrites the disliked spans accordingly, proceeding from left to right, forming a sequence of incremental improvements. We construct preference pairs for direct alignment from each adjacent step in the chain, enabling the model to learn from localized, targeted edits. We find that our approach outperforms direct alignment methods based on standard A/B preference ranking or full contrastive rewrites, demonstrating that structured, revision-based supervision leads to more efficient and effective preference tuning.",
    "authors": [
      "Sky CH-Wang",
      "Justin Svegliato",
      "Helen Appel",
      "Jason Eisner"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23693v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23693v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.23635v1",
    "title": "Rethinking the Spatio-Temporal Alignment of End-to-End 3D Perception",
    "summary": "Spatio-temporal alignment is crucial for temporal modeling of end-to-end (E2E) perception in autonomous driving (AD), providing valuable structural and textural prior information. Existing methods typically rely on the attention mechanism to align objects across frames, simplifying the motion model with a unified explicit physical model (constant velocity, etc.). These approaches prefer semantic features for implicit alignment, challenging the importance of explicit motion modeling in the traditional perception paradigm. However, variations in motion states and object features across categories and frames render this alignment suboptimal. To address this, we propose HAT, a spatio-temporal alignment module that allows each object to adaptively decode the optimal alignment proposal from multiple hypotheses without direct supervision. Specifically, HAT first utilizes multiple explicit motion models to generate spatial anchors and motion-aware feature proposals for historical instances. It then performs multi-hypothesis decoding by incorporating semantic and motion cues embedded in cached object queries, ultimately providing the optimal alignment proposal for the target frame. On nuScenes, HAT consistently improves 3D temporal detectors and trackers across diverse baselines. It achieves state-of-the-art tracking results with 46.0% AMOTA on the test set when paired with the DETR3D detector. In an object-centric E2E AD method, HAT enhances perception accuracy (+1.3% mAP, +3.1% AMOTA) and reduces the collision rate by 32%. When semantics are corrupted (nuScenes-C), the enhancement of motion modeling by HAT enables more robust perception and planning in the E2E AD.",
    "authors": [
      "Xiaoyu Li",
      "Peidong Li",
      "Xian Wu",
      "Long Shi",
      "Dedong Liu",
      "Yitao Wu",
      "Jiajia Fu",
      "Dixiao Cui",
      "Lijun Zhao",
      "Lining Sun"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23635v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23635v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.23617v1",
    "title": "Le Cam Distortion: A Decision-Theoretic Framework for Robust Transfer Learning",
    "summary": "Distribution shift is the defining challenge of real-world machine learning. The dominant paradigm--Unsupervised Domain Adaptation (UDA)--enforces feature invariance, aligning source and target representations via symmetric divergence minimization [Ganin et al., 2016]. We demonstrate that this approach is fundamentally flawed: when domains are unequally informative (e.g., high-quality vs degraded sensors), strict invariance necessitates information destruction, causing \"negative transfer\" that can be catastrophic in safety-critical applications [Wang et al., 2019].   We propose a decision-theoretic framework grounded in Le Cam's theory of statistical experiments [Le Cam, 1986], using constructive approximations to replace symmetric invariance with directional simulability. We introduce Le Cam Distortion, quantified by the Deficiency Distance $δ(E_1, E_2)$, as a rigorous upper bound for transfer risk conditional on simulability. Our framework enables transfer without source degradation by learning a kernel that simulates the target from the source. Across five experiments (genomics, vision, reinforcement learning), Le Cam Distortion achieves: (1) near-perfect frequency estimation in HLA genomics (correlation $r=0.999$, matching classical methods), (2) zero source utility loss in CIFAR-10 image classification (81.2% accuracy preserved vs 34.7% drop for CycleGAN), and (3) safe policy transfer in RL control where invariance-based methods suffer catastrophic collapse. Le Cam Distortion provides the first principled framework for risk-controlled transfer learning in domains where negative transfer is unacceptable: medical imaging, autonomous systems, and precision medicine.",
    "authors": [
      "Deniz Akdemir"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ME",
      "stat.ML"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23617v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23617v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.23515v1",
    "title": "Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning",
    "summary": "Signal decay and regime shifts pose recurring challenges for data-driven investment strategies in non-stationary markets. Conventional time-series and machine learning approaches, which rely primarily on historical correlations, often struggle to generalize when the economic environment changes. While large language models (LLMs) offer strong capabilities for processing unstructured information, their potential to support quantitative factor screening through explicit economic reasoning remains underexplored. Existing factor-based methods typically reduce alphas to numerical time series, overlooking the semantic rationale that determines when a factor is economically relevant. We propose Alpha-R1, an 8B-parameter reasoning model trained via reinforcement learning for context-aware alpha screening. Alpha-R1 reasons over factor logic and real-time news to evaluate alpha relevance under changing market conditions, selectively activating or deactivating factors based on contextual consistency. Empirical results across multiple asset pools show that Alpha-R1 consistently outperforms benchmark strategies and exhibits improved robustness to alpha decay. The full implementation and resources are available at https://github.com/FinStep-AI/Alpha-R1.",
    "authors": [
      "Zuoyou Jiang",
      "Li Zhao",
      "Rui Sun",
      "Ruohan Sun",
      "Zhongjian Li",
      "Jing Li",
      "Daxin Jiang",
      "Zuo Bai",
      "Cheng Hua"
    ],
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23515v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23515v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.23489v1",
    "title": "The Gaining Paths to Investment Success: Information-Driven LLM Graph Reasoning for Venture Capital Prediction",
    "summary": "Most venture capital (VC) investments fail, while a few deliver outsized returns. Accurately predicting startup success requires synthesizing complex relational evidence, including company disclosures, investor track records, and investment network structures, through explicit reasoning to form coherent, interpretable investment theses. Traditional machine learning and graph neural networks both lack this reasoning capability. Large language models (LLMs) offer strong reasoning but face a modality mismatch with graphs. Recent graph-LLM methods target in-graph tasks where answers lie within the graph, whereas VC prediction is off-graph: the target exists outside the network. The core challenge is selecting graph paths that maximize predictor performance on an external objective while enabling step-by-step reasoning. We present MIRAGE-VC, a multi-perspective retrieval-augmented generation framework that addresses two obstacles: path explosion (thousands of candidate paths overwhelm LLM context) and heterogeneous evidence fusion (different startups need different analytical emphasis). Our information-gain-driven path retriever iteratively selects high-value neighbors, distilling investment networks into compact chains for explicit reasoning. A multi-agent architecture integrates three evidence streams via a learnable gating mechanism based on company attributes. Under strict anti-leakage controls, MIRAGE-VC achieves +5.0% F1 and +16.6% PrecisionAt5, and sheds light on other off-graph prediction tasks such as recommendation and risk assessment. Code: https://anonymous.4open.science/r/MIRAGE-VC-323F.",
    "authors": [
      "Haoyu Pei",
      "Zhongyang Liu",
      "Xiangyi Xiao",
      "Xiaocong Du",
      "Haipeng Zhang",
      "Kunpeng Zhang",
      "Suting Hong"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23489v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23489v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.23421v1",
    "title": "DriveLaW:Unifying Planning and Video Generation in a Latent Driving World",
    "summary": "World models have become crucial for autonomous driving, as they learn how scenarios evolve over time to address the long-tail challenges of the real world. However, current approaches relegate world models to limited roles: they operate within ostensibly unified architectures that still keep world prediction and motion planning as decoupled processes. To bridge this gap, we propose DriveLaW, a novel paradigm that unifies video generation and motion planning. By directly injecting the latent representation from its video generator into the planner, DriveLaW ensures inherent consistency between high-fidelity future generation and reliable trajectory planning. Specifically, DriveLaW consists of two core components: DriveLaW-Video, our powerful world model that generates high-fidelity forecasting with expressive latent representations, and DriveLaW-Act, a diffusion planner that generates consistent and reliable trajectories from the latent of DriveLaW-Video, with both components optimized by a three-stage progressive training strategy. The power of our unified paradigm is demonstrated by new state-of-the-art results across both tasks. DriveLaW not only advances video prediction significantly, surpassing best-performing work by 33.3% in FID and 1.8% in FVD, but also achieves a new record on the NAVSIM planning benchmark.",
    "authors": [
      "Tianze Xia",
      "Yongkang Li",
      "Lijun Zhou",
      "Jingfeng Yao",
      "Kaixin Xiong",
      "Haiyang Sun",
      "Bing Wang",
      "Kun Ma",
      "Hangjun Ye",
      "Wenyu Liu",
      "Xinggang Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23421v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23421v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.23375v1",
    "title": "Diffusion priors enhanced velocity model building from time-lag images using a neural operator",
    "summary": "Velocity model building serves as a crucial component for achieving high precision subsurface imaging. However, conventional velocity model building methods are often computationally expensive and time consuming. In recent years, with the rapid advancement of deep learning, particularly the success of generative models and neural operators, deep learning based approaches that integrate data and their statistics have attracted increasing attention in addressing the limitations of traditional methods. In this study, we propose a novel framework that combines generative models with neural operators to obtain high resolution velocity models efficiently. Within this workflow, the neural operator functions as a forward mapping operator to rapidly generate time lag reverse time migration (RTM) extended images from the true and migration velocity models. In this framework, the neural operator is acting as a surrogate for modeling followed by migration, which uses the true and migration velocities, respectively. The trained neural operator is then employed, through automatic differentiation, to gradually update the migration velocity placed in the true velocity input channel with high resolution components so that the output of the network matches the time lag images of observed data obtained using the migration velocity. By embedding a generative model, trained on a high-resolution velocity model distribution, which corresponds to the true velocity model distribution used to train the neural operator, as a regularizer, the resulting predictions are cleaner with higher resolution information. Both synthetic and field data experiments demonstrate the effectiveness of the proposed generative neural operator based velocity model building approach.",
    "authors": [
      "Xiao Ma",
      "Mohammad Hasyim Taufik",
      "Tariq Alkhalifah"
    ],
    "categories": [
      "cs.LG",
      "physics.geo-ph"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23375v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23375v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.23324v1",
    "title": "On Conformant Planning and Model-Checking of $\\exists^*\\forall^*$ Hyperproperties",
    "summary": "We study the connection of two problems within the planning and verification community: Conformant planning and model-checking of hyperproperties. Conformant planning is the task of finding a sequential plan that achieves a given objective independent of non-deterministic action effects during the plan's execution. Hyperproperties are system properties that relate multiple execution traces of a system and, e.g., capture information-flow and fairness policies. In this paper, we show that model-checking of $\\exists^*\\forall^*$ hyperproperties is closely related to the problem of computing a conformant plan. Firstly, we show that we can efficiently reduce a hyperproperty model-checking instance to a conformant planning instance, and prove that our encoding is sound and complete. Secondly, we establish the converse direction: Every conformant planning problem is, itself, a hyperproperty model-checking task.",
    "authors": [
      "Raven Beutner",
      "Bernd Finkbeiner"
    ],
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23324v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23324v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.23214v1",
    "title": "Anka: A Domain-Specific Language for Reliable LLM Code Generation",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in code generation, yet they exhibit systematic errors on complex, multi-step programming tasks. We hypothesize that these errors stem from the flexibility of general-purpose languages, which permits multiple valid approaches and requires implicit state management. To test this hypothesis, we introduce Anka, a domain-specific language (DSL) for data transformation pipelines designed with explicit, constrained syntax that reduces ambiguity in code generation. Despite having zero prior training exposure to Anka, Claude 3.5 Haiku achieves 99.9% parse success and 95.8% overall task accuracy across 100 benchmark problems. Critically, Anka demonstrates a 40 percentage point accuracy advantage over Python on multi-step pipeline tasks (100% vs. 60%), where Python's flexible syntax leads to frequent errors in operation sequencing and variable management. Cross-model validation with GPT-4o-mini confirms this advantage (+26.7 percentage points on multi-step tasks). Our results demonstrate that: (1) LLMs can learn novel DSLs entirely from in-context prompts, achieving near-native accuracy; (2) constrained syntax significantly reduces errors on complex tasks; and (3) domain-specific languages purposefully designed for LLM generation can outperform general-purpose languages on which the LLM has extensive training. We release the complete language implementation, benchmark suite, and evaluation framework to facilitate further research.",
    "authors": [
      "Saif Khalfan Saif Al Mazrouei"
    ],
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.PL",
      "cs.SE"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23214v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23214v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.23190v1",
    "title": "A Simple, Optimal and Efficient Algorithm for Online Exp-Concave Optimization",
    "summary": "Online eXp-concave Optimization (OXO) is a fundamental problem in online learning. The standard algorithm, Online Newton Step (ONS), balances statistical optimality and computational practicality, guaranteeing an optimal regret of $O(d \\log T)$, where $d$ is the dimension and $T$ is the time horizon. ONS faces a computational bottleneck due to the Mahalanobis projections at each round. This step costs $Ω(d^ω)$ arithmetic operations for bounded domains, even for the unit ball, where $ω\\in (2,3]$ is the matrix-multiplication exponent. As a result, the total runtime can reach $\\tilde{O}(d^ωT)$, particularly when iterates frequently oscillate near the domain boundary. For Stochastic eXp-concave Optimization (SXO), computational cost is also a challenge. Deploying ONS with online-to-batch conversion for SXO requires $T = \\tilde{O}(d/ε)$ rounds to achieve an excess risk of $ε$, and thereby necessitates an $\\tilde{O}(d^{ω+1}/ε)$ runtime. A COLT'13 open problem posed by Koren [2013] asks for an SXO algorithm with runtime less than $\\tilde{O}(d^{ω+1}/ε)$.   This paper proposes a simple variant of ONS, LightONS, which reduces the total runtime to $O(d^2 T + d^ω\\sqrt{T \\log T})$ while preserving the optimal $O(d \\log T)$ regret. LightONS implies an SXO method with runtime $\\tilde{O}(d^3/ε)$, thereby answering the open problem. Importantly, LightONS preserves the elegant structure of ONS by leveraging domain-conversion techniques from parameter-free online learning to introduce a hysteresis mechanism that delays expensive Mahalanobis projections until necessary. This design enables LightONS to serve as an efficient plug-in replacement of ONS in broader scenarios, even beyond regret minimization, including gradient-norm adaptive regret, parametric stochastic bandits, and memory-efficient online learning.",
    "authors": [
      "Yi-Han Wang",
      "Peng Zhao",
      "Zhi-Hua Zhou"
    ],
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23190v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23190v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.23180v1",
    "title": "GaussianDWM: 3D Gaussian Driving World Model for Unified Scene Understanding and Multi-Modal Generation",
    "summary": "Driving World Models (DWMs) have been developing rapidly with the advances of generative models. However, existing DWMs lack 3D scene understanding capabilities and can only generate content conditioned on input data, without the ability to interpret or reason about the driving environment. Moreover, current approaches represent 3D spatial information with point cloud or BEV features do not accurately align textual information with the underlying 3D scene. To address these limitations, we propose a novel unified DWM framework based on 3D Gaussian scene representation, which enables both 3D scene understanding and multi-modal scene generation, while also enabling contextual enrichment for understanding and generation tasks. Our approach directly aligns textual information with the 3D scene by embedding rich linguistic features into each Gaussian primitive, thereby achieving early modality alignment. In addition, we design a novel task-aware language-guided sampling strategy that removes redundant 3D Gaussians and injects accurate and compact 3D tokens into LLM. Furthermore, we design a dual-condition multi-modal generation model, where the information captured by our vision-language model is leveraged as a high-level language condition in combination with a low-level image condition, jointly guiding the multi-modal generation process. We conduct comprehensive studies on the nuScenes, and NuInteract datasets to validate the effectiveness of our framework. Our method achieves state-of-the-art performance. We will release the code publicly on GitHub https://github.com/dtc111111/GaussianDWM.",
    "authors": [
      "Tianchen Deng",
      "Xuefeng Chen",
      "Yi Chen",
      "Qu Chen",
      "Yuyao Xu",
      "Lijin Yang",
      "Le Xu",
      "Yu Zhang",
      "Bo Zhang",
      "Wuxiong Huang",
      "Hesheng Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23180v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23180v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.23165v1",
    "title": "Evaluating Parameter Efficient Methods for RLVR",
    "summary": "We systematically evaluate Parameter-Efficient Fine-Tuning (PEFT) methods under the paradigm of Reinforcement Learning with Verifiable Rewards (RLVR). RLVR incentivizes language models to enhance their reasoning capabilities through verifiable feedback; however, while methods like LoRA are commonly used, the optimal PEFT architecture for RLVR remains unidentified. In this work, we conduct the first comprehensive evaluation of over 12 PEFT methodologies across the DeepSeek-R1-Distill families on mathematical reasoning benchmarks. Our empirical results challenge the default adoption of standard LoRA with three main findings. First, we demonstrate that structural variants, such as DoRA, AdaLoRA, and MiSS, consistently outperform LoRA. Second, we uncover a spectral collapse phenomenon in SVD-informed initialization strategies (\\textit{e.g.,} PiSSA, MiLoRA), attributing their failure to a fundamental misalignment between principal-component updates and RL optimization. Furthermore, our ablations reveal that extreme parameter reduction (\\textit{e.g.,} VeRA, Rank-1) severely bottlenecks reasoning capacity. We further conduct ablation studies and scaling experiments to validate our findings. This work provides a definitive guide for advocating for more exploration for parameter-efficient RL methods.",
    "authors": [
      "Qingyu Yin",
      "Yulun Wu",
      "Zhennan Shen",
      "Sunbowen Li",
      "Zhilin Wang",
      "Yanshu Li",
      "Chak Tou Leong",
      "Jiale Kang",
      "Jinjin Gu"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23165v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23165v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.23705v1",
    "title": "Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation",
    "summary": "Transparent objects remain notoriously hard for perception systems: refraction, reflection and transmission break the assumptions behind stereo, ToF and purely discriminative monocular depth, causing holes and temporally unstable estimates. Our key observation is that modern video diffusion models already synthesize convincing transparent phenomena, suggesting they have internalized the optical rules. We build TransPhy3D, a synthetic video corpus of transparent/reflective scenes: 11k sequences rendered with Blender/Cycles. Scenes are assembled from a curated bank of category-rich static assets and shape-rich procedural assets paired with glass/plastic/metal materials. We render RGB + depth + normals with physically based ray tracing and OptiX denoising. Starting from a large video diffusion model, we learn a video-to-video translator for depth (and normals) via lightweight LoRA adapters. During training we concatenate RGB and (noisy) depth latents in the DiT backbone and co-train on TransPhy3D and existing frame-wise synthetic datasets, yielding temporally consistent predictions for arbitrary-length input videos. The resulting model, DKT, achieves zero-shot SOTA on real and synthetic video benchmarks involving transparency: ClearPose, DREDS (CatKnown/CatNovel), and TransPhy3D-Test. It improves accuracy and temporal consistency over strong image/video baselines, and a normal variant sets the best video normal estimation results on ClearPose. A compact 1.3B version runs at ~0.17 s/frame. Integrated into a grasping stack, DKT's depth boosts success rates across translucent, reflective and diffuse surfaces, outperforming prior estimators. Together, these results support a broader claim: \"Diffusion knows transparency.\" Generative video priors can be repurposed, efficiently and label-free, into robust, temporally coherent perception for challenging real-world manipulation.",
    "authors": [
      "Shaocong Xu",
      "Songlin Wei",
      "Qizhe Wei",
      "Zheng Geng",
      "Hong Li",
      "Licheng Shen",
      "Qianpu Sun",
      "Shu Han",
      "Bin Ma",
      "Bohan Li",
      "Chongjie Ye",
      "Yuhang Zheng",
      "Nan Wang",
      "Saining Zhang",
      "Hao Zhao"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23705v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23705v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.23631v1",
    "title": "BOAD: Discovering Hierarchical Software Engineering Agents via Bandit Optimization",
    "summary": "Large language models (LLMs) have shown strong reasoning and coding capabilities, yet they struggle to generalize to real-world software engineering (SWE) problems that are long-horizon and out of distribution. Existing systems often rely on a single agent to handle the entire workflow-interpreting issues, navigating large codebases, and implementing fixes-within one reasoning chain. Such monolithic designs force the model to retain irrelevant context, leading to spurious correlations and poor generalization. Motivated by how human engineers decompose complex problems, we propose structuring SWE agents as orchestrators coordinating specialized sub-agents for sub-tasks such as localization, editing, and validation. The challenge lies in discovering effective hierarchies automatically: as the number of sub-agents grows, the search space becomes combinatorial, and it is difficult to attribute credit to individual sub-agents within a team. We address these challenges by formulating hierarchy discovery as a multi-armed bandit (MAB) problem, where each arm represents a candidate sub-agent and the reward measures its helpfulness when collaborating with others. This framework, termed Bandit Optimization for Agent Design (BOAD), enables efficient exploration of sub-agent designs under limited evaluation budgets. On SWE-bench-Verified, BOAD outperforms single-agent and manually designed multi-agent systems. On SWE-bench-Live, featuring more recent and out-of-distribution issues, our 36B system ranks second on the leaderboard at the time of evaluation, surpassing larger models such as GPT-4 and Claude. These results demonstrate that automatically discovered hierarchical multi-agent systems significantly improve generalization on challenging long-horizon SWE tasks. Code is available at https://github.com/iamxjy/BOAD-SWE-Agent.",
    "authors": [
      "Iris Xu",
      "Guangtao Zeng",
      "Zexue He",
      "Charles Jin",
      "Aldo Pareja",
      "Dan Gutfreund",
      "Chuang Gan",
      "Zhang-Wei Hong"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23631v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23631v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.23626v1",
    "title": "Regret-Based Federated Causal Discovery with Unknown Interventions",
    "summary": "Most causal discovery methods recover a completed partially directed acyclic graph representing a Markov equivalence class from observational data. Recent work has extended these methods to federated settings to address data decentralization and privacy constraints, but often under idealized assumptions that all clients share the same causal model. Such assumptions are unrealistic in practice, as client-specific policies or protocols, for example, across hospitals, naturally induce heterogeneous and unknown interventions. In this work, we address federated causal discovery under unknown client-level interventions. We propose I-PERI, a novel federated algorithm that first recovers the CPDAG of the union of client graphs and then orients additional edges by exploiting structural differences induced by interventions across clients. This yields a tighter equivalence class, which we call the $\\mathbfΦ$-Markov Equivalence Class, represented by the $\\mathbfΦ$-CPDAG. We provide theoretical guarantees on the convergence of I-PERI, as well as on its privacy-preserving properties, and present empirical evaluations on synthetic data demonstrating the effectiveness of the proposed algorithm.",
    "authors": [
      "Federico Baldo",
      "Charles K. Assaad"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23626v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23626v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.23568v1",
    "title": "ThinkGen: Generalized Thinking for Visual Generation",
    "summary": "Recent progress in Multimodal Large Language Models (MLLMs) demonstrates that Chain-of-Thought (CoT) reasoning enables systematic solutions to complex understanding tasks. However, its extension to generation tasks remains nascent and limited by scenario-specific mechanisms that hinder generalization and adaptation. In this work, we present ThinkGen, the first think-driven visual generation framework that explicitly leverages MLLM's CoT reasoning in various generation scenarios. ThinkGen employs a decoupled architecture comprising a pretrained MLLM and a Diffusion Transformer (DiT), wherein the MLLM generates tailored instructions based on user intent, and DiT produces high-quality images guided by these instructions. We further propose a separable GRPO-based training paradigm (SepGRPO), alternating reinforcement learning between the MLLM and DiT modules. This flexible design enables joint training across diverse datasets, facilitating effective CoT reasoning for a wide range of generative scenarios. Extensive experiments demonstrate that ThinkGen achieves robust, state-of-the-art performance across multiple generation benchmarks. Code is available: https://github.com/jiaosiyuu/ThinkGen",
    "authors": [
      "Siyu Jiao",
      "Yiheng Lin",
      "Yujie Zhong",
      "Qi She",
      "Wei Zhou",
      "Xiaohan Lan",
      "Zilong Huang",
      "Fei Yu",
      "Yingchen Yu",
      "Yunqing Zhao",
      "Yao Zhao",
      "Yunchao Wei"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23568v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23568v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.23461v1",
    "title": "Eliminating Inductive Bias in Reward Models with Information-Theoretic Guidance",
    "summary": "Reward models (RMs) are essential in reinforcement learning from human feedback (RLHF) to align large language models (LLMs) with human values. However, RM training data is commonly recognized as low-quality, containing inductive biases that can easily lead to overfitting and reward hacking. For example, more detailed and comprehensive responses are usually human-preferred but with more words, leading response length to become one of the inevitable inductive biases. A limited number of prior RM debiasing approaches either target a single specific type of bias or model the problem with only simple linear correlations, \\textit{e.g.}, Pearson coefficients. To mitigate more complex and diverse inductive biases in reward modeling, we introduce a novel information-theoretic debiasing method called \\textbf{D}ebiasing via \\textbf{I}nformation optimization for \\textbf{R}M (DIR). Inspired by the information bottleneck (IB), we maximize the mutual information (MI) between RM scores and human preference pairs, while minimizing the MI between RM outputs and biased attributes of preference inputs. With theoretical justification from information theory, DIR can handle more sophisticated types of biases with non-linear correlations, broadly extending the real-world application scenarios for RM debiasing methods. In experiments, we verify the effectiveness of DIR with three types of inductive biases: \\textit{response length}, \\textit{sycophancy}, and \\textit{format}. We discover that DIR not only effectively mitigates target inductive biases but also enhances RLHF performance across diverse benchmarks, yielding better generalization abilities. The code and training recipes are available at https://github.com/Qwen-Applications/DIR.",
    "authors": [
      "Zhuo Li",
      "Pengyu Cheng",
      "Zhechao Yu",
      "Feifei Tong",
      "Anningzhe Gao",
      "Tsung-Hui Chang",
      "Xiang Wan",
      "Erchao Zhao",
      "Xiaoxi Jiang",
      "Guanjun Jiang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23461v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23461v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.23457v1",
    "title": "Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following",
    "summary": "Reinforcement Learning (RL) has shown promise for aligning Large Language Models (LLMs) to follow instructions with various constraints. Despite the encouraging results, RL improvement inevitably relies on sampling successful, high-quality responses; however, the initial model often struggles to generate responses that satisfy all constraints due to its limited capabilities, yielding sparse or indistinguishable rewards that impede learning. In this work, we propose Hindsight instruction Replay (HiR), a novel sample-efficient RL framework for complex instruction following tasks, which employs a select-then-rewrite strategy to replay failed attempts as successes based on the constraints that have been satisfied in hindsight. We perform RL on these replayed samples as well as the original ones, theoretically framing the objective as dual-preference learning at both the instruction- and response-level to enable efficient optimization using only a binary reward signal. Extensive experiments demonstrate that the proposed HiR yields promising results across different instruction following tasks, while requiring less computational budget. Our code and dataset is available at https://github.com/sastpg/HIR.",
    "authors": [
      "Kongcheng Zhang",
      "Qi Yao",
      "Shunyu Liu",
      "Wenjian Zhang",
      "Min Cen",
      "Yang Zhou",
      "Wenkai Fang",
      "Yiru Zhao",
      "Baisheng Lai",
      "Mingli Song"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23457v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23457v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.23410v1",
    "title": "Directly Constructing Low-Dimensional Solution Subspaces in Deep Neural Networks",
    "summary": "While it is well-established that the weight matrices and feature manifolds of deep neural networks exhibit a low Intrinsic Dimension (ID), current state-of-the-art models still rely on massive high-dimensional widths. This redundancy is not required for representation, but is strictly necessary to solve the non-convex optimization search problem-finding a global minimum, which remains intractable for compact networks. In this work, we propose a constructive approach to bypass this optimization bottleneck. By decoupling the solution geometry from the ambient search space, we empirically demonstrate across ResNet-50, ViT, and BERT that the classification head can be compressed by even huge factors of 16 with negligible performance degradation. This motivates Subspace-Native Distillation as a novel paradigm: by defining the target directly in this constructed subspace, we provide a stable geometric coordinate system for student models, potentially allowing them to circumvent the high-dimensional search problem entirely and realize the vision of Train Big, Deploy Small.",
    "authors": [
      "Yusuf Kalyoncuoglu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23410v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23410v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.23380v1",
    "title": "A unified framework for detecting point and collective anomalies in operating system logs via collaborative transformers",
    "summary": "Log anomaly detection is crucial for preserving the security of operating systems. Depending on the source of log data collection, various information is recorded in logs that can be considered log modalities. In light of this intuition, unimodal methods often struggle by ignoring the different modalities of log data. Meanwhile, multimodal methods fail to handle the interactions between these modalities. Applying multimodal sentiment analysis to log anomaly detection, we propose CoLog, a framework that collaboratively encodes logs utilizing various modalities. CoLog utilizes collaborative transformers and multi-head impressed attention to learn interactions among several modalities, ensuring comprehensive anomaly detection. To handle the heterogeneity caused by these interactions, CoLog incorporates a modality adaptation layer, which adapts the representations from different log modalities. This methodology enables CoLog to learn nuanced patterns and dependencies within the data, enhancing its anomaly detection capabilities. Extensive experiments demonstrate CoLog's superiority over existing state-of-the-art methods. Furthermore, in detecting both point and collective anomalies, CoLog achieves a mean precision of 99.63%, a mean recall of 99.59%, and a mean F1 score of 99.61% across seven benchmark datasets for log-based anomaly detection. The comprehensive detection capabilities of CoLog make it highly suitable for cybersecurity, system monitoring, and operational efficiency. CoLog represents a significant advancement in log anomaly detection, providing a sophisticated and effective solution to point and collective anomaly detection through a unified framework and a solution to the complex challenges automatic log data analysis poses. We also provide the implementation of CoLog at https://github.com/NasirzadehMoh/CoLog.",
    "authors": [
      "Mohammad Nasirzadeh",
      "Jafar Tahmoresnezhad",
      "Parviz Rashidi-Khazaee"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NI",
      "cs.OS"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23380v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23380v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.23335v1",
    "title": "Visual Language Hypothesis",
    "summary": "We study visual representation learning from a structural and topological perspective. We begin from a single hypothesis: that visual understanding presupposes a semantic language for vision, in which many perceptual observations correspond to a small number of discrete semantic states. Together with widely assumed premises on transferability and abstraction in representation learning, this hypothesis implies that the visual observation space must be organized in a fiber bundle like structure, where nuisance variation populates fibers and semantics correspond to a quotient base space. From this structure we derive two theoretical consequences. First, the semantic quotient $X/G$ is not a submanifold of $X$ and cannot be obtained through smooth deformation alone, semantic invariance requires a non-homeomorphic, discriminative target, for example, supervision via labels, cross instance identification, or multimodal alignment that supplies explicit semantic equivalence. Second, we show that approximating the quotient also places structural demands on the model architecture. Semantic abstraction requires not only an external semantic target, but a representation mechanism capable of supporting topology change: an expand-and-snap process in which the manifold is first geometrically expanded to separate structure and then collapsed to form discrete semantic regions. We emphasize that these results are interpretive rather than prescriptive: the framework provides a topological lens that aligns with empirical regularities observed in large-scale discriminative and multimodal models, and with classical principles in statistical learning theory.",
    "authors": [
      "Xiu Li"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23335v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23335v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.23260v1",
    "title": "Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation",
    "summary": "Parameter-efficient fine-tuning has become the dominant paradigm for adapting large language models to downstream tasks. Low-rank adaptation methods such as LoRA operate under the assumption that task-relevant weight updates reside in a low-rank subspace, yet this subspace is learned implicitly from data in a black-box manner, offering no interpretability or direct control. We hypothesize that this difficulty stems from polysemanticity--individual dimensions encoding multiple entangled concepts. To address this, we leverage pre-trained Sparse Autoencoders (SAEs) to identify task-relevant features in a disentangled feature space, then construct an explicit, interpretable low-rank subspace to guide adapter initialization. We provide theoretical analysis proving that under monosemanticity assumptions, SAE-based subspace identification achieves arbitrarily small recovery error, while direct identification in polysemantic space suffers an irreducible error floor. On safety alignment, our method achieves up to 99.6% safety rate--exceeding full fine-tuning by 7.4 percentage points and approaching RLHF-based methods--while updating only 0.19-0.24% of parameters. Crucially, our method provides interpretable insights into the learned alignment subspace through the semantic grounding of SAE features. Our work demonstrates that incorporating mechanistic interpretability into the fine-tuning process can simultaneously improve both performance and transparency.",
    "authors": [
      "Dianyun Wang",
      "Qingsen Ma",
      "Yuhu Shang",
      "Zhifeng Lu",
      "Lechen Ning",
      "Zhenbo Xu",
      "Huijia Wu",
      "Zhaofeng He"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23260v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23260v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.23239v1",
    "title": "RS-Prune: Training-Free Data Pruning at High Ratios for Efficient Remote Sensing Diffusion Foundation Models",
    "summary": "Diffusion-based remote sensing (RS) generative foundation models are cruial for downstream tasks. However, these models rely on large amounts of globally representative data, which often contain redundancy, noise, and class imbalance, reducing training efficiency and preventing convergence. Existing RS diffusion foundation models typically aggregate multiple classification datasets or apply simplistic deduplication, overlooking the distributional requirements of generation modeling and the heterogeneity of RS imagery. To address these limitations, we propose a training-free, two-stage data pruning approach that quickly select a high-quality subset under high pruning ratios, enabling a preliminary foundation model to converge rapidly and serve as a versatile backbone for generation, downstream fine-tuning, and other applications. Our method jointly considers local information content with global scene-level diversity and representativeness. First, an entropy-based criterion efficiently removes low-information samples. Next, leveraging RS scene classification datasets as reference benchmarks, we perform scene-aware clustering with stratified sampling to improve clustering effectiveness while reducing computational costs on large-scale unlabeled data. Finally, by balancing cluster-level uniformity and sample representativeness, the method enables fine-grained selection under high pruning ratios while preserving overall diversity and representativeness. Experiments show that, even after pruning 85\\% of the training data, our method significantly improves convergence and generation quality. Furthermore, diffusion foundation models trained with our method consistently achieve state-of-the-art performance across downstream tasks, including super-resolution and semantic image synthesis. This data pruning paradigm offers practical guidance for developing RS generative foundation models.",
    "authors": [
      "Fan Wei",
      "Runmin Dong",
      "Yushan Lai",
      "Yixiang Yang",
      "Zhaoyang Luo",
      "Jinxiao Zhang",
      "Miao Yang",
      "Shuai Yuan",
      "Jiyao Zhao",
      "Bin Luo",
      "Haohuan Fu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23239v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23239v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.23200v1",
    "title": "Energy and Memory-Efficient Federated Learning With Ordered Layer Freezing",
    "summary": "Federated Learning (FL) has emerged as a privacy-preserving paradigm for training machine learning models across distributed edge devices in the Internet of Things (IoT). By keeping data local and coordinating model training through a central server, FL effectively addresses privacy concerns and reduces communication overhead. However, the limited computational power, memory, and bandwidth of IoT edge devices pose significant challenges to the efficiency and scalability of FL, especially when training deep neural networks. Various FL frameworks have been proposed to reduce computation and communication overheads through dropout or layer freezing. However, these approaches often sacrifice accuracy or neglect memory constraints. To this end, in this work, we introduce Federated Learning with Ordered Layer Freezing (FedOLF). FedOLF consistently freezes layers in a predefined order before training, significantly mitigating computation and memory requirements. To further reduce communication and energy costs, we incorporate Tensor Operation Approximation (TOA), a lightweight alternative to conventional quantization that better preserves model accuracy. Experimental results demonstrate that over non-iid data, FedOLF achieves at least 0.3%, 6.4%, 5.81%, 4.4%, 6.27% and 1.29% higher accuracy than existing works respectively on EMNIST (with CNN), CIFAR-10 (with AlexNet), CIFAR-100 (with ResNet20 and ResNet44), and CINIC-10 (with ResNet20 and ResNet44), along with higher energy efficiency and lower memory footprint.",
    "authors": [
      "Ziru Niu",
      "Hai Dong",
      "A. K. Qin",
      "Tao Gu",
      "Pengcheng Zhang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23200v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23200v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.23557v1",
    "title": "Toward Trustworthy Agentic AI: A Multimodal Framework for Preventing Prompt Injection Attacks",
    "summary": "Powerful autonomous systems, which reason, plan, and converse using and between numerous tools and agents, are made possible by Large Language Models (LLMs), Vision-Language Models (VLMs), and new agentic AI systems, like LangChain and GraphChain. Nevertheless, this agentic environment increases the probability of the occurrence of multimodal prompt injection (PI) attacks, in which concealed or malicious instructions carried in text, pictures, metadata, or agent-to-agent messages may spread throughout the graph and lead to unintended behavior, a breach of policy, or corruption of state. In order to mitigate these risks, this paper suggests a Cross-Agent Multimodal Provenanc- Aware Defense Framework whereby all the prompts, either user-generated or produced by upstream agents, are sanitized and all the outputs generated by an LLM are verified independently before being sent to downstream nodes. This framework contains a Text sanitizer agent, visual sanitizer agent, and output validator agent all coordinated by a provenance ledger, which keeps metadata of modality, source, and trust level throughout the entire agent network. This architecture makes sure that agent-to-agent communication abides by clear trust frames such such that injected instructions are not propagated down LangChain or GraphChain-style-workflows. The experimental assessments show that multimodal injection detection accuracy is significantly enhanced, and the cross-agent trust leakage is minimized, as well as, agentic execution pathways become stable. The framework, which expands the concept of provenance tracking and validation to the multi-agent orchestration, enhances the establishment of secure, understandable and reliable agentic AI systems.",
    "authors": [
      "Toqeer Ali Syed",
      "Mishal Ateeq Almutairi",
      "Mahmoud Abdel Moaty"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23557v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23557v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2512.23453v1",
    "title": "CoFi-Dec: Hallucination-Resistant Decoding via Coarse-to-Fine Generative Feedback in Large Vision-Language Models",
    "summary": "Large Vision-Language Models (LVLMs) have achieved impressive progress in multi-modal understanding and generation. However, they still tend to produce hallucinated content that is inconsistent with the visual input, which limits their reliability in real-world applications. We propose \\textbf{CoFi-Dec}, a training-free decoding framework that mitigates hallucinations by integrating generative self-feedback with coarse-to-fine visual conditioning. Inspired by the human visual process from global scene perception to detailed inspection, CoFi-Dec first generates two intermediate textual responses conditioned on coarse- and fine-grained views of the original image. These responses are then transformed into synthetic images using a text-to-image model, forming multi-level visual hypotheses that enrich grounding cues. To unify the predictions from these multiple visual conditions, we introduce a Wasserstein-based fusion mechanism that aligns their predictive distributions into a geometrically consistent decoding trajectory. This principled fusion reconciles high-level semantic consistency with fine-grained visual grounding, leading to more robust and faithful outputs. Extensive experiments on six hallucination-focused benchmarks show that CoFi-Dec substantially reduces both entity-level and semantic-level hallucinations, outperforming existing decoding strategies. The framework is model-agnostic, requires no additional training, and can be seamlessly applied to a wide range of LVLMs. The implementation is available at https://github.com/AI-Researcher-Team/CoFi-Dec.",
    "authors": [
      "Zongsheng Cao",
      "Yangfan He",
      "Anran Liu",
      "Jun Xie",
      "Feng Chen",
      "Zepeng Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23453v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23453v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2512.23329v1",
    "title": "Deep learning for pedestrians: backpropagation in Transformers",
    "summary": "This document is a follow-up to our previous paper dedicated to a vectorized derivation of backpropagation in CNNs. Following the same principles and notations already put in place there, we now focus on transformer-based next-token-prediction architectures. To this end, we apply our lightweight index-free methodology to new types of layers such as embedding, multi-headed self-attention and layer normalization. In addition, we also provide gradient expressions for LoRA layers to illustrate parameter-efficient fine-tuning. Why bother doing manual backpropagation when there are so many tools that do this automatically? Any gap in understanding of how values propagate forward will become evident when attempting to differentiate the loss function. By working through the backward pass manually, we gain a deeper intuition for how each operation influences the final output. A complete PyTorch implementation of a minimalistic GPT-like network is also provided along with analytical expressions for of all of its gradient updates.",
    "authors": [
      "Laurent Boué"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23329v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23329v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2512.23163v1",
    "title": "Why We Need a New Framework for Emotional Intelligence in AI",
    "summary": "In this paper, we develop the position that current frameworks for evaluating emotional intelligence (EI) in artificial intelligence (AI) systems need refinement because they do not adequately or comprehensively measure the various aspects of EI relevant in AI. Human EI often involves a phenomenological component and a sense of understanding that artificially intelligent systems lack; therefore, some aspects of EI are irrelevant in evaluating AI systems. However, EI also includes an ability to sense an emotional state, explain it, respond appropriately, and adapt to new contexts (e.g., multicultural), and artificially intelligent systems can do such things to greater or lesser degrees. Several benchmark frameworks specialize in evaluating the capacity of different AI models to perform some tasks related to EI, but these often lack a solid foundation regarding the nature of emotion and what it is to be emotionally intelligent. In this project, we begin by reviewing different theories about emotion and general EI, evaluating the extent to which each is applicable to artificial systems. We then critically evaluate the available benchmark frameworks, identifying where each falls short in light of the account of EI developed in the first section. Lastly, we outline some options for improving evaluation strategies to avoid these shortcomings in EI evaluation in AI systems.",
    "authors": [
      "Max Parks",
      "Kheli Atluru",
      "Meera Vinod",
      "Mike Kuniavsky",
      "Jud Brewer",
      "Sean White",
      "Sarah Adler",
      "Wendy Ju"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23163v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23163v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2512.23162v1",
    "title": "SurgWorld: Learning Surgical Robot Policies from Videos via World Modeling",
    "summary": "Data scarcity remains a fundamental barrier to achieving fully autonomous surgical robots. While large scale vision language action (VLA) models have shown impressive generalization in household and industrial manipulation by leveraging paired video action data from diverse domains, surgical robotics suffers from the paucity of datasets that include both visual observations and accurate robot kinematics. In contrast, vast corpora of surgical videos exist, but they lack corresponding action labels, preventing direct application of imitation learning or VLA training. In this work, we aim to alleviate this problem by learning policy models from SurgWorld, a world model designed for surgical physical AI. We curated the Surgical Action Text Alignment (SATA) dataset with detailed action description specifically for surgical robots. Then we built SurgeWorld based on the most advanced physical AI world model and SATA. It's able to generate diverse, generalizable and realistic surgery videos. We are also the first to use an inverse dynamics model to infer pseudokinematics from synthetic surgical videos, producing synthetic paired video action data. We demonstrate that a surgical VLA policy trained with these augmented data significantly outperforms models trained only on real demonstrations on a real surgical robot platform. Our approach offers a scalable path toward autonomous surgical skill acquisition by leveraging the abundance of unlabeled surgical video and generative world modeling, thus opening the door to generalizable and data efficient surgical robot policies.",
    "authors": [
      "Yufan He",
      "Pengfei Guo",
      "Mengya Xu",
      "Zhaoshuo Li",
      "Andriy Myronenko",
      "Dillan Imans",
      "Bingjie Liu",
      "Dongren Yang",
      "Mingxue Gu",
      "Yongnan Ji",
      "Yueming Jin",
      "Ren Zhao",
      "Baiyong Shen",
      "Daguang Xu"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23162v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23162v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2512.23597v1",
    "title": "Scalable Residual Feature Aggregation Framework with Hybrid Metaheuristic Optimization for Robust Early Pancreatic Neoplasm Detection in Multimodal CT Imaging",
    "summary": "The early detection of pancreatic neoplasm is a major clinical dilemma, and it is predominantly so because tumors are likely to occur with minimal contrast margins and a large spread anatomy-wide variation amongst patients on a CT scan. These complexities require to be addressed with an effective and scalable system that can assist in enhancing the salience of the subtle visual cues and provide a high level of the generalization on the multimodal imaging data. A Scalable Residual Feature Aggregation (SRFA) framework is proposed to be used to meet these conditions in this study. The framework integrates a pipeline of preprocessing followed by the segmentation using the MAGRes-UNet that is effective in making the pancreatic structures and isolating regions of interest more visible. DenseNet-121 performed with residual feature storage is used to extract features to allow deep hierarchical features to be aggregated without properties loss. To go further, hybrid HHO-BA metaheuristic feature selection strategy is used, which guarantees the best feature subset refinement. To be classified, the system is trained based on a new hybrid model that integrates the ability to pay attention on the world, which is the Vision Transformer (ViT) with the high representational efficiency of EfficientNet-B3. A dual optimization mechanism incorporating SSA and GWO is used to fine-tune hyperparameters to enhance greater robustness and less overfitting. Experimental results support the significant improvement in performance, with the suggested model reaching 96.23% accuracy, 95.58% F1-score and 94.83% specificity, the model is significantly better than the traditional CNNs and contemporary transformer-based models. Such results highlight the possibility of the SRFA framework as a useful instrument in the early detection of pancreatic tumors.",
    "authors": [
      "Janani Annur Thiruvengadam",
      "Kiran Mayee Nabigaru",
      "Anusha Kovi"
    ],
    "categories": [
      "cs.CV",
      "cs.IR"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23597v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23597v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.23406v1",
    "title": "Task-driven Heterophilic Graph Structure Learning",
    "summary": "Graph neural networks (GNNs) often struggle to learn discriminative node representations for heterophilic graphs, where connected nodes tend to have dissimilar labels and feature similarity provides weak structural cues. We propose frequency-guided graph structure learning (FgGSL), an end-to-end graph inference framework that jointly learns homophilic and heterophilic graph structures along with a spectral encoder. FgGSL employs a learnable, symmetric, feature-driven masking function to infer said complementary graphs, which are processed using pre-designed low- and high-pass graph filter banks. A label-based structural loss explicitly promotes the recovery of homophilic and heterophilic edges, enabling task-driven graph structure learning. We derive stability bounds for the structural loss and establish robustness guarantees for the filter banks under graph perturbations. Experiments on six heterophilic benchmarks demonstrate that FgGSL consistently outperforms state-of-the-art GNNs and graph rewiring methods, highlighting the benefits of combining frequency information with supervised topology inference.",
    "authors": [
      "Ayushman Raghuvanshi",
      "Gonzalo Mateos",
      "Sundeep Prabhakar Chepuri"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23406v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23406v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.23343v1",
    "title": "AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents",
    "summary": "Memory serves as the pivotal nexus bridging past and future, providing both humans and AI systems with invaluable concepts and experience to navigate complex tasks. Recent research on autonomous agents has increasingly focused on designing efficient memory workflows by drawing on cognitive neuroscience. However, constrained by interdisciplinary barriers, existing works struggle to assimilate the essence of human memory mechanisms. To bridge this gap, we systematically synthesizes interdisciplinary knowledge of memory, connecting insights from cognitive neuroscience with LLM-driven agents. Specifically, we first elucidate the definition and function of memory along a progressive trajectory from cognitive neuroscience through LLMs to agents. We then provide a comparative analysis of memory taxonomy, storage mechanisms, and the complete management lifecycle from both biological and artificial perspectives. Subsequently, we review the mainstream benchmarks for evaluating agent memory. Additionally, we explore memory security from dual perspectives of attack and defense. Finally, we envision future research directions, with a focus on multimodal memory systems and skill acquisition.",
    "authors": [
      "Jiafeng Liang",
      "Hao Li",
      "Chang Li",
      "Jiaqi Zhou",
      "Shixin Jiang",
      "Zekun Wang",
      "Changkai Ji",
      "Zhihao Zhu",
      "Runxuan Liu",
      "Tao Ren",
      "Jinlan Fu",
      "See-Kiong Ng",
      "Xia Liang",
      "Ming Liu",
      "Bing Qin"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23343v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23343v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.23222v1",
    "title": "Bridging Your Imagination with Audio-Video Generation via a Unified Director",
    "summary": "Existing AI-driven video creation systems typically treat script drafting and key-shot design as two disjoint tasks: the former relies on large language models, while the latter depends on image generation models. We argue that these two tasks should be unified within a single framework, as logical reasoning and imaginative thinking are both fundamental qualities of a film director. In this work, we propose UniMAGE, a unified director model that bridges user prompts with well-structured scripts, thereby empowering non-experts to produce long-context, multi-shot films by leveraging existing audio-video generation models. To achieve this, we employ the Mixture-of-Transformers architecture that unifies text and image generation. To further enhance narrative logic and keyframe consistency, we introduce a ``first interleaving, then disentangling'' training paradigm. Specifically, we first perform Interleaved Concept Learning, which utilizes interleaved text-image data to foster the model's deeper understanding and imaginative interpretation of scripts. We then conduct Disentangled Expert Learning, which decouples script writing from keyframe generation, enabling greater flexibility and creativity in storytelling. Extensive experiments demonstrate that UniMAGE achieves state-of-the-art performance among open-source models, generating logically coherent video scripts and visually consistent keyframe images.",
    "authors": [
      "Jiaxu Zhang",
      "Tianshu Hu",
      "Yuan Zhang",
      "Zenan Li",
      "Linjie Luo",
      "Guosheng Lin",
      "Xin Chen"
    ],
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23222v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23222v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.23184v1",
    "title": "From Model Choice to Model Belief: Establishing a New Measure for LLM-Based Research",
    "summary": "Large language models (LLMs) are increasingly used to simulate human behavior, but common practices to use LLM-generated data are inefficient. Treating an LLM's output (\"model choice\") as a single data point underutilizes the information inherent to the probabilistic nature of LLMs. This paper introduces and formalizes \"model belief,\" a measure derived from an LLM's token-level probabilities that captures the model's belief distribution over choice alternatives in a single generation run. The authors prove that model belief is asymptotically equivalent to the mean of model choices (a non-trivial property) but forms a more statistically efficient estimator, with lower variance and a faster convergence rate. Analogous properties are shown to hold for smooth functions of model belief and model choice often used in downstream applications. The authors demonstrate the performance of model belief through a demand estimation study, where an LLM simulates consumer responses to different prices. In practical settings with limited numbers of runs, model belief explains and predicts ground-truth model choice better than model choice itself, and reduces the computation needed to reach sufficiently accurate estimates by roughly a factor of 20. The findings support using model belief as the default measure to extract more information from LLM-generated data.",
    "authors": [
      "Hongshen Sun",
      "Juanjuan Zhang"
    ],
    "categories": [
      "cs.AI",
      "econ.EM"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23184v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23184v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.23178v1",
    "title": "Clipped Gradient Methods for Nonsmooth Convex Optimization under Heavy-Tailed Noise: A Refined Analysis",
    "summary": "Optimization under heavy-tailed noise has become popular recently, since it better fits many modern machine learning tasks, as captured by empirical observations. Concretely, instead of a finite second moment on gradient noise, a bounded ${\\frak p}$-th moment where ${\\frak p}\\in(1,2]$ has been recognized to be more realistic (say being upper bounded by $σ_{\\frak l}^{\\frak p}$ for some $σ_{\\frak l}\\ge0$). A simple yet effective operation, gradient clipping, is known to handle this new challenge successfully. Specifically, Clipped Stochastic Gradient Descent (Clipped SGD) guarantees a high-probability rate ${\\cal O}(σ_{\\frak l}\\ln(1/δ)T^{1/{\\frak p}-1})$ (resp. ${\\cal O}(σ_{\\frak l}^2\\ln^2(1/δ)T^{2/{\\frak p}-2})$) for nonsmooth convex (resp. strongly convex) problems, where $δ\\in(0,1]$ is the failure probability and $T\\in\\mathbb{N}$ is the time horizon. In this work, we provide a refined analysis for Clipped SGD and offer two faster rates, ${\\cal O}(σ_{\\frak l}d_{\\rm eff}^{-1/2{\\frak p}}\\ln^{1-1/{\\frak p}}(1/δ)T^{1/{\\frak p}-1})$ and ${\\cal O}(σ_{\\frak l}^2d_{\\rm eff}^{-1/{\\frak p}}\\ln^{2-2/{\\frak p}}(1/δ)T^{2/{\\frak p}-2})$, than the aforementioned best results, where $d_{\\rm eff}\\ge1$ is a quantity we call the $\\textit{generalized effective dimension}$. Our analysis improves upon the existing approach on two sides: better utilization of Freedman's inequality and finer bounds for clipping error under heavy-tailed noise. In addition, we extend the refined analysis to convergence in expectation and obtain new rates that break the known lower bounds. Lastly, to complement the study, we establish new lower bounds for both high-probability and in-expectation convergence. Notably, the in-expectation lower bounds match our new upper bounds, indicating the optimality of our refined analysis for convergence in expectation.",
    "authors": [
      "Zijian Liu"
    ],
    "categories": [
      "math.OC",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23178v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23178v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.23169v1",
    "title": "REVEALER: Reinforcement-Guided Visual Reasoning for Element-Level Text-Image Alignment Evaluation",
    "summary": "Evaluating the alignment between textual prompts and generated images is critical for ensuring the reliability and usability of text-to-image (T2I) models. However, most existing evaluation methods rely on coarse-grained metrics or static QA pipelines, which lack fine-grained interpretability and struggle to reflect human preferences. To address this, we propose REVEALER, a unified framework for element-level alignment evaluation based on reinforcement-guided visual reasoning. Adopting a structured \"grounding-reasoning-conclusion\" paradigm, our method enables Multimodal Large Language Models (MLLMs) to explicitly localize semantic elements and derive interpretable alignment judgments. We optimize the model via Group Relative Policy Optimization(GRPO) using a composite reward function that incorporates structural format, grounding accuracy, and alignment fidelity. Extensive experiments across four benchmarks-EvalMuse-40K, RichHF, MHaluBench, and GenAI-Bench-demonstrate that REVEALER achieves state-of-the-art performance. Our approach consistently outperforms both strong proprietary models and supervised baselines while demonstrating superior inference efficiency compared to existing iterative visual reasoning methods.",
    "authors": [
      "Fulin Shi",
      "Wenyi Xiao",
      "Bin Chen",
      "Liang Din",
      "Leilei Gan"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23169v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23169v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.23150v1",
    "title": "Constraint programming model and biased random-key genetic algorithm for the single-machine coupled task scheduling problem with exact delays to minimize the makespan",
    "summary": "We consider the strongly NP-hard single-machine coupled task scheduling problem with exact delays to minimize the makespan. In this problem, a set of jobs has to be scheduled, each composed of two tasks interspersed by an exact delay. Given that no preemption is allowed, the goal consists of minimizing the completion time of the last scheduled task. We model the problem using constraint programming (CP) and propose a biased random-key genetic algorithm (BRKGA). Our CP model applies well-established global constraints. Our BRKGA combines some successful components in the literature: an initial solution generator, periodical restarts and shakes, and a local search algorithm. Furthermore, the BRKGA's decoder is focused on efficiency rather than optimality, which accelerates the solution space exploration. Computational experiments on a benchmark set containing instances with up to 100 jobs (200 tasks) indicate that the proposed BRKGA can efficiently explore the problem solution space, providing high-quality approximate solutions within low computational times. It can also provide better solutions than the CP model under the same computational settings, i.e., three minutes of time limit and a single thread. The CP model, when offered a longer running time of 3600 seconds and multiple threads, significantly improved the results, reaching the current best-known solution for 90.56% of these instances. Finally, our experiments highlight the importance of the shake and local search components in the BRKGA, whose combination significantly improves the results of a standard BRKGA.",
    "authors": [
      "Vítor A. Barbosa",
      "Rafael A. Melo"
    ],
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23150v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23150v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.23676v1",
    "title": "Web World Models",
    "summary": "Language agents increasingly require persistent worlds in which they can act, remember, and learn. Existing approaches sit at two extremes: conventional web frameworks provide reliable but fixed contexts backed by databases, while fully generative world models aim for unlimited environments at the expense of controllability and practical engineering. In this work, we introduce the Web World Model (WWM), a middle ground where world state and ``physics'' are implemented in ordinary web code to ensure logical consistency, while large language models generate context, narratives, and high-level decisions on top of this structured latent state. We build a suite of WWMs on a realistic web stack, including an infinite travel atlas grounded in real geography, fictional galaxy explorers, web-scale encyclopedic and narrative worlds, and simulation- and game-like environments. Across these systems, we identify practical design principles for WWMs: separating code-defined rules from model-driven imagination, representing latent state as typed web interfaces, and utilizing deterministic generation to achieve unlimited but structured exploration. Our results suggest that web stacks themselves can serve as a scalable substrate for world models, enabling controllable yet open-ended environments. Project Page: https://github.com/Princeton-AI2-Lab/Web-World-Models.",
    "authors": [
      "Jichen Feng",
      "Yifan Zhang",
      "Chenggong Zhang",
      "Yifu Lu",
      "Shilong Liu",
      "Mengdi Wang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23676v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23676v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.23646v1",
    "title": "OmniAgent: Audio-Guided Active Perception Agent for Omnimodal Audio-Video Understanding",
    "summary": "Omnimodal large language models have made significant strides in unifying audio and visual modalities; however, they often lack the fine-grained cross-modal understanding and have difficulty with multimodal alignment. To address these limitations, we introduce OmniAgent, a fully audio-guided active perception agent that dynamically orchestrates specialized tools to achieve more fine-grained audio-visual reasoning. Unlike previous works that rely on rigid, static workflows and dense frame-captioning, this paper demonstrates a paradigm shift from passive response generation to active multimodal inquiry. OmniAgent employs dynamic planning to autonomously orchestrate tool invocation on demand, strategically concentrating perceptual attention on task-relevant cues. Central to our approach is a novel coarse-to-fine audio-guided perception paradigm, which leverages audio cues to localize temporal events and guide subsequent reasoning. Extensive empirical evaluations on three audio-video understanding benchmarks demonstrate that OmniAgent achieves state-of-the-art performance, surpassing leading open-source and proprietary models by substantial margins of 10% - 20% accuracy.",
    "authors": [
      "Keda Tao",
      "Wenjie Du",
      "Bohan Yu",
      "Weiqiang Wang",
      "Jian Liu",
      "Huan Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23646v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23646v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.23602v1",
    "title": "Distribution-Free Process Monitoring with Conformal Prediction",
    "summary": "Traditional Statistical Process Control (SPC) is essential for quality management but is limited by its reliance on often violated statistical assumptions, leading to unreliable monitoring in modern, complex manufacturing environments. This paper introduces a hybrid framework that enhances SPC by integrating the distribution free, model agnostic guarantees of Conformal Prediction. We propose two novel applications: Conformal-Enhanced Control Charts, which visualize process uncertainty and enable proactive signals like 'uncertainty spikes', and Conformal-Enhanced Process Monitoring, which reframes multivariate control as a formal anomaly detection problem using an intuitive p-value chart. Our framework provides a more robust and statistically rigorous approach to quality control while maintaining the interpretability and ease of use of classic methods.",
    "authors": [
      "Christopher Burger"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23602v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23602v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.23594v1",
    "title": "Detection Fire in Camera RGB-NIR",
    "summary": "Improving the accuracy of fire detection using infrared night vision cameras remains a challenging task. Previous studies have reported strong performance with popular detection models. For example, YOLOv7 achieved an mAP50-95 of 0.51 using an input image size of 640 x 1280, RT-DETR reached an mAP50-95 of 0.65 with an image size of 640 x 640, and YOLOv9 obtained an mAP50-95 of 0.598 at the same resolution. Despite these results, limitations in dataset construction continue to cause issues, particularly the frequent misclassification of bright artificial lights as fire.   This report presents three main contributions: an additional NIR dataset, a two-stage detection model, and Patched-YOLO. First, to address data scarcity, we explore and apply various data augmentation strategies for both the NIR dataset and the classification dataset. Second, to improve night-time fire detection accuracy while reducing false positives caused by artificial lights, we propose a two-stage pipeline combining YOLOv11 and EfficientNetV2-B0. The proposed approach achieves higher detection accuracy compared to previous methods, particularly for night-time fire detection. Third, to improve fire detection in RGB images, especially for small and distant objects, we introduce Patched-YOLO, which enhances the model's detection capability through patch-based processing. Further details of these contributions are discussed in the following sections.",
    "authors": [
      "Nguyen Truong Khai",
      "Luong Duc Vinh"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23594v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23594v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.23546v1",
    "title": "PurifyGen: A Risk-Discrimination and Semantic-Purification Model for Safe Text-to-Image Generation",
    "summary": "Recent advances in diffusion models have notably enhanced text-to-image (T2I) generation quality, but they also raise the risk of generating unsafe content. Traditional safety methods like text blacklisting or harmful content classification have significant drawbacks: they can be easily circumvented or require extensive datasets and extra training. To overcome these challenges, we introduce PurifyGen, a novel, training-free approach for safe T2I generation that retains the model's original weights. PurifyGen introduces a dual-stage strategy for prompt purification. First, we evaluate the safety of each token in a prompt by computing its complementary semantic distance, which measures the semantic proximity between the prompt tokens and concept embeddings from predefined toxic and clean lists. This enables fine-grained prompt classification without explicit keyword matching or retraining. Tokens closer to toxic concepts are flagged as risky. Second, for risky prompts, we apply a dual-space transformation: we project toxic-aligned embeddings into the null space of the toxic concept matrix, effectively removing harmful semantic components, and simultaneously align them into the range space of clean concepts. This dual alignment purifies risky prompts by both subtracting unsafe semantics and reinforcing safe ones, while retaining the original intent and coherence. We further define a token-wise strategy to selectively replace only risky token embeddings, ensuring minimal disruption to safe content. PurifyGen offers a plug-and-play solution with theoretical grounding and strong generalization to unseen prompts and models. Extensive testing shows that PurifyGen surpasses current methods in reducing unsafe content across five datasets and competes well with training-dependent approaches. The code can refer to https://github.com/AI-Researcher-Team/PurifyGen.",
    "authors": [
      "Zongsheng Cao",
      "Yangfan He",
      "Anran Liu",
      "Jun Xie",
      "Feng Chen",
      "Zepeng Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23546v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23546v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.23486v1",
    "title": "Multi-label Classification with Panoptic Context Aggregation Networks",
    "summary": "Context modeling is crucial for visual recognition, enabling highly discriminative image representations by integrating both intrinsic and extrinsic relationships between objects and labels in images. A limitation in current approaches is their focus on basic geometric relationships or localized features, often neglecting cross-scale contextual interactions between objects. This paper introduces the Deep Panoptic Context Aggregation Network (PanCAN), a novel approach that hierarchically integrates multi-order geometric contexts through cross-scale feature aggregation in a high-dimensional Hilbert space. Specifically, PanCAN learns multi-order neighborhood relationships at each scale by combining random walks with an attention mechanism. Modules from different scales are cascaded, where salient anchors at a finer scale are selected and their neighborhood features are dynamically fused via attention. This enables effective cross-scale modeling that significantly enhances complex scene understanding by combining multi-order and cross-scale context-aware features. Extensive multi-label classification experiments on NUS-WIDE, PASCAL VOC2007, and MS-COCO benchmarks demonstrate that PanCAN consistently achieves competitive results, outperforming state-of-the-art techniques in both quantitative and qualitative evaluations, thereby substantially improving multi-label classification performance.",
    "authors": [
      "Mingyuan Jiu",
      "Hailong Zhu",
      "Wenchuan Wei",
      "Hichem Sahbi",
      "Rongrong Ji",
      "Mingliang Xu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23486v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23486v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.23471v1",
    "title": "Semantic Tree Inference on Text Corpa using a Nested Density Approach together with Large Language Model Embeddings",
    "summary": "Semantic text classification has undergone significant advances in recent years due to the rise of large language models (LLMs) and their high dimensional embeddings. While LLM-embeddings are frequently used to store and retrieve text by semantic similarity in vector databases, the global structure semantic relationships in text corpora often remains opaque. Herein we propose a nested density clustering approach, to infer hierarchical trees of semantically related texts. The method starts by identifying texts of strong semantic similarity as it searches for dense clusters in LLM embedding space. As the density criterion is gradually relaxed, these dense clusters merge into more diffuse clusters, until the whole dataset is represented by a single cluster -- the root of the tree. By embedding dense clusters into increasingly diffuse ones, we construct a tree structure that captures hierarchical semantic relationships among texts. We outline how this approach can be used to classify textual data for abstracts of scientific abstracts as a case study. This enables the data-driven discovery research areas and their subfields without predefined categories. To evaluate the general applicability of the method, we further apply it to established benchmark datasets such as the 20 Newsgroups and IMDB 50k Movie Reviews, demonstrating its robustness across domains. Finally we discuss possible applications on scientometrics, topic evolution, highlighting how nested density trees can reveal semantic structure and evolution in textual datasets.",
    "authors": [
      "Thomas Haschka",
      "Joseph Bakarji"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23471v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23471v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.23440v1",
    "title": "ClinDEF: A Dynamic Evaluation Framework for Large Language Models in Clinical Reasoning",
    "summary": "Clinical diagnosis begins with doctor-patient interaction, during which physicians iteratively gather information, determine examination and refine differential diagnosis through patients' response. This dynamic clinical-reasoning process is poorly represented by existing LLM benchmarks that focus on static question-answering. To mitigate these gaps, recent methods explore dynamic medical frameworks involving interactive clinical dialogues. Although effective, they often rely on limited, contamination-prone datasets and lack granular, multi-level evaluation. In this work, we propose ClinDEF, a dynamic framework for assessing clinical reasoning in LLMs through simulated diagnostic dialogues. Grounded in a disease knowledge graph, our method dynamically generates patient cases and facilitates multi-turn interactions between an LLM-based doctor and an automated patient agent. Our evaluation protocol goes beyond diagnostic accuracy by incorporating fine-grained efficiency analysis and rubric-based assessment of diagnostic quality. Experiments show that ClinDEF effectively exposes critical clinical reasoning gaps in state-of-the-art LLMs, offering a more nuanced and clinically meaningful evaluation paradigm.",
    "authors": [
      "Yuqi Tang",
      "Jing Yu",
      "Zichang Su",
      "Kehua Feng",
      "Zhihui Zhu",
      "Libin Wang",
      "Lei Liang",
      "Qiang Zhang",
      "Keyan Ding",
      "Huajun Chen"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23440v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23440v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.23422v1",
    "title": "Entropy-Guided Token Dropout: Training Autoregressive Language Models with Limited Domain Data",
    "summary": "As access to high-quality, domain-specific data grows increasingly scarce, multi-epoch training has become a practical strategy for adapting large language models (LLMs). However, autoregressive models often suffer from performance degradation under repeated data exposure, where overfitting leads to a marked decline in model capability. Through empirical analysis, we trace this degradation to an imbalance in learning dynamics: predictable, low-entropy tokens are learned quickly and come to dominate optimization, while the model's ability to generalize on high-entropy tokens deteriorates with continued training. To address this, we introduce EntroDrop, an entropy-guided token dropout method that functions as structured data regularization. EntroDrop selectively masks low-entropy tokens during training and employs a curriculum schedule to adjust regularization strength in alignment with training progress. Experiments across model scales from 0.6B to 8B parameters show that EntroDrop consistently outperforms standard regularization baselines and maintains robust performance throughout extended multi-epoch training. These findings underscore the importance of aligning regularization with token-level learning dynamics when training on limited data. Our approach offers a promising pathway toward more effective adaptation of LLMs in data-constrained domains.",
    "authors": [
      "Jiapeng Wang",
      "Yiwen Hu",
      "Yanzipeng Gao",
      "Haoyu Wang",
      "Shuo Wang",
      "Hongyu Lu",
      "Jiaxin Mao",
      "Wayne Xin Zhao",
      "Junyi Li",
      "Xiao Zhang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23422v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23422v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.23413v1",
    "title": "Bridging Cognitive Gap: Hierarchical Description Learning for Artistic Image Aesthetics Assessment",
    "summary": "The aesthetic quality assessment task is crucial for developing a human-aligned quantitative evaluation system for AIGC. However, its inherently complex nature, spanning visual perception, cognition, and emotion, poses fundamental challenges. Although aesthetic descriptions offer a viable representation of this complexity, two critical challenges persist: (1) data scarcity and imbalance: existing dataset overly focuses on visual perception and neglects deeper dimensions due to the expensive manual annotation; and (2) model fragmentation: current visual networks isolate aesthetic attributes with multi-branch encoder, while multimodal methods represented by contrastive learning struggle to effectively process long-form textual descriptions. To resolve challenge (1), we first present the Refined Aesthetic Description (RAD) dataset, a large-scale (70k), multi-dimensional structured dataset, generated via an iterative pipeline without heavy annotation costs and easy to scale. To address challenge (2), we propose ArtQuant, an aesthetics assessment framework for artistic images which not only couples isolated aesthetic dimensions through joint description generation, but also better models long-text semantics with the help of LLM decoders. Besides, theoretical analysis confirms this symbiosis: RAD's semantic adequacy (data) and generation paradigm (model) collectively minimize prediction entropy, providing mathematical grounding for the framework. Our approach achieves state-of-the-art performance on several datasets while requiring only 33% of conventional training epochs, narrowing the cognitive gap between artistic images and aesthetic judgment. We will release both code and dataset to support future research.",
    "authors": [
      "Henglin Liu",
      "Nisha Huang",
      "Chang Liu",
      "Jiangpeng Yan",
      "Huijuan Huang",
      "Jixuan Ying",
      "Tong-Yee Lee",
      "Pengfei Wan",
      "Xiangyang Ji"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23413v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23413v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.23347v1",
    "title": "ECG-RAMBA: Zero-Shot ECG Generalization by Morphology-Rhythm Disentanglement and Long-Range Modeling",
    "summary": "Deep learning has achieved strong performance for electrocardiogram (ECG) classification within individual datasets, yet dependable generalization across heterogeneous acquisition settings remains a major obstacle to clinical deployment and longitudinal monitoring. A key limitation of many model architectures is the implicit entanglement of morphological waveform patterns and rhythm dynamics, which can promote shortcut learning and amplify sensitivity to distribution shifts. We propose ECG-RAMBA, a framework that separates morphology and rhythm and then re-integrates them through context-aware fusion. ECG-RAMBA combines: (i) deterministic morphological features extracted by MiniRocket, (ii) global rhythm descriptors computed from heart-rate variability (HRV), and (iii) long-range contextual modeling via a bi-directional Mamba backbone. To improve sensitivity to transient abnormalities under windowed inference, we introduce a numerically stable Power Mean pooling operator ($Q=3$) that emphasizes high-evidence segments while avoiding the brittleness of max pooling and the dilution of averaging. We evaluate under a protocol-faithful setting with subject-level cross-validation, a fixed decision threshold, and no test-time adaptation. On the Chapman--Shaoxing dataset, ECG-RAMBA achieves a macro ROC-AUC $\\approx 0.85$. In zero-shot transfer, it attains PR-AUC $=0.708$ for atrial fibrillation detection on the external CPSC-2021 dataset, substantially outperforming a comparable raw-signal Mamba baseline, and shows consistent cross-dataset performance on PTB-XL. Ablation studies indicate that deterministic morphology provides a strong foundation, while explicit rhythm modeling and long-range context are critical drivers of cross-domain robustness.",
    "authors": [
      "Hai Duong Nguyen",
      "Xuan-The Tran"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23347v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23347v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.23340v1",
    "title": "The Law of Multi-Model Collaboration: Scaling Limits of Model Ensembling for Large Language Models",
    "summary": "Recent advances in large language models (LLMs) have been largely driven by scaling laws for individual models, which predict performance improvements as model parameters and data volume increase. However, the capabilities of any single LLM are inherently bounded. One solution originates from intricate interactions among multiple LLMs, rendering their collective performance surpasses that of any constituent model. Despite the rapid proliferation of multi-model integration techniques such as model routing and post-hoc ensembling, a unifying theoretical framework of performance scaling for multi-model collaboration remains absent. In this work, we propose the Law of Multi-model Collaboration, a scaling law that predicts the performance limits of LLM ensembles based on their aggregated parameter budget. To quantify the intrinsic upper bound of multi-model collaboration, we adopt a method-agnostic formulation and assume an idealized integration oracle where the total cross-entropy loss of each sample is determined by the minimum loss of any model in the model pool. Experimental results reveal that multi-model systems follow a power-law scaling with respect to the total parameter count, exhibiting a more significant improvement trend and a lower theoretical loss floor compared to single model scaling. Moreover, ensembles of heterogeneous model families achieve better performance scaling than those formed within a single model family, indicating that model diversity is a primary driver of collaboration gains. These findings suggest that model collaboration represents a critical axis for extending the intelligence frontier of LLMs.",
    "authors": [
      "Dakuan Lu",
      "Jiaqi Zhang",
      "Cheng Yuan",
      "Jiawei Shao",
      "Chi Zhang",
      "Xuelong Li"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23340v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23340v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.23234v1",
    "title": "Physics-Inspired Modeling and Content Adaptive Routing in an Infrared Gas Leak Detection Network",
    "summary": "Detecting infrared gas leaks is critical for environmental monitoring and industrial safety, yet remains difficult because plumes are faint, small, semitransparent, and have weak, diffuse boundaries. We present physics-edge hybrid gas dynamic routing network (PEG-DRNet). First, we introduce the Gas Block, a diffusion-convection unit modeling gas transport: a local branch captures short-range variations, while a large-kernel branch captures long-range propagation. An edge-gated learnable fusion module balances local detail and global context, strengthening weak-contrast plume and contour cues. Second, we propose the adaptive gradient and phase edge operator (AGPEO), computing reliable edge priors from multi-directional gradients and phase-consistent responses. These are transformed by a multi-scale edge perception module (MSEPM) into hierarchical edge features that reinforce boundaries. Finally, the content-adaptive sparse routing path aggregation network (CASR-PAN), with adaptive information modulation modules for fusion and self, selectively propagates informative features across scales based on edge and content cues, improving cross-scale discriminability while reducing redundancy. Experiments on the IIG dataset show that PEG-DRNet achieves an overall AP of 29.8\\%, an AP$_{50}$ of 84.3\\%, and a small-object AP of 25.3\\%, surpassing the RT-DETR-R18 baseline by 3.0\\%, 6.5\\%, and 5.3\\%, respectively, while requiring only 43.7 Gflops and 14.9 M parameters. The proposed PEG-DRNet achieves superior overall performance with the best balance of accuracy and computational efficiency, outperforming existing CNN and Transformer detectors in AP and AP$_{50}$ on the IIG and LangGas dataset.",
    "authors": [
      "Dongsheng Li",
      "Chaobo Chen",
      "Siling Wang",
      "Song Gao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23234v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23234v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.23208v1",
    "title": "Exploring Syn-to-Real Domain Adaptation for Military Target Detection",
    "summary": "Object detection is one of the key target tasks of interest in the context of civil and military applications. In particular, the real-world deployment of target detection methods is pivotal in the decision-making process during military command and reconnaissance. However, current domain adaptive object detection algorithms consider adapting one domain to another similar one only within the scope of natural or autonomous driving scenes. Since military domains often deal with a mixed variety of environments, detecting objects from multiple varying target domains poses a greater challenge. Several studies for armored military target detection have made use of synthetic aperture radar (SAR) data due to its robustness to all weather, long range, and high-resolution characteristics. Nevertheless, the costs of SAR data acquisition and processing are still much higher than those of the conventional RGB camera, which is a more affordable alternative with significantly lower data processing time. Furthermore, the lack of military target detection datasets limits the use of such a low-cost approach. To mitigate these issues, we propose to generate RGB-based synthetic data using a photorealistic visual tool, Unreal Engine, for military target detection in a cross-domain setting. To this end, we conducted synthetic-to-real transfer experiments by training our synthetic dataset and validating on our web-collected real military target datasets. We benchmark the state-of-the-art domain adaptation methods distinguished by the degree of supervision on our proposed train-val dataset pair, and find that current methods using minimal hints on the image (e.g., object class) achieve a substantial improvement over unsupervised or semi-supervised DA methods. From these observations, we recognize the current challenges that remain to be overcome.",
    "authors": [
      "Jongoh Jeong",
      "Youngjin Oh",
      "Gyeongrae Nam",
      "Jeongeun Lee",
      "Kuk-Jin Yoon"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23208v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23208v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.23493v1",
    "title": "Joint Link Adaptation and Device Scheduling Approach for URLLC Industrial IoT Network: A DRL-based Method with Bayesian Optimization",
    "summary": "In this article, we consider an industrial internet of things (IIoT) network supporting multi-device dynamic ultra-reliable low-latency communication (URLLC) while the channel state information (CSI) is imperfect. A joint link adaptation (LA) and device scheduling (including the order) design is provided, aiming at maximizing the total transmission rate under strict block error rate (BLER) constraints. In particular, a Bayesian optimization (BO) driven Twin Delayed Deep Deterministic Policy Gradient (TD3) method is proposed, which determines the device served order sequence and the corresponding modulation and coding scheme (MCS) adaptively based on the imperfect CSI. Note that the imperfection of CSI, error sample imbalance in URLLC networks, as well as the parameter sensitivity nature of the TD3 algorithm likely diminish the algorithm's convergence speed and reliability. To address such an issue, we proposed a BO based training mechanism for the convergence speed improvement, which provides a more reliable learning direction and sample selection method to track the imbalance sample problem. Via extensive simulations, we show that the proposed algorithm achieves faster convergence and higher sum-rate performance compared to existing solutions.",
    "authors": [
      "Wei Gao",
      "Paul Zheng",
      "Peng Wu",
      "Yulin Hu",
      "Anke Schmeink"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23493v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23493v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.23443v1",
    "title": "Adaptive Fusion Graph Network for 3D Strain Field Prediction in Solid Rocket Motor Grains",
    "summary": "Local high strain in solid rocket motor grains is a primary cause of structural failure. However, traditional numerical simulations are computationally expensive, and existing surrogate models cannot explicitly establish geometric models and accurately capture high-strain regions. Therefore, this paper proposes an adaptive graph network, GrainGNet, which employs an adaptive pooling dynamic node selection mechanism to effectively preserve the key mechanical features of structurally critical regions, while concurrently utilising feature fusion to transmit deep features and enhance the model's representational capacity. In the joint prediction task involving four sequential conditions--curing and cooling, storage, overloading, and ignition--GrainGNet reduces the mean squared error by 62.8% compared to the baseline graph U-Net model, with only a 5.2% increase in parameter count and an approximately sevenfold improvement in training efficiency. Furthermore, in the high-strain regions of debonding seams, the prediction error is further reduced by 33% compared to the second-best method, offering a computationally efficient and high-fidelity approach to evaluate motor structural safety.",
    "authors": [
      "Jiada Huang",
      "Hao Ma",
      "Zhibin Shen",
      "Yizhou Qiao",
      "Haiyang Li"
    ],
    "categories": [
      "physics.app-ph",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23443v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23443v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.23411v1",
    "title": "SOFTooth: Semantics-Enhanced Order-Aware Fusion for Tooth Instance Segmentation",
    "summary": "Three-dimensional (3D) tooth instance segmentation remains challenging due to crowded arches, ambiguous tooth-gingiva boundaries, missing teeth, and rare yet clinically important third molars. Native 3D methods relying on geometric cues often suffer from boundary leakage, center drift, and inconsistent tooth identities, especially for minority classes and complex anatomies. Meanwhile, 2D foundation models such as the Segment Anything Model (SAM) provide strong boundary-aware semantics, but directly applying them in 3D is impractical in clinical workflows. To address these issues, we propose SOFTooth, a semantics-enhanced, order-aware 2D-3D fusion framework that leverages frozen 2D semantics without explicit 2D mask supervision. First, a point-wise residual gating module injects occlusal-view SAM embeddings into 3D point features to refine tooth-gingiva and inter-tooth boundaries. Second, a center-guided mask refinement regularizes consistency between instance masks and geometric centroids, reducing center drift. Furthermore, an order-aware Hungarian matching strategy integrates anatomical tooth order and center distance into similarity-based assignment, ensuring coherent labeling even under missing or crowded dentitions. On 3DTeethSeg'22, SOFTooth achieves state-of-the-art overall accuracy and mean IoU, with clear gains on cases involving third molars, demonstrating that rich 2D semantics can be effectively transferred to 3D tooth instance segmentation without 2D fine-tuning.",
    "authors": [
      "Xiaolan Li",
      "Wanquan Liu",
      "Pengcheng Li",
      "Pengyu Jie",
      "Chenqiang Gao"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23411v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23411v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.23273v1",
    "title": "YOLO-Master: MOE-Accelerated with Specialized Transformers for Enhanced Real-time Detection",
    "summary": "Existing Real-Time Object Detection (RTOD) methods commonly adopt YOLO-like architectures for their favorable trade-off between accuracy and speed. However, these models rely on static dense computation that applies uniform processing to all inputs, misallocating representational capacity and computational resources such as over-allocating on trivial scenes while under-serving complex ones. This mismatch results in both computational redundancy and suboptimal detection performance. To overcome this limitation, we propose YOLO-Master, a novel YOLO-like framework that introduces instance-conditional adaptive computation for RTOD. This is achieved through a Efficient Sparse Mixture-of-Experts (ES-MoE) block that dynamically allocates computational resources to each input according to its scene complexity. At its core, a lightweight dynamic routing network guides expert specialization during training through a diversity enhancing objective, encouraging complementary expertise among experts. Additionally, the routing network adaptively learns to activate only the most relevant experts, thereby improving detection performance while minimizing computational overhead during inference. Comprehensive experiments on five large-scale benchmarks demonstrate the superiority of YOLO-Master. On MS COCO, our model achieves 42.4% AP with 1.62ms latency, outperforming YOLOv13-N by +0.8% mAP and 17.8% faster inference. Notably, the gains are most pronounced on challenging dense scenes, while the model preserves efficiency on typical inputs and maintains real-time inference speed. Code will be available.",
    "authors": [
      "Xu Lin",
      "Jinlong Peng",
      "Zhenye Gan",
      "Jiawen Zhu",
      "Jun Liu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23273v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23273v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.23245v1",
    "title": "ASemConsist: Adaptive Semantic Feature Control for Training-Free Identity-Consistent Generation",
    "summary": "Recent text-to-image diffusion models have significantly improved visual quality and text alignment. However, generating a sequence of images while preserving consistent character identity across diverse scene descriptions remains a challenging task. Existing methods often struggle with a trade-off between maintaining identity consistency and ensuring per-image prompt alignment. In this paper, we introduce a novel framework, ASemconsist, that addresses this challenge through selective text embedding modification, enabling explicit semantic control over character identity without sacrificing prompt alignment. Furthermore, based on our analysis of padding embeddings in FLUX, we propose a semantic control strategy that repurposes padding embeddings as semantic containers. Additionally, we introduce an adaptive feature-sharing strategy that automatically evaluates textual ambiguity and applies constraints only to the ambiguous identity prompt. Finally, we propose a unified evaluation protocol, the Consistency Quality Score (CQS), which integrates identity preservation and per-image text alignment into a single comprehensive metric, explicitly capturing performance imbalances between the two metrics. Our framework achieves state-of-the-art performance, effectively overcoming prior trade-offs. Project page: https://minjung-s.github.io/asemconsist",
    "authors": [
      "Shin seong Kim",
      "Minjung Shin",
      "Hyunin Cho",
      "Youngjung Uh"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23245v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23245v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.23221v1",
    "title": "Holi-DETR: Holistic Fashion Item Detection Leveraging Contextual Information",
    "summary": "Fashion item detection is challenging due to the ambiguities introduced by the highly diverse appearances of fashion items and the similarities among item subcategories. To address this challenge, we propose a novel Holistic Detection Transformer (Holi-DETR) that detects fashion items in outfit images holistically, by leveraging contextual information. Fashion items often have meaningful relationships as they are combined to create specific styles. Unlike conventional detectors that detect each item independently, Holi-DETR detects multiple items while reducing ambiguities by leveraging three distinct types of contextual information: (1) the co-occurrence relationship between fashion items, (2) the relative position and size based on inter-item spatial arrangements, and (3) the spatial relationships between items and human body key-points. %Holi-DETR explicitly incorporates three types of contextual information: (1) the co-occurrence probability between fashion items, (2) the relative position and size based on inter-item spatial arrangements, and (3) the spatial relationships between items and human body key-points. To this end, we propose a novel architecture that integrates these three types of heterogeneous contextual information into the Detection Transformer (DETR) and its subsequent models. In experiments, the proposed methods improved the performance of the vanilla DETR and the more recently developed Co-DETR by 3.6 percent points (pp) and 1.1 pp, respectively, in terms of average precision (AP).",
    "authors": [
      "Youngchae Kwon",
      "Jinyoung Choi",
      "Injung Kim"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23221v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23221v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.23185v1",
    "title": "EIR: Enhanced Image Representations for Medical Report Generation",
    "summary": "Generating medical reports from chest X-ray images is a critical and time-consuming task for radiologists, especially in emergencies. To alleviate the stress on radiologists and reduce the risk of misdiagnosis, numerous research efforts have been dedicated to automatic medical report generation in recent years. Most recent studies have developed methods that represent images by utilizing various medical metadata, such as the clinical document history of the current patient and the medical graphs constructed from retrieved reports of other similar patients. However, all existing methods integrate additional metadata representations with visual representations through a simple \"Add and LayerNorm\" operation, which suffers from the information asymmetry problem due to the distinct distributions between them. In addition, chest X-ray images are usually represented using pre-trained models based on natural domain images, which exhibit an obvious domain gap between general and medical domain images. To this end, we propose a novel approach called Enhanced Image Representations (EIR) for generating accurate chest X-ray reports. We utilize cross-modal transformers to fuse metadata representations with image representations, thereby effectively addressing the information asymmetry problem between them, and we leverage medical domain pre-trained models to encode medical images, effectively bridging the domain gap for image representation. Experimental results on the widely used MIMIC and Open-I datasets demonstrate the effectiveness of our proposed method.",
    "authors": [
      "Qiang Sun",
      "Zongcheng Ji",
      "Yinlong Xiao",
      "Peng Chang",
      "Jun Yu"
    ],
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23185v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23185v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.23161v1",
    "title": "Diffusion-based Decentralized Federated Multi-Task Representation Learning",
    "summary": "Representation learning is a widely adopted framework for learning in data-scarce environments to obtain a feature extractor or representation from various different yet related tasks. Despite extensive research on representation learning, decentralized approaches remain relatively underexplored. This work develops a decentralized projected gradient descent-based algorithm for multi-task representation learning. We focus on the problem of multi-task linear regression in which multiple linear regression models share a common, low-dimensional linear representation. We present an alternating projected gradient descent and minimization algorithm for recovering a low-rank feature matrix in a diffusion-based decentralized and federated fashion. We obtain constructive, provable guarantees that provide a lower bound on the required sample complexity and an upper bound on the iteration complexity of our proposed algorithm. We analyze the time and communication complexity of our algorithm and show that it is fast and communication-efficient. We performed numerical simulations to validate the performance of our algorithm and compared it with benchmark algorithms.",
    "authors": [
      "Donghwa Kang",
      "Shana Moothedath"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23161v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23161v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.23131v1",
    "title": "SE-MLP Model for Predicting Prior Acceleration Features in Penetration Signals",
    "summary": "Accurate identification of the penetration process relies heavily on prior feature values of penetration acceleration. However, these feature values are typically obtained through long simulation cycles and expensive computations. To overcome this limitation, this paper proposes a multi-layer Perceptron architecture, termed squeeze and excitation multi-layer perceptron (SE-MLP), which integrates a channel attention mechanism with residual connections to enable rapid prediction of acceleration feature values. Using physical parameters under different working conditions as inputs, the model outputs layer-wise acceleration features, thereby establishing a nonlinear mapping between physical parameters and penetration characteristics. Comparative experiments against conventional MLP, XGBoost, and Transformer models demonstrate that SE-MLP achieves superior prediction accuracy, generalization, and stability. Ablation studies further confirm that both the channel attention module and residual structure contribute significantly to performance gains. Numerical simulations and range recovery tests show that the discrepancies between predicted and measured acceleration peaks and pulse widths remain within acceptable engineering tolerances. These results validate the feasibility and engineering applicability of the proposed method and provide a practical basis for rapidly generating prior feature values for penetration fuzes.",
    "authors": [
      "Yankang Li",
      "Changsheng Li"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23131v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23131v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.23130v1",
    "title": "PathoSyn: Imaging-Pathology MRI Synthesis via Disentangled Deviation Diffusion",
    "summary": "We present PathoSyn, a unified generative framework for Magnetic Resonance Imaging (MRI) image synthesis that reformulates imaging-pathology as a disentangled additive deviation on a stable anatomical manifold. Current generative models typically operate in the global pixel domain or rely on binary masks, these paradigms often suffer from feature entanglement, leading to corrupted anatomical substrates or structural discontinuities. PathoSyn addresses these limitations by decomposing the synthesis task into deterministic anatomical reconstruction and stochastic deviation modeling. Central to our framework is a Deviation-Space Diffusion Model designed to learn the conditional distribution of pathological residuals, thereby capturing localized intensity variations while preserving global structural integrity by construction. To ensure spatial coherence, the diffusion process is coupled with a seam-aware fusion strategy and an inference-time stabilization module, which collectively suppress boundary artifacts and produce high-fidelity internal lesion heterogeneity. PathoSyn provides a mathematically principled pipeline for generating high-fidelity patient-specific synthetic datasets, facilitating the development of robust diagnostic algorithms in low-data regimes. By allowing interpretable counterfactual disease progression modeling, the framework supports precision intervention planning and provides a controlled environment for benchmarking clinical decision-support systems. Quantitative and qualitative evaluations on tumor imaging benchmarks demonstrate that PathoSyn significantly outperforms holistic diffusion and mask-conditioned baselines in both perceptual realism and anatomical fidelity. The source code of this work will be made publicly available.",
    "authors": [
      "Jian Wang",
      "Sixing Rong",
      "Jiarui Xing",
      "Yuling Xu",
      "Weide Liu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23130v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23130v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.23649v1",
    "title": "RoboMirror: Understand Before You Imitate for Video to Humanoid Locomotion",
    "summary": "Humans learn locomotion through visual observation, interpreting visual content first before imitating actions. However, state-of-the-art humanoid locomotion systems rely on either curated motion capture trajectories or sparse text commands, leaving a critical gap between visual understanding and control. Text-to-motion methods suffer from semantic sparsity and staged pipeline errors, while video-based approaches only perform mechanical pose mimicry without genuine visual understanding. We propose RoboMirror, the first retargeting-free video-to-locomotion framework embodying \"understand before you imitate\". Leveraging VLMs, it distills raw egocentric/third-person videos into visual motion intents, which directly condition a diffusion-based policy to generate physically plausible, semantically aligned locomotion without explicit pose reconstruction or retargeting. Extensive experiments validate the effectiveness of RoboMirror, it enables telepresence via egocentric videos, drastically reduces third-person control latency by 80%, and achieves a 3.7% higher task success rate than baselines. By reframing humanoid control around video understanding, we bridge the visual understanding and action gap.",
    "authors": [
      "Zhe Li",
      "Cheng Chi",
      "Yangyang Wei",
      "Boan Zhu",
      "Tao Huang",
      "Zhenguo Sun",
      "Yibo Peng",
      "Pengwei Wang",
      "Zhongyuan Wang",
      "Fangzhou Liu",
      "Chang Xu",
      "Shanghang Zhang"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23649v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23649v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.23562v1",
    "title": "VL-RouterBench: A Benchmark for Vision-Language Model Routing",
    "summary": "Multi-model routing has evolved from an engineering technique into essential infrastructure, yet existing work lacks a systematic, reproducible benchmark for evaluating vision-language models (VLMs). We present VL-RouterBench to assess the overall capability of VLM routing systems systematically. The benchmark is grounded in raw inference and scoring logs from VLMs and constructs quality and cost matrices over sample-model pairs. In scale, VL-RouterBench covers 14 datasets across 3 task groups, totaling 30,540 samples, and includes 15 open-source models and 2 API models, yielding 519,180 sample-model pairs and a total input-output token volume of 34,494,977. The evaluation protocol jointly measures average accuracy, average cost, and throughput, and builds a ranking score from the harmonic mean of normalized cost and accuracy to enable comparison across router configurations and cost budgets. On this benchmark, we evaluate 10 routing methods and baselines and observe a significant routability gain, while the best current routers still show a clear gap to the ideal Oracle, indicating considerable room for improvement in router architecture through finer visual cues and modeling of textual structure. We will open-source the complete data construction and evaluation toolchain to promote comparability, reproducibility, and practical deployment in multimodal routing research.",
    "authors": [
      "Zhehao Huang",
      "Baijiong Lin",
      "Jingyuan Zhang",
      "Jingying Wang",
      "Yuhang Liu",
      "Ning Lu",
      "Tao Li",
      "Xiaolin Huang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23562v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23562v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.23526v1",
    "title": "EEG-based Graph-guided Domain Adaptation for Robust Cross-Session Emotion Recognition",
    "summary": "Accurate recognition of human emotional states is critical for effective human-machine interaction. Electroencephalography (EEG) offers a reliable source for emotion recognition due to its high temporal resolution and its direct reflection of neural activity. Nevertheless, variations across recording sessions present a major challenge for model generalization. To address this issue, we propose EGDA, a framework that reduces cross-session discrepancies by jointly aligning the global (marginal) and class-specific (conditional) distributions, while preserving the intrinsic structure of EEG data through graph regularization. Experimental results on the SEED-IV dataset demonstrate that EGDA achieves robust cross-session performance, obtaining accuracies of 81.22%, 80.15%, and 83.27% across three transfer tasks, and surpassing several baseline methods. Furthermore, the analysis highlights the Gamma frequency band as the most discriminative and identifies the central-parietal and prefrontal brain regions as critical for reliable emotion recognition.",
    "authors": [
      "Maryam Mirzaei",
      "Farzaneh Shayegh",
      "Hamed Narimani"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23526v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23526v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.23454v1",
    "title": "Automated river gauge plate reading using a hybrid object detection and generative AI framework in the Limpopo River Basin",
    "summary": "Accurate and continuous monitoring of river water levels is essential for flood forecasting, water resource management, and ecological protection. Traditional hydrological observation methods are often limited by manual measurement errors and environmental constraints. This study presents a hybrid framework integrating vision based waterline detection, YOLOv8 pose scale extraction, and large multimodal language models (GPT 4o and Gemini 2.0 Flash) for automated river gauge plate reading. The methodology involves sequential stages of image preprocessing, annotation, waterline detection, scale gap estimation, and numeric reading extraction. Experiments demonstrate that waterline detection achieved high precision of 94.24 percent and an F1 score of 83.64 percent, while scale gap detection provided accurate geometric calibration for subsequent reading extraction. Incorporating scale gap metadata substantially improved the predictive performance of LLMs, with Gemini Stage 2 achieving the highest accuracy, with a mean absolute error of 5.43 cm, root mean square error of 8.58 cm, and R squared of 0.84 under optimal image conditions. Results highlight the sensitivity of LLMs to image quality, with degraded images producing higher errors, and underscore the importance of combining geometric metadata with multimodal artificial intelligence for robust water level estimation. Overall, the proposed approach offers a scalable, efficient, and reliable solution for automated hydrological monitoring, demonstrating potential for real time river gauge digitization and improved water resource management.",
    "authors": [
      "Kayathri Vigneswaran",
      "Hugo Retief",
      "Jai Clifford Holmes",
      "Mariangel Garcia Andarcia",
      "Hansaka Tennakoon"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23454v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23454v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.23447v1",
    "title": "Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss",
    "summary": "Mixture-of-Experts (MoE) models lack explicit constraints to ensure the router's decisions align well with the experts' capabilities, which ultimately limits model performance. To address this, we propose expert-router coupling (ERC) loss, a lightweight auxiliary loss that tightly couples the router's decisions with expert capabilities. Our approach treats each expert's router embedding as a proxy token for the tokens assigned to that expert, and feeds perturbed router embeddings through the experts to obtain internal activations. The ERC loss enforces two constraints on these activations: (1) Each expert must exhibit higher activation for its own proxy token than for the proxy tokens of any other expert. (2) Each proxy token must elicit stronger activation from its corresponding expert than from any other expert. These constraints jointly ensure that each router embedding faithfully represents its corresponding expert's capability, while each expert specializes in processing the tokens actually routed to it. The ERC loss is computationally efficient, operating only on n^2 activations, where n is the number of experts. This represents a fixed cost independent of batch size, unlike prior coupling methods that scale with the number of tokens (often millions per batch). Through pre-training MoE-LLMs ranging from 3B to 15B parameters and extensive analysis on trillions of tokens, we demonstrate the effectiveness of the ERC loss. Moreover, the ERC loss offers flexible control and quantitative tracking of expert specialization levels during training, providing valuable insights into MoEs.",
    "authors": [
      "Ang Lv",
      "Jin Ma",
      "Yiyuan Ma",
      "Siyuan Qiao"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23447v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23447v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.23412v1",
    "title": "MindWatcher: Toward Smarter Multimodal Tool-Integrated Reasoning",
    "summary": "Traditional workflow-based agents exhibit limited intelligence when addressing real-world problems requiring tool invocation. Tool-integrated reasoning (TIR) agents capable of autonomous reasoning and tool invocation are rapidly emerging as a powerful approach for complex decision-making tasks involving multi-step interactions with external environments. In this work, we introduce MindWatcher, a TIR agent integrating interleaved thinking and multimodal chain-of-thought (CoT) reasoning. MindWatcher can autonomously decide whether and how to invoke diverse tools and coordinate their use, without relying on human prompts or workflows. The interleaved thinking paradigm enables the model to switch between thinking and tool calling at any intermediate stage, while its multimodal CoT capability allows manipulation of images during reasoning to yield more precise search results. We implement automated data auditing and evaluation pipelines, complemented by manually curated high-quality datasets for training, and we construct a benchmark, called MindWatcher-Evaluate Bench (MWE-Bench), to evaluate its performance. MindWatcher is equipped with a comprehensive suite of auxiliary reasoning tools, enabling it to address broad-domain multimodal problems. A large-scale, high-quality local image retrieval database, covering eight categories including cars, animals, and plants, endows model with robust object recognition despite its small size. Finally, we design a more efficient training infrastructure for MindWatcher, enhancing training speed and hardware utilization. Experiments not only demonstrate that MindWatcher matches or exceeds the performance of larger or more recent models through superior tool invocation, but also uncover critical insights for agent training, such as the genetic inheritance phenomenon in agentic RL.",
    "authors": [
      "Jiawei Chen",
      "Xintian Shen",
      "Lihao Zheng",
      "Zhenwei Shao",
      "Hongyuan Zhang",
      "Pengfei Yu",
      "Xudong Rao",
      "Ning Mao",
      "Xiaobo Liu",
      "Lian Wen",
      "Chaoqun Du",
      "Feng Gu",
      "Wei He",
      "Qizhen Li",
      "Shanshan Li",
      "Zide Liu",
      "Jing Luo",
      "Lifu Mu",
      "Xuhao Pan",
      "Chang Ren",
      "Haoyi Sun",
      "Qian Wang",
      "Wei Wang",
      "Hongfu Yang",
      "Jiqing Zhan",
      "Chunpeng Zhou",
      "Zheng Zhou",
      "Hao Ma",
      "Tao Wei",
      "Pan Zhou",
      "Wei Chen"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23412v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23412v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.23328v1",
    "title": "CubeBench: Diagnosing Interactive, Long-Horizon Spatial Reasoning Under Partial Observations",
    "summary": "Large Language Model (LLM) agents, while proficient in the digital realm, face a significant gap in physical-world deployment due to the challenge of forming and maintaining a robust spatial mental model. We identify three core cognitive challenges hindering this transition: spatial reasoning, long-horizon state tracking via mental simulation, and active exploration under partial observation. To isolate and evaluate these faculties, we introduce CubeBench, a novel generative benchmark centered on the Rubik's Cube. CubeBench uses a three-tiered diagnostic framework that progressively assesses agent capabilities, from foundational state tracking with full symbolic information to active exploration with only partial visual data. Our experiments on leading LLMs reveal critical limitations, including a uniform 0.00% pass rate on all long-horizon tasks, exposing a fundamental failure in long-term planning. We also propose a diagnostic framework to isolate these cognitive bottlenecks by providing external solver tools. By analyzing the failure modes, we provide key insights to guide the development of more physically-grounded intelligent agents.",
    "authors": [
      "Huan-ang Gao",
      "Zikang Zhang",
      "Tianwei Luo",
      "Kaisen Yang",
      "Xinzhe Juan",
      "Jiahao Qiu",
      "Tianxing Chen",
      "Bingxiang He",
      "Hao Zhao",
      "Hao Zhou",
      "Shilong Liu",
      "Mengdi Wang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23328v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23328v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.23304v1",
    "title": "MedGemma vs GPT-4: Open-Source and Proprietary Zero-shot Medical Disease Classification from Images",
    "summary": "Multimodal Large Language Models (LLMs) introduce an emerging paradigm for medical imaging by interpreting scans through the lens of extensive clinical knowledge, offering a transformative approach to disease classification. This study presents a critical comparison between two fundamentally different AI architectures: the specialized open-source agent MedGemma and the proprietary large multimodal model GPT-4 for diagnosing six different diseases. The MedGemma-4b-it model, fine-tuned using Low-Rank Adaptation (LoRA), demonstrated superior diagnostic capability by achieving a mean test accuracy of 80.37% compared to 69.58% for the untuned GPT-4. Furthermore, MedGemma exhibited notably higher sensitivity in high-stakes clinical tasks, such as cancer and pneumonia detection. Quantitative analysis via confusion matrices and classification reports provides comprehensive insights into model performance across all categories. These results emphasize that domain-specific fine-tuning is essential for minimizing hallucinations in clinical implementation, positioning MedGemma as a sophisticated tool for complex, evidence-based medical reasoning.",
    "authors": [
      "Md. Sazzadul Islam Prottasha",
      "Nabil Walid Rafi"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23304v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23304v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.23280v1",
    "title": "Chinese Morph Resolution in E-commerce Live Streaming Scenarios",
    "summary": "E-commerce live streaming in China, particularly on platforms like Douyin, has become a major sales channel, but hosts often use morphs to evade scrutiny and engage in false advertising. This study introduces the Live Auditory Morph Resolution (LiveAMR) task to detect such violations. Unlike previous morph research focused on text-based evasion in social media and underground industries, LiveAMR targets pronunciation-based evasion in health and medical live streams. We constructed the first LiveAMR dataset with 86,790 samples and developed a method to transform the task into a text-to-text generation problem. By leveraging large language models (LLMs) to generate additional training data, we improved performance and demonstrated that morph resolution significantly enhances live streaming regulation.",
    "authors": [
      "Jiahao Zhu",
      "Jipeng Qiang",
      "Ran Bai",
      "Chenyu Liu",
      "Xiaoye Ouyang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23280v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23280v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.23138v1",
    "title": "Why Machine Learning Models Systematically Underestimate Extreme Values II: How to Fix It with LatentNN",
    "summary": "Attenuation bias -- the systematic underestimation of regression coefficients due to measurement errors in input variables -- affects astronomical data-driven models. For linear regression, this problem was solved by treating the true input values as latent variables to be estimated alongside model parameters. In this paper, we show that neural networks suffer from the same attenuation bias and that the latent variable solution generalizes directly to neural networks. We introduce LatentNN, a method that jointly optimizes network parameters and latent input values by maximizing the joint likelihood of observing both inputs and outputs. We demonstrate the correction on one-dimensional regression, multivariate inputs with correlated features, and stellar spectroscopy applications. LatentNN reduces attenuation bias across a range of signal-to-noise ratios where standard neural networks show large bias. This provides a framework for improved neural network inference in the low signal-to-noise regime characteristic of astronomical data. This bias correction is most effective when measurement errors are less than roughly half the intrinsic data range; in the regime of very low signal-to-noise and few informative features. Code is available at https://github.com/tingyuansen/LatentNN.",
    "authors": [
      "Yuan-Sen Ting"
    ],
    "categories": [
      "astro-ph.IM",
      "astro-ph.SR",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23138v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23138v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.23572v1",
    "title": "Instruction-Following Evaluation of Large Vision-Language Models",
    "summary": "Following the initial flourishing of large language models (LLMs), there has been a surge in proposed large vision-language models (LVLMs) that integrate LLMs with vision capabilities. However, it has been observed that LVLMs, after tuning to visual instruction using commonly used training datasets, often fail to exhibit the instruction-following ability that was present in the LLM before integration, leading to results in which they do not follow task instructions as expected. This study quantitatively demonstrates that LVLMs' instruction-following ability declines after fine-tuning and analyzes its underlying causes. In particular, we constructed new training datasets highlighting whether the output format is specified. Then, we investigated how explicitly indicating the output format during fine-tuning affects LVLMs' instruction-following ability. Our quantitative evaluation confirmed that LVLMs' instruction-following ability declines after fine-tuning with commonly used datasets. Furthermore, we found that LVLMs trained with datasets, including instructions on output format, tend to follow instructions more accurately than models that do not. These findings suggest that including samples with instructions on output format during (visual) instruction tuning may help mitigate the decline in instruction-following abilities.",
    "authors": [
      "Daiki Shiono",
      "Shumpei Miyawaki",
      "Ryota Tanaka",
      "Jun Suzuki"
    ],
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23572v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23572v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2512.23310v1",
    "title": "Splitwise: Collaborative Edge-Cloud Inference for LLMs via Lyapunov-Assisted DRL",
    "summary": "Deploying large language models (LLMs) on edge devices is challenging due to their limited memory and power resources. Cloud-only inference reduces device burden but introduces high latency and cost. Static edge-cloud partitions optimize a single metric and struggle when bandwidth fluctuates. We propose Splitwise, a novel Lyapunov-assisted deep reinforcement learning (DRL) framework for fine-grained, adaptive partitioning of LLMs across edge and cloud environments. Splitwise decomposes transformer layers into attention heads and feed-forward sub-blocks, exposing more partition choices than layer-wise schemes. A hierarchical DRL policy, guided by Lyapunov optimization, jointly minimizes latency, energy consumption, and accuracy degradation while guaranteeing queue stability under stochastic workloads and variable network bandwidth. Splitwise also guarantees robustness via partition checkpoints with exponential backoff recovery in case of communication failures. Experiments on Jetson Orin NX, Galaxy S23, and Raspberry Pi 5 with GPT-2 (1.5B), LLaMA-7B, and LLaMA-13B show that Splitwise reduces end-to-end latency by 1.4x-2.8x and cuts energy consumption by up to 41% compared with existing partitioners. It lowers the 95th-percentile latency by 53-61% relative to cloud-only execution, while maintaining accuracy and modest memory requirements.",
    "authors": [
      "Abolfazl Younesi",
      "Abbas Shabrang Maryan",
      "Elyas Oustad",
      "Zahra Najafabadi Samani",
      "Mohsen Ansari",
      "Thomas Fahringer"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.ET",
      "cs.NI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23310v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23310v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2512.23292v1",
    "title": "Agentic Physical AI toward a Domain-Specific Foundation Model for Nuclear Reactor Control",
    "summary": "The prevailing paradigm in AI for physical systems, scaling general-purpose foundation models toward universal multimodal reasoning, confronts a fundamental barrier at the control interface. Recent benchmarks show that even frontier vision-language models achieve only 50-53% accuracy on basic quantitative physics tasks, behaving as approximate guessers that preserve semantic plausibility while violating physical constraints. This input unfaithfulness is not a scaling deficiency but a structural limitation. Perception-centric architectures optimize parameter-space imitation, whereas safety-critical control demands outcome-space guarantees over executed actions. Here, we present a fundamentally different pathway toward domain-specific foundation models by introducing compact language models operating as Agentic Physical AI, in which policy optimization is driven by physics-based validation rather than perceptual inference. We train a 360-million-parameter model on synthetic reactor control scenarios, scaling the dataset from 10^3 to 10^5 examples. This induces a sharp phase transition absent in general-purpose models. Small-scale systems exhibit high-variance imitation with catastrophic tail risk, while large-scale models undergo variance collapse exceeding 500x reduction, stabilizing execution-level behavior. Despite balanced exposure to four actuation families, the model autonomously rejects approximately 70% of the training distribution and concentrates 95% of runtime execution on a single-bank strategy. Learned representations transfer across distinct physics and continuous input modalities without architectural modification.",
    "authors": [
      "Yoonpyo Lee",
      "Kazuma Kobayashi",
      "Sai Puppala",
      "Sajedul Talukder",
      "Seid Koric",
      "Souvik Chakraborty",
      "Syed Bahauddin Alam"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23292v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23292v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2512.23210v1",
    "title": "Task-oriented Learnable Diffusion Timesteps for Universal Few-shot Learning of Dense Tasks",
    "summary": "Denoising diffusion probabilistic models have brought tremendous advances in generative tasks, achieving state-of-the-art performance thus far. Current diffusion model-based applications exploit the power of learned visual representations from multistep forward-backward Markovian processes for single-task prediction tasks by attaching a task-specific decoder. However, the heuristic selection of diffusion timestep features still heavily relies on empirical intuition, often leading to sub-optimal performance biased towards certain tasks. To alleviate this constraint, we investigate the significance of versatile diffusion timestep features by adaptively selecting timesteps best suited for the few-shot dense prediction task, evaluated on an arbitrary unseen task. To this end, we propose two modules: Task-aware Timestep Selection (TTS) to select ideal diffusion timesteps based on timestep-wise losses and similarity scores, and Timestep Feature Consolidation (TFC) to consolidate the selected timestep features to improve the dense predictive performance in a few-shot setting. Accompanied by our parameter-efficient fine-tuning adapter, our framework effectively achieves superiority in dense prediction performance given only a few support queries. We empirically validate our learnable timestep consolidation method on the large-scale challenging Taskonomy dataset for dense prediction, particularly for practical universal and few-shot learning scenarios.",
    "authors": [
      "Changgyoon Oh",
      "Jongoh Jeong",
      "Jegyeong Cho",
      "Kuk-Jin Yoon"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23210v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23210v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2512.23147v1",
    "title": "GeoTeacher: Geometry-Guided Semi-Supervised 3D Object Detection",
    "summary": "Semi-supervised 3D object detection, aiming to explore unlabeled data for boosting 3D object detectors, has emerged as an active research area in recent years. Some previous methods have shown substantial improvements by either employing heterogeneous teacher models to provide high-quality pseudo labels or enforcing feature-perspective consistency between the teacher and student networks. However, these methods overlook the fact that the model usually tends to exhibit low sensitivity to object geometries with limited labeled data, making it difficult to capture geometric information, which is crucial for enhancing the student model's ability in object perception and localization. In this paper, we propose GeoTeacher to enhance the student model's ability to capture geometric relations of objects with limited training data, especially unlabeled data. We design a keypoint-based geometric relation supervision module that transfers the teacher model's knowledge of object geometry to the student, thereby improving the student's capability in understanding geometric relations. Furthermore, we introduce a voxel-wise data augmentation strategy that increases the diversity of object geometries, thereby further improving the student model's ability to comprehend geometric structures. To preserve the integrity of distant objects during augmentation, we incorporate a distance-decay mechanism into this strategy. Moreover, GeoTeacher can be combined with different SS3D methods to further improve their performance. Extensive experiments on the ONCE and Waymo datasets indicate the effectiveness and generalization of our method and we achieve the new state-of-the-art results. Code will be available at https://github.com/SII-Whaleice/GeoTeacher",
    "authors": [
      "Jingyu Li",
      "Xiaolong Zhao",
      "Zhe Liu",
      "Wenxiao Wu",
      "Li Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23147v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23147v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2512.23145v1",
    "title": "Reservoir Computing inspired Matrix Multiplication-free Language Model",
    "summary": "Large language models (LLMs) have achieved state-of-the-art performance in natural language processing; however, their high computational cost remains a major bottleneck. In this study, we target computational efficiency by focusing on a matrix multiplication free language model (MatMul-free LM) and further reducing the training cost through an architecture inspired by reservoir computing. Specifically, we partially fix and share the weights of selected layers in the MatMul-free LM and insert reservoir layers to obtain rich dynamic representations without additional training overhead. Additionally, several operations are combined to reduce memory accesses. Experimental results show that the proposed architecture reduces the number of parameters by up to 19%, training time by 9.9%, and inference time by 8.0%, while maintaining comparable performance to the baseline model.",
    "authors": [
      "Takumi Shiratsuchi",
      "Yuichiro Tanaka",
      "Hakaru Tamukoh"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23145v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23145v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2512.23126v1",
    "title": "InSPO: Unlocking Intrinsic Self-Reflection for LLM Preference Optimization",
    "summary": "Direct Preference Optimization (DPO) and its variants have become standard for aligning Large Language Models due to their simplicity and offline stability. However, we identify two fundamental limitations. First, the optimal policy depends on arbitrary modeling choices (scalarization function, reference policy), yielding behavior reflecting parameterization artifacts rather than true preferences. Second, treating response generation in isolation fails to leverage comparative information in pairwise data, leaving the model's capacity for intrinsic self-reflection untapped. To address it, we propose Intrinsic Self-reflective Preference Optimization (\\q), deriving a globally optimal policy conditioning on both context and alternative responses. We prove this formulation superior to DPO/RLHF while guaranteeing invariance to scalarization and reference choices. \\q~serves as a plug-and-play enhancement without architectural changes or inference overhead. Experiments demonstrate consistent improvements in win rates and length-controlled metrics, validating that unlocking self-reflection yields more robust, human-aligned LLMs.",
    "authors": [
      "Yu Li",
      "Tian Lan",
      "Zhengling Qi"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23126v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23126v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2512.23565v1",
    "title": "RxnBench: A Multimodal Benchmark for Evaluating Large Language Models on Chemical Reaction Understanding from Scientific Literature",
    "summary": "The integration of Multimodal Large Language Models (MLLMs) into chemistry promises to revolutionize scientific discovery, yet their ability to comprehend the dense, graphical language of reactions within authentic literature remains underexplored. Here, we introduce RxnBench, a multi-tiered benchmark designed to rigorously evaluate MLLMs on chemical reaction understanding from scientific PDFs. RxnBench comprises two tasks: Single-Figure QA (SF-QA), which tests fine-grained visual perception and mechanistic reasoning using 1,525 questions derived from 305 curated reaction schemes, and Full-Document QA (FD-QA), which challenges models to synthesize information from 108 articles, requiring cross-modal integration of text, schemes, and tables. Our evaluation of MLLMs reveals a critical capability gap: while models excel at extracting explicit text, they struggle with deep chemical logic and precise structural recognition. Notably, models with inference-time reasoning significantly outperform standard architectures, yet none achieve 50\\% accuracy on FD-QA. These findings underscore the urgent need for domain-specific visual encoders and stronger reasoning engines to advance autonomous AI chemists.",
    "authors": [
      "Hanzheng Li",
      "Xi Fang",
      "Yixuan Li",
      "Chaozheng Huang",
      "Junjie Wang",
      "Xi Wang",
      "Hongzhe Bai",
      "Bojun Hao",
      "Shenyu Lin",
      "Huiqi Liang",
      "Linfeng Zhang",
      "Guolin Ke"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23565v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23565v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.23480v1",
    "title": "Agentic AI for Autonomous Defense in Software Supply Chain Security: Beyond Provenance to Vulnerability Mitigation",
    "summary": "The software supply chain attacks are becoming more and more focused on trusted development and delivery procedures, so the conventional post-build integrity mechanisms cannot be used anymore. The available frameworks like SLSA, SBOM and in toto are majorly used to offer provenance and traceability but do not have the capabilities of actively identifying and removing vulnerabilities in software production. The current paper includes an example of agentic artificial intelligence (AI) based on autonomous software supply chain security that combines large language model (LLM)-based reasoning, reinforcement learning (RL), and multi-agent coordination. The suggested system utilizes specialized security agents coordinated with the help of LangChain and LangGraph, communicates with actual CI/CD environments with the Model Context Protocol (MCP), and documents all the observations and actions in a blockchain security ledger to ensure integrity and auditing. Reinforcement learning can be used to achieve adaptive mitigation strategies that consider the balance between security effectiveness and the operational overhead, and LLMs can be used to achieve semantic vulnerability analysis, as well as explainable decisions. This framework is tested based on simulated pipelines, as well as, actual world CI/CD integrations on GitHub Actions and Jenkins, including injection attacks, insecure deserialization, access control violations, and configuration errors. Experimental outcomes indicate better detection accuracy, shorter mitigation latency and reasonable build-time overhead than rule-based, provenance only and RL only baselines. These results show that agentic AI can facilitate the transition to self defending, proactive software supply chains rather than reactive verification ones.",
    "authors": [
      "Toqeer Ali Syed",
      "Mohammad Riyaz Belgaum",
      "Salman Jan",
      "Asadullah Abdullah Khan",
      "Saad Said Alqahtani"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23480v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23480v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.23473v1",
    "title": "SC-Net: Robust Correspondence Learning via Spatial and Cross-Channel Context",
    "summary": "Recent research has focused on using convolutional neural networks (CNNs) as the backbones in two-view correspondence learning, demonstrating significant superiority over methods based on multilayer perceptrons. However, CNN backbones that are not tailored to specific tasks may fail to effectively aggregate global context and oversmooth dense motion fields in scenes with large disparity. To address these problems, we propose a novel network named SC-Net, which effectively integrates bilateral context from both spatial and channel perspectives. Specifically, we design an adaptive focused regularization module (AFR) to enhance the model's position-awareness and robustness against spurious motion samples, thereby facilitating the generation of a more accurate motion field. We then propose a bilateral field adjustment module (BFA) to refine the motion field by simultaneously modeling long-range relationships and facilitating interaction across spatial and channel dimensions. Finally, we recover the motion vectors from the refined field using a position-aware recovery module (PAR) that ensures consistency and precision. Extensive experiments demonstrate that SC-Net outperforms state-of-the-art methods in relative pose estimation and outlier removal tasks on YFCC100M and SUN3D datasets. Source code is available at http://www.linshuyuan.com.",
    "authors": [
      "Shuyuan Lin",
      "Hailiang Liao",
      "Qiang Qi",
      "Junjie Huang",
      "Taotao Lai",
      "Jian Weng"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23473v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23473v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.23448v1",
    "title": "Dynamic Subspace Composition: Efficient Adaptation via Contractive Basis Expansion",
    "summary": "Mixture of Experts (MoE) models scale capacity but often suffer from representation collapse and gradient instability. We propose Dynamic Subspace Composition (DSC), a framework that approximates context-dependent weights via a state-dependent, sparse expansion of a shared basis bank. Formally, DSC models the weight update as a residual trajectory within a Star- Shaped Domain, employing a Magnitude-Gated Simplex Interpolation to ensure continuity at the identity. Unlike standard Mixture-of-LoRAs, which incurs O(M rd) parameter complexity by retrieving independent rank-r matrices, DSC constructs a compositional rank-K approximation from decoupled unit-norm basis vectors. This reduces parameter complexity to O(M d) and memory traffic to O(Kd), while Frame-Theoretic regularization and spectral constraints provide rigorous worst-case bounds on the dynamic update. The code is available at https://github. com/VladimerKhasia/DSC",
    "authors": [
      "Vladimer Khasia"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23448v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23448v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.23419v1",
    "title": "The World Is Bigger! A Computationally-Embedded Perspective on the Big World Hypothesis",
    "summary": "Continual learning is often motivated by the idea, known as the big world hypothesis, that \"the world is bigger\" than the agent. Recent problem formulations capture this idea by explicitly constraining an agent relative to the environment. These constraints lead to solutions in which the agent continually adapts to best use its limited capacity, rather than converging to a fixed solution. However, explicit constraints can be ad hoc, difficult to incorporate, and may limit the effectiveness of scaling up the agent's capacity. In this paper, we characterize a problem setting in which an agent, regardless of its capacity, is constrained by being embedded in the environment. In particular, we introduce a computationally-embedded perspective that represents an embedded agent as an automaton simulated within a universal (formal) computer. Such an automaton is always constrained; we prove that it is equivalent to an agent that interacts with a partially observable Markov decision process over a countably infinite state-space. We propose an objective for this setting, which we call interactivity, that measures an agent's ability to continually adapt its behaviour by learning new predictions. We then develop a model-based reinforcement learning algorithm for interactivity-seeking, and use it to construct a synthetic problem to evaluate continual learning capability. Our results show that deep nonlinear networks struggle to sustain interactivity, whereas deep linear networks sustain higher interactivity as capacity increases.",
    "authors": [
      "Alex Lewandowski",
      "Adtiya A. Ramesh",
      "Edan Meyer",
      "Dale Schuurmans",
      "Marlos C. Machado"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23419v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23419v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.23396v1",
    "title": "PINNs for Electromagnetic Wave Propagation",
    "summary": "Physics-Informed Neural Networks (PINNs) are a methodology that aims to solve physical systems by directly embedding PDE constraints into the neural network training process. In electromagnetism, where well-established methodologies such as FDTD and FEM already exist, new methodologies are expected to provide clear advantages to be accepted. Despite their mesh-free nature and applicability to inverse problems, PINNs can exhibit deficiencies in terms of accuracy and energy metrics when compared to FDTD solutions. This study demonstrates hybrid training strategies can bring PINNs closer to FDTD-level accuracy and energy consistency.   This study presents a hybrid methodology addressing common challenges in wave propagation scenarios. The causality collapse problem in time-dependent PINN training is addressed via time marching and causality-aware weighting. In order to mitigate the discontinuities that are introduced by time marching, a two-stage interface continuity loss is applied. In order to suppress loss accumulation, which is manifested as cumulative energy drift in electromagnetic waves, a local Poynting-based regularizer has been developed.   In the developed PINN model, high field accuracy is achieved with an average 0.09\\% $NRMSE$ and 1.01\\% $L^2$ error over time. Energy conservation is achieved on the PINN side with only a 0.024\\% relative energy mismatch in the 2D PEC cavity scenario. Training is performed without labeled field data, using only physics-based residual losses; FDTD is used solely for post-training evaluation. The results demonstrate that PINNs can achieve competitive results with FDTD in canonical electromagnetic examples and are a viable alternative.",
    "authors": [
      "Nilufer K. Bulut"
    ],
    "categories": [
      "physics.comp-ph",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23396v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23396v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.23385v1",
    "title": "Securing the AI Supply Chain: What Can We Learn From Developer-Reported Security Issues and Solutions of AI Projects?",
    "summary": "The rapid growth of Artificial Intelligence (AI) models and applications has led to an increasingly complex security landscape. Developers of AI projects must contend not only with traditional software supply chain issues but also with novel, AI-specific security threats. However, little is known about what security issues are commonly encountered and how they are resolved in practice. This gap hinders the development of effective security measures for each component of the AI supply chain. We bridge this gap by conducting an empirical investigation of developer-reported issues and solutions, based on discussions from Hugging Face and GitHub. To identify security-related discussions, we develop a pipeline that combines keyword matching with an optimal fine-tuned distilBERT classifier, which achieved the best performance in our extensive comparison of various deep learning and large language models. This pipeline produces a dataset of 312,868 security discussions, providing insights into the security reporting practices of AI applications and projects. We conduct a thematic analysis of 753 posts sampled from our dataset and uncover a fine-grained taxonomy of 32 security issues and 24 solutions across four themes: (1) System and Software, (2) External Tools and Ecosystem, (3) Model, and (4) Data. We reveal that many security issues arise from the complex dependencies and black-box nature of AI components. Notably, challenges related to Models and Data often lack concrete solutions. Our insights can offer evidence-based guidance for developers and researchers to address real-world security threats across the AI supply chain.",
    "authors": [
      "The Anh Nguyen",
      "Triet Huynh Minh Le",
      "M. Ali Babar"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR",
      "cs.HC"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23385v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23385v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.23312v1",
    "title": "Explainable Neural Inverse Kinematics for Obstacle-Aware Robotic Manipulation: A Comparative Analysis of IKNet Variants",
    "summary": "Deep neural networks have accelerated inverse-kinematics (IK) inference to the point where low cost manipulators can execute complex trajectories in real time, yet the opaque nature of these models contradicts the transparency and safety requirements emerging in responsible AI regulation. This study proposes an explainability centered workflow that integrates Shapley-value attribution with physics-based obstacle avoidance evaluation for the ROBOTIS OpenManipulator-X. Building upon the original IKNet, two lightweight variants-Improved IKNet with residual connections and Focused IKNet with position-orientation decoupling are trained on a large, synthetically generated pose-joint dataset. SHAP is employed to derive both global and local importance rankings, while the InterpretML toolkit visualizes partial-dependence patterns that expose non-linear couplings between Cartesian poses and joint angles. To bridge algorithmic insight and robotic safety, each network is embedded in a simulator that subjects the arm to randomized single and multi-obstacle scenes; forward kinematics, capsule-based collision checks, and trajectory metrics quantify the relationship between attribution balance and physical clearance. Qualitative heat maps reveal that architectures distributing importance more evenly across pose dimensions tend to maintain wider safety margins without compromising positional accuracy. The combined analysis demonstrates that explainable AI(XAI) techniques can illuminate hidden failure modes, guide architectural refinements, and inform obstacle aware deployment strategies for learning based IK. The proposed methodology thus contributes a concrete path toward trustworthy, data-driven manipulation that aligns with emerging responsible-AI standards.",
    "authors": [
      "Sheng-Kai Chen",
      "Yi-Ling Tsai",
      "Chun-Chih Chang",
      "Yan-Chen Chen",
      "Po-Chiang Lin"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23312v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23312v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.23262v1",
    "title": "PFed-Signal: An ADR Prediction Model based on Federated Learning",
    "summary": "The adverse drug reactions (ADRs) predicted based on the biased records in FAERS (U.S. Food and Drug Administration Adverse Event Reporting System) may mislead diagnosis online. Generally, such problems are solved by optimizing reporting odds ratio (ROR) or proportional reporting ratio (PRR). However, these methods that rely on statistical methods cannot eliminate the biased data, leading to inaccurate signal prediction. In this paper, we propose PFed-signal, a federated learning-based signal prediction model of ADR, which utilizes the Euclidean distance to eliminate the biased data from FAERS, thereby improving the accuracy of ADR prediction. Specifically, we first propose Pfed-Split, a method to split the original dataset into a split dataset based on ADR. Then we propose ADR-signal, an ADR prediction model, including a biased data identification method based on federated learning and an ADR prediction model based on Transformer. The former identifies the biased data according to the Euclidean distance and generates a clean dataset by deleting the biased data. The latter is an ADR prediction model based on Transformer trained on the clean data set. The results show that the ROR and PRR on the clean dataset are better than those of the traditional methods. Furthermore, the accuracy rate, F1 score, recall rate and AUC of PFed-Signal are 0.887, 0.890, 0.913 and 0.957 respectively, which are higher than the baselines.",
    "authors": [
      "Tao Li",
      "Peilin Li",
      "Kui Lu",
      "Yilei Wang",
      "Junliang Shang",
      "Guangshun Li",
      "Huiyu Zhou"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23262v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23262v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.23206v1",
    "title": "Not too long do read: Evaluating LLM-generated extreme scientific summaries",
    "summary": "High-quality scientific extreme summary (TLDR) facilitates effective science communication. How do large language models (LLMs) perform in generating them? How are LLM-generated summaries different from those written by human experts? However, the lack of a comprehensive, high-quality scientific TLDR dataset hinders both the development and evaluation of LLMs' summarization ability. To address these, we propose a novel dataset, BiomedTLDR, containing a large sample of researcher-authored summaries from scientific papers, which leverages the common practice of including authors' comments alongside bibliography items. We then test popular open-weight LLMs for generating TLDRs based on abstracts. Our analysis reveals that, although some of them successfully produce humanoid summaries, LLMs generally exhibit a greater affinity for the original text's lexical choices and rhetorical structures, hence tend to be more extractive rather than abstractive in general, compared to humans. Our code and datasets are available at https://github.com/netknowledge/LLM_summarization (Lyu and Ke, 2025).",
    "authors": [
      "Zhuoqi Lyu",
      "Qing Ke"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23206v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23206v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.23177v1",
    "title": "Machine Learning-Assisted Vocal Cord Ultrasound Examination: Project VIPR",
    "summary": "Intro: Vocal cord ultrasound (VCUS) has emerged as a less invasive and better tolerated examination technique, but its accuracy is operator dependent. This research aims to apply a machine learning-assisted algorithm to automatically identify the vocal cords and distinguish normal vocal cord images from vocal cord paralysis (VCP). Methods: VCUS videos were acquired from 30 volunteers, which were split into still frames and cropped to a uniform size. Healthy and simulated VCP images were used as training data for vocal cord segmentation and VCP classification models. Results: The vocal cord segmentation model achieved a validation accuracy of 96%, while the best classification model (VIPRnet) achieved a validation accuracy of 99%. Conclusion: Machine learning-assisted analysis of VCUS shows great promise in improving diagnostic accuracy over operator-dependent human interpretation.",
    "authors": [
      "Will Sebelik-Lassiter",
      "Evan Schubert",
      "Muhammad Alliyu",
      "Quentin Robbins",
      "Excel Olatunji",
      "Mustafa Barry"
    ],
    "categories": [
      "cs.LG",
      "cs.CE",
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23177v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23177v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.23671v1",
    "title": "Calibrated Multi-Level Quantile Forecasting",
    "summary": "We present an online method for guaranteeing calibration of quantile forecasts at multiple quantile levels simultaneously. A sequence of $α$-level quantile forecasts is calibrated if the forecasts are larger than the target value at an $α$-fraction of time steps. We introduce a lightweight method called Multi-Level Quantile Tracker (MultiQT) that wraps around any existing point or quantile forecaster to produce corrected forecasts guaranteed to achieve calibration, even against adversarial distribution shifts, while ensuring that the forecasts are ordered -- e.g., the 0.5-level quantile forecast is never larger than the 0.6-level forecast. Furthermore, the method comes with a no-regret guarantee that implies it will not worsen the performance of an existing forecaster, asymptotically, with respect to the quantile loss. In experiments, we find that MultiQT significantly improves the calibration of real forecasters in epidemic and energy forecasting problems.",
    "authors": [
      "Tiffany Ding",
      "Isaac Gibbs",
      "Ryan J. Tibshirani"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.OC",
      "stat.ME"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23671v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23671v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.23609v1",
    "title": "The Big Three in Marriage Talk: LLM-Assisted Analysis of Moral Ethics and Sentiment on Weibo and Xiaohongshu",
    "summary": "China's marriage registrations have declined dramatically, dropping from 13.47 million couples in 2013 to 6.1 million in 2024. Understanding public attitudes toward marriage requires examining not only emotional sentiment but also the moral reasoning underlying these evaluations. This study analyzed 219,358 marriage-related posts from two major Chinese social media platforms (Sina Weibo and Xiaohongshu) using large language model (LLM)-assisted content analysis. Drawing on Shweder's Big Three moral ethics framework, posts were coded for sentiment (positive, negative, neutral) and moral dimensions (Autonomy, Community, Divinity). Results revealed platform differences: Weibo discourse skewed positive, while Xiaohongshu was predominantly neutral. Most posts across both platforms lacked explicit moral framing. However, when moral ethics were invoked, significant associations with sentiment emerged. Posts invoking Autonomy ethics and Community ethics were predominantly negative, whereas Divinity-framed posts tended toward neutral or positive sentiment. These findings suggest that concerns about both personal autonomy constraints and communal obligations drive negative marriage attitudes in contemporary China. The study demonstrates LLMs' utility for scaling qualitative analysis and offers insights for developing culturally informed policies addressing marriage decline in Chinese contexts.",
    "authors": [
      "Frank Tian-Fang Ye",
      "Xiaozi Gao"
    ],
    "categories": [
      "econ.GN",
      "cs.CL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23609v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23609v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.23445v1",
    "title": "Assessing behaviour coverage in a multi-agent system simulation for autonomous vehicle testing",
    "summary": "As autonomous vehicle technology advances, ensuring the safety and reliability of these systems becomes paramount. Consequently, comprehensive testing methodologies are essential to evaluate the performance of autonomous vehicles in diverse and complex real-world scenarios. This study focuses on the behaviour coverage analysis of a multi-agent system simulation designed for autonomous vehicle testing, and provides a systematic approach to measure and assess behaviour coverage within the simulation environment. By defining a set of driving scenarios, and agent interactions, we evaluate the extent to which the simulation encompasses a broad range of behaviours relevant to autonomous driving.   Our findings highlight the importance of behaviour coverage in validating the effectiveness and robustness of autonomous vehicle systems. Through the analysis of behaviour coverage metrics and coverage-based testing, we identify key areas for improvement and optimization in the simulation framework. Thus, a Model Predictive Control (MPC) pedestrian agent is proposed, where its objective function is formulated to encourage \\textit{interesting} tests while promoting a more realistic behaviour than other previously studied pedestrian agents. This research contributes to advancing the field of autonomous vehicle testing by providing insights into the comprehensive evaluation of system behaviour in simulated environments. The results offer valuable implications for enhancing the safety, reliability, and performance of autonomous vehicles through rigorous testing methodologies.",
    "authors": [
      "Manuel Franco-Vivo"
    ],
    "categories": [
      "cs.MA",
      "cs.LG",
      "cs.RO"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23445v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23445v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.23430v1",
    "title": "C2PO: Diagnosing and Disentangling Bias Shortcuts in LLMs",
    "summary": "Bias in Large Language Models (LLMs) poses significant risks to trustworthiness, manifesting primarily as stereotypical biases (e.g., gender or racial stereotypes) and structural biases (e.g., lexical overlap or position preferences). However, prior paradigms typically address these in isolation, often mitigating one at the expense of exacerbating the other. To address this, we conduct a systematic exploration of these reasoning failures and identify a primary inducement: the latent spurious feature correlations within the input that drive these erroneous reasoning shortcuts. Driven by these findings, we introduce Causal-Contrastive Preference Optimization (C2PO), a unified alignment framework designed to tackle these specific failures by simultaneously discovering and suppressing these correlations directly within the optimization process. Specifically, C2PO leverages causal counterfactual signals to isolate bias-inducing features from valid reasoning paths, and employs a fairness-sensitive preference update mechanism to dynamically evaluate logit-level contributions and suppress shortcut features. Extensive experiments across multiple benchmarks covering stereotypical bias (BBQ, Unqover), structural bias (MNLI, HANS, Chatbot, MT-Bench), out-of-domain fairness (StereoSet, WinoBias), and general utility (MMLU, GSM8K) demonstrate that C2PO effectively mitigates stereotypical and structural biases while preserving robust general reasoning capabilities.",
    "authors": [
      "Xuan Feng",
      "Bo An",
      "Tianlong Gu",
      "Liang Chang",
      "Fengrui Hao",
      "Peipeng Yu",
      "Shuai Zhao"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23430v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23430v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.23353v1",
    "title": "ISOPO: Proximal policy gradients without pi-old",
    "summary": "This note introduces Isometric Policy Optimization (ISOPO), an efficient method to approximate the natural policy gradient in a single gradient step. In comparison, existing proximal policy methods such as GRPO or CISPO use multiple gradient steps with variants of importance ratio clipping to approximate a natural gradient step relative to a reference policy. In its simplest form, ISOPO normalizes the log-probability gradient of each sequence in the Fisher metric before contracting with the advantages. Another variant of ISOPO transforms the microbatch advantages based on the neural tangent kernel in each layer. ISOPO applies this transformation layer-wise in a single backward pass and can be implemented with negligible computational overhead compared to vanilla REINFORCE.",
    "authors": [
      "Nilin Abrahamsen"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23353v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23353v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.23255v1",
    "title": "Contour Information Aware 2D Gaussian Splatting for Image Representation",
    "summary": "Image representation is a fundamental task in computer vision. Recently, Gaussian Splatting has emerged as an efficient representation framework, and its extension to 2D image representation enables lightweight, yet expressive modeling of visual content. While recent 2D Gaussian Splatting (2DGS) approaches provide compact storage and real-time decoding, they often produce blurry or indistinct boundaries when the number of Gaussians is small due to the lack of contour awareness. In this work, we propose a Contour Information-Aware 2D Gaussian Splatting framework that incorporates object segmentation priors into Gaussian-based image representation. By constraining each Gaussian to a specific segmentation region during rasterization, our method prevents cross-boundary blending and preserves edge structures under high compression. We also introduce a warm-up scheme to stabilize training and improve convergence. Experiments on synthetic color charts and the DAVIS dataset demonstrate that our approach achieves higher reconstruction quality around object edges compared to existing 2DGS methods. The improvement is particularly evident in scenarios with very few Gaussians, while our method still maintains fast rendering and low memory usage.",
    "authors": [
      "Masaya Takabe",
      "Hiroshi Watanabe",
      "Sujun Hong",
      "Tomohiro Ikai",
      "Zheming Fan",
      "Ryo Ishimoto",
      "Kakeru Sugimoto",
      "Ruri Imichi"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23255v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23255v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.23675v1",
    "title": "End-to-End Test-Time Training for Long Context",
    "summary": "We formulate long-context language modeling as a problem in continual learning rather than architecture design. Under this formulation, we only use a standard architecture -- a Transformer with sliding-window attention. However, our model continues learning at test time via next-token prediction on the given context, compressing the context it reads into its weights. In addition, we improve the model's initialization for learning at test time via meta-learning at training time. Overall, our method, a form of Test-Time Training (TTT), is End-to-End (E2E) both at test time (via next-token prediction) and training time (via meta-learning), in contrast to previous forms. We conduct extensive experiments with a focus on scaling properties. In particular, for 3B models trained with 164B tokens, our method (TTT-E2E) scales with context length in the same way as Transformer with full attention, while others, such as Mamba 2 and Gated DeltaNet, do not. However, similar to RNNs, TTT-E2E has constant inference latency regardless of context length, making it 2.7 times faster than full attention for 128K context. Our code is publicly available.",
    "authors": [
      "Arnuv Tandon",
      "Karan Dalal",
      "Xinhao Li",
      "Daniel Koceja",
      "Marcel Rød",
      "Sam Buchanan",
      "Xiaolong Wang",
      "Jure Leskovec",
      "Sanmi Koyejo",
      "Tatsunori Hashimoto",
      "Carlos Guestrin",
      "Jed McCaleb",
      "Yejin Choi",
      "Yu Sun"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23675v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23675v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.23611v1",
    "title": "Close the Loop: Synthesizing Infinite Tool-Use Data via Multi-Agent Role-Playing",
    "summary": "Enabling Large Language Models (LLMs) to reliably invoke external tools remains a critical bottleneck for autonomous agents. Existing approaches suffer from three fundamental challenges: expensive human annotation for high-quality trajectories, poor generalization to unseen tools, and quality ceilings inherent in single-model synthesis that perpetuate biases and coverage gaps. We introduce InfTool, a fully autonomous framework that breaks these barriers through self-evolving multi-agent synthesis. Given only raw API specifications, InfTool orchestrates three collaborative agents (User Simulator, Tool-Calling Assistant, and MCP Server) to generate diverse, verified trajectories spanning single-turn calls to complex multi-step workflows. The framework establishes a closed loop: synthesized data trains the model via Group Relative Policy Optimization (GRPO) with gated rewards, the improved model generates higher-quality data targeting capability gaps, and this cycle iterates without human intervention. Experiments on the Berkeley Function-Calling Leaderboard (BFCL) demonstrate that InfTool transforms a base 32B model from 19.8% to 70.9% accuracy (+258%), surpassing models 10x larger and rivaling Claude-Opus, and entirely from synthetic data without human annotation.",
    "authors": [
      "Yuwen Li",
      "Wei Zhang",
      "Zelong Huang",
      "Mason Yang",
      "Jiajun Wu",
      "Shawn Guo",
      "Huahao Hu",
      "Lingyi Sun",
      "Jian Yang",
      "Mingjie Tang",
      "Byran Dai"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23611v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23611v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.23512v1",
    "title": "UniHetero: Could Generation Enhance Understanding for Vision-Language-Model at Large Data Scale?",
    "summary": "Vision-language large models are moving toward the unification of visual understanding and visual generation tasks. However, whether generation can enhance understanding is still under-explored on large data scale. In this work, we analysis the unified model with a concise structure, UniHetero, under large-scale pretraining (>200M samples). Our key observations are: (1) Generation can improve understanding, but Only if you generate Semantics, Not Pixels. (2) Generation reveals a superior Data Scaling trend and higher Data Utilization. (3) Autoregression on Input Embedding is effective to capture visual details.",
    "authors": [
      "Fengjiao Chen",
      "Minhao Jing",
      "Weitao Lu",
      "Yan Feng",
      "Xiaoyu Li",
      "Xuezhi Cao"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23512v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23512v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.23482v1",
    "title": "Theory of Mind for Explainable Human-Robot Interaction",
    "summary": "Within the context of human-robot interaction (HRI), Theory of Mind (ToM) is intended to serve as a user-friendly backend to the interface of robotic systems, enabling robots to infer and respond to human mental states. When integrated into robots, ToM allows them to adapt their internal models to users' behaviors, enhancing the interpretability and predictability of their actions. Similarly, Explainable Artificial Intelligence (XAI) aims to make AI systems transparent and interpretable, allowing humans to understand and interact with them effectively. Since ToM in HRI serves related purposes, we propose to consider ToM as a form of XAI and evaluate it through the eValuation XAI (VXAI) framework and its seven desiderata. This paper identifies a critical gap in the application of ToM within HRI, as existing methods rarely assess the extent to which explanations correspond to the robot's actual internal reasoning. To address this limitation, we propose to integrate ToM within XAI frameworks. By embedding ToM principles inside XAI, we argue for a shift in perspective, as current XAI research focuses predominantly on the AI system itself and often lacks user-centered explanations. Incorporating ToM would enable a change in focus, prioritizing the user's informational needs and perspective.",
    "authors": [
      "Marie Bauer",
      "Julia Gachot",
      "Matthias Kerzel",
      "Cornelius Weber",
      "Stefan Wermter"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23482v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23482v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.23472v1",
    "title": "MCI-Net: A Robust Multi-Domain Context Integration Network for Point Cloud Registration",
    "summary": "Robust and discriminative feature learning is critical for high-quality point cloud registration. However, existing deep learning-based methods typically rely on Euclidean neighborhood-based strategies for feature extraction, which struggle to effectively capture the implicit semantics and structural consistency in point clouds. To address these issues, we propose a multi-domain context integration network (MCI-Net) that improves feature representation and registration performance by aggregating contextual cues from diverse domains. Specifically, we propose a graph neighborhood aggregation module, which constructs a global graph to capture the overall structural relationships within point clouds. We then propose a progressive context interaction module to enhance feature discriminability by performing intra-domain feature decoupling and inter-domain context interaction. Finally, we design a dynamic inlier selection method that optimizes inlier weights using residual information from multiple iterations of pose estimation, thereby improving the accuracy and robustness of registration. Extensive experiments on indoor RGB-D and outdoor LiDAR datasets show that the proposed MCI-Net significantly outperforms existing state-of-the-art methods, achieving the highest registration recall of 96.4\\% on 3DMatch. Source code is available at http://www.linshuyuan.com.",
    "authors": [
      "Shuyuan Lin",
      "Wenwu Peng",
      "Junjie Huang",
      "Qiang Qi",
      "Miaohui Wang",
      "Jian Weng"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23472v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23472v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.23436v1",
    "title": "Fuzzy-Logic and Deep Learning for Environmental Condition-Aware Road Surface Classification",
    "summary": "Monitoring states of road surfaces provides valuable information for the planning and controlling vehicles and active vehicle control systems. Classical road monitoring methods are expensive and unsystematic because they require time for measurements. This article proposes an real time system based on weather conditional data and road surface condition data. For this purpose, we collected data with a mobile phone camera on the roads around the campus of the Karlsruhe Institute of Technology. We tested a large number of different image-based deep learning algorithms for road classification. In addition, we used road acceleration data along with road image data for training by using them as images. We compared the performances of acceleration-based and camera image-based approaches. The performances of the simple Alexnet, LeNet, VGG, and Resnet algorithms were compared as deep learning algorithms. For road condition classification, 5 classes were considered: asphalt, damaged asphalt, gravel road, damaged gravel road, pavement road and over 95% accuracy performance was achieved. It is also proposed to use the acceleration or the camera image to classify the road surface according to the weather and the time of day using fuzzy logic.",
    "authors": [
      "Mustafa Demetgul",
      "Sanja Lazarova Molnar"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23436v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23436v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.23407v1",
    "title": "Theoretical Foundations of Scaling Law in Familial Models",
    "summary": "Neural scaling laws have become foundational for optimizing large language model (LLM) training, yet they typically assume a single dense model output. This limitation effectively overlooks \"Familial models, a transformative paradigm essential for realizing ubiquitous intelligence across heterogeneous device-edge-cloud hierarchies. Transcending static architectures, familial models integrate early exits with relay-style inference to spawn G deployable sub-models from a single shared backbone. In this work, we theoretically and empirically extend the scaling law to capture this \"one-run, many-models\" paradigm by introducing Granularity (G) as a fundamental scaling variable alongside model size (N) and training tokens (D). To rigorously quantify this relationship, we propose a unified functional form L(N, D, G) and parameterize it using large-scale empirical runs. Specifically, we employ a rigorous IsoFLOP experimental design to strictly isolate architectural impact from computational scale. Across fixed budgets, we systematically sweep model sizes (N) and granularities (G) while dynamically adjusting tokens (D). This approach effectively decouples the marginal cost of granularity from the benefits of scale, ensuring high-fidelity parameterization of our unified scaling law. Our results reveal that the granularity penalty follows a multiplicative power law with an extremely small exponent. Theoretically, this bridges fixed-compute training with dynamic architectures. Practically, it validates the \"train once, deploy many\" paradigm, demonstrating that deployment flexibility is achievable without compromising the compute-optimality of dense baselines.",
    "authors": [
      "Huan Song",
      "Qingfei Zhao",
      "Ting Long",
      "Shuyu Tian",
      "Hongjun An",
      "Jiawei Shao",
      "Chi Zhang",
      "Xuelong Li"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23407v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23407v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.23300v1",
    "title": "AI4Reading: Chinese Audiobook Interpretation System Based on Multi-Agent Collaboration",
    "summary": "Audiobook interpretations are attracting increasing attention, as they provide accessible and in-depth analyses of books that offer readers practical insights and intellectual inspiration. However, their manual creation process remains time-consuming and resource-intensive. To address this challenge, we propose AI4Reading, a multi-agent collaboration system leveraging large language models (LLMs) and speech synthesis technology to generate podcast, like audiobook interpretations. The system is designed to meet three key objectives: accurate content preservation, enhanced comprehensibility, and a logical narrative structure. To achieve these goals, we develop a framework composed of 11 specialized agents,including topic analysts, case analysts, editors, a narrator, and proofreaders that work in concert to explore themes, extract real world cases, refine content organization, and synthesize natural spoken language. By comparing expert interpretations with our system's output, the results show that although AI4Reading still has a gap in speech generation quality, the generated interpretative scripts are simpler and more accurate.",
    "authors": [
      "Minjiang Huang",
      "Jipeng Qiang",
      "Yi Zhu",
      "Chaowei Zhang",
      "Xiangyu Zhao",
      "Kui Yu"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23300v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23300v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.23132v1",
    "title": "Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems",
    "summary": "Machine learning (ML) underpins foundation models in finance, healthcare, and critical infrastructure, making them targets for data poisoning, model extraction, prompt injection, automated jailbreaking, and preference-guided black-box attacks that exploit model comparisons. Larger models can be more vulnerable to introspection-driven jailbreaks and cross-modal manipulation. Traditional cybersecurity lacks ML-specific threat modeling for foundation, multimodal, and RAG systems. Objective: Characterize ML security risks by identifying dominant TTPs, vulnerabilities, and targeted lifecycle stages. Methods: We extract 93 threats from MITRE ATLAS (26), AI Incident Database (12), and literature (55), and analyze 854 GitHub/Python repositories. A multi-agent RAG system (ChatGPT-4o, temp 0.4) mines 300+ articles to build an ontology-driven threat graph linking TTPs, vulnerabilities, and stages. Results: We identify unreported threats including commercial LLM API model stealing, parameter memorization leakage, and preference-guided text-only jailbreaks. Dominant TTPs include MASTERKEY-style jailbreaking, federated poisoning, diffusion backdoors, and preference optimization leakage, mainly impacting pre-training and inference. Graph analysis reveals dense vulnerability clusters in libraries with poor patch propagation. Conclusion: Adaptive, ML-specific security frameworks, combining dependency hygiene, threat intelligence, and monitoring, are essential to mitigate supply-chain and inference risks across the ML lifecycle.",
    "authors": [
      "Armstrong Foundjem",
      "Lionel Nganyewou Tidjon",
      "Leuson Da Silva",
      "Foutse Khomh"
    ],
    "categories": [
      "cs.CR",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23132v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23132v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.23128v1",
    "title": "It's a TRAP! Task-Redirecting Agent Persuasion Benchmark for Web Agents",
    "summary": "Web-based agents powered by large language models are increasingly used for tasks such as email management or professional networking. Their reliance on dynamic web content, however, makes them vulnerable to prompt injection attacks: adversarial instructions hidden in interface elements that persuade the agent to divert from its original task. We introduce the Task-Redirecting Agent Persuasion Benchmark (TRAP), an evaluation for studying how persuasion techniques misguide autonomous web agents on realistic tasks. Across six frontier models, agents are susceptible to prompt injection in 25\\% of tasks on average (13\\% for GPT-5 to 43\\% for DeepSeek-R1), with small interface or contextual changes often doubling success rates and revealing systemic, psychologically driven vulnerabilities in web-based agents. We also provide a modular social-engineering injection framework with controlled experiments on high-fidelity website clones, allowing for further benchmark expansion.",
    "authors": [
      "Karolina Korgul",
      "Yushi Yang",
      "Arkadiusz Drohomirecki",
      "Piotr Błaszczyk",
      "Will Howard",
      "Lukas Aichberger",
      "Chris Russell",
      "Philip H. S. Torr",
      "Adam Mahdi",
      "Adel Bibi"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23128v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23128v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.23643v1",
    "title": "Simultaneous Approximation of the Score Function and Its Derivatives by Deep Neural Networks",
    "summary": "We present a theory for simultaneous approximation of the score function and its derivatives, enabling the handling of data distributions with low-dimensional structure and unbounded support. Our approximation error bounds match those in the literature while relying on assumptions that relax the usual bounded support requirement. Crucially, our bounds are free from the curse of dimensionality. Moreover, we establish approximation guarantees for derivatives of any prescribed order, extending beyond the commonly considered first-order setting.",
    "authors": [
      "Konstantin Yakovlev",
      "Nikita Puchkin"
    ],
    "categories": [
      "math.NA",
      "cs.LG",
      "math.ST",
      "stat.ML"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23643v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23643v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.23427v1",
    "title": "Towards Integrating Uncertainty for Domain-Agnostic Segmentation",
    "summary": "Foundation models for segmentation such as the Segment Anything Model (SAM) family exhibit strong zero-shot performance, but remain vulnerable in shifted or limited-knowledge domains. This work investigates whether uncertainty quantification can mitigate such challenges and enhance model generalisability in a domain-agnostic manner. To this end, we (1) curate UncertSAM, a benchmark comprising eight datasets designed to stress-test SAM under challenging segmentation conditions including shadows, transparency, and camouflage; (2) evaluate a suite of lightweight, post-hoc uncertainty estimation methods; and (3) assess a preliminary uncertainty-guided prediction refinement step. Among evaluated approaches, a last-layer Laplace approximation yields uncertainty estimates that correlate well with segmentation errors, indicating a meaningful signal. While refinement benefits are preliminary, our findings underscore the potential of incorporating uncertainty into segmentation models to support robust, domain-agnostic performance. Our benchmark and code are made publicly available.",
    "authors": [
      "Jesse Brouwers",
      "Xiaoyan Xing",
      "Alexander Timans"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23427v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23427v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.23425v1",
    "title": "A general framework for deep learning",
    "summary": "This paper develops a general approach for deep learning for a setting that includes nonparametric regression and classification. We perform a framework from data that fulfills a generalized Bernstein-type inequality, including independent, $φ$-mixing, strongly mixing and $\\mathcal{C}$-mixing observations. Two estimators are proposed: a non-penalized deep neural network estimator (NPDNN) and a sparse-penalized deep neural network estimator (SPDNN). For each of these estimators, bounds of the expected excess risk on the class of Hölder smooth functions and composition Hölder functions are established. Applications to independent data, as well as to $φ$-mixing, strongly mixing, $\\mathcal{C}$-mixing processes are considered. For each of these examples, the upper bounds of the expected excess risk of the proposed NPDNN and SPDNN predictors are derived. It is shown that both the NPDNN and SPDNN estimators are minimax optimal (up to a logarithmic factor) in many classical settings.",
    "authors": [
      "William Kengne",
      "Modou Wade"
    ],
    "categories": [
      "math.ST",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23425v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23425v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.23405v1",
    "title": "On the Sample Complexity of Learning for Blind Inverse Problems",
    "summary": "Blind inverse problems arise in many experimental settings where the forward operator is partially or entirely unknown. In this context, methods developed for the non-blind case cannot be adapted in a straightforward manner. Recently, data-driven approaches have been proposed to address blind inverse problems, demonstrating strong empirical performance and adaptability. However, these methods often lack interpretability and are not supported by rigorous theoretical guarantees, limiting their reliability in applied domains such as imaging inverse problems. In this work, we shed light on learning in blind inverse problems within the simplified yet insightful framework of Linear Minimum Mean Square Estimators (LMMSEs). We provide an in-depth theoretical analysis, deriving closed-form expressions for optimal estimators and extending classical results. In particular, we establish equivalences with suitably chosen Tikhonov-regularized formulations, where the regularization depends explicitly on the distributions of the unknown signal, the noise, and the random forward operators. We also prove convergence results under appropriate source condition assumptions. Furthermore, we derive rigorous finite-sample error bounds that characterize the performance of learned estimators as a function of the noise level, problem conditioning, and number of available samples. These bounds explicitly quantify the impact of operator randomness and reveal the associated convergence rates as this randomness vanishes. Finally, we validate our theoretical findings through illustrative numerical experiments that confirm the predicted convergence behavior.",
    "authors": [
      "Nathan Buskulic",
      "Luca Calatroni",
      "Lorenzo Rosasco",
      "Silvia Villa"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23405v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23405v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.23400v1",
    "title": "Beyond-Diagonal Reconfigurable Intelligent Surfaces for 6G Networks: Principles, Challenges, and Quantum Horizons",
    "summary": "A beyond-diagonal reconfigurable intelligent surface (BD-RIS) is an innovative type of reconfigurable intelligent surface (RIS) that has recently been proposed and is considered a revolutionary advancement in wave manipulation. Unlike the mutually disconnected arrangement of elements in traditional RISs, BD-RIS creates cost-effective and simple inter-element connections, allowing for greater freedom in configuring the amplitude and phase of impinging waves. However, there are numerous underlying challenges in realizing the advantages associated with BD-RIS, prompting the research community to actively investigate cutting-edge schemes and algorithms in this direction. Particularly, the passive beamforming design for BD-RIS under specific environmental conditions has become a major focus in this research area. In this article, we provide a systematic introduction to BD-RIS, elaborating on its functional principles concerning architectural design, promising advantages, and classification. Subsequently, we present recent advances and identify a series of challenges and opportunities. Additionally, we consider a specific case study where beamforming is designed using four different algorithms, and we analyze their performance with respect to sum rate and computation cost. To augment the beamforming capabilities in 6G BD-RIS with quantum enhancement, we analyze various hybrid quantum-classical machine learning (ML) models to improve beam prediction performance, employing real-world communication Scenario 8 from the DeepSense 6G dataset. Consequently, we derive useful insights about the practical implications of BD-RIS.",
    "authors": [
      "Abd Ullah Khan",
      "Uman Khalid",
      "Muhammad Tanveer",
      "Trung Q. Duong",
      "Hyundong Shin"
    ],
    "categories": [
      "cs.SI",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23400v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23400v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.23369v1",
    "title": "MGCA-Net: Multi-Graph Contextual Attention Network for Two-View Correspondence Learning",
    "summary": "Two-view correspondence learning is a key task in computer vision, which aims to establish reliable matching relationships for applications such as camera pose estimation and 3D reconstruction. However, existing methods have limitations in local geometric modeling and cross-stage information optimization, which make it difficult to accurately capture the geometric constraints of matched pairs and thus reduce the robustness of the model. To address these challenges, we propose a Multi-Graph Contextual Attention Network (MGCA-Net), which consists of a Contextual Geometric Attention (CGA) module and a Cross-Stage Multi-Graph Consensus (CSMGC) module. Specifically, CGA dynamically integrates spatial position and feature information via an adaptive attention mechanism and enhances the capability to capture both local and global geometric relationships. Meanwhile, CSMGC establishes geometric consensus via a cross-stage sparse graph network, ensuring the consistency of geometric information across different stages. Experimental results on two representative YFCC100M and SUN3D datasets show that MGCA-Net significantly outperforms existing SOTA methods in the outlier rejection and camera pose estimation tasks. Source code is available at http://www.linshuyuan.com.",
    "authors": [
      "Shuyuan Lin",
      "Mengtin Lo",
      "Haosheng Chen",
      "Yanjie Liang",
      "Qiangqiang Wu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23369v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23369v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.23365v1",
    "title": "SpatialMosaic: A Multiview VLM Dataset for Partial Visibility",
    "summary": "The rapid progress of Multimodal Large Language Models (MLLMs) has unlocked the potential for enhanced 3D scene understanding and spatial reasoning. However, existing approaches often rely on pre-constructed 3D representations or off-the-shelf reconstruction pipelines, which constrain scalability and real-world applicability. A recent line of work explores learning spatial reasoning directly from multi-view images, enabling Vision-Language Models (VLMs) to understand 3D scenes without explicit 3D reconstructions. Nevertheless, key challenges that frequently arise in real-world environments, such as partial visibility, occlusion, and low-overlap conditions that require spatial reasoning from fragmented visual cues, remain under-explored. To address these limitations, we propose a scalable multi-view data generation and annotation pipeline that constructs realistic spatial reasoning QAs, resulting in SpatialMosaic, a comprehensive instruction-tuning dataset featuring 2M QA pairs. We further introduce SpatialMosaic-Bench, a challenging benchmark for evaluating multi-view spatial reasoning under realistic and challenging scenarios, consisting of 1M QA pairs across 6 tasks. In addition, we present SpatialMosaicVLM, a hybrid framework that integrates 3D reconstruction models as geometry encoders within VLMs for robust spatial reasoning. Extensive experiments demonstrate that our proposed dataset and VQA tasks effectively enhance spatial reasoning under challenging multi-view conditions, validating the effectiveness of our data generation pipeline in constructing realistic and diverse QA pairs. Code and dataset will be available soon.",
    "authors": [
      "Kanghee Lee",
      "Injae Lee",
      "Minseok Kwak",
      "Kwonyoung Ryu",
      "Jungi Hong",
      "Jaesik Park"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23365v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23365v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.23624v1",
    "title": "Physics-Informed Neural Networks for Device and Circuit Modeling: A Case Study of NeuroSPICE",
    "summary": "We present NeuroSPICE, a physics-informed neural network (PINN) framework for device and circuit simulation. Unlike conventional SPICE, which relies on time-discretized numerical solvers, NeuroSPICE leverages PINNs to solve circuit differential-algebraic equations (DAEs) by minimizing the residual of the equations through backpropagation. It models device and circuit waveforms using analytical equations in time domain with exact temporal derivatives. While PINNs do not outperform SPICE in speed or accuracy during training, they offer unique advantages such as surrogate models for design optimization and inverse problems. NeuroSPICE's flexibility enables the simulation of emerging devices, including highly nonlinear systems such as ferroelectric memories.",
    "authors": [
      "Chien-Ting Tung",
      "Chenming Hu"
    ],
    "categories": [
      "cs.AI",
      "physics.app-ph"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23624v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23624v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.23524v1",
    "title": "Trustworthy Machine Learning under Distribution Shifts",
    "summary": "Machine Learning (ML) has been a foundational topic in artificial intelligence (AI), providing both theoretical groundwork and practical tools for its exciting advancements. From ResNet for visual recognition to Transformer for vision-language alignment, the AI models have achieved superior capability to humans. Furthermore, the scaling law has enabled AI to initially develop general intelligence, as demonstrated by Large Language Models (LLMs). To this stage, AI has had an enormous influence on society and yet still keeps shaping the future for humanity. However, distribution shift remains a persistent ``Achilles' heel'', fundamentally limiting the reliability and general usefulness of ML systems. Moreover, generalization under distribution shift would also cause trust issues for AIs. Motivated by these challenges, my research focuses on \\textit{Trustworthy Machine Learning under Distribution Shifts}, with the goal of expanding AI's robustness, versatility, as well as its responsibility and reliability. We carefully study the three common distribution shifts into: (1) Perturbation Shift, (2) Domain Shift, and (3) Modality Shift. For all scenarios, we also rigorously investigate trustworthiness via three aspects: (1) Robustness, (2) Explainability, and (3) Adaptability. Based on these dimensions, we propose effective solutions and fundamental insights, meanwhile aiming to enhance the critical ML problems, such as efficiency, adaptability, and safety.",
    "authors": [
      "Zhuo Huang"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23524v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23524v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.23487v1",
    "title": "ML Compass: Navigating Capability, Cost, and Compliance Trade-offs in AI Model Deployment",
    "summary": "We study how organizations should select among competing AI models when user utility, deployment costs, and compliance requirements jointly matter. Widely used capability leaderboards do not translate directly into deployment decisions, creating a capability -- deployment gap; to bridge it, we take a systems-level view in which model choice is tied to application outcomes, operating constraints, and a capability-cost frontier. We develop ML Compass, a framework that treats model selection as constrained optimization over this frontier. On the theory side, we characterize optimal model configurations under a parametric frontier and show a three-regime structure in optimal internal measures: some dimensions are pinned at compliance minima, some saturate at maximum levels, and the remainder take interior values governed by frontier curvature. We derive comparative statics that quantify how budget changes, regulatory tightening, and technological progress propagate across capability dimensions and costs. On the implementation side, we propose a pipeline that (i) extracts low-dimensional internal measures from heterogeneous model descriptors, (ii) estimates an empirical frontier from capability and cost data, (iii) learns a user- or task-specific utility function from interaction outcome data, and (iv) uses these components to target capability-cost profiles and recommend models. We validate ML Compass with two case studies: a general-purpose conversational setting using the PRISM Alignment dataset and a healthcare setting using a custom dataset we build using HealthBench. In both environments, our framework produces recommendations -- and deployment-aware leaderboards based on predicted deployment value under constraints -- that can differ materially from capability-only rankings, and clarifies how trade-offs between capability, cost, and safety shape optimal model choice.",
    "authors": [
      "Vassilis Digalakis",
      "Ramayya Krishnan",
      "Gonzalo Martin Fernandez",
      "Agni Orfanoudaki"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23487v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23487v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.23483v1",
    "title": "TV-RAG: A Temporal-aware and Semantic Entropy-Weighted Framework for Long Video Retrieval and Understanding",
    "summary": "Large Video Language Models (LVLMs) have rapidly emerged as the focus of multimedia AI research. Nonetheless, when confronted with lengthy videos, these models struggle: their temporal windows are narrow, and they fail to notice fine-grained semantic shifts that unfold over extended durations. Moreover, mainstream text-based retrieval pipelines, which rely chiefly on surface-level lexical overlap, ignore the rich temporal interdependence among visual, audio, and subtitle channels. To mitigate these limitations, we propose TV-RAG, a training-free architecture that couples temporal alignment with entropy-guided semantics to improve long-video reasoning. The framework contributes two main mechanisms: \\emph{(i)} a time-decay retrieval module that injects explicit temporal offsets into the similarity computation, thereby ranking text queries according to their true multimedia context; and \\emph{(ii)} an entropy-weighted key-frame sampler that selects evenly spaced, information-dense frames, reducing redundancy while preserving representativeness. By weaving these temporal and semantic signals together, TV-RAG realises a dual-level reasoning routine that can be grafted onto any LVLM without re-training or fine-tuning. The resulting system offers a lightweight, budget-friendly upgrade path and consistently surpasses most leading baselines across established long-video benchmarks such as Video-MME, MLVU, and LongVideoBench, confirming the effectiveness of our model. The code can be found at https://github.com/AI-Researcher-Team/TV-RAG.",
    "authors": [
      "Zongsheng Cao",
      "Yangfan He",
      "Anran Liu",
      "Feng Chen",
      "Zepeng Wang",
      "Jun Xie"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23483v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23483v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.23408v1",
    "title": "Probabilistic Modelling is Sufficient for Causal Inference",
    "summary": "Causal inference is a key research area in machine learning, yet confusion reigns over the tools needed to tackle it. There are prevalent claims in the machine learning literature that you need a bespoke causal framework or notation to answer causal questions. In this paper, we want to make it clear that you \\emph{can} answer any causal inference question within the realm of probabilistic modelling and inference, without causal-specific tools or notation. Through concrete examples, we demonstrate how causal questions can be tackled by writing down the probability of everything. Lastly, we reinterpret causal tools as emerging from standard probabilistic modelling and inference, elucidating their necessity and utility.",
    "authors": [
      "Bruno Mlodozeniec",
      "David Krueger",
      "Richard E. Turner"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23408v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23408v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.23351v1",
    "title": "CountGD++: Generalized Prompting for Open-World Counting",
    "summary": "The flexibility and accuracy of methods for automatically counting objects in images and videos are limited by the way the object can be specified. While existing methods allow users to describe the target object with text and visual examples, the visual examples must be manually annotated inside the image, and there is no way to specify what not to count. To address these gaps, we introduce novel capabilities that expand how the target object can be specified. Specifically, we extend the prompt to enable what not to count to be described with text and/or visual examples, introduce the concept of `pseudo-exemplars' that automate the annotation of visual examples at inference, and extend counting models to accept visual examples from both natural and synthetic external images. We also use our new counting model, CountGD++, as a vision expert agent for an LLM. Together, these contributions expand the prompt flexibility of multi-modal open-world counting and lead to significant improvements in accuracy, efficiency, and generalization across multiple datasets. Code is available at https://github.com/niki-amini-naieni/CountGDPlusPlus.",
    "authors": [
      "Niki Amini-Naieni",
      "Andrew Zisserman"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23351v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23351v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.23295v1",
    "title": "Spectral Analysis of Hard-Constraint PINNs: The Spatial Modulation Mechanism of Boundary Functions",
    "summary": "Physics-Informed Neural Networks with hard constraints (HC-PINNs) are increasingly favored for their ability to strictly enforce boundary conditions via a trial function ansatz $\\tilde{u} = A + B \\cdot N$, yet the theoretical mechanisms governing their training dynamics have remained unexplored.   Unlike soft-constrained formulations where boundary terms act as additive penalties, this work reveals that the boundary function $B$ introduces a multiplicative spatial modulation that fundamentally alters the learning landscape.   A rigorous Neural Tangent Kernel (NTK) framework for HC-PINNs is established, deriving the explicit kernel composition law.   This relationship demonstrates that the boundary function $B(\\vec{x})$ functions as a spectral filter, reshaping the eigenspectrum of the neural network's native kernel.   Through spectral analysis, the effective rank of the residual kernel is identified as a deterministic predictor of training convergence, superior to classical condition numbers.   It is shown that widely used boundary functions can inadvertently induce spectral collapse, leading to optimization stagnation despite exact boundary satisfaction.   Validated across multi-dimensional benchmarks, this framework transforms the design of boundary functions from a heuristic choice into a principled spectral optimization problem, providing a solid theoretical foundation for geometric hard constraints in scientific machine learning.",
    "authors": [
      "Yuchen Xie",
      "Honghang Chi",
      "Haopeng Quan",
      "Yahui Wang",
      "Wei Wang",
      "Yu Ma"
    ],
    "categories": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23295v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23295v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.23284v1",
    "title": "Revealing design archetypes and flexibility in e-molecule import pathways using Modeling to Generate Alternatives and interpretable machine learning",
    "summary": "Given the central role of green e-molecule imports in the European energy transition, many studies optimize import pathways and identify a single cost-optimal solution. However, cost optimality is fragile, as real-world implementation depends on regulatory, spatial, and stakeholder constraints that are difficult to represent in optimization models and can render cost-optimal designs infeasible. To address this limitation, we generate a diverse set of near-cost-optimal alternatives within an acceptable cost margin using Modeling to Generate Alternatives, accounting for unmodeled uncertainties. Interpretable machine learning is then applied to extract insights from the resulting solution space. The approach is applied to hydrogen import pathways considering hydrogen, ammonia, methane, and methanol as carriers. Results reveal a broad near-optimal space with great flexibility: solar, wind, and storage are not strictly required to remain within 10% of the cost optimum. Wind constraints favor solar-storage methanol pathways, while limited storage favors wind-based ammonia or methane pathways.",
    "authors": [
      "Mahdi Kchaou",
      "Francesco Contino",
      "Diederik Coppitters"
    ],
    "categories": [
      "eess.SY",
      "cs.LG",
      "math.OC"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23284v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23284v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.23144v1",
    "title": "An Inference-Based Architecture for Intent and Affordance Saturation in Decision-Making",
    "summary": "Decision paralysis, i.e. hesitation, freezing, or failure to act despite full knowledge and motivation, poses a challenge for choice models that assume options are already specified and readily comparable. Drawing on qualitative reports in autism research that are especially salient, we propose a computational account in which paralysis arises from convergence failure in a hierarchical decision process. We separate intent selection (what to pursue) from affordance selection (how to pursue the goal) and formalize commitment as inference under a mixture of reverse- and forward-Kullback-Leibler (KL) objectives. Reverse KL is mode-seeking and promotes rapid commitment, whereas forward KL is mode-covering and preserves multiple plausible goals or actions. In static and dynamic (drift-diffusion) models, forward-KL-biased inference yields slow, heavy-tailed response times and two distinct failure modes, intent saturation and affordance saturation, when values are similar. Simulations in multi-option tasks reproduce key features of decision inertia and shutdown, treating autism as an extreme regime of a general, inference-based, decision-making continuum.",
    "authors": [
      "Wendyam Eric Lionel Ilboudo",
      "Saori C Tanaka"
    ],
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23144v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23144v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.23694v1",
    "title": "Bellman Calibration for V-Learning in Offline Reinforcement Learning",
    "summary": "We introduce Iterated Bellman Calibration, a simple, model-agnostic, post-hoc procedure for calibrating off-policy value predictions in infinite-horizon Markov decision processes. Bellman calibration requires that states with similar predicted long-term returns exhibit one-step returns consistent with the Bellman equation under the target policy. We adapt classical histogram and isotonic calibration to the dynamic, counterfactual setting by repeatedly regressing fitted Bellman targets onto a model's predictions, using a doubly robust pseudo-outcome to handle off-policy data. This yields a one-dimensional fitted value iteration scheme that can be applied to any value estimator. Our analysis provides finite-sample guarantees for both calibration and prediction under weak assumptions, and critically, without requiring Bellman completeness or realizability.",
    "authors": [
      "Lars van der Laan",
      "Nathan Kallus"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "econ.EM"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23694v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23694v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.23686v1",
    "title": "PROFASR-BENCH: A Benchmark for Context-Conditioned ASR in High-Stakes Professional Speech",
    "summary": "Automatic Speech Recognition (ASR) in professional settings faces challenges that existing benchmarks underplay: dense domain terminology, formal register variation, and near-zero tolerance for critical entity errors. We present ProfASR-Bench, a professional-talk evaluation suite for high-stakes applications across finance, medicine, legal, and technology. Each example pairs a natural-language prompt (domain cue and/or speaker profile) with an entity-rich target utterance, enabling controlled measurement of context-conditioned recognition. The corpus supports conventional ASR metrics alongside entity-aware scores and slice-wise reporting by accent and gender. Using representative families Whisper (encoder-decoder ASR) and Qwen-Omni (audio language models) under matched no-context, profile, domain+profile, oracle, and adversarial conditions, we find a consistent pattern: lightweight textual context produces little to no change in average word error rate (WER), even with oracle prompts, and adversarial prompts do not reliably degrade performance. We term this the context-utilization gap (CUG): current systems are nominally promptable yet underuse readily available side information. ProfASR-Bench provides a standardized context ladder, entity- and slice-aware reporting with confidence intervals, and a reproducible testbed for comparing fusion strategies across model families.   Dataset: https://huggingface.co/datasets/prdeepakbabu/ProfASR-Bench   Code: https://github.com/prdeepakbabu/ProfASR-Bench",
    "authors": [
      "Deepak Babu Piskala"
    ],
    "categories": [
      "cs.CL",
      "cs.SD"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23686v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23686v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.23684v1",
    "title": "Multilingual Hidden Prompt Injection Attacks on LLM-Based Academic Reviewing",
    "summary": "Large language models (LLMs) are increasingly considered for use in high-impact workflows, including academic peer review. However, LLMs are vulnerable to document-level hidden prompt injection attacks. In this work, we construct a dataset of approximately 500 real academic papers accepted to ICML and evaluate the effect of embedding hidden adversarial prompts within these documents. Each paper is injected with semantically equivalent instructions in four different languages and reviewed using an LLM. We find that prompt injection induces substantial changes in review scores and accept/reject decisions for English, Japanese, and Chinese injections, while Arabic injections produce little to no effect. These results highlight the susceptibility of LLM-based reviewing systems to document-level prompt injection and reveal notable differences in vulnerability across languages.",
    "authors": [
      "Panagiotis Theocharopoulos",
      "Ajinkya Kulkarni",
      "Mathew Magimai. -Doss"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23684v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23684v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.23659v1",
    "title": "Less is more: Probabilistic reduction is best explained by small-scale predictability measures",
    "summary": "The primary research questions of this paper center on defining the amount of context that is necessary and/or appropriate when investigating the relationship between language model probabilities and cognitive phenomena. We investigate whether whole utterances are necessary to observe probabilistic reduction and demonstrate that n-gram representations suffice as cognitive units of planning.",
    "authors": [
      "Cassandra L. Jacobs",
      "Andrés Buxó-Lugo",
      "Anna K. Taylor",
      "Marie Leopold-Hooke"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23659v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23659v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.23647v1",
    "title": "Nested Browser-Use Learning for Agentic Information Seeking",
    "summary": "Information-seeking (IS) agents have achieved strong performance across a range of wide and deep search tasks, yet their tool use remains largely restricted to API-level snippet retrieval and URL-based page fetching, limiting access to the richer information available through real browsing. While full browser interaction could unlock deeper capabilities, its fine-grained control and verbose page content returns introduce substantial complexity for ReAct-style function-calling agents. To bridge this gap, we propose Nested Browser-Use Learning (NestBrowse), which introduces a minimal and complete browser-action framework that decouples interaction control from page exploration through a nested structure. This design simplifies agentic reasoning while enabling effective deep-web information acquisition. Empirical results on challenging deep IS benchmarks demonstrate that NestBrowse offers clear benefits in practice. Further in-depth analyses underscore its efficiency and flexibility.",
    "authors": [
      "Baixuan Li",
      "Jialong Wu",
      "Wenbiao Yin",
      "Kuan Li",
      "Zhongwang Zhang",
      "Huifeng Yin",
      "Zhengwei Tao",
      "Liwen Zhang",
      "Pengjun Xie",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.MA"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23647v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23647v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.23578v1",
    "title": "Style Amnesia: Investigating Speaking Style Degradation and Mitigation in Multi-Turn Spoken Language Models",
    "summary": "In this paper, we show that when spoken language models (SLMs) are instructed to speak in a specific speaking style at the beginning of a multi-turn conversation, they cannot maintain the required speaking styles after several turns of interaction; we refer to this as the style amnesia of SLMs. We focus on paralinguistic speaking styles, including emotion, accent, volume, and speaking speed. We evaluate three proprietary and two open-source SLMs, demonstrating that none of these models can maintain a consistent speaking style when instructed to do so. We further show that when SLMs are asked to recall the style instruction in later turns, they can recall the style instruction, but they fail to express it throughout the conversation. We also show that explicitly asking the model to recall the style instruction can partially mitigate style amnesia. In addition, we examine various prompting strategies and find that SLMs struggle to follow the required style when the instruction is placed in system messages rather than user messages, which contradicts the intended function of system prompts.",
    "authors": [
      "Yu-Xiang Lin",
      "Cheng-Han Chiang",
      "Hung-yi Lee"
    ],
    "categories": [
      "cs.CL",
      "cs.SD"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23578v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23578v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.23508v1",
    "title": "Why AI Safety Requires Uncertainty, Incomplete Preferences, and Non-Archimedean Utilities",
    "summary": "How can we ensure that AI systems are aligned with human values and remain safe? We can study this problem through the frameworks of the AI assistance and the AI shutdown games. The AI assistance problem concerns designing an AI agent that helps a human to maximise their utility function(s). However, only the human knows these function(s); the AI assistant must learn them. The shutdown problem instead concerns designing AI agents that: shut down when a shutdown button is pressed; neither try to prevent nor cause the pressing of the shutdown button; and otherwise accomplish their task competently. In this paper, we show that addressing these challenges requires AI agents that can reason under uncertainty and handle both incomplete and non-Archimedean preferences.",
    "authors": [
      "Alessio Benavoli",
      "Alessandro Facchini",
      "Marco Zaffalon"
    ],
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23508v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23508v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.23474v1",
    "title": "Deep classifier kriging for probabilistic spatial prediction of air quality index",
    "summary": "Accurate spatial interpolation of the air quality index (AQI), computed from concentrations of multiple air pollutants, is essential for regulatory decision-making, yet AQI fields are inherently non-Gaussian and often exhibit complex nonlinear spatial structure. Classical spatial prediction methods such as kriging are linear and rely on Gaussian assumptions, which limits their ability to capture these features and to provide reliable predictive distributions. In this study, we propose \\textit{deep classifier kriging} (DCK), a flexible, distribution-free deep learning framework for estimating full predictive distribution functions for univariate and bivariate spatial processes, together with a \\textit{data fusion} mechanism that enables modeling of non-collocated bivariate processes and integration of heterogeneous air pollution data sources. Through extensive simulation experiments, we show that DCK consistently outperforms conventional approaches in predictive accuracy and uncertainty quantification. We further apply DCK to probabilistic spatial prediction of AQI by fusing sparse but high-quality station observations with spatially continuous yet biased auxiliary model outputs, yielding spatially resolved predictive distributions that support downstream tasks such as exceedance and extreme-event probability estimation for regulatory risk assessment and policy formulation.",
    "authors": [
      "Junyu Chen",
      "Pratik Nag",
      "Huixia Judy-Wang",
      "Ying Sun"
    ],
    "categories": [
      "stat.ME",
      "stat.ML"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23474v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23474v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.23429v1",
    "title": "The Effect of Gender Diversity on Scientific Team Impact: A Team Roles Perspective",
    "summary": "The influence of gender diversity on the success of scientific teams is of great interest to academia. However, prior findings remain inconsistent, and most studies operationalize diversity in aggregate terms, overlooking internal role differentiation. This limitation obscures a more nuanced understanding of how gender diversity shapes team impact. In particular, the effect of gender diversity across different team roles remains poorly understood. To this end, we define a scientific team as all coauthors of a paper and measure team impact through five-year citation counts. Using author contribution statements, we classified members into leadership and support roles. Drawing on more than 130,000 papers from PLOS journals, most of which are in biomedical-related disciplines, we employed multivariable regression to examine the association between gender diversity in these roles and team impact. Furthermore, we apply a threshold regression model to investigate how team size moderates this relationship. The results show that (1) the relationship between gender diversity and team impact follows an inverted U-shape for both leadership and support groups; (2) teams with an all-female leadership group and an all-male support group achieve higher impact than other team types. Interestingly, (3) the effect of leadership-group gender diversity is significantly negative for small teams but becomes positive and statistically insignificant in large teams. In contrast, the estimates for support-group gender diversity remain significant and positive, regardless of team size.",
    "authors": [
      "Yi Zhao",
      "Yongjun Zhu",
      "Donghun Kim",
      "Yuzhuo Wang",
      "Heng Zhang",
      "Chao Lu",
      "Chengzhi Zhang"
    ],
    "categories": [
      "cs.CL",
      "cs.CY",
      "cs.DL"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23429v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23429v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.23348v1",
    "title": "Persistent Homology via Finite Topological Spaces",
    "summary": "We propose a functorial framework for persistent homology based on finite topological spaces and their associated posets. Starting from a finite metric space, we associate a filtration of finite topologies whose structure maps are continuous identity maps. By passing functorially to posets and to simplicial complexes via crosscut constructions, we obtain persistence modules without requiring inclusion relations between the resulting complexes. We show that standard poset-level simplifications preserve persistent invariants and prove stability of the resulting persistence diagrams under perturbations of the input metric in a density-based instantiation.",
    "authors": [
      "Selçuk Kayacan"
    ],
    "categories": [
      "math.AT",
      "cs.CG",
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23348v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23348v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.23265v1",
    "title": "On the Inverse Flow Matching Problem in the One-Dimensional and Gaussian Cases",
    "summary": "This paper studies the inverse problem of flow matching (FM) between distributions with finite exponential moment, a problem motivated by modern generative AI applications such as the distillation of flow matching models. Uniqueness of the solution is established in two cases - the one-dimensional setting and the Gaussian case. The general multidimensional problem remains open for future studies.",
    "authors": [
      "Alexander Korotin",
      "Gudmund Pammer"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23265v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23265v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.23667v1",
    "title": "IDT: A Physically Grounded Transformer for Feed-Forward Multi-View Intrinsic Decomposition",
    "summary": "Intrinsic image decomposition is fundamental for visual understanding, as RGB images entangle material properties, illumination, and view-dependent effects. Recent diffusion-based methods have achieved strong results for single-view intrinsic decomposition; however, extending these approaches to multi-view settings remains challenging, often leading to severe view inconsistency. We propose \\textbf{Intrinsic Decomposition Transformer (IDT)}, a feed-forward framework for multi-view intrinsic image decomposition. By leveraging transformer-based attention to jointly reason over multiple input images, IDT produces view-consistent intrinsic factors in a single forward pass, without iterative generative sampling. IDT adopts a physically grounded image formation model that explicitly decomposes images into diffuse reflectance, diffuse shading, and specular shading. This structured factorization separates Lambertian and non-Lambertian light transport, enabling interpretable and controllable decomposition of material and illumination effects across views. Experiments on both synthetic and real-world datasets demonstrate that IDT achieves cleaner diffuse reflectance, more coherent diffuse shading, and better-isolated specular components, while substantially improving multi-view consistency compared to prior intrinsic decomposition methods.",
    "authors": [
      "Kang Du",
      "Yirui Guan",
      "Zeyu Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23667v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23667v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2512.23374v1",
    "title": "NeXT-IMDL: Build Benchmark for NeXT-Generation Image Manipulation Detection & Localization",
    "summary": "The accessibility surge and abuse risks of user-friendly image editing models have created an urgent need for generalizable, up-to-date methods for Image Manipulation Detection and Localization (IMDL). Current IMDL research typically uses cross-dataset evaluation, where models trained on one benchmark are tested on others. However, this simplified evaluation approach conceals the fragility of existing methods when handling diverse AI-generated content, leading to misleading impressions of progress. This paper challenges this illusion by proposing NeXT-IMDL, a large-scale diagnostic benchmark designed not just to collect data, but to probe the generalization boundaries of current detectors systematically. Specifically, NeXT-IMDL categorizes AIGC-based manipulations along four fundamental axes: editing models, manipulation types, content semantics, and forgery granularity. Built upon this, NeXT-IMDL implements five rigorous cross-dimension evaluation protocols. Our extensive experiments on 11 representative models reveal a critical insight: while these models perform well in their original settings, they exhibit systemic failures and significant performance degradation when evaluated under our designed protocols that simulate real-world, various generalization scenarios. By providing this diagnostic toolkit and the new findings, we aim to advance the development towards building truly robust, next-generation IMDL models.",
    "authors": [
      "Yifei Li",
      "Haoyuan He",
      "Yu Zheng",
      "Bingyao Yu",
      "Wenzhao Zheng",
      "Lei Chen",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23374v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23374v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2512.23215v1",
    "title": "AVOID: The Adverse Visual Conditions Dataset with Obstacles for Driving Scene Understanding",
    "summary": "Understanding road scenes for visual perception remains crucial for intelligent self-driving cars. In particular, it is desirable to detect unexpected small road hazards reliably in real-time, especially under varying adverse conditions (e.g., weather and daylight). However, existing road driving datasets provide large-scale images acquired in either normal or adverse scenarios only, and often do not contain the road obstacles captured in the same visual domain as for the other classes. To address this, we introduce a new dataset called AVOID, the Adverse Visual Conditions Dataset, for real-time obstacle detection collected in a simulated environment. AVOID consists of a large set of unexpected road obstacles located along each path captured under various weather and time conditions. Each image is coupled with the corresponding semantic and depth maps, raw and semantic LiDAR data, and waypoints, thereby supporting most visual perception tasks. We benchmark the results on high-performing real-time networks for the obstacle detection task, and also propose and conduct ablation studies using a comprehensive multi-task network for semantic segmentation, depth and waypoint prediction tasks.",
    "authors": [
      "Jongoh Jeong",
      "Taek-Jin Song",
      "Jong-Hwan Kim",
      "Kuk-Jin Yoon"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23215v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23215v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2512.23519v1",
    "title": "IdentityStory: Taming Your Identity-Preserving Generator for Human-Centric Story Generation",
    "summary": "Recent visual generative models enable story generation with consistent characters from text, but human-centric story generation faces additional challenges, such as maintaining detailed and diverse human face consistency and coordinating multiple characters across different images. This paper presents IdentityStory, a framework for human-centric story generation that ensures consistent character identity across multiple sequential images. By taming identity-preserving generators, the framework features two key components: Iterative Identity Discovery, which extracts cohesive character identities, and Re-denoising Identity Injection, which re-denoises images to inject identities while preserving desired context. Experiments on the ConsiStory-Human benchmark demonstrate that IdentityStory outperforms existing methods, particularly in face consistency, and supports multi-character combinations. The framework also shows strong potential for applications such as infinite-length story generation and dynamic character composition.",
    "authors": [
      "Donghao Zhou",
      "Jingyu Lin",
      "Guibao Shen",
      "Quande Liu",
      "Jialin Gao",
      "Lihao Liu",
      "Lan Du",
      "Cunjian Chen",
      "Chi-Wing Fu",
      "Xiaowei Hu",
      "Pheng-Ann Heng"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23519v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23519v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2512.23426v1",
    "title": "Direct Diffusion Score Preference Optimization via Stepwise Contrastive Policy-Pair Supervision",
    "summary": "Diffusion models have achieved impressive results in generative tasks such as text-to-image synthesis, yet they often struggle to fully align outputs with nuanced user intent and maintain consistent aesthetic quality. Existing preference-based training methods like Diffusion Direct Preference Optimization help address these issues but rely on costly and potentially noisy human-labeled datasets. In this work, we introduce Direct Diffusion Score Preference Optimization (DDSPO), which directly derives per-timestep supervision from winning and losing policies when such policies are available. Unlike prior methods that operate solely on final samples, DDSPO provides dense, transition-level signals across the denoising trajectory. In practice, we avoid reliance on labeled data by automatically generating preference signals using a pretrained reference model: we contrast its outputs when conditioned on original prompts versus semantically degraded variants. This practical strategy enables effective score-space preference supervision without explicit reward modeling or manual annotations. Empirical results demonstrate that DDSPO improves text-image alignment and visual quality, outperforming or matching existing preference-based methods while requiring significantly less supervision. Our implementation is available at: https://dohyun-as.github.io/DDSPO",
    "authors": [
      "Dohyun Kim",
      "Seungwoo Lyu",
      "Seung Wook Kim",
      "Paul Hongsuck Seo"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23426v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23426v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2512.23333v1",
    "title": "CME-CAD: Heterogeneous Collaborative Multi-Expert Reinforcement Learning for CAD Code Generation",
    "summary": "Computer-Aided Design (CAD) is essential in industrial design, but the complexity of traditional CAD modeling and workflows presents significant challenges for automating the generation of high-precision, editable CAD models. Existing methods that reconstruct 3D models from sketches often produce non-editable and approximate models that fall short of meeting the stringent requirements for precision and editability in industrial design. Moreover, the reliance on text or image-based inputs often requires significant manual annotation, limiting their scalability and applicability in industrial settings. To overcome these challenges, we propose the Heterogeneous Collaborative Multi-Expert Reinforcement Learning (CME-CAD) paradigm, a novel training paradigm for CAD code generation. Our approach integrates the complementary strengths of these models, facilitating collaborative learning and improving the model's ability to generate accurate, constraint-compatible, and fully editable CAD models. We introduce a two-stage training process: Multi-Expert Fine-Tuning (MEFT), and Multi-Expert Reinforcement Learning (MERL). Additionally, we present CADExpert, an open-source benchmark consisting of 17,299 instances, including orthographic projections with precise dimension annotations, expert-generated Chain-of-Thought (CoT) processes, executable CADQuery code, and rendered 3D models.",
    "authors": [
      "Ke Niu",
      "Haiyang Yu",
      "Zhuofan Chen",
      "Zhengtao Yao",
      "Weitao Jia",
      "Xiaodong Ge",
      "Jingqun Tang",
      "Benlei Cui",
      "Bin Li",
      "Xiangyang Xue"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23333v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23333v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2512.23592v1",
    "title": "Same or Not? Enhancing Visual Perception in Vision-Language Models",
    "summary": "Vision-language models (VLMs) excel at broad visual understanding but remain coarse-grained, exhibit visual biases, and miss subtle visual details. Existing training corpora reinforce this limitation by emphasizing general recognition (\"Is it a cat or a dog?\") over fine-grained perception. To address this, we introduce a new training corpus and task designed to enhance the perceptual abilities of VLMs. TWIN is a large-scale dataset of 561,000 image-pair queries that task models to determine whether two visually similar images depict the same object, encouraging attention to nuanced visual cues. The dataset spans a diverse range of everyday objects across contexts, viewpoints, and appearances. Fine-tuning VLMs on TWIN yields notable gains in fine-grained recognition, even on unseen domains such as art, animals, plants, and landmarks. To quantify these gains, we introduce FGVQA, a benchmark suite of 12,000 queries that repurposes fine-grained recognition and retrieval datasets from multiple domains. While existing VLMs struggle on FGVQA, when fine-tuned on TWIN they improve by up to 19.3%, without compromising performance on general VQA benchmarks. Finally, our TWIN dataset scales favorably with object annotations, and our analysis shows that scale is key to performance. We envision TWIN as a drop-in addition to open-source VLM training corpora, advancing perceptual precision of future models. Project webpage: https://glab-caltech.github.io/twin/",
    "authors": [
      "Damiano Marsili",
      "Aditya Mehta",
      "Ryan Y. Lin",
      "Georgia Gkioxari"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23592v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23592v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.49
  },
  {
    "arxiv_id": "2512.23232v1",
    "title": "SURE Guided Posterior Sampling: Trajectory Correction for Diffusion-Based Inverse Problems",
    "summary": "Diffusion models have emerged as powerful learned priors for solving inverse problems. However, current iterative solving approaches which alternate between diffusion sampling and data consistency steps typically require hundreds or thousands of steps to achieve high quality reconstruction due to accumulated errors. We address this challenge with SURE Guided Posterior Sampling (SGPS), a method that corrects sampling trajectory deviations using Stein's Unbiased Risk Estimate (SURE) gradient updates and PCA based noise estimation. By mitigating noise induced errors during the critical early and middle sampling stages, SGPS enables more accurate posterior sampling and reduces error accumulation. This allows our method to maintain high reconstruction quality with fewer than 100 Neural Function Evaluations (NFEs). Our extensive evaluation across diverse inverse problems demonstrates that SGPS consistently outperforms existing methods at low NFE counts.",
    "authors": [
      "Minwoo Kim",
      "Hongki Lim"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23232v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23232v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.49
  },
  {
    "arxiv_id": "2512.23463v1",
    "title": "Deterministic Image-to-Image Translation via Denoising Brownian Bridge Models with Dual Approximators",
    "summary": "Image-to-Image (I2I) translation involves converting an image from one domain to another. Deterministic I2I translation, such as in image super-resolution, extends this concept by guaranteeing that each input generates a consistent and predictable output, closely matching the ground truth (GT) with high fidelity. In this paper, we propose a denoising Brownian bridge model with dual approximators (Dual-approx Bridge), a novel generative model that exploits the Brownian bridge dynamics and two neural network-based approximators (one for forward and one for reverse process) to produce faithful output with negligible variance and high image quality in I2I translations. Our extensive experiments on benchmark datasets including image generation and super-resolution demonstrate the consistent and superior performance of Dual-approx Bridge in terms of image quality and faithfulness to GT when compared to both stochastic and deterministic baselines. Project page and code: https://github.com/bohan95/dual-app-bridge",
    "authors": [
      "Bohan Xiao",
      "Peiyong Wang",
      "Qisheng He",
      "Ming Dong"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23463v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23463v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.48
  },
  {
    "arxiv_id": "2512.23291v1",
    "title": "Multi-Track Multimodal Learning on iMiGUE: Micro-Gesture and Emotion Recognition",
    "summary": "Micro-gesture recognition and behavior-based emotion prediction are both highly challenging tasks that require modeling subtle, fine-grained human behaviors, primarily leveraging video and skeletal pose data. In this work, we present two multimodal frameworks designed to tackle both problems on the iMiGUE dataset. For micro-gesture classification, we explore the complementary strengths of RGB and 3D pose-based representations to capture nuanced spatio-temporal patterns. To comprehensively represent gestures, video, and skeletal embeddings are extracted using MViTv2-S and 2s-AGCN, respectively. Then, they are integrated through a Cross-Modal Token Fusion module to combine spatial and pose information. For emotion recognition, our framework extends to behavior-based emotion prediction, a binary classification task identifying emotional states based on visual cues. We leverage facial and contextual embeddings extracted using SwinFace and MViTv2-S models and fuse them through an InterFusion module designed to capture emotional expressions and body gestures. Experiments conducted on the iMiGUE dataset, within the scope of the MiGA 2025 Challenge, demonstrate the robust performance and accuracy of our method in the behavior-based emotion prediction task, where our approach secured 2nd place.",
    "authors": [
      "Arman Martirosyan",
      "Shahane Tigranyan",
      "Maria Razzhivina",
      "Artak Aslanyan",
      "Nazgul Salikhova",
      "Ilya Makarov",
      "Andrey Savchenko",
      "Aram Avetisyan"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23291v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23291v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.48
  },
  {
    "arxiv_id": "2512.23569v1",
    "title": "Image Denoising Using Global and Local Circulant Representation",
    "summary": "The proliferation of imaging devices and countless image data generated every day impose an increasingly high demand on efficient and effective image denoising. In this paper, we establish a theoretical connection between principal component analysis (PCA) and the Haar transform under circulant representation, and present a computationally simple denoising algorithm. The proposed method, termed Haar-tSVD, exploits a unified tensor singular value decomposition (t-SVD) projection combined with Haar transform to efficiently capture global and local patch correlations. Haar-tSVD operates as a one-step, parallelizable plug-and-play denoiser that eliminates the need for learning local bases, thereby striking a balance between denoising speed and performance. Besides, an adaptive noise estimation scheme is introduced to improve robustness according to eigenvalue analysis of the circulant structure. To further enhance the performance under severe noise conditions, we integrate deep neural networks with Haar-tSVD based on the established Haar-PCA relationship. Experimental results on various denoising datasets demonstrate the efficiency and effectiveness of proposed method for noise removal. Our code is publicly available at https://github.com/ZhaomingKong/Haar-tSVD.",
    "authors": [
      "Zhaoming Kong",
      "Xiaowei Yang",
      "Jiahuan Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23569v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23569v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2512.23142v1",
    "title": "Domain-Shift Immunity in Deep Deformable Registration via Local Feature Representations",
    "summary": "Deep learning has advanced deformable image registration, surpassing traditional optimization-based methods in both accuracy and efficiency. However, learning-based models are widely believed to be sensitive to domain shift, with robustness typically pursued through large and diverse training datasets, without explaining the underlying mechanisms. In this work, we show that domain-shift immunity is an inherent property of deep deformable registration models, arising from their reliance on local feature representations rather than global appearance for deformation estimation. To isolate and validate this mechanism, we introduce UniReg, a universal registration framework that decouples feature extraction from deformation estimation using fixed, pre-trained feature extractors and a UNet-based deformation network. Despite training on a single dataset, UniReg exhibits robust cross-domain and multi-modal performance comparable to optimization-based methods. Our analysis further reveals that failures of conventional CNN-based models under modality shift originate from dataset-induced biases in early convolutional layers. These findings identify local feature consistency as the key driver of robustness in learning-based deformable registration and motivate backbone designs that preserve domain-invariant local features.",
    "authors": [
      "Mingzhen Shao",
      "Sarang Joshi"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23142v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23142v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.46
  },
  {
    "arxiv_id": "2512.23532v1",
    "title": "Iterative Inference-time Scaling with Adaptive Frequency Steering for Image Super-Resolution",
    "summary": "Diffusion models have become a leading paradigm for image super-resolution (SR), but existing methods struggle to guarantee both the high-frequency perceptual quality and the low-frequency structural fidelity of generated images. Although inference-time scaling can theoretically improve this trade-off by allocating more computation, existing strategies remain suboptimal: reward-driven particle optimization often causes perceptual over-smoothing, while optimal-path search tends to lose structural consistency. To overcome these difficulties, we propose Iterative Diffusion Inference-Time Scaling with Adaptive Frequency Steering (IAFS), a training-free framework that jointly leverages iterative refinement and frequency-aware particle fusion. IAFS addresses the challenge of balancing perceptual quality and structural fidelity by progressively refining the generated image through iterative correction of structural deviations. Simultaneously, it ensures effective frequency fusion by adaptively integrating high-frequency perceptual cues with low-frequency structural information, allowing for a more accurate and balanced reconstruction across different image details. Extensive experiments across multiple diffusion-based SR models show that IAFS effectively resolves the perception-fidelity conflict, yielding consistently improved perceptual detail and structural accuracy, and outperforming existing inference-time scaling methods.",
    "authors": [
      "Hexin Zhang",
      "Dong Li",
      "Jie Huang",
      "Bingzhou Wang",
      "Xueyang Fu",
      "Zhengjun Zha"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23532v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23532v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.44
  },
  {
    "arxiv_id": "2512.23318v1",
    "title": "PCR-ORB: Enhanced ORB-SLAM3 with Point Cloud Refinement Using Deep Learning-Based Dynamic Object Filtering",
    "summary": "Visual Simultaneous Localization and Mapping (vSLAM) systems encounter substantial challenges in dynamic environments where moving objects compromise tracking accuracy and map consistency. This paper introduces PCR-ORB (Point Cloud Refinement ORB), an enhanced ORB-SLAM3 framework that integrates deep learning-based point cloud refinement to mitigate dynamic object interference. Our approach employs YOLOv8 for semantic segmentation combined with CUDA-accelerated processing to achieve real-time performance. The system implements a multi-stage filtering strategy encompassing ground plane estimation, sky region removal, edge filtering, and temporal consistency validation. Comprehensive evaluation on the KITTI dataset (sequences 00-09) demonstrates performance characteristics across different environmental conditions and scene types. Notable improvements are observed in specific sequences, with sequence 04 achieving 25.9% improvement in ATE RMSE and 30.4% improvement in ATE median. However, results show mixed performance across sequences, indicating scenario-dependent effectiveness. The implementation provides insights into dynamic object filtering challenges and opportunities for robust navigation in complex environments.",
    "authors": [
      "Sheng-Kai Chen",
      "Jie-Yu Chao",
      "Jr-Yu Chang",
      "Po-Lien Wu",
      "Po-Chiang Lin"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23318v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23318v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.44
  },
  {
    "arxiv_id": "2512.23219v1",
    "title": "MM-UAVBench: How Well Do Multimodal Large Language Models See, Think, and Plan in Low-Altitude UAV Scenarios?",
    "summary": "While Multimodal Large Language Models (MLLMs) have exhibited remarkable general intelligence across diverse domains, their potential in low-altitude applications dominated by Unmanned Aerial Vehicles (UAVs) remains largely underexplored. Existing MLLM benchmarks rarely cover the unique challenges of low-altitude scenarios, while UAV-related evaluations mainly focus on specific tasks such as localization or navigation, without a unified evaluation of MLLMs'general intelligence. To bridge this gap, we present MM-UAVBench, a comprehensive benchmark that systematically evaluates MLLMs across three core capability dimensions-perception, cognition, and planning-in low-altitude UAV scenarios. MM-UAVBench comprises 19 sub-tasks with over 5.7K manually annotated questions, all derived from real-world UAV data collected from public datasets. Extensive experiments on 16 open-source and proprietary MLLMs reveal that current models struggle to adapt to the complex visual and cognitive demands of low-altitude scenarios. Our analyses further uncover critical bottlenecks such as spatial bias and multi-view understanding that hinder the effective deployment of MLLMs in UAV scenarios. We hope MM-UAVBench will foster future research on robust and reliable MLLMs for real-world UAV intelligence.",
    "authors": [
      "Shiqi Dai",
      "Zizhi Ma",
      "Zhicong Luo",
      "Xuesong Yang",
      "Yibin Huang",
      "Wanyue Zhang",
      "Chi Chen",
      "Zonghao Guo",
      "Wang Xu",
      "Yufei Sun",
      "Maosong Sun"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23219v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23219v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.44
  },
  {
    "arxiv_id": "2512.23437v1",
    "title": "RealX3D: A Physically-Degraded 3D Benchmark for Multi-view Visual Restoration and Reconstruction",
    "summary": "We introduce RealX3D, a real-capture benchmark for multi-view visual restoration and 3D reconstruction under diverse physical degradations. RealX3D groups corruptions into four families, including illumination, scattering, occlusion, and blurring, and captures each at multiple severity levels using a unified acquisition protocol that yields pixel-aligned LQ/GT views. Each scene includes high-resolution capture, RAW images, and dense laser scans, from which we derive world-scale meshes and metric depth. Benchmarking a broad range of optimization-based and feed-forward methods shows substantial degradation in reconstruction quality under physical corruptions, underscoring the fragility of current multi-view pipelines in real-world challenging environments.",
    "authors": [
      "Shuhong Liu",
      "Chenyu Bao",
      "Ziteng Cui",
      "Yun Liu",
      "Xuangeng Chu",
      "Lin Gu",
      "Marcos V. Conde",
      "Ryo Umagami",
      "Tomohiro Hashimoto",
      "Zijian Hu",
      "Tianhan Xu",
      "Yuan Gan",
      "Yusuke Kurose",
      "Tatsuya Harada"
    ],
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "published": "2025-12-29",
    "url": "https://arxiv.org/abs/2512.23437v1",
    "pdf_url": "https://arxiv.org/pdf/2512.23437v1.pdf",
    "date": "2025-12-31",
    "source": "arxiv",
    "research_score": 0.42
  }
]