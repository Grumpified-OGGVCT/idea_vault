[
  {
    "arxiv_id": "2511.07343v1",
    "title": "TNT: Improving Chunkwise Training for Test-Time Memorization",
    "summary": "Recurrent neural networks (RNNs) with deep test-time memorization modules, such as Titans and TTT, represent a promising, linearly-scaling paradigm distinct from Transformers. While these expressive models do not yet match the peak performance of state-of-the-art Transformers, their potential has been largely untapped due to prohibitively slow training and low hardware utilization. Existing parallelization methods force a fundamental conflict governed by the chunksize hyperparameter: large chunks boost speed but degrade performance, necessitating a fixed, suboptimal compromise. To solve this challenge, we introduce TNT, a novel training paradigm that decouples training efficiency from inference performance through a two-stage process. Stage one is an efficiency-focused pre-training phase utilizing a hierarchical memory. A global module processes large, hardware-friendly chunks for long-range context, while multiple parallel local modules handle fine-grained details. Crucially, by periodically resetting local memory states, we break sequential dependencies to enable massive context parallelization. Stage two is a brief fine-tuning phase where only the local memory modules are adapted to a smaller, high-resolution chunksize, maximizing accuracy with minimal overhead. Evaluated on Titans and TTT models, TNT achieves a substantial acceleration in training speed-up to 17 times faster than the most accurate baseline configuration - while simultaneously improving model accuracy. This improvement removes a critical scalability barrier, establishing a practical foundation for developing expressive RNNs and facilitating future work to close the performance gap with Transformers.",
    "authors": [
      "Zeman Li",
      "Ali Behrouz",
      "Yuan Deng",
      "Peilin Zhong",
      "Praneeth Kacham",
      "Mahdi Karami",
      "Meisam Razaviyayn",
      "Vahab Mirrokni"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07343v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07343v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.91
  },
  {
    "arxiv_id": "2511.07329v1",
    "title": "Preparation of Fractal-Inspired Computational Architectures for Advanced Large Language Model Analysis",
    "summary": "It introduces FractalNet, a fractal-inspired computational architectures for advanced large language model analysis that mainly challenges model diversity on a large scale in an efficient manner. The new set-up involves a template-driven generator, runner, and evaluation framework that, through systematic permutations of convolutional, normalization, activation, and dropout layers, can create more than 1,200 variants of neural networks. Fractal templates allow for structural recursion and multi-column pathways, thus, models become deeper and wider in a balanced way. Training utilizes PyTorch, Automatic Mixed Precision (AMP), and gradient checkpointing and is carried out on the CIFAR-10 dataset for five epochs. The outcomes show that fractal-based architectures are capable of strong performance and are computationally efficient. The paper positions fractal design as a feasible and resource-efficient method of automated architecture exploration.",
    "authors": [
      "Yash Mittal",
      "Dmitry Ignatov",
      "Radu Timofte"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07329v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07329v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.9
  },
  {
    "arxiv_id": "2511.06424v1",
    "title": "Turbo-DDCM: Fast and Flexible Zero-Shot Diffusion-Based Image Compression",
    "summary": "While zero-shot diffusion-based compression methods have seen significant progress in recent years, they remain notoriously slow and computationally demanding. This paper presents an efficient zero-shot diffusion-based compression method that runs substantially faster than existing methods, while maintaining performance that is on par with the state-of-the-art techniques. Our method builds upon the recently proposed Denoising Diffusion Codebook Models (DDCMs) compression scheme. Specifically, DDCM compresses an image by sequentially choosing the diffusion noise vectors from reproducible random codebooks, guiding the denoiser's output to reconstruct the target image. We modify this framework with Turbo-DDCM, which efficiently combines a large number of noise vectors at each denoising step, thereby significantly reducing the number of required denoising operations. This modification is also coupled with an improved encoding protocol. Furthermore, we introduce two flexible variants of Turbo-DDCM, a priority-aware variant that prioritizes user-specified regions and a distortion-controlled variant that compresses an image based on a target PSNR rather than a target BPP. Comprehensive experiments position Turbo-DDCM as a compelling, practical, and flexible image compression scheme.",
    "authors": [
      "Amit Vaisman",
      "Guy Ohayon",
      "Hila Manor",
      "Michael Elad",
      "Tomer Michaeli"
    ],
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "eess.SP",
      "stat.ML"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06424v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06424v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.89
  },
  {
    "arxiv_id": "2511.06265v1",
    "title": "CAMP-HiVe: Cyclic Pair Merging based Efficient DNN Pruning with Hessian-Vector Approximation for Resource-Constrained Systems",
    "summary": "Deep learning algorithms are becoming an essential component of many artificial intelligence (AI) driven applications, many of which run on resource-constrained and energy-constrained systems. For efficient deployment of these algorithms, although different techniques for the compression of neural network models are proposed, neural pruning is one of the fastest and effective methods, which can provide a high compression gain with minimal cost. To harness enhanced performance gain with respect to model complexity, we propose a novel neural network pruning approach utilizing Hessian-vector products that approximate crucial curvature information in the loss function, which significantly reduces the computation demands. By employing a power iteration method, our algorithm effectively identifies and preserves the essential information, ensuring a balanced trade-off between model accuracy and computational efficiency. Herein, we introduce CAMP-HiVe, a cyclic pair merging-based pruning with Hessian Vector approximation by iteratively consolidating weight pairs, combining significant and less significant weights, thus effectively streamlining the model while preserving its performance. This dynamic, adaptive framework allows for real-time adjustment of weight significance, ensuring that only the most critical parameters are retained. Our experimental results demonstrate that our proposed method achieves significant reductions in computational requirements while maintaining high performance across different neural network architectures, e.g., ResNet18, ResNet56, and MobileNetv2, on standard benchmark datasets, e.g., CIFAR10, CIFAR-100, and ImageNet, and it outperforms the existing state-of-the-art neural pruning methods.",
    "authors": [
      "Mohammad Helal Uddin",
      "Sai Krishna Ghanta",
      "Liam Seymour",
      "Sabur Baidya"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06265v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06265v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.07068v1",
    "title": "ClusterMine: Robust Label-Free Visual Out-Of-Distribution Detection via Concept Mining from Text Corpora",
    "summary": "Large-scale visual out-of-distribution (OOD) detection has witnessed remarkable progress by leveraging vision-language models such as CLIP. However, a significant limitation of current methods is their reliance on a pre-defined set of in-distribution (ID) ground-truth label names (positives). These fixed label names can be unavailable, unreliable at scale, or become less relevant due to in-distribution shifts after deployment. Towards truly unsupervised OOD detection, we utilize widely available text corpora for positive label mining, bypassing the need for positives. In this paper, we utilize widely available text corpora for positive label mining under a general concept mining paradigm. Within this framework, we propose ClusterMine, a novel positive label mining method. ClusterMine is the first method to achieve state-of-the-art OOD detection performance without access to positive labels. It extracts positive concepts from a large text corpus by combining visual-only sample consistency (via clustering) and zero-shot image-text consistency. Our experimental study reveals that ClusterMine is scalable across a plethora of CLIP models and achieves state-of-the-art robustness to covariate in-distribution shifts. The code is available at https://github.com/HHU-MMBS/clustermine_wacv_official.",
    "authors": [
      "Nikolas Adaloglou",
      "Diana Petrusheva",
      "Mohamed Asker",
      "Felix Michels",
      "Markus Kollmann"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07068v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07068v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.06716v1",
    "title": "MirrorMamba: Towards Scalable and Robust Mirror Detection in Videos",
    "summary": "Video mirror detection has received significant research attention, yet existing methods suffer from limited performance and robustness. These approaches often over-rely on single, unreliable dynamic features, and are typically built on CNNs with limited receptive fields or Transformers with quadratic computational complexity. To address these limitations, we propose a new effective and scalable video mirror detection method, called MirrorMamba. Our approach leverages multiple cues to adapt to diverse conditions, incorporating perceived depth, correspondence and optical. We also introduce an innovative Mamba-based Multidirection Correspondence Extractor, which benefits from the global receptive field and linear complexity of the emerging Mamba spatial state model to effectively capture correspondence properties. Additionally, we design a Mamba-based layer-wise boundary enforcement decoder to resolve the unclear boundary caused by the blurred depth map. Notably, this work marks the first successful application of the Mamba-based architecture in the field of mirror detection. Extensive experiments demonstrate that our method outperforms existing state-of-the-art approaches for video mirror detection on the benchmark datasets. Furthermore, on the most challenging and representative image-based mirror detection dataset, our approach achieves state-of-the-art performance, proving its robustness and generalizability.",
    "authors": [
      "Rui Song",
      "Jiaying Lin",
      "Rynson W. H. Lau"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06716v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06716v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.06696v1",
    "title": "Magnitude-Modulated Equivariant Adapter for Parameter-Efficient Fine-Tuning of Equivariant Graph Neural Networks",
    "summary": "Pretrained equivariant graph neural networks based on spherical harmonics offer efficient and accurate alternatives to computationally expensive ab-initio methods, yet adapting them to new tasks and chemical environments still requires fine-tuning. Conventional parameter-efficient fine-tuning (PEFT) techniques, such as Adapters and LoRA, typically break symmetry, making them incompatible with those equivariant architectures. ELoRA, recently proposed, is the first equivariant PEFT method. It achieves improved parameter efficiency and performance on many benchmarks. However, the relatively high degrees of freedom it retains within each tensor order can still perturb pretrained feature distributions and ultimately degrade performance. To address this, we present Magnitude-Modulated Equivariant Adapter (MMEA), a novel equivariant fine-tuning method which employs lightweight scalar gating to modulate feature magnitudes on a per-order and per-multiplicity basis. We demonstrate that MMEA preserves strict equivariance and, across multiple benchmarks, consistently improves energy and force predictions to state-of-the-art levels while training fewer parameters than competing approaches. These results suggest that, in many practical scenarios, modulating channel magnitudes is sufficient to adapt equivariant models to new chemical environments without breaking symmetry, pointing toward a new paradigm for equivariant PEFT design.",
    "authors": [
      "Dian Jin",
      "Yancheng Yuan",
      "Xiaoming Tao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06696v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06696v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.06446v1",
    "title": "SR-KI: Scalable and Real-Time Knowledge Integration into LLMs via Supervised Attention",
    "summary": "This paper proposes SR-KI, a novel approach for integrating real-time and large-scale structured knowledge bases (KBs) into large language models (LLMs). SR-KI begins by encoding KBs into key-value pairs using a pretrained encoder, and injects them into LLMs' KV cache. Building on this representation, we employ a two-stage training paradigm: first locating a dedicated retrieval layer within the LLM, and then applying an attention-based loss at this layer to explicitly supervise attention toward relevant KB entries. Unlike traditional retrieval-augmented generation methods that rely heavily on the performance of external retrievers and multi-stage pipelines, SR-KI supports end-to-end inference by performing retrieval entirely within the models latent space. This design enables efficient compression of injected knowledge and facilitates dynamic knowledge updates. Comprehensive experiments demonstrate that SR-KI enables the integration of up to 40K KBs into a 7B LLM on a single A100 40GB GPU, and achieves strong retrieval performance, maintaining over 98% Recall@10 on the best-performing task and exceeding 88% on average across all tasks. Task performance on question answering and KB ID generation also demonstrates that SR-KI maintains strong performance while achieving up to 99.75% compression of the injected KBs.",
    "authors": [
      "Bohan Yu",
      "Wei Huang",
      "Kang Liu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06446v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06446v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.79
  },
  {
    "arxiv_id": "2511.06237v1",
    "title": "Mixtures of SubExperts for Large Language Continual Learning",
    "summary": "Adapting Large Language Models (LLMs) to a continuous stream of tasks is a critical yet challenging endeavor. While Parameter-Efficient Fine-Tuning (PEFT) methods have become a standard for this, they face a fundamental dilemma in continual learning. Reusing a single set of PEFT parameters for new tasks often leads to catastrophic forgetting of prior knowledge. Conversely, allocating distinct parameters for each task prevents forgetting but results in a linear growth of the model's size and fails to facilitate knowledge transfer between related tasks. To overcome these limitations, we propose a novel adaptive PEFT method referred to as \\textit{Mixtures of SubExperts (MoSEs)}, a novel continual learning framework designed for minimal forgetting and efficient scalability. MoSEs integrate a sparse Mixture of SubExperts into the transformer layers, governed by a task-specific routing mechanism. This architecture allows the model to isolate and protect knowledge within dedicated SubExperts, thereby minimizing parameter interference and catastrophic forgetting. Crucially, the router can adaptively select and combine previously learned sparse parameters for new tasks, enabling effective knowledge transfer while ensuring that the model's capacity grows sublinearly. We evaluate MoSEs on the comprehensive TRACE benchmark datasets. Our experiments demonstrate that MoSEs significantly outperform conventional continual learning approaches in both knowledge retention and scalability to new tasks, achieving state-of-the-art performance with substantial memory and computational savings.",
    "authors": [
      "Haeyong Kang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06237v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06237v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2511.07418v1",
    "title": "Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields",
    "summary": "Despite years of research, real-time diverse grasp synthesis for dexterous hands remains an unsolved core challenge in robotics and computer graphics. We present Lightning Grasp, a novel high-performance procedural grasp synthesis algorithm that achieves orders-of-magnitude speedups over state-of-the-art approaches, while enabling unsupervised grasp generation for irregular, tool-like objects. The method avoids many limitations of prior approaches, such as the need for carefully tuned energy functions and sensitive initialization. This breakthrough is driven by a key insight: decoupling complex geometric computation from the search process via a simple, efficient data structure - the Contact Field. This abstraction collapses the problem complexity, enabling a procedural search at unprecedented speeds. We open-source our system to propel further innovation in robotic manipulation.",
    "authors": [
      "Zhao-Heng Yin",
      "Pieter Abbeel"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.DC",
      "cs.GR"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07418v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07418v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2511.06665v1",
    "title": "Sim4Seg: Boosting Multimodal Multi-disease Medical Diagnosis Segmentation with Region-Aware Vision-Language Similarity Masks",
    "summary": "Despite significant progress in pixel-level medical image analysis, existing medical image segmentation models rarely explore medical segmentation and diagnosis tasks jointly. However, it is crucial for patients that models can provide explainable diagnoses along with medical segmentation results. In this paper, we introduce a medical vision-language task named Medical Diagnosis Segmentation (MDS), which aims to understand clinical queries for medical images and generate the corresponding segmentation masks as well as diagnostic results. To facilitate this task, we first present the Multimodal Multi-disease Medical Diagnosis Segmentation (M3DS) dataset, containing diverse multimodal multi-disease medical images paired with their corresponding segmentation masks and diagnosis chain-of-thought, created via an automated diagnosis chain-of-thought generation pipeline. Moreover, we propose Sim4Seg, a novel framework that improves the performance of diagnosis segmentation by taking advantage of the Region-Aware Vision-Language Similarity to Mask (RVLS2M) module. To improve overall performance, we investigate a test-time scaling strategy for MDS tasks. Experimental results demonstrate that our method outperforms the baselines in both segmentation and diagnosis.",
    "authors": [
      "Lingran Song",
      "Yucheng Zhou",
      "Jianbing Shen"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06665v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06665v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2511.06215v1",
    "title": "Explicit Knowledge-Guided In-Context Learning for Early Detection of Alzheimer's Disease",
    "summary": "Detecting Alzheimer's Disease (AD) from narrative transcripts remains a challenging task for large language models (LLMs), particularly under out-of-distribution (OOD) and data-scarce conditions. While in-context learning (ICL) provides a parameter-efficient alternative to fine-tuning, existing ICL approaches often suffer from task recognition failure, suboptimal demonstration selection, and misalignment between label words and task objectives, issues that are amplified in clinical domains like AD detection. We propose Explicit Knowledge In-Context Learners (EK-ICL), a novel framework that integrates structured explicit knowledge to enhance reasoning stability and task alignment in ICL. EK-ICL incorporates three knowledge components: confidence scores derived from small language models (SLMs) to ground predictions in task-relevant patterns, parsing feature scores to capture structural differences and improve demo selection, and label word replacement to resolve semantic misalignment with LLM priors. In addition, EK-ICL employs a parsing-based retrieval strategy and ensemble prediction to mitigate the effects of semantic homogeneity in AD transcripts. Extensive experiments across three AD datasets demonstrate that EK-ICL significantly outperforms state-of-the-art fine-tuning and ICL baselines. Further analysis reveals that ICL performance in AD detection is highly sensitive to the alignment of label semantics and task-specific context, underscoring the importance of explicit knowledge in clinical reasoning under low-resource conditions.",
    "authors": [
      "Puzhen Su",
      "Yongzhu Miao",
      "Chunxi Guo",
      "Jintao Tang",
      "Shasha Li",
      "Ting Wang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06215v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06215v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.77
  },
  {
    "arxiv_id": "2511.06658v1",
    "title": "Active Learning for Animal Re-Identification with Ambiguity-Aware Sampling",
    "summary": "Animal Re-ID has recently gained substantial attention in the AI research community due to its high impact on biodiversity monitoring and unique research challenges arising from environmental factors. The subtle distinguishing patterns, handling new species and the inherent open-set nature make the problem even harder. To address these complexities, foundation models trained on labeled, large-scale and multi-species animal Re-ID datasets have recently been introduced to enable zero-shot Re-ID. However, our benchmarking reveals significant gaps in their zero-shot Re-ID performance for both known and unknown species. While this highlights the need for collecting labeled data in new domains, exhaustive annotation for Re-ID is laborious and requires domain expertise. Our analyses show that existing unsupervised (USL) and AL Re-ID methods underperform for animal Re-ID. To address these limitations, we introduce a novel AL Re-ID framework that leverages complementary clustering methods to uncover and target structurally ambiguous regions in the embedding space for mining pairs of samples that are both informative and broadly representative. Oracle feedback on these pairs, in the form of must-link and cannot-link constraints, facilitates a simple annotation interface, which naturally integrates with existing USL methods through our proposed constrained clustering refinement algorithm. Through extensive experiments, we demonstrate that, by utilizing only 0.033% of all annotations, our approach consistently outperforms existing foundational, USL and AL baselines. Specifically, we report an average improvement of 10.49%, 11.19% and 3.99% (mAP) on 13 wildlife datasets over foundational, USL and AL methods, respectively, while attaining state-of-the-art performance on each dataset. Furthermore, we also show an improvement of 11.09%, 8.2% and 2.06% for unknown individuals in an open-world setting.",
    "authors": [
      "Depanshu Sani",
      "Mehar Khurana",
      "Saket Anand"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06658v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06658v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2511.06785v1",
    "title": "Resource Efficient Sleep Staging via Multi-Level Masking and Prompt Learning",
    "summary": "Automatic sleep staging plays a vital role in assessing sleep quality and diagnosing sleep disorders. Most existing methods rely heavily on long and continuous EEG recordings, which poses significant challenges for data acquisition in resource-constrained systems, such as wearable or home-based monitoring systems. In this paper, we propose the task of resource-efficient sleep staging, which aims to reduce the amount of signal collected per sleep epoch while maintaining reliable classification performance. To solve this task, we adopt the masking and prompt learning strategy and propose a novel framework called Mask-Aware Sleep Staging (MASS). Specifically, we design a multi-level masking strategy to promote effective feature modeling under partial and irregular observations. To mitigate the loss of contextual information introduced by masking, we further propose a hierarchical prompt learning mechanism that aggregates unmasked data into a global prompt, serving as a semantic anchor for guiding both patch-level and epoch-level feature modeling. MASS is evaluated on four datasets, demonstrating state-of-the-art performance, especially when the amount of data is very limited. This result highlights its potential for efficient and scalable deployment in real-world low-resource sleep monitoring environments.",
    "authors": [
      "Lejun Ai",
      "Yulong Li",
      "Haodong Yi",
      "Jixuan Xie",
      "Yue Wang",
      "Jia Liu",
      "Min Chen",
      "Rui Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06785v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06785v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2511.07379v1",
    "title": "LoReTTA: A Low Resource Framework To Poison Continuous Time Dynamic Graphs",
    "summary": "Temporal Graph Neural Networks (TGNNs) are increasingly used in high-stakes domains, such as financial forecasting, recommendation systems, and fraud detection. However, their susceptibility to poisoning attacks poses a critical security risk. We introduce LoReTTA (Low Resource Two-phase Temporal Attack), a novel adversarial framework on Continuous-Time Dynamic Graphs, which degrades TGNN performance by an average of 29.47% across 4 widely benchmark datasets and 4 State-of-the-Art (SotA) models. LoReTTA operates through a two-stage approach: (1) sparsify the graph by removing high-impact edges using any of the 16 tested temporal importance metrics, (2) strategically replace removed edges with adversarial negatives via LoReTTA's novel degree-preserving negative sampling algorithm. Our plug-and-play design eliminates the need for expensive surrogate models while adhering to realistic unnoticeability constraints. LoReTTA degrades performance by upto 42.0% on MOOC, 31.5% on Wikipedia, 28.8% on UCI, and 15.6% on Enron. LoReTTA outperforms 11 attack baselines, remains undetectable to 4 leading anomaly detection systems, and is robust to 4 SotA adversarial defense training methods, establishing its effectiveness, unnoticeability, and robustness.",
    "authors": [
      "Himanshu Pal",
      "Venkata Sai Pranav Bachina",
      "Ankit Gangwal",
      "Charu Sharma"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07379v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07379v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2511.06836v1",
    "title": "NeuroBridge: Bio-Inspired Self-Supervised EEG-to-Image Decoding via Cognitive Priors and Bidirectional Semantic Alignment",
    "summary": "Visual neural decoding seeks to reconstruct or infer perceived visual stimuli from brain activity patterns, providing critical insights into human cognition and enabling transformative applications in brain-computer interfaces and artificial intelligence. Current approaches, however, remain constrained by the scarcity of high-quality stimulus-brain response pairs and the inherent semantic mismatch between neural representations and visual content. Inspired by perceptual variability and co-adaptive strategy of the biological systems, we propose a novel self-supervised architecture, named NeuroBridge, which integrates Cognitive Prior Augmentation (CPA) with Shared Semantic Projector (SSP) to promote effective cross-modality alignment. Specifically, CPA simulates perceptual variability by applying asymmetric, modality-specific transformations to both EEG signals and images, enhancing semantic diversity. Unlike previous approaches, SSP establishes a bidirectional alignment process through a co-adaptive strategy, which mutually aligns features from two modalities into a shared semantic space for effective cross-modal learning. NeuroBridge surpasses previous state-of-the-art methods under both intra-subject and inter-subject settings. In the intra-subject scenario, it achieves the improvements of 12.3% in top-1 accuracy and 10.2% in top-5 accuracy, reaching 63.2% and 89.9% respectively on a 200-way zero-shot retrieval task. Extensive experiments demonstrate the effectiveness, robustness, and scalability of the proposed framework for neural visual decoding.",
    "authors": [
      "Wenjiang Zhang",
      "Sifeng Wang",
      "Yuwei Su",
      "Xinyu Li",
      "Chen Zhang",
      "Suyu Zhong"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06836v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06836v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2511.06380v1",
    "title": "What Makes Reasoning Invalid: Echo Reflection Mitigation for Large Language Models",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of reasoning tasks. Recent methods have further improved LLM performance in complex mathematical reasoning. However, when extending these methods beyond the domain of mathematical reasoning to tasks involving complex domain-specific knowledge, we observe a consistent failure of LLMs to generate novel insights during the reflection stage. Instead of conducting genuine cognitive refinement, the model tends to mechanically reiterate earlier reasoning steps without introducing new information or perspectives, a phenomenon referred to as \"Echo Reflection\". We attribute this behavior to two key defects: (1) Uncontrollable information flow during response generation, which allows premature intermediate thoughts to propagate unchecked and distort final decisions; (2) Insufficient exploration of internal knowledge during reflection, leading to repeating earlier findings rather than generating new cognitive insights. Building on these findings, we proposed a novel reinforcement learning method termed Adaptive Entropy Policy Optimization (AEPO). Specifically, the AEPO framework consists of two major components: (1) Reflection-aware Information Filtration, which quantifies the cognitive information flow and prevents the final answer from being affected by earlier bad cognitive information; (2) Adaptive-Entropy Optimization, which dynamically balances exploration and exploitation across different reasoning stages, promoting both reflective diversity and answer correctness. Extensive experiments demonstrate that AEPO consistently achieves state-of-the-art performance over mainstream reinforcement learning baselines across diverse benchmarks.",
    "authors": [
      "Chen He",
      "Xun Jiang",
      "Lei Wang",
      "Hao Yang",
      "Chong Peng",
      "Peng Yan",
      "Fumin Shen",
      "Xing Xu"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06380v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06380v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2511.07233v1",
    "title": "Noise & pattern: identity-anchored Tikhonov regularization for robust structural anomaly detection",
    "summary": "Anomaly detection plays a pivotal role in automated industrial inspection, aiming to identify subtle or rare defects in otherwise uniform visual patterns. As collecting representative examples of all possible anomalies is infeasible, we tackle structural anomaly detection using a self-supervised autoencoder that learns to repair corrupted inputs. To this end, we introduce a corruption model that injects artificial disruptions into training images to mimic structural defects. While reminiscent of denoising autoencoders, our approach differs in two key aspects. First, instead of unstructured i.i.d.\\ noise, we apply structured, spatially coherent perturbations that make the task a hybrid of segmentation and inpainting. Second, and counterintuitively, we add and preserve Gaussian noise on top of the occlusions, which acts as a Tikhonov regularizer anchoring the Jacobian of the reconstruction function toward identity. This identity-anchored regularization stabilizes reconstruction and further improves both detection and segmentation accuracy. On the MVTec AD benchmark, our method achieves state-of-the-art results (I/P-AUROC: 99.9/99.4), supporting our theoretical framework and demonstrating its practical relevance for automatic inspection.",
    "authors": [
      "Alexander Bauer",
      "Klaus-Robert Müller"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07233v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07233v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2511.06313v1",
    "title": "Precision-Scalable Microscaling Datapaths with Optimized Reduction Tree for Efficient NPU Integration",
    "summary": "Emerging continual learning applications necessitate next-generation neural processing unit (NPU) platforms to support both training and inference operations. The promising Microscaling (MX) standard enables narrow bit-widths for inference and large dynamic ranges for training. However, existing MX multiply-accumulate (MAC) designs face a critical trade-off: integer accumulation requires expensive conversions from narrow floating-point products, while FP32 accumulation suffers from quantization losses and costly normalization. To address these limitations, we propose a hybrid precision-scalable reduction tree for MX MACs that combines the benefits of both approaches, enabling efficient mixed-precision accumulation with controlled accuracy relaxation. Moreover, we integrate an 8x8 array of these MACs into the state-of-the-art (SotA) NPU integration platform, SNAX, to provide efficient control and data transfer to our optimized precision-scalable MX datapath. We evaluate our design both on MAC and system level and compare it to the SotA. Our integrated system achieves an energy efficiency of 657, 1438-1675, and 4065 GOPS/W, respectively, for MXINT8, MXFP8/6, and MXFP4, with a throughput of 64, 256, and 512 GOPS.",
    "authors": [
      "Stef Cuyckens",
      "Xiaoling Yi",
      "Robin Geens",
      "Joren Dumoulin",
      "Martin Wiesner",
      "Chao Fang",
      "Marian Verhelst"
    ],
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06313v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06313v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2511.06490v1",
    "title": "Zooming into Comics: Region-Aware RL Improves Fine-Grained Comic Understanding in Vision-Language Models",
    "summary": "Complex visual narratives, such as comics, present a significant challenge to Vision-Language Models (VLMs). Despite excelling on natural images, VLMs often struggle with stylized line art, onomatopoeia, and densely packed multi-panel layouts. To address this gap, we introduce AI4VA-FG, the first fine-grained and comprehensive benchmark for VLM-based comic understanding. It spans tasks from foundational recognition and detection to high-level character reasoning and narrative construction, supported by dense annotations for characters, poses, and depth. Beyond that, we evaluate state-of-the-art proprietary models, including GPT-4o and Gemini-2.5, and open-source models such as Qwen2.5-VL, revealing substantial performance deficits across core tasks of our benchmarks and underscoring that comic understanding remains an unsolved challenge. To enhance VLMs' capabilities in this domain, we systematically investigate post-training strategies, including supervised fine-tuning on solutions (SFT-S), supervised fine-tuning on reasoning trajectories (SFT-R), and reinforcement learning (RL). Beyond that, inspired by the emerging \"Thinking with Images\" paradigm, we propose Region-Aware Reinforcement Learning (RARL) for VLMs, which trains models to dynamically attend to relevant regions through zoom-in operations. We observe that when applied to the Qwen2.5-VL model, RL and RARL yield significant gains in low-level entity recognition and high-level storyline ordering, paving the way for more accurate and efficient VLM applications in the comics domain.",
    "authors": [
      "Yule Chen",
      "Yufan Ren",
      "Sabine Süsstrunk"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06490v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06490v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2511.06272v1",
    "title": "LaneDiffusion: Improving Centerline Graph Learning via Prior Injected BEV Feature Generation",
    "summary": "Centerline graphs, crucial for path planning in autonomous driving, are traditionally learned using deterministic methods. However, these methods often lack spatial reasoning and struggle with occluded or invisible centerlines. Generative approaches, despite their potential, remain underexplored in this domain. We introduce LaneDiffusion, a novel generative paradigm for centerline graph learning. LaneDiffusion innovatively employs diffusion models to generate lane centerline priors at the Bird's Eye View (BEV) feature level, instead of directly predicting vectorized centerlines. Our method integrates a Lane Prior Injection Module (LPIM) and a Lane Prior Diffusion Module (LPDM) to effectively construct diffusion targets and manage the diffusion process. Furthermore, vectorized centerlines and topologies are then decoded from these prior-injected BEV features. Extensive evaluations on the nuScenes and Argoverse2 datasets demonstrate that LaneDiffusion significantly outperforms existing methods, achieving improvements of 4.2%, 4.6%, 4.7%, 6.4% and 1.8% on fine-grained point-level metrics (GEO F1, TOPO F1, JTOPO F1, APLS and SDA) and 2.3%, 6.4%, 6.8% and 2.1% on segment-level metrics (IoU, mAP_cf, DET_l and TOP_ll). These results establish state-of-the-art performance in centerline graph learning, offering new insights into generative models for this task.",
    "authors": [
      "Zijie Wang",
      "Weiming Zhang",
      "Wei Zhang",
      "Xiao Tan",
      "Hongxing Liu",
      "Yaowei Wang",
      "Guanbin Li"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06272v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06272v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2511.06898v1",
    "title": "A Hybrid Autoencoder-Transformer Model for Robust Day-Ahead Electricity Price Forecasting under Extreme Conditions",
    "summary": "Accurate day-ahead electricity price forecasting (DAEPF) is critical for the efficient operation of power systems, but extreme condition and market anomalies pose significant challenges to existing forecasting methods. To overcome these challenges, this paper proposes a novel hybrid deep learning framework that integrates a Distilled Attention Transformer (DAT) model and an Autoencoder Self-regression Model (ASM). The DAT leverages a self-attention mechanism to dynamically assign higher weights to critical segments of historical data, effectively capturing both long-term trends and short-term fluctuations. Concurrently, the ASM employs unsupervised learning to detect and isolate anomalous patterns induced by extreme conditions, such as heavy rain, heat waves, or human festivals. Experiments on datasets sampled from California and Shandong Province demonstrate that our framework significantly outperforms state-of-the-art methods in prediction accuracy, robustness, and computational efficiency. Our framework thus holds promise for enhancing grid resilience and optimizing market operations in future power systems.",
    "authors": [
      "Boyan Tang",
      "Xuanhao Ren",
      "Peng Xiao",
      "Shunbo Lei",
      "Xiaorong Sun",
      "Jianghua Wu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06898v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06898v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2511.06776v1",
    "title": "Data Trajectory Alignment for LLM Domain Adaptation: A Two-Phase Synthesis Framework for Telecommunications Mathematics",
    "summary": "General-purpose large language models (LLMs) are increasingly deployed in verticals such as telecommunications, where adaptation is hindered by scarce, low-information-density corpora and tight mobile/edge constraints. We propose Data Trajectory Alignment (DTA), a two-phase, model-agnostic data curation framework that treats solution processes - not only final answers - as first-class supervision. Phase I (Initializing) synthesizes diverse, high-coverage candidates using an ensemble of strong teachers. Phase II (DTA) rewrites teacher solutions to align intermediate steps and presentation style with the target student's inductive biases and then performs signal-aware exemplar selection via agreement checks and reflection-based judging. Instantiated on telecommunications mathematics (e.g., link budgets, SNR/AMC selection, and power-control feasibility), DTA yields state-of-the-art (SOTA) accuracy on TELEMATH without enabling explicit \"thinking\" modes: 72.45% pass@1, surpassing distilled-only training by +17.65 points and outperforming a strong baseline (Qwen3-32B with thinking enabled) by +2.94 points. Token-shift analyses indicate that DTA concentrates gains on logical-structural discourse markers rather than merely amplifying domain nouns, indicating improved reasoning scaffolding. Under edge-like inference settings, DTA improves efficiency by reducing reliance on multi-sample voting and disabling expensive reasoning heuristics, cutting energy per output token by ~42% versus Qwen3-32B (thinking mode enabled) and end-to-end latency by ~60% versus Qwen3-32B (thinking mode disabled). These results demonstrate that aligning how solutions are produced enables compact, high-yield supervision that is effective for both accuracy and efficiency, offering a practical recipe for domain adaptation in low-resource verticals beyond telecom.",
    "authors": [
      "Zhicheng Zhou",
      "Jing Li",
      "Suming Qiu",
      "Junjie Huang",
      "Linyuan Qiu",
      "Zhijie Sun"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06776v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06776v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2511.07171v1",
    "title": "Federated Learning for Video Violence Detection: Complementary Roles of Lightweight CNNs and Vision-Language Models for Energy-Efficient Use",
    "summary": "Deep learning-based video surveillance increasingly demands privacy-preserving architectures with low computational and environmental overhead. Federated learning preserves privacy but deploying large vision-language models (VLMs) introduces major energy and sustainability challenges. We compare three strategies for federated violence detection under realistic non-IID splits on the RWF-2000 and RLVS datasets: zero-shot inference with pretrained VLMs, LoRA-based fine-tuning of LLaVA-NeXT-Video-7B, and personalized federated learning of a 65.8M-parameter 3D CNN. All methods exceed 90% accuracy in binary violence detection. The 3D CNN achieves superior calibration (ROC AUC 92.59%) at roughly half the energy cost (240 Wh vs. 570 Wh) of federated LoRA, while VLMs provide richer multimodal reasoning. Hierarchical category grouping (based on semantic similarity and class exclusion) boosts VLM multiclass accuracy from 65.31% to 81% on the UCF-Crime dataset. To our knowledge, this is the first comparative simulation study of LoRA-tuned VLMs and personalized CNNs for federated violence detection, with explicit energy and CO2e quantification. Our results inform hybrid deployment strategies that default to efficient CNNs for routine inference and selectively engage VLMs for complex contextual reasoning.",
    "authors": [
      "Sébastien Thuau",
      "Siba Haidar",
      "Rachid Chelouah"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07171v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07171v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.06344v1",
    "title": "TimeSense:Making Large Language Models Proficient in Time-Series Analysis",
    "summary": "In the time-series domain, an increasing number of works combine text with temporal data to leverage the reasoning capabilities of large language models (LLMs) for various downstream time-series understanding tasks. This enables a single model to flexibly perform tasks that previously required specialized models for each domain. However, these methods typically rely on text labels for supervision during training, biasing the model toward textual cues while potentially neglecting the full temporal features. Such a bias can lead to outputs that contradict the underlying time-series context. To address this issue, we construct the EvalTS benchmark, comprising 10 tasks across three difficulty levels, from fundamental temporal pattern recognition to complex real-world reasoning, to evaluate models under more challenging and realistic scenarios. We also propose TimeSense, a multimodal framework that makes LLMs proficient in time-series analysis by balancing textual reasoning with a preserved temporal sense. TimeSense incorporates a Temporal Sense module that reconstructs the input time-series within the model's context, ensuring that textual reasoning is grounded in the time-series dynamics. Moreover, to enhance spatial understanding of time-series data, we explicitly incorporate coordinate-based positional embeddings, which provide each time point with spatial context and enable the model to capture structural dependencies more effectively. Experimental results demonstrate that TimeSense achieves state-of-the-art performance across multiple tasks, and it particularly outperforms existing methods on complex multi-dimensional time-series reasoning tasks.",
    "authors": [
      "Zhirui Zhang",
      "Changhua Pei",
      "Tianyi Gao",
      "Zhe Xie",
      "Yibo Hao",
      "Zhaoyang Yu",
      "Longlong Xu",
      "Tong Xiao",
      "Jing Han",
      "Dan Pei"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06344v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06344v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.06682v1",
    "title": "Textual Self-attention Network: Test-Time Preference Optimization through Textual Gradient-based Attention",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable generalization capabilities, but aligning their outputs with human preferences typically requires expensive supervised fine-tuning. Recent test-time methods leverage textual feedback to overcome this, but they often critique and revise a single candidate response, lacking a principled mechanism to systematically analyze, weigh, and synthesize the strengths of multiple promising candidates. Such a mechanism is crucial because different responses may excel in distinct aspects (e.g., clarity, factual accuracy, or tone), and combining their best elements may produce a far superior outcome. This paper proposes the Textual Self-Attention Network (TSAN), a new paradigm for test-time preference optimization that requires no parameter updates. TSAN emulates self-attention entirely in natural language to overcome this gap: it analyzes multiple candidates by formatting them into textual keys and values, weighs their relevance using an LLM-based attention module, and synthesizes their strengths into a new, preference-aligned response under the guidance of the learned textual attention. This entire process operates in a textual gradient space, enabling iterative and interpretable optimization. Empirical evaluations demonstrate that with just three test-time iterations on a base SFT model, TSAN outperforms supervised models like Llama-3.1-70B-Instruct and surpasses the current state-of-the-art test-time alignment method by effectively leveraging multiple candidate solutions.",
    "authors": [
      "Shibing Mo",
      "Haoyang Ruan",
      "Kai Wu",
      "Jing Liu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06682v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06682v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.06751v1",
    "title": "Hierarchical Spatial-Frequency Aggregation for Spectral Deconvolution Imaging",
    "summary": "Computational spectral imaging (CSI) achieves real-time hyperspectral imaging through co-designed optics and algorithms, but typical CSI methods suffer from a bulky footprint and limited fidelity. Therefore, Spectral Deconvolution imaging (SDI) methods based on PSF engineering have been proposed to achieve high-fidelity compact CSI design recently. However, the composite convolution-integration operations of SDI render the normal-equation coefficient matrix scene-dependent, which hampers the efficient exploitation of imaging priors and poses challenges for accurate reconstruction. To tackle the inherent data-dependent operators in SDI, we introduce a Hierarchical Spatial-Spectral Aggregation Unfolding Framework (HSFAUF). By decomposing subproblems and projecting them into the frequency domain, HSFAUF transforms nonlinear processes into linear mappings, thereby enabling efficient solutions. Furthermore, to integrate spatial-spectral priors during iterative refinement, we propose a Spatial-Frequency Aggregation Transformer (SFAT), which explicitly aggregates information across spatial and frequency domains. By integrating SFAT into HSFAUF, we develop a Transformer-based deep unfolding method, \\textbf{H}ierarchical \\textbf{S}patial-\\textbf{F}requency \\textbf{A}ggregation \\textbf{U}nfolding \\textbf{T}ransformer (HSFAUT), to solve the inverse problem of SDI. Systematic simulated and real experiments show that HSFAUT surpasses SOTA methods with cheaper memory and computational costs, while exhibiting optimal performance on different SDI systems.",
    "authors": [
      "Tao Lv",
      "Daoming Zhou",
      "Chenglong Huang",
      "Chongde Zi",
      "Linsen Chen",
      "Xun Cao"
    ],
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06751v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06751v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.06437v1",
    "title": "Optimizing Chain-of-Thought Confidence via Topological and Dirichlet Risk Analysis",
    "summary": "Chain-of-thought (CoT) prompting enables Large Language Models to solve complex problems, but deploying these models safely requires reliable confidence estimates, a capability where existing methods suffer from poor calibration and severe overconfidence on incorrect predictions. We propose Enhanced Dirichlet and Topology Risk (EDTR), a novel decoding strategy that combines topological analysis with Dirichlet-based uncertainty quantification to measure LLM confidence across multiple reasoning paths. EDTR treats each CoT as a vector in high-dimensional space and extracts eight topological risk features capturing the geometric structure of reasoning distributions: tighter, more coherent clusters indicate higher confidence while dispersed, inconsistent paths signal uncertainty. We evaluate EDTR against three state-of-the-art calibration methods across four diverse reasoning benchmarks spanning olympiad-level mathematics (AIME), grade school math (GSM8K), commonsense reasoning, and stock price prediction \\cite{zhang2025aime, cobbe2021training, talmor-etal-2019-commonsenseqa, yahoo_finance}. EDTR achieves 41\\% better calibration than competing methods with an average ECE of 0.287 and the best overall composite score of 0.672, while notably achieving perfect accuracy on AIME and exceptional calibration on GSM8K with an ECE of 0.107, domains where baselines exhibit severe overconfidence. Our work provides a geometric framework for understanding and quantifying uncertainty in multi-step LLM reasoning, enabling more reliable deployment where calibrated confidence estimates are essential.",
    "authors": [
      "Abhishek More",
      "Anthony Zhang",
      "Nicole Bonilla",
      "Ashvik Vivekan",
      "Kevin Zhu",
      "Parham Sharafoleslami",
      "Maheep Chaudhary"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06437v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06437v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2511.06348v1",
    "title": "GazeVLM: A Vision-Language Model for Multi-Task Gaze Understanding",
    "summary": "Gaze understanding unifies the detection of people, their gaze targets, and objects of interest into a single framework, offering critical insight into visual attention and intent estimation. Although prior research has modelled gaze cues in visual scenes, a unified system is still needed for gaze understanding using both visual and language prompts. This paper introduces GazeVLM, a novel Vision-Language Model (VLM) for multi-task gaze understanding in images, addressing person detection, gaze target detection, and gaze object identification. While other transformer-based methods exist for gaze analysis, GazeVLM represents, to our knowledge, the first application of a VLM to these combined tasks, allowing for selective execution of each task. Through the integration of visual (RGB and depth) and textual modalities, our ablation study on visual input combinations revealed that a fusion of RGB images with HHA-encoded depth maps, guided by text prompts, yields superior performance. We also introduce an object-level gaze detection metric for gaze object identification ($AP_{ob}$). Through experiments, GazeVLM demonstrates significant improvements, notably achieving state-of-the-art evaluation scores on GazeFollow and VideoAttentionTarget datasets.",
    "authors": [
      "Athul M. Mathew",
      "Haithem Hermassi",
      "Thariq Khalid",
      "Arshad Ali Khan",
      "Riad Souissi"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06348v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06348v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2511.07006v1",
    "title": "S$^2$Drug: Bridging Protein Sequence and 3D Structure in Contrastive Representation Learning for Virtual Screening",
    "summary": "Virtual screening (VS) is an essential task in drug discovery, focusing on the identification of small-molecule ligands that bind to specific protein pockets. Existing deep learning methods, from early regression models to recent contrastive learning approaches, primarily rely on structural data while overlooking protein sequences, which are more accessible and can enhance generalizability. However, directly integrating protein sequences poses challenges due to the redundancy and noise in large-scale protein-ligand datasets. To address these limitations, we propose \\textbf{S$^2$Drug}, a two-stage framework that explicitly incorporates protein \\textbf{S}equence information and 3D \\textbf{S}tructure context in protein-ligand contrastive representation learning. In the first stage, we perform protein sequence pretraining on ChemBL using an ESM2-based backbone, combined with a tailored data sampling strategy to reduce redundancy and noise on both protein and ligand sides. In the second stage, we fine-tune on PDBBind by fusing sequence and structure information through a residue-level gating module, while introducing an auxiliary binding site prediction task. This auxiliary task guides the model to accurately localize binding residues within the protein sequence and capture their 3D spatial arrangement, thereby refining protein-ligand matching. Across multiple benchmarks, S$^2$Drug consistently improves virtual screening performance and achieves strong results on binding site prediction, demonstrating the value of bridging sequence and structure in contrastive learning.",
    "authors": [
      "Bowei He",
      "Bowen Gao",
      "Yankai Chen",
      "Yanyan Lan",
      "Chen Ma",
      "Philip S. Yu",
      "Ya-Qin Zhang",
      "Wei-Ying Ma"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07006v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07006v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.07377v1",
    "title": "Real-Time LiDAR Super-Resolution via Frequency-Aware Multi-Scale Fusion",
    "summary": "LiDAR super-resolution addresses the challenge of achieving high-quality 3D perception from cost-effective, low-resolution sensors. While recent transformer-based approaches like TULIP show promise, they remain limited to spatial-domain processing with restricted receptive fields. We introduce FLASH (Frequency-aware LiDAR Adaptive Super-resolution with Hierarchical fusion), a novel framework that overcomes these limitations through dual-domain processing. FLASH integrates two key innovations: (i) Frequency-Aware Window Attention that combines local spatial attention with global frequency-domain analysis via FFT, capturing both fine-grained geometry and periodic scanning patterns at log-linear complexity. (ii) Adaptive Multi-Scale Fusion that replaces conventional skip connections with learned position-specific feature aggregation, enhanced by CBAM attention for dynamic feature selection. Extensive experiments on KITTI demonstrate that FLASH achieves state-of-the-art performance across all evaluation metrics, surpassing even uncertainty-enhanced baselines that require multiple forward passes. Notably, FLASH outperforms TULIP with Monte Carlo Dropout while maintaining single-pass efficiency, which enables real-time deployment. The consistent superiority across all distance ranges validates that our dual-domain approach effectively handles uncertainty through architectural design rather than computationally expensive stochastic inference, making it practical for autonomous systems.",
    "authors": [
      "June Moh Goo",
      "Zichao Zeng",
      "Jan Boehm"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07377v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07377v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.06893v1",
    "title": "DeepBooTS: Dual-Stream Residual Boosting for Drift-Resilient Time-Series Forecasting",
    "summary": "Time-Series (TS) exhibits pronounced non-stationarity. Consequently, most forecasting methods display compromised robustness to concept drift, despite the prevalent application of instance normalization. We tackle this challenge by first analysing concept drift through a bias-variance lens and proving that weighted ensemble reduces variance without increasing bias. These insights motivate DeepBooTS, a novel end-to-end dual-stream residual-decreasing boosting method that progressively reconstructs the intrinsic signal. In our design, each block of a deep model becomes an ensemble of learners with an auxiliary output branch forming a highway to the final prediction. The block-wise outputs correct the residuals of previous blocks, leading to a learning-driven decomposition of both inputs and targets. This method enhances versatility and interpretability while substantially improving robustness to concept drift. Extensive experiments, including those on large-scale datasets, show that the proposed method outperforms existing methods by a large margin, yielding an average performance improvement of 15.8% across various datasets, establishing a new benchmark for TS forecasting.",
    "authors": [
      "Daojun Liang",
      "Jing Chen",
      "Xiao Wang",
      "Yinglong Wang",
      "Suo Li"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06893v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06893v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.06757v1",
    "title": "Implicit Federated In-context Learning For Task-Specific LLM Fine-Tuning",
    "summary": "As large language models continue to develop and expand, the extensive public data they rely on faces the risk of depletion. Consequently, leveraging private data within organizations to enhance the performance of large models has emerged as a key challenge. The federated learning paradigm, combined with model fine-tuning techniques, effectively reduces the number of trainable parameters. However,the necessity to process high-dimensional feature spaces results in substantial overall computational overhead. To address this issue, we propose the Implicit Federated In-Context Learning (IFed-ICL) framework. IFed-ICL draws inspiration from federated learning to establish a novel distributed collaborative paradigm, by converting client local context examples into implicit vector representations, it enables distributed collaborative computation during the inference phase and injects model residual streams to enhance model performance. Experiments demonstrate that our proposed method achieves outstanding performance across multiple text classification tasks. Compared to traditional methods, IFed-ICL avoids the extensive parameter updates required by conventional fine-tuning methods while reducing data transmission and local computation at the client level in federated learning. This enables efficient distributed context learning using local private-domain data, significantly improving model performance on specific tasks.",
    "authors": [
      "Dongcheng Li",
      "Junhan Chen",
      "Aoxiang Zhou",
      "Chunpei Li",
      "Youquan Xian",
      "Peng Liu",
      "Xianxian Li"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06757v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06757v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.07301v1",
    "title": "Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection",
    "summary": "Source-Free Object Detection (SFOD) aims to adapt a source-pretrained object detector to a target domain without access to source data. However, existing SFOD methods predominantly rely on internal knowledge from the source model, which limits their capacity to generalize across domains and often results in biased pseudo-labels, thereby hindering both transferability and discriminability. In contrast, Vision Foundation Models (VFMs), pretrained on massive and diverse data, exhibit strong perception capabilities and broad generalization, yet their potential remains largely untapped in the SFOD setting. In this paper, we propose a novel SFOD framework that leverages VFMs as external knowledge sources to jointly enhance feature alignment and label quality. Specifically, we design three VFM-based modules: (1) Patch-weighted Global Feature Alignment (PGFA) distills global features from VFMs using patch-similarity-based weighting to enhance global feature transferability; (2) Prototype-based Instance Feature Alignment (PIFA) performs instance-level contrastive learning guided by momentum-updated VFM prototypes; and (3) Dual-source Enhanced Pseudo-label Fusion (DEPF) fuses predictions from detection VFMs and teacher models via an entropy-aware strategy to yield more reliable supervision. Extensive experiments on six benchmarks demonstrate that our method achieves state-of-the-art SFOD performance, validating the effectiveness of integrating VFMs to simultaneously improve transferability and discriminability.",
    "authors": [
      "Huizai Yao",
      "Sicheng Zhao",
      "Pengteng Li",
      "Yi Cui",
      "Shuo Lu",
      "Weiyu Guo",
      "Yunfan Lu",
      "Yijie Xu",
      "Hui Xiong"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07301v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07301v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.06273v1",
    "title": "COTN: A Chaotic Oscillatory Transformer Network for Complex Volatile Systems under Extreme Conditions",
    "summary": "Accurate prediction of financial and electricity markets, especially under extreme conditions, remains a significant challenge due to their intrinsic nonlinearity, rapid fluctuations, and chaotic patterns. To address these limitations, we propose the Chaotic Oscillatory Transformer Network (COTN). COTN innovatively combines a Transformer architecture with a novel Lee Oscillator activation function, processed through Max-over-Time pooling and a lambda-gating mechanism. This design is specifically tailored to effectively capture chaotic dynamics and improve responsiveness during periods of heightened volatility, where conventional activation functions (e.g., ReLU, GELU) tend to saturate. Furthermore, COTN incorporates an Autoencoder Self-Regressive (ASR) module to detect and isolate abnormal market patterns, such as sudden price spikes or crashes, thereby preventing corruption of the core prediction process and enhancing robustness. Extensive experiments across electricity spot markets and financial markets demonstrate the practical applicability and resilience of COTN. Our approach outperforms state-of-the-art deep learning models like Informer by up to 17% and traditional statistical methods like GARCH by as much as 40%. These results underscore COTN's effectiveness in navigating real-world market uncertainty and complexity, offering a powerful tool for forecasting highly volatile systems under duress.",
    "authors": [
      "Boyan Tang",
      "Yilong Zeng",
      "Xuanhao Ren",
      "Peng Xiao",
      "Yuhan Zhao",
      "Raymond Lee",
      "Jianghua Wu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06273v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06273v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.06943v1",
    "title": "PlantTraitNet: An Uncertainty-Aware Multimodal Framework for Global-Scale Plant Trait Inference from Citizen Science Data",
    "summary": "Global plant maps of plant traits, such as leaf nitrogen or plant height, are essential for understanding ecosystem processes, including the carbon and energy cycles of the Earth system. However, existing trait maps remain limited by the high cost and sparse geographic coverage of field-based measurements. Citizen science initiatives offer a largely untapped resource to overcome these limitations, with over 50 million geotagged plant photographs worldwide capturing valuable visual information on plant morphology and physiology. In this study, we introduce PlantTraitNet, a multi-modal, multi-task uncertainty-aware deep learning framework that predictsfour key plant traits (plant height, leaf area, specific leaf area, and nitrogen content) from citizen science photos using weak supervision. By aggregating individual trait predictions across space, we generate global maps of trait distributions. We validate these maps against independent vegetation survey data (sPlotOpen) and benchmark them against leading global trait products. Our results show that PlantTraitNet consistently outperforms existing trait maps across all evaluated traits, demonstrating that citizen science imagery, when integrated with computer vision and geospatial AI, enables not only scalable but also more accurate global trait mapping. This approach offers a powerful new pathway for ecological research and Earth system modeling.",
    "authors": [
      "Ayushi Sharma",
      "Johanna Trost",
      "Daniel Lusk",
      "Johannes Dollinger",
      "Julian Schrader",
      "Christian Rossi",
      "Javier Lopatin",
      "Etienne Laliberté",
      "Simon Haberstroh",
      "Jana Eichel",
      "Daniel Mederer",
      "Jose Miguel Cerda-Paredes",
      "Shyam S. Phartyal",
      "Lisa-Maricia Schwarz",
      "Anja Linstädter",
      "Maria Conceição Caldeira",
      "Teja Kattenborn"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06943v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06943v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.06767v1",
    "title": "QUARK: Quantization-Enabled Circuit Sharing for Transformer Acceleration by Exploiting Common Patterns in Nonlinear Operations",
    "summary": "Transformer-based models have revolutionized computer vision (CV) and natural language processing (NLP) by achieving state-of-the-art performance across a range of benchmarks. However, nonlinear operations in models significantly contribute to inference latency, presenting unique challenges for efficient hardware acceleration. To this end, we propose QUARK, a quantization-enabled FPGA acceleration framework that leverages common patterns in nonlinear operations to enable efficient circuit sharing, thereby reducing hardware resource requirements. QUARK targets all nonlinear operations within Transformer-based models, achieving high-performance approximation through a novel circuit-sharing design tailored to accelerate these operations. Our evaluation demonstrates that QUARK significantly reduces the computational overhead of nonlinear operators in mainstream Transformer architectures, achieving up to a 1.96 times end-to-end speedup over GPU implementations. Moreover, QUARK lowers the hardware overhead of nonlinear modules by more than 50% compared to prior approaches, all while maintaining high model accuracy -- and even substantially boosting accuracy under ultra-low-bit quantization.",
    "authors": [
      "Zhixiong Zhao",
      "Haomin Li",
      "Fangxin Liu",
      "Yuncheng Lu",
      "Zongwu Wang",
      "Tao Yang",
      "Li Jiang",
      "Haibing Guan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06767v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06767v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.06625v1",
    "title": "Explainable Cross-Disease Reasoning for Cardiovascular Risk Assessment from LDCT",
    "summary": "Low-dose chest computed tomography (LDCT) inherently captures both pulmonary and cardiac structures, offering a unique opportunity for joint assessment of lung and cardiovascular health. However, most existing approaches treat these domains as independent tasks, overlooking their physiological interplay and shared imaging biomarkers. We propose an Explainable Cross-Disease Reasoning Framework that enables interpretable cardiopulmonary risk assessment from a single LDCT scan. The framework introduces an agentic reasoning process that emulates clinical diagnostic thinking-first perceiving pulmonary findings, then reasoning through established medical knowledge, and finally deriving a cardiovascular judgment with explanatory rationale. It integrates three synergistic components: a pulmonary perception module that summarizes lung abnormalities, a knowledge-guided reasoning module that infers their cardiovascular implications, and a cardiac representation module that encodes structural biomarkers. Their outputs are fused to produce a holistic cardiovascular risk prediction that is both accurate and physiologically grounded. Experiments on the NLST cohort demonstrate that the proposed framework achieves state-of-the-art performance for CVD screening and mortality prediction, outperforming single-disease and purely image-based baselines. Beyond quantitative gains, the framework provides human-verifiable reasoning that aligns with cardiological understanding, revealing coherent links between pulmonary abnormalities and cardiac stress mechanisms. Overall, this work establishes a unified and explainable paradigm for cardiovascular analysis from LDCT, bridging the gap between image-based prediction and mechanism-based medical interpretation.",
    "authors": [
      "Yifei Zhang",
      "Jiashuo Zhang",
      "Xiaofeng Yang",
      "Liang Zhao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06625v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06625v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.06197v1",
    "title": "Enhancing Adversarial Robustness of IoT Intrusion Detection via SHAP-Based Attribution Fingerprinting",
    "summary": "The rapid proliferation of Internet of Things (IoT) devices has transformed numerous industries by enabling seamless connectivity and data-driven automation. However, this expansion has also exposed IoT networks to increasingly sophisticated security threats, including adversarial attacks targeting artificial intelligence (AI) and machine learning (ML)-based intrusion detection systems (IDS) to deliberately evade detection, induce misclassification, and systematically undermine the reliability and integrity of security defenses. To address these challenges, we propose a novel adversarial detection model that enhances the robustness of IoT IDS against adversarial attacks through SHapley Additive exPlanations (SHAP)-based fingerprinting. Using SHAP's DeepExplainer, we extract attribution fingerprints from network traffic features, enabling the IDS to reliably distinguish between clean and adversarially perturbed inputs. By capturing subtle attribution patterns, the model becomes more resilient to evasion attempts and adversarial manipulations. We evaluated the model on a standard IoT benchmark dataset, where it significantly outperformed a state-of-the-art method in detecting adversarial attacks. In addition to enhanced robustness, this approach improves model transparency and interpretability, thereby increasing trust in the IDS through explainable AI.",
    "authors": [
      "Dilli Prasad Sharma",
      "Liang Xue",
      "Xiaowei Sun",
      "Xiaodong Lin",
      "Pulei Xiong"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.NI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06197v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06197v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07399v1",
    "title": "StreamDiffusionV2: A Streaming System for Dynamic and Interactive Video Generation",
    "summary": "Generative models are reshaping the live-streaming industry by redefining how content is created, styled, and delivered. Previous image-based streaming diffusion models have powered efficient and creative live streaming products but have hit limits on temporal consistency due to the foundation of image-based designs. Recent advances in video diffusion have markedly improved temporal consistency and sampling efficiency for offline generation. However, offline generation systems primarily optimize throughput by batching large workloads. In contrast, live online streaming operates under strict service-level objectives (SLOs): time-to-first-frame must be minimal, and every frame must meet a per-frame deadline with low jitter. Besides, scalable multi-GPU serving for real-time streams remains largely unresolved so far. To address this, we present StreamDiffusionV2, a training-free pipeline for interactive live streaming with video diffusion models. StreamDiffusionV2 integrates an SLO-aware batching scheduler and a block scheduler, together with a sink-token--guided rolling KV cache, a motion-aware noise controller, and other system-level optimizations. Moreover, we introduce a scalable pipeline orchestration that parallelizes the diffusion process across denoising steps and network layers, achieving near-linear FPS scaling without violating latency guarantees. The system scales seamlessly across heterogeneous GPU environments and supports flexible denoising steps (e.g., 1--4), enabling both ultra-low-latency and higher-quality modes. Without TensorRT or quantization, StreamDiffusionV2 renders the first frame within 0.5s and attains 58.28 FPS with a 14B-parameter model and 64.52 FPS with a 1.3B-parameter model on four H100 GPUs, making state-of-the-art generative live streaming practical and accessible--from individual creators to enterprise-scale platforms.",
    "authors": [
      "Tianrui Feng",
      "Zhi Li",
      "Shuo Yang",
      "Haocheng Xi",
      "Muyang Li",
      "Xiuyu Li",
      "Lvmin Zhang",
      "Keting Yang",
      "Kelly Peng",
      "Song Han",
      "Maneesh Agrawala",
      "Kurt Keutzer",
      "Akio Kodaira",
      "Chenfeng Xu"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07399v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07399v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.06794v1",
    "title": "Beyond Uniform Deletion: A Data Value-Weighted Framework for Certified Machine Unlearning",
    "summary": "As the right to be forgotten becomes legislated worldwide, machine unlearning mechanisms have emerged to efficiently update models for data deletion and enhance user privacy protection. However, existing machine unlearning algorithms frequently neglect the fact that different data points may contribute unequally to model performance (i.e., heterogeneous data values). Treat them equally in machine unlearning procedure can potentially degrading the performance of updated models. To address this limitation, we propose Data Value-Weighted Unlearning (DVWU), a general unlearning framework that accounts for data value heterogeneity into the unlearning process. Specifically, we design a weighting strategy based on data values, which are then integrated into the unlearning procedure to enable differentiated unlearning for data points with varying utility to the model. The DVWU framework can be broadly adapted to various existing machine unlearning methods. We use the one-step Newton update as an example for implementation, developing both output and objective perturbation algorithms to achieve certified unlearning. Experiments on both synthetic and real-world datasets demonstrate that our methods achieve superior predictive performance and robustness compared to conventional unlearning approaches. We further show the extensibility of our framework on gradient ascent method by incorporating the proposed weighting strategy into the gradient terms, highlighting the adaptability of DVWU for broader gradient-based deep unlearning methods.",
    "authors": [
      "Lisong He",
      "Yi Yang",
      "Xiangyu Chang"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06794v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06794v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.06441v1",
    "title": "Towards Resource-Efficient Multimodal Intelligence: Learned Routing among Specialized Expert Models",
    "summary": "As AI moves beyond text, large language models (LLMs) increasingly power vision, audio, and document understanding; however, their high inference costs hinder real-time, scalable deployment. Conversely, smaller open-source models offer cost advantages but struggle with complex or multimodal queries. We introduce a unified, modular framework that intelligently routes each query - textual, multimodal, or complex - to the most fitting expert model, using a learned routing network that balances cost and quality. For vision tasks, we employ a two-stage open-source pipeline optimized for efficiency and reviving efficient classical vision components where they remain SOTA for sub-tasks. On benchmarks such as Massive Multitask Language Understanding (MMLU) and Visual Question Answering (VQA), we match or exceed the performance of always-premium LLM (monolithic systems with one model serving all query types) performance, yet reduce the reliance on costly models by over 67%. With its extensible, multi-agent orchestration, we deliver high-quality, resource-efficient AI at scale.",
    "authors": [
      "Mayank Saini",
      "Arit Kumar Bishwas"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06441v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06441v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.06250v1",
    "title": "Test-Time Iterative Error Correction for Efficient Diffusion Models",
    "summary": "With the growing demand for high-quality image generation on resource-constrained devices, efficient diffusion models have received increasing attention. However, such models suffer from approximation errors introduced by efficiency techniques, which significantly degrade generation quality. Once deployed, these errors are difficult to correct, as modifying the model is typically infeasible in deployment environments. Through an analysis of error propagation across diffusion timesteps, we reveal that these approximation errors can accumulate exponentially, severely impairing output quality. Motivated by this insight, we propose Iterative Error Correction (IEC), a novel test-time method that mitigates inference-time errors by iteratively refining the model's output. IEC is theoretically proven to reduce error propagation from exponential to linear growth, without requiring any retraining or architectural changes. IEC can seamlessly integrate into the inference process of existing diffusion models, enabling a flexible trade-off between performance and efficiency. Extensive experiments show that IEC consistently improves generation quality across various datasets, efficiency techniques, and model architectures, establishing it as a practical and generalizable solution for test-time enhancement of efficient diffusion models.",
    "authors": [
      "Yunshan Zhong",
      "Yanwei Qi",
      "Yuxin Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06250v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06250v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07293v1",
    "title": "Verifying rich robustness properties for neural networks",
    "summary": "Robustness is a important problem in AI alignment and safety, with models such as neural networks being increasingly used in safety-critical systems. In the last decade, a large body of work has emerged on local robustness, i.e., checking if the decision of a neural network remains unchanged when the input is slightly perturbed. However, many of these approaches require specialized encoding and often ignore the confidence of a neural network on its output. In this paper, our goal is to build a generalized framework to specify and verify variants of robustness in neural network verification. We propose a specification framework using a simple grammar, which is flexible enough to capture most existing variants. This allows us to introduce new variants of robustness that take into account the confidence of the neural network in its outputs. Next, we develop a novel and powerful unified technique to verify all such variants in a homogeneous way, viz., by adding a few additional layers to the neural network. This enables us to use any state-of-the-art neural network verification tool, without having to tinker with the encoding within, while incurring an approximation error that we show is bounded. We perform an extensive experimental evaluation over a large suite of 8870 benchmarks having 138M parameters in a largest network, and show that we are able to capture a wide set of robustness variants and outperform direct encoding approaches by a significant margin.",
    "authors": [
      "Mohammad Afzal",
      "S. Akshay",
      "Ashutosh Gupta"
    ],
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07293v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07293v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.06944v1",
    "title": "From Attribution to Action: Jointly ALIGNing Predictions and Explanations",
    "summary": "Explanation-guided learning (EGL) has shown promise in aligning model predictions with interpretable reasoning, particularly in computer vision tasks. However, most approaches rely on external annotations or heuristic-based segmentation to supervise model explanations, which can be noisy, imprecise and difficult to scale. In this work, we provide both empirical and theoretical evidence that low-quality supervision signals can degrade model performance rather than improve it. In response, we propose ALIGN, a novel framework that jointly trains a classifier and a masker in an iterative manner. The masker learns to produce soft, task-relevant masks that highlight informative regions, while the classifier is optimized for both prediction accuracy and alignment between its saliency maps and the learned masks. By leveraging high-quality masks as guidance, ALIGN improves both interpretability and generalizability, showing its superiority across various settings. Experiments on the two domain generalization benchmarks, VLCS and Terra Incognita, show that ALIGN consistently outperforms six strong baselines in both in-distribution and out-of-distribution settings. Besides, ALIGN also yields superior explanation quality concerning sufficiency and comprehensiveness, highlighting its effectiveness in producing accurate and interpretable models.",
    "authors": [
      "Dongsheng Hong",
      "Chao Chen",
      "Yanhui Chen",
      "Shanshan Lin",
      "Zhihao Chen",
      "Xiangwen Liao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06944v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06944v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07238v1",
    "title": "Leveraging Text-Driven Semantic Variation for Robust OOD Segmentation",
    "summary": "In autonomous driving and robotics, ensuring road safety and reliable decision-making critically depends on out-of-distribution (OOD) segmentation. While numerous methods have been proposed to detect anomalous objects on the road, leveraging the vision-language space-which provides rich linguistic knowledge-remains an underexplored field. We hypothesize that incorporating these linguistic cues can be especially beneficial in the complex contexts found in real-world autonomous driving scenarios.   To this end, we present a novel approach that trains a Text-Driven OOD Segmentation model to learn a semantically diverse set of objects in the vision-language space. Concretely, our approach combines a vision-language model's encoder with a transformer decoder, employs Distance-Based OOD prompts located at varying semantic distances from in-distribution (ID) classes, and utilizes OOD Semantic Augmentation for OOD representations. By aligning visual and textual information, our approach effectively generalizes to unseen objects and provides robust OOD segmentation in diverse driving environments.   We conduct extensive experiments on publicly available OOD segmentation datasets such as Fishyscapes, Segment-Me-If-You-Can, and Road Anomaly datasets, demonstrating that our approach achieves state-of-the-art performance across both pixel-level and object-level evaluations. This result underscores the potential of vision-language-based OOD segmentation to bolster the safety and reliability of future autonomous driving systems.",
    "authors": [
      "Seungheon Song",
      "Jaekoo Lee"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07238v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07238v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07085v1",
    "title": "Achieving Effective Virtual Reality Interactions via Acoustic Gesture Recognition based on Large Language Models",
    "summary": "Natural and efficient interaction remains a critical challenge for virtual reality and augmented reality (VR/AR) systems. Vision-based gesture recognition suffers from high computational cost, sensitivity to lighting conditions, and privacy leakage concerns. Acoustic sensing provides an attractive alternative: by emitting inaudible high-frequency signals and capturing their reflections, channel impulse response (CIR) encodes how gestures perturb the acoustic field in a low-cost and user-transparent manner. However, existing CIR-based gesture recognition methods often rely on extensive training of models on large labeled datasets, making them unsuitable for few-shot VR scenarios. In this work, we propose the first framework that leverages large language models (LLMs) for CIR-based gesture recognition in VR/AR systems. Despite LLMs' strengths, it is non-trivial to achieve few-shot and zero-shot learning of CIR gestures due to their inconspicuous features. To tackle this challenge, we collect differential CIR rather than original CIR data. Moreover, we construct a real-world dataset collected from 10 participants performing 15 gestures across three categories (digits, letters, and shapes), with 10 repetitions each. We then conduct extensive experiments on this dataset using an LLM-adopted classifier. Results show that our LLM-based framework achieves accuracy comparable to classical machine learning baselines, while requiring no domain-specific retraining.",
    "authors": [
      "Xijie Zhang",
      "Fengliang He",
      "Hong-Ning Dai"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07085v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07085v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07327v1",
    "title": "IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction",
    "summary": "Recent advances in deep-research agents have shown promise for autonomous knowledge construction through dynamic reasoning over external sources. However, existing approaches rely on a mono-contextual paradigm that accumulates all information in a single, expanding context window, leading to context suffocation and noise contamination that limit their effectiveness on long-horizon tasks. We introduce IterResearch, a novel iterative deep-research paradigm that reformulates long-horizon research as a Markov Decision Process with strategic workspace reconstruction. By maintaining an evolving report as memory and periodically synthesizing insights, our approach preserves consistent reasoning capacity across arbitrary exploration depths. We further develop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learning framework that incentivizes efficient exploration through geometric reward discounting and enables stable distributed training via adaptive downsampling. Extensive experiments demonstrate that IterResearch achieves substantial improvements over existing open-source agents with average +14.5pp across six benchmarks and narrows the gap with frontier proprietary systems. Remarkably, our paradigm exhibits unprecedented interaction scaling, extending to 2048 interactions with dramatic performance gains (from 3.5\\% to 42.5\\%), and serves as an effective prompting strategy, improving frontier models by up to 19.2pp over ReAct on long-horizon tasks. These findings position IterResearch as a versatile solution for long-horizon reasoning, effective both as a trained agent and as a prompting paradigm for frontier models.",
    "authors": [
      "Guoxin Chen",
      "Zile Qiao",
      "Xuanzhong Chen",
      "Donglei Yu",
      "Haotian Xu",
      "Wayne Xin Zhao",
      "Ruihua Song",
      "Wenbiao Yin",
      "Huifeng Yin",
      "Liwen Zhang",
      "Kuan Li",
      "Minpeng Liao",
      "Yong Jiang",
      "Pengjun Xie",
      "Fei Huang",
      "Jingren Zhou"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07327v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07327v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07262v1",
    "title": "AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery in Scientific Machine Learning",
    "summary": "Scientific Machine Learning (SciML) integrates data-driven inference with physical modeling to solve complex problems in science and engineering. However, the design of SciML architectures, loss formulations, and training strategies remains an expert-driven research process, requiring extensive experimentation and problem-specific insights. Here we introduce AgenticSciML, a collaborative multi-agent system in which over 10 specialized AI agents collaborate to propose, critique, and refine SciML solutions through structured reasoning and iterative evolution. The framework integrates structured debate, retrieval-augmented method memory, and ensemble-guided evolutionary search, enabling the agents to generate and assess new hypotheses about architectures and optimization procedures. Across physics-informed learning and operator learning tasks, the framework discovers solution methods that outperform single-agent and human-designed baselines by up to four orders of magnitude in error reduction. The agents produce novel strategies -- including adaptive mixture-of-expert architectures, decomposition-based PINNs, and physics-informed operator learning models -- that do not appear explicitly in the curated knowledge base. These results show that collaborative reasoning among AI agents can yield emergent methodological innovation, suggesting a path toward scalable, transparent, and autonomous discovery in scientific computing.",
    "authors": [
      "Qile Jiang",
      "George Karniadakis"
    ],
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07262v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07262v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07338v1",
    "title": "DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas",
    "summary": "Simulating human profiles by instilling personas into large language models (LLMs) is rapidly transforming research in agentic behavioral simulation, LLM personalization, and human-AI alignment. However, most existing synthetic personas remain shallow and simplistic, capturing minimal attributes and failing to reflect the rich complexity and diversity of real human identities. We introduce DEEPPERSONA, a scalable generative engine for synthesizing narrative-complete synthetic personas through a two-stage, taxonomy-guided method. First, we algorithmically construct the largest-ever human-attribute taxonomy, comprising over hundreds of hierarchically organized attributes, by mining thousands of real user-ChatGPT conversations. Second, we progressively sample attributes from this taxonomy, conditionally generating coherent and realistic personas that average hundreds of structured attributes and roughly 1 MB of narrative text, two orders of magnitude deeper than prior works. Intrinsic evaluations confirm significant improvements in attribute diversity (32 percent higher coverage) and profile uniqueness (44 percent greater) compared to state-of-the-art baselines. Extrinsically, our personas enhance GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on average across ten metrics and substantially narrow (by 31.7 percent) the gap between simulated LLM citizens and authentic human responses in social surveys. Our generated national citizens reduced the performance gap on the Big Five personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA thus provides a rigorous, scalable, and privacy-free platform for high-fidelity human simulation and personalized AI research.",
    "authors": [
      "Zhen Wang",
      "Yufan Zhou",
      "Zhongyan Luo",
      "Lyumanshan Ye",
      "Adam Wood",
      "Man Yao",
      "Luoshang Pan"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07338v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07338v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.06430v1",
    "title": "CG-TTRL: Context-Guided Test-Time Reinforcement Learning for On-Device Large Language Models",
    "summary": "Test-time Reinforcement Learning (TTRL) has shown promise in adapting foundation models for complex tasks at test-time, resulting in large performance improvements. TTRL leverages an elegant two-phase sampling strategy: first, multi-sampling derives a pseudo-label via majority voting, while subsequent downsampling and reward-based fine-tuning encourages the model to explore and learn diverse valid solutions, with the pseudo-label modulating the reward signal. Meanwhile, in-context learning has been widely explored at inference time and demonstrated the ability to enhance model performance without weight updates. However, TTRL's two-phase sampling strategy under-utilizes contextual guidance, which can potentially improve pseudo-label accuracy in the initial exploitation phase while regulating exploration in the second. To address this, we propose context-guided TTRL (CG-TTRL), integrating context dynamically into both sampling phases and propose a method for efficient context selection for on-device applications. Our evaluations on mathematical and scientific QA benchmarks show CG-TTRL outperforms TTRL (e.g. additional 7% relative accuracy improvement over TTRL), while boosting efficiency by obtaining strong performance after only a few steps of test-time training (e.g. 8% relative improvement rather than 1% over TTRL after 3 steps).",
    "authors": [
      "Peyman Hosseini",
      "Ondrej Bohdal",
      "Taha Ceritli",
      "Ignacio Castro",
      "Matthew Purver",
      "Mete Ozay",
      "Umberto Michieli"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06430v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06430v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.06859v1",
    "title": "TuckA: Hierarchical Compact Tensor Experts for Efficient Fine-Tuning",
    "summary": "Efficiently fine-tuning pre-trained models for downstream tasks is a key challenge in the era of foundation models. Parameter-efficient fine-tuning (PEFT) presents a promising solution, achieving performance comparable to full fine-tuning by updating only a small number of adaptation weights per layer. Traditional PEFT methods typically rely on a single expert, where the adaptation weight is a low-rank matrix. However, for complex tasks, the data's inherent diversity poses a significant challenge for such models, as a single adaptation weight cannot adequately capture the features of all samples. To address this limitation, we explore how to integrate multiple small adaptation experts into a compact structure to defeat a large adapter. Specifically, we propose Tucker Adaptation (TuckA), a method with four key properties: (i) We use Tucker decomposition to create a compact 3D tensor where each slice naturally serves as an expert. The low-rank nature of this decomposition ensures that the number of parameters scales efficiently as more experts are added. (ii) We introduce a hierarchical strategy that organizes these experts into groups at different granularities, allowing the model to capture both local and global data patterns. (iii) We develop an efficient batch-level routing mechanism, which reduces the router's parameter size by a factor of $L$ compared to routing at every adapted layer (where $L$ is the number of adapted layers) (iv) We propose data-aware initialization to achieve loss-free expert load balancing based on theoretical analysis. Extensive experiments on benchmarks in natural language understanding, image classification, and mathematical reasoning speak to the efficacy of TuckA, offering a new and effective solution to the PEFT problem.",
    "authors": [
      "Qifeng Lei",
      "Zhiyong Yang",
      "Qianqian Xu",
      "Cong Hua",
      "Peisong Wen",
      "Qingming Huang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06859v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06859v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.06363v1",
    "title": "Privacy-Preserving Federated Learning for Fair and Efficient Urban Traffic Optimization",
    "summary": "The optimization of urban traffic is threatened by the complexity of achieving a balance between transport efficiency and the maintenance of privacy, as well as the equitable distribution of traffic based on socioeconomically diverse neighborhoods. Current centralized traffic management schemes invade user location privacy and further entrench traffic disparity by offering disadvantaged route suggestions, whereas current federated learning frameworks do not consider fairness constraints in multi-objective traffic settings. This study presents a privacy-preserving federated learning framework, termed FedFair-Traffic, that jointly and simultaneously optimizes travel efficiency, traffic fairness, and differential privacy protection. This is the first attempt to integrate three conflicting objectives to improve urban transportation systems. The proposed methodology enables collaborative learning between related vehicles with data locality by integrating Graph Neural Networks with differential privacy mechanisms ($ε$-privacy guarantees) and Gini coefficient-based fair constraints using multi-objective optimization. The framework uses federated aggregation methods of gradient clipping and noise injection to provide differential privacy and optimize Pareto-efficient solutions for the efficiency-fairness tradeoff. Real-world comprehensive experiments on the METR-LA traffic dataset showed that FedFair-Traffic can reduce the average travel time by 7\\% (14.2 minutes) compared with their centralized baselines, promote traffic fairness by 73\\% (Gini coefficient, 0.78), and offer high privacy protection (privacy score, 0.8) with an 89\\% reduction in communication overhead. These outcomes demonstrate that FedFair-Traffic is a scalable privacy-aware smart city infrastructure with possible use-cases in metropolitan traffic flow control and federated transportation networks.",
    "authors": [
      "Rathin Chandra Shit",
      "Sharmila Subudhi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI",
      "eess.SY"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06363v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06363v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07166v1",
    "title": "AdaRec: Adaptive Recommendation with LLMs via Narrative Profiling and Dual-Channel Reasoning",
    "summary": "We propose AdaRec, a few-shot in-context learning framework that leverages large language models for an adaptive personalized recommendation. AdaRec introduces narrative profiling, transforming user-item interactions into natural language representations to enable unified task handling and enhance human readability. Centered on a bivariate reasoning paradigm, AdaRec employs a dual-channel architecture that integrates horizontal behavioral alignment, discovering peer-driven patterns, with vertical causal attribution, highlighting decisive factors behind user preferences. Unlike existing LLM-based approaches, AdaRec eliminates manual feature engineering through semantic representations and supports rapid cross-task adaptation with minimal supervision. Experiments on real ecommerce datasets demonstrate that AdaRec outperforms both machine learning models and LLM-based baselines by up to eight percent in few-shot settings. In zero-shot scenarios, it achieves up to a nineteen percent improvement over expert-crafted profiling, showing effectiveness for long-tail personalization with minimal interaction data. Furthermore, lightweight fine-tuning on synthetic data generated by AdaRec matches the performance of fully fine-tuned models, highlighting its efficiency and generalization across diverse tasks.",
    "authors": [
      "Meiyun Wang",
      "Charin Polpanumas"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07166v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07166v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.06852v1",
    "title": "Differentiated Directional Intervention A Framework for Evading LLM Safety Alignment",
    "summary": "Safety alignment instills in Large Language Models (LLMs) a critical capacity to refuse malicious requests. Prior works have modeled this refusal mechanism as a single linear direction in the activation space. We posit that this is an oversimplification that conflates two functionally distinct neural processes: the detection of harm and the execution of a refusal. In this work, we deconstruct this single representation into a Harm Detection Direction and a Refusal Execution Direction. Leveraging this fine-grained model, we introduce Differentiated Bi-Directional Intervention (DBDI), a new white-box framework that precisely neutralizes the safety alignment at critical layer. DBDI applies adaptive projection nullification to the refusal execution direction while suppressing the harm detection direction via direct steering. Extensive experiments demonstrate that DBDI outperforms prominent jailbreaking methods, achieving up to a 97.88\\% attack success rate on models such as Llama-2. By providing a more granular and mechanistic framework, our work offers a new direction for the in-depth understanding of LLM safety alignment.",
    "authors": [
      "Peng Zhang",
      "peijie sun"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06852v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06852v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.06817v1",
    "title": "TiS-TSL: Image-Label Supervised Surgical Video Stereo Matching via Time-Switchable Teacher-Student Learning",
    "summary": "Stereo matching in minimally invasive surgery (MIS) is essential for next-generation navigation and augmented reality. Yet, dense disparity supervision is nearly impossible due to anatomical constraints, typically limiting annotations to only a few image-level labels acquired before the endoscope enters deep body cavities. Teacher-Student Learning (TSL) offers a promising solution by leveraging a teacher trained on sparse labels to generate pseudo labels and associated confidence maps from abundant unlabeled surgical videos. However, existing TSL methods are confined to image-level supervision, providing only spatial confidence and lacking temporal consistency estimation. This absence of spatio-temporal reliability results in unstable disparity predictions and severe flickering artifacts across video frames. To overcome these challenges, we propose TiS-TSL, a novel time-switchable teacher-student learning framework for video stereo matching under minimal supervision. At its core is a unified model that operates in three distinct modes: Image-Prediction (IP), Forward Video-Prediction (FVP), and Backward Video-Prediction (BVP), enabling flexible temporal modeling within a single architecture. Enabled by this unified model, TiS-TSL adopts a two-stage learning strategy. The Image-to-Video (I2V) stage transfers sparse image-level knowledge to initialize temporal modeling. The subsequent Video-to-Video (V2V) stage refines temporal disparity predictions by comparing forward and backward predictions to calculate bidirectional spatio-temporal consistency. This consistency identifies unreliable regions across frames, filters noisy video-level pseudo labels, and enforces temporal coherence. Experimental results on two public datasets demonstrate that TiS-TSL exceeds other image-based state-of-the-arts by improving TEPE and EPE by at least 2.11% and 4.54%, respectively..",
    "authors": [
      "Rui Wang",
      "Ying Zhou",
      "Hao Wang",
      "Wenwei Zhang",
      "Qiang Li",
      "Zhiwei Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06817v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06817v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.06678v1",
    "title": "Flexible Concept Bottleneck Model",
    "summary": "Concept bottleneck models (CBMs) improve neural network interpretability by introducing an intermediate layer that maps human-understandable concepts to predictions. Recent work has explored the use of vision-language models (VLMs) to automate concept selection and annotation. However, existing VLM-based CBMs typically require full model retraining when new concepts are involved, which limits their adaptability and flexibility in real-world scenarios, especially considering the rapid evolution of vision-language foundation models. To address these issues, we propose Flexible Concept Bottleneck Model (FCBM), which supports dynamic concept adaptation, including complete replacement of the original concept set. Specifically, we design a hypernetwork that generates prediction weights based on concept embeddings, allowing seamless integration of new concepts without retraining the entire model. In addition, we introduce a modified sparsemax module with a learnable temperature parameter that dynamically selects the most relevant concepts, enabling the model to focus on the most informative features. Extensive experiments on five public benchmarks demonstrate that our method achieves accuracy comparable to state-of-the-art baselines with a similar number of effective concepts. Moreover, the model generalizes well to unseen concepts with just a single epoch of fine-tuning, demonstrating its strong adaptability and flexibility.",
    "authors": [
      "Xingbo Du",
      "Qiantong Dou",
      "Lei Fan",
      "Rui Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06678v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06678v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.06172v1",
    "title": "MambaOVSR: Multiscale Fusion with Global Motion Modeling for Chinese Opera Video Super-Resolution",
    "summary": "Chinese opera is celebrated for preserving classical art. However, early filming equipment limitations have degraded videos of last-century performances by renowned artists (e.g., low frame rates and resolution), hindering archival efforts. Although space-time video super-resolution (STVSR) has advanced significantly, applying it directly to opera videos remains challenging. The scarcity of datasets impedes the recovery of high frequency details, and existing STVSR methods lack global modeling capabilities, compromising visual quality when handling opera's characteristic large motions. To address these challenges, we pioneer a large scale Chinese Opera Video Clip (COVC) dataset and propose the Mamba-based multiscale fusion network for space-time Opera Video Super-Resolution (MambaOVSR). Specifically, MambaOVSR involves three novel components: the Global Fusion Module (GFM) for motion modeling through a multiscale alternating scanning mechanism, and the Multiscale Synergistic Mamba Module (MSMM) for alignment across different sequence lengths. Additionally, our MambaVR block resolves feature artifacts and positional information loss during alignment. Experimental results on the COVC dataset show that MambaOVSR significantly outperforms the SOTA STVSR method by an average of 1.86 dB in terms of PSNR. Dataset and Code will be publicly released.",
    "authors": [
      "Hua Chang",
      "Xin Xu",
      "Wei Liu",
      "Wei Wang",
      "Xin Yuan",
      "Kui Jiang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06172v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06172v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07103v1",
    "title": "GEWDiff: Geometric Enhanced Wavelet-based Diffusion Model for Hyperspectral Image Super-resolution",
    "summary": "Improving the quality of hyperspectral images (HSIs), such as through super-resolution, is a crucial research area. However, generative modeling for HSIs presents several challenges. Due to their high spectral dimensionality, HSIs are too memory-intensive for direct input into conventional diffusion models. Furthermore, general generative models lack an understanding of the topological and geometric structures of ground objects in remote sensing imagery. In addition, most diffusion models optimize loss functions at the noise level, leading to a non-intuitive convergence behavior and suboptimal generation quality for complex data. To address these challenges, we propose a Geometric Enhanced Wavelet-based Diffusion Model (GEWDiff), a novel framework for reconstructing hyperspectral images at 4-times super-resolution. A wavelet-based encoder-decoder is introduced that efficiently compresses HSIs into a latent space while preserving spectral-spatial information. To avoid distortion during generation, we incorporate a geometry-enhanced diffusion process that preserves the geometric features. Furthermore, a multi-level loss function was designed to guide the diffusion process, promoting stable convergence and improved reconstruction fidelity. Our model demonstrated state-of-the-art results across multiple dimensions, including fidelity, spectral accuracy, visual realism, and clarity.",
    "authors": [
      "Sirui Wang",
      "Jiang He",
      "Natàlia Blasco Andreo",
      "Xiao Xiang Zhu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07103v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07103v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07156v1",
    "title": "Conditional Diffusion as Latent Constraints for Controllable Symbolic Music Generation",
    "summary": "Recent advances in latent diffusion models have demonstrated state-of-the-art performance in high-dimensional time-series data synthesis while providing flexible control through conditioning and guidance. However, existing methodologies primarily rely on musical context or natural language as the main modality of interacting with the generative process, which may not be ideal for expert users who seek precise fader-like control over specific musical attributes. In this work, we explore the application of denoising diffusion processes as plug-and-play latent constraints for unconditional symbolic music generation models. We focus on a framework that leverages a library of small conditional diffusion models operating as implicit probabilistic priors on the latents of a frozen unconditional backbone. While previous studies have explored domain-specific use cases, this work, to the best of our knowledge, is the first to demonstrate the versatility of such an approach across a diverse array of musical attributes, such as note density, pitch range, contour, and rhythm complexity. Our experiments show that diffusion-driven constraints outperform traditional attribute regularization and other latent constraints architectures, achieving significantly stronger correlations between target and generated attributes while maintaining high perceptual quality and diversity.",
    "authors": [
      "Matteo Pettenó",
      "Alessandro Ilic Mezza",
      "Alberto Bernardini"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.AS"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07156v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07156v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.06450v1",
    "title": "Countering Multi-modal Representation Collapse through Rank-targeted Fusion",
    "summary": "Multi-modal fusion methods often suffer from two types of representation collapse: feature collapse where individual dimensions lose their discriminative power (as measured by eigenspectra), and modality collapse where one dominant modality overwhelms the other. Applications like human action anticipation that require fusing multifarious sensor data are hindered by both feature and modality collapse. However, existing methods attempt to counter feature collapse and modality collapse separately. This is because there is no unifying framework that efficiently addresses feature and modality collapse in conjunction. In this paper, we posit the utility of effective rank as an informative measure that can be utilized to quantify and counter both the representation collapses. We propose \\textit{Rank-enhancing Token Fuser}, a theoretically grounded fusion framework that selectively blends less informative features from one modality with complementary features from another modality. We show that our method increases the effective rank of the fused representation. To address modality collapse, we evaluate modality combinations that mutually increase each others' effective rank. We show that depth maintains representational balance when fused with RGB, avoiding modality collapse. We validate our method on action anticipation, where we present \\texttt{R3D}, a depth-informed fusion framework. Extensive experiments on NTURGBD, UTKinect, and DARai demonstrate that our approach significantly outperforms prior state-of-the-art methods by up to 3.74\\%. Our code is available at: \\href{https://github.com/olivesgatech/R3D}{https://github.com/olivesgatech/R3D}.",
    "authors": [
      "Seulgi Kim",
      "Kiran Kokilepersaud",
      "Mohit Prabhushankar",
      "Ghassan AlRegib"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06450v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06450v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.06169v1",
    "title": "Local K-Similarity Constraint for Federated Learning with Label Noise",
    "summary": "Federated learning on clients with noisy labels is a challenging problem, as such clients can infiltrate the global model, impacting the overall generalizability of the system. Existing methods proposed to handle noisy clients assume that a sufficient number of clients with clean labels are available, which can be leveraged to learn a robust global model while dampening the impact of noisy clients. This assumption fails when a high number of heterogeneous clients contain noisy labels, making the existing approaches ineffective. In such scenarios, it is important to locally regularize the clients before communication with the global model, to ensure the global model isn't corrupted by noisy clients. While pre-trained self-supervised models can be effective for local regularization, existing centralized approaches relying on pretrained initialization are impractical in a federated setting due to the potentially large size of these models, which increases communication costs. In that line, we propose a regularization objective for client models that decouples the pre-trained and classification models by enforcing similarity between close data points within the client. We leverage the representation space of a self-supervised pretrained model to evaluate the closeness among examples. This regularization, when applied with the standard objective function for the downstream task in standard noisy federated settings, significantly improves performance, outperforming existing state-of-the-art federated methods in multiple computer vision and medical image classification benchmarks. Unlike other techniques that rely on self-supervised pretrained initialization, our method does not require the pretrained model and classifier backbone to share the same architecture, making it architecture-agnostic.",
    "authors": [
      "Sanskar Amgain",
      "Prashant Shrestha",
      "Bidur Khanal",
      "Alina Devkota",
      "Yash Raj Shrestha",
      "Seungryul Baek",
      "Prashnna Gyawali",
      "Binod Bhattarai"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06169v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06169v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07318v1",
    "title": "When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs",
    "summary": "Despite substantial advances, large language models (LLMs) continue to exhibit hallucinations, generating plausible yet incorrect responses. In this paper, we highlight a critical yet previously underexplored class of hallucinations driven by spurious correlations -- superficial but statistically prominent associations between features (e.g., surnames) and attributes (e.g., nationality) present in the training data. We demonstrate that these spurious correlations induce hallucinations that are confidently generated, immune to model scaling, evade current detection methods, and persist even after refusal fine-tuning. Through systematically controlled synthetic experiments and empirical evaluations on state-of-the-art open-source and proprietary LLMs (including GPT-5), we show that existing hallucination detection methods, such as confidence-based filtering and inner-state probing, fundamentally fail in the presence of spurious correlations. Our theoretical analysis further elucidates why these statistical biases intrinsically undermine confidence-based detection techniques. Our findings thus emphasize the urgent need for new approaches explicitly designed to address hallucinations caused by spurious correlations.",
    "authors": [
      "Shaowen Wang",
      "Yiqi Dong",
      "Ruinian Chang",
      "Tansheng Zhu",
      "Yuebo Sun",
      "Kaifeng Lyu",
      "Jian Li"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07318v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07318v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.07362v1",
    "title": "Inference-Time Scaling of Diffusion Models for Infrared Data Generation",
    "summary": "Infrared imagery enables temperature-based scene understanding using passive sensors, particularly under conditions of low visibility where traditional RGB imaging fails. Yet, developing downstream vision models for infrared applications is hindered by the scarcity of high-quality annotated data, due to the specialized expertise required for infrared annotation. While synthetic infrared image generation has the potential to accelerate model development by providing large-scale, diverse training data, training foundation-level generative diffusion models in the infrared domain has remained elusive due to limited datasets. In light of such data constraints, we explore an inference-time scaling approach using a domain-adapted CLIP-based verifier for enhanced infrared image generation quality. We adapt FLUX.1-dev, a state-of-the-art text-to-image diffusion model, to the infrared domain by finetuning it on a small sample of infrared images using parameter-efficient techniques. The trained verifier is then employed during inference to guide the diffusion sampling process toward higher quality infrared generations that better align with input text prompts. Empirically, we find that our approach leads to consistent improvements in generation quality, reducing FID scores on the KAIST Multispectral Pedestrian Detection Benchmark dataset by 10% compared to unguided baseline samples. Our results suggest that inference-time guidance offers a promising direction for bridging the domain gap in low-data infrared settings.",
    "authors": [
      "Kai A. Horstmann",
      "Maxim Clouser",
      "Kia Khezeli"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07362v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07362v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06854v1",
    "title": "Beyond Observations: Reconstruction Error-Guided Irregularly Sampled Time Series Representation Learning",
    "summary": "Irregularly sampled time series (ISTS), characterized by non-uniform time intervals with natural missingness, are prevalent in real-world applications. Existing approaches for ISTS modeling primarily rely on observed values to impute unobserved ones or infer latent dynamics. However, these methods overlook a critical source of learning signal: the reconstruction error inherently produced during model training. Such error implicitly reflects how well a model captures the underlying data structure and can serve as an informative proxy for unobserved values. To exploit this insight, we propose iTimER, a simple yet effective self-supervised pre-training framework for ISTS representation learning. iTimER models the distribution of reconstruction errors over observed values and generates pseudo-observations for unobserved timestamps through a mixup strategy between sampled errors and the last available observations. This transforms unobserved timestamps into noise-aware training targets, enabling meaningful reconstruction signals. A Wasserstein metric aligns reconstruction error distributions between observed and pseudo-observed regions, while a contrastive learning objective enhances the discriminability of learned representations. Extensive experiments on classification, interpolation, and forecasting tasks demonstrate that iTimER consistently outperforms state-of-the-art methods under the ISTS setting.",
    "authors": [
      "Jiexi Liu",
      "Meng Cao",
      "Songcan Chen"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06854v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06854v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06634v1",
    "title": "CaberNet: Causal Representation Learning for Cross-Domain HVAC Energy Prediction",
    "summary": "Cross-domain HVAC energy prediction is essential for scalable building energy management, particularly because collecting extensive labeled data for every new building is both costly and impractical. Yet, this task remains highly challenging due to the scarcity and heterogeneity of data across different buildings, climate zones, and seasonal patterns. In particular, buildings situated in distinct climatic regions introduce variability that often leads existing methods to overfit to spurious correlations, rely heavily on expert intervention, or compromise on data diversity. To address these limitations, we propose CaberNet, a causal and interpretable deep sequence model that learns invariant (Markov blanket) representations for robust cross-domain prediction. In a purely data-driven fashion and without requiring any prior knowledge, CaberNet integrates i) a global feature gate trained with a self-supervised Bernoulli regularization to distinguish superior causal features from inferior ones, and ii) a domain-wise training scheme that balances domain contributions, minimizes cross-domain loss variance, and promotes latent factor independence. We evaluate CaberNet on real-world datasets collected from three buildings located in three climatically diverse cities, and it consistently outperforms all baselines, achieving a 22.9\\% reduction in normalized mean squared error (NMSE) compared to the best benchmark. Our code is available at https://github.com/rickzky1001/CaberNet-CRL.",
    "authors": [
      "Kaiyuan Zhai",
      "Jiacheng Cui",
      "Zhehao Zhang",
      "Junyu Xue",
      "Yang Deng",
      "Kui Wu",
      "Guoming Tang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06634v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06634v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06715v1",
    "title": "Sensor Calibration Model Balancing Accuracy, Real-time, and Efficiency",
    "summary": "Most on-device sensor calibration studies benchmark models only against three macroscopic requirements (i.e., accuracy, real-time, and resource efficiency), thereby hiding deployment bottlenecks such as instantaneous error and worst-case latency. We therefore decompose this triad into eight microscopic requirements and introduce Scare (Sensor Calibration model balancing Accuracy, Real-time, and Efficiency), an ultra-compressed transformer that fulfills them all. SCARE comprises three core components: (1) Sequence Lens Projector (SLP) that logarithmically compresses time-series data while preserving boundary information across bins, (2) Efficient Bitwise Attention (EBA) module that replaces costly multiplications with bitwise operations via binary hash codes, and (3) Hash optimization strategy that ensures stable training without auxiliary loss terms. Together, these components minimize computational overhead while maintaining high accuracy and compatibility with microcontroller units (MCUs). Extensive experiments on large-scale air-quality datasets and real microcontroller deployments demonstrate that Scare outperforms existing linear, hybrid, and deep-learning baselines, making Scare, to the best of our knowledge, the first model to meet all eight microscopic requirements simultaneously.",
    "authors": [
      "Jinyong Yun",
      "Hyungjin Kim",
      "Seokho Ahn",
      "Euijong Lee",
      "Young-Duk Seo"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06715v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06715v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.07092v1",
    "title": "Sample-efficient quantum error mitigation via classical learning surrogates",
    "summary": "The pursuit of practical quantum utility on near-term quantum processors is critically challenged by their inherent noise. Quantum error mitigation (QEM) techniques are leading solutions to improve computation fidelity with relatively low qubit-overhead, while full-scale quantum error correction remains a distant goal. However, QEM techniques incur substantial measurement overheads, especially when applied to families of quantum circuits parameterized by classical inputs. Focusing on zero-noise extrapolation (ZNE), a widely adopted QEM technique, here we devise the surrogate-enabled ZNE (S-ZNE), which leverages classical learning surrogates to perform ZNE entirely on the classical side. Unlike conventional ZNE, whose measurement cost scales linearly with the number of circuits, S-ZNE requires only constant measurement overhead for an entire family of quantum circuits, offering superior scalability. Theoretical analysis indicates that S-ZNE achieves accuracy comparable to conventional ZNE in many practical scenarios, and numerical experiments on up to 100-qubit ground-state energy and quantum metrology tasks confirm its effectiveness. Our approach provides a template that can be effectively extended to other quantum error mitigation protocols, opening a promising path toward scalable error mitigation.",
    "authors": [
      "Wei-You Liao",
      "Ge Yan",
      "Yujin Song",
      "Tian-Ci Tian",
      "Wei-Ming Zhu",
      "De-Tao Jiang",
      "Yuxuan Du",
      "He-Liang Huang"
    ],
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07092v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07092v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06239v1",
    "title": "Functional Adjoint Sampler: Scalable Sampling on Infinite Dimensional Spaces",
    "summary": "Learning-based methods for sampling from the Gibbs distribution in finite-dimensional spaces have progressed quickly, yet theory and algorithmic design for infinite-dimensional function spaces remain limited. This gap persists despite their strong potential for sampling the paths of conditional diffusion processes, enabling efficient simulation of trajectories of diffusion processes that respect rare events or boundary constraints. In this work, we present the adjoint sampler for infinite-dimensional function spaces, a stochastic optimal control-based diffusion sampler that operates in function space and targets Gibbs-type distributions on infinite-dimensional Hilbert spaces. Our Functional Adjoint Sampler (FAS) generalizes Adjoint Sampling (Havens et al., 2025) to Hilbert spaces based on a SOC theory called stochastic maximum principle, yielding a simple and scalable matching-type objective for a functional representation. We show that FAS achieves superior transition path sampling performance across synthetic potential and real molecular systems, including Alanine Dipeptide and Chignolin.",
    "authors": [
      "Byoungwoo Park",
      "Juho Lee",
      "Guan-Horng Liu"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06239v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06239v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06496v1",
    "title": "A Low-Rank Method for Vision Language Model Hallucination Mitigation in Autonomous Driving",
    "summary": "Vision Language Models (VLMs) are increasingly used in autonomous driving to help understand traffic scenes, but they sometimes produce hallucinations, which are false details not grounded in the visual input. Detecting and mitigating hallucinations is challenging when ground-truth references are unavailable and model internals are inaccessible. This paper proposes a novel self-contained low-rank approach to automatically rank multiple candidate captions generated by multiple VLMs based on their hallucination levels, using only the captions themselves without requiring external references or model access. By constructing a sentence-embedding matrix and decomposing it into a low-rank consensus component and a sparse residual, we use the residual magnitude to rank captions: selecting the one with the smallest residual as the most hallucination-free. Experiments on the NuScenes dataset demonstrate that our approach achieves 87% selection accuracy in identifying hallucination-free captions, representing a 19% improvement over the unfiltered baseline and a 6-10% improvement over multi-agent debate method. The sorting produced by sparse error magnitudes shows strong correlation with human judgments of hallucinations, validating our scoring mechanism. Additionally, our method, which can be easily parallelized, reduces inference time by 51-67% compared to debate approaches, making it practical for real-time autonomous driving applications.",
    "authors": [
      "Keke Long",
      "Jiacheng Guo",
      "Tianyun Zhang",
      "Hongkai Yu",
      "Xiaopeng Li"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06496v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06496v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06494v1",
    "title": "Route Experts by Sequence, not by Token",
    "summary": "Mixture-of-Experts (MoE) architectures scale large language models (LLMs) by activating only a subset of experts per token, but the standard TopK routing assigns the same fixed number of experts to all tokens, ignoring their varying complexity. Prior adaptive routing methods introduce additional modules and hyperparameters, often requiring costly retraining from scratch. We propose Sequence-level TopK (SeqTopK), a minimal modification that shifts the expert budget from the token level to the sequence level. By selecting the top $T \\cdot K$ experts across all $T$ tokens, SeqTopK enables end-to-end learned dynamic allocation -- assigning more experts to difficult tokens and fewer to easy ones -- while preserving the same overall budget. SeqTopK requires only a few lines of code, adds less than 1% overhead, and remains fully compatible with pretrained MoE models. Experiments across math, coding, law, and writing show consistent improvements over TopK and prior parameter-free adaptive methods, with gains that become substantially larger under higher sparsity (up to 16.9%). These results highlight SeqTopK as a simple, efficient, and scalable routing strategy, particularly well-suited for the extreme sparsity regimes of next-generation LLMs. Code is available at https://github.com/Y-Research-SBU/SeqTopK.",
    "authors": [
      "Tiansheng Wen",
      "Yifei Wang",
      "Aosong Feng",
      "Long Ma",
      "Xinyang Liu",
      "Yifan Wang",
      "Lixuan Guo",
      "Bo Chen",
      "Stefanie Jegelka",
      "Chenyu You"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06494v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06494v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06458v1",
    "title": "EchoMark: Perceptual Acoustic Environment Transfer with Watermark-Embedded Room Impulse Response",
    "summary": "Acoustic Environment Matching (AEM) is the task of transferring clean audio into a target acoustic environment, enabling engaging applications such as audio dubbing and auditory immersive virtual reality (VR). Recovering similar room impulse response (RIR) directly from reverberant speech offers more accessible and flexible AEM solution. However, this capability also introduces vulnerabilities of arbitrary ``relocation\" if misused by malicious user, such as facilitating advanced voice spoofing attacks or undermining the authenticity of recorded evidence. To address this issue, we propose EchoMark, the first deep learning-based AEM framework that generates perceptually similar RIRs with embedded watermark. Our design tackle the challenges posed by variable RIR characteristics, such as different durations and energy decays, by operating in the latent domain. By jointly optimizing the model with a perceptual loss for RIR reconstruction and a loss for watermark detection, EchoMark achieves both high-quality environment transfer and reliable watermark recovery. Experiments on diverse datasets validate that EchoMark achieves room acoustic parameter matching performance comparable to FiNS, the state-of-the-art RIR estimator. Furthermore, a high Mean Opinion Score (MOS) of 4.22 out of 5, watermark detection accuracy exceeding 99\\%, and bit error rates (BER) below 0.3\\% collectively demonstrate the effectiveness of EchoMark in preserving perceptual quality while ensuring reliable watermark embedding.",
    "authors": [
      "Chenpei Huang",
      "Lingfeng Yao",
      "Kyu In Lee",
      "Lan Emily Zhang",
      "Xun Chen",
      "Miao Pan"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06458v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06458v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06946v1",
    "title": "Learning to Focus: Prioritizing Informative Histories with Structured Attention Mechanisms in Partially Observable Reinforcement Learning",
    "summary": "Transformers have shown strong ability to model long-term dependencies and are increasingly adopted as world models in model-based reinforcement learning (RL) under partial observability. However, unlike natural language corpora, RL trajectories are sparse and reward-driven, making standard self-attention inefficient because it distributes weight uniformly across all past tokens rather than emphasizing the few transitions critical for control. To address this, we introduce structured inductive priors into the self-attention mechanism of the dynamics head: (i) per-head memory-length priors that constrain attention to task-specific windows, and (ii) distributional priors that learn smooth Gaussian weightings over past state-action pairs. We integrate these mechanisms into UniZero, a model-based RL agent with a Transformer-based world model that supports planning under partial observability. Experiments on the Atari 100k benchmark show that most efficiency gains arise from the Gaussian prior, which smoothly allocates attention to informative transitions, while memory-length priors often truncate useful signals with overly restrictive cut-offs. In particular, Gaussian Attention achieves a 77% relative improvement in mean human-normalized scores over UniZero. These findings suggest that in partially observable RL domains with non-stationary temporal dependencies, discrete memory windows are difficult to learn reliably, whereas smooth distributional priors flexibly adapt across horizons and yield more robust data efficiency. Overall, our results demonstrate that encoding structured temporal priors directly into self-attention improves the prioritization of informative histories for dynamics modeling under partial observability.",
    "authors": [
      "Daniel De Dios Allegue",
      "Jinke He",
      "Frans A. Oliehoek"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06946v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06946v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06470v1",
    "title": "Brain-Inspired Planning for Better Generalization in Reinforcement Learning",
    "summary": "Existing Reinforcement Learning (RL) systems encounter significant challenges when applied to real-world scenarios, primarily due to poor generalization across environments that differ from their training conditions. This thesis explores the direction of enhancing agents' zero-shot systematic generalization abilities by granting RL agents reasoning behaviors that are found to help systematic generalization in the human brain. Inspired by human conscious planning behaviors, we first introduced a top-down attention mechanism, which allows a decision-time planning agent to dynamically focus its reasoning on the most relevant aspects of the environmental state given its instantaneous intentions, a process we call \"spatial abstraction\". This approach significantly improves systematic generalization outside the training tasks. Subsequently, building on spatial abstraction, we developed the Skipper framework to automatically decompose complex tasks into simpler, more manageable sub-tasks. Skipper provides robustness against distributional shifts and efficacy in long-term, compositional planning by focusing on pertinent spatial and temporal elements of the environment. Finally, we identified a common failure mode and safety risk in planning agents that rely on generative models to generate state targets during planning. It is revealed that most agents blindly trust the targets they hallucinate, resulting in delusional planning behaviors. Inspired by how the human brain rejects delusional intentions, we propose learning a feasibility evaluator to enable rejecting hallucinated infeasible targets, which led to significant performance improvements in various kinds of planning agents. Finally, we suggest directions for future research, aimed at achieving general task abstraction and fully enabling abstract planning.",
    "authors": [
      "Mingde \"Harry\" Zhao"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06470v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06470v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.07099v1",
    "title": "E2E-VGuard: Adversarial Prevention for Production LLM-based End-To-End Speech Synthesis",
    "summary": "Recent advancements in speech synthesis technology have enriched our daily lives, with high-quality and human-like audio widely adopted across real-world applications. However, malicious exploitation like voice-cloning fraud poses severe security risks. Existing defense techniques struggle to address the production large language model (LLM)-based speech synthesis. While previous studies have considered the protection for fine-tuning synthesizers, they assume manually annotated transcripts. Given the labor intensity of manual annotation, end-to-end (E2E) systems leveraging automatic speech recognition (ASR) to generate transcripts are becoming increasingly prevalent, e.g., voice cloning via commercial APIs. Therefore, this E2E speech synthesis also requires new security mechanisms. To tackle these challenges, we propose E2E-VGuard, a proactive defense framework for two emerging threats: (1) production LLM-based speech synthesis, and (2) the novel attack arising from ASR-driven E2E scenarios. Specifically, we employ the encoder ensemble with a feature extractor to protect timbre, while ASR-targeted adversarial examples disrupt pronunciation. Moreover, we incorporate the psychoacoustic model to ensure perturbative imperceptibility. For a comprehensive evaluation, we test 16 open-source synthesizers and 3 commercial APIs across Chinese and English datasets, confirming E2E-VGuard's effectiveness in timbre and pronunciation protection. Real-world deployment validation is also conducted. Our code and demo page are available at https://wxzyd123.github.io/e2e-vguard/.",
    "authors": [
      "Zhisheng Zhang",
      "Derui Wang",
      "Yifan Mi",
      "Zhiyong Wu",
      "Jie Gao",
      "Yuxin Cao",
      "Kai Ye",
      "Minhui Xue",
      "Jie Hao"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07099v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07099v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.06325v1",
    "title": "CINEMAE: Leveraging Frozen Masked Autoencoders for Cross-Generator AI Image Detection",
    "summary": "While context-based detectors have achieved strong generalization for AI-generated text by measuring distributional inconsistencies, image-based detectors still struggle with overfitting to generator-specific artifacts. We introduce CINEMAE, a novel paradigm for AIGC image detection that adapts the core principles of text detection methods to the visual domain. Our key insight is that Masked AutoEncoder (MAE), trained to reconstruct masked patches conditioned on visible context, naturally encodes semantic consistency expectations. We formalize this reconstruction process probabilistically, computing conditional Negative Log-Likelihood (NLL, p(masked | visible)) to quantify local semantic anomalies. By aggregating these patch-level statistics with global MAE features through learned fusion, CINEMAE achieves strong cross-generator generalization. Trained exclusively on Stable Diffusion v1.4, our method achieves over 95% accuracy on all eight unseen generators in the GenImage benchmark, substantially outperforming state-of-the-art detectors. This demonstrates that context-conditional reconstruction uncertainty provides a robust, transferable signal for AIGC detection.",
    "authors": [
      "Minsuk Jang",
      "Hyeonseo Jeong",
      "Minseok Son",
      "Changick Kim"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06325v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06325v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.07332v1",
    "title": "Grounding Computer Use Agents on Human Demonstrations",
    "summary": "Building reliable computer-use agents requires grounding: accurately connecting natural language instructions to the correct on-screen elements. While large datasets exist for web and mobile interactions, high-quality resources for desktop environments are limited. To address this gap, we introduce GroundCUA, a large-scale desktop grounding dataset built from expert human demonstrations. It covers 87 applications across 12 categories and includes 56K screenshots, with every on-screen element carefully annotated for a total of over 3.56M human-verified annotations. From these demonstrations, we generate diverse instructions that capture a wide range of real-world tasks, providing high-quality data for model training. Using GroundCUA, we develop the GroundNext family of models that map instructions to their target UI elements. At both 3B and 7B scales, GroundNext achieves state-of-the-art results across five benchmarks using supervised fine-tuning, while requiring less than one-tenth the training data of prior work. Reinforcement learning post-training further improves performance, and when evaluated in an agentic setting on the OSWorld benchmark using o3 as planner, GroundNext attains comparable or superior results to models trained with substantially more data,. These results demonstrate the critical role of high-quality, expert-driven datasets in advancing general-purpose computer-use agents.",
    "authors": [
      "Aarash Feizi",
      "Shravan Nayak",
      "Xiangru Jian",
      "Kevin Qinghong Lin",
      "Kaixin Li",
      "Rabiul Awal",
      "Xing Han Lù",
      "Johan Obando-Ceron",
      "Juan A. Rodriguez",
      "Nicolas Chapados",
      "David Vazquez",
      "Adriana Romero-Soriano",
      "Reihaneh Rabbany",
      "Perouz Taslakian",
      "Christopher Pal",
      "Spandana Gella",
      "Sai Rajeswar"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07332v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07332v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.06645v1",
    "title": "Adaptive Testing for Segmenting Watermarked Texts From Language Models",
    "summary": "The rapid adoption of large language models (LLMs), such as GPT-4 and Claude 3.5, underscores the need to distinguish LLM-generated text from human-written content to mitigate the spread of misinformation and misuse in education. One promising approach to address this issue is the watermark technique, which embeds subtle statistical signals into LLM-generated text to enable reliable identification. In this paper, we first generalize the likelihood-based LLM detection method of a previous study by introducing a flexible weighted formulation, and further adapt this approach to the inverse transform sampling method. Moving beyond watermark detection, we extend this adaptive detection strategy to tackle the more challenging problem of segmenting a given text into watermarked and non-watermarked substrings. In contrast to the approach in a previous study, which relies on accurate estimation of next-token probabilities that are highly sensitive to prompt estimation, our proposed framework removes the need for precise prompt estimation. Extensive numerical experiments demonstrate that the proposed methodology is both effective and robust in accurately segmenting texts containing a mixture of watermarked and non-watermarked content.",
    "authors": [
      "Xingchi Li",
      "Xiaochi Liu",
      "Guanxun Li"
    ],
    "categories": [
      "stat.ML",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06645v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06645v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07364v1",
    "title": "Self-Evaluating LLMs for Multi-Step Tasks: Stepwise Confidence Estimation for Failure Detection",
    "summary": "Reliability and failure detection of large language models (LLMs) is critical for their deployment in high-stakes, multi-step reasoning tasks. Prior work explores confidence estimation for self-evaluating LLM-scorer systems, with confidence scorers estimating the likelihood of errors in LLM responses. However, most methods focus on single-step outputs and overlook the challenges of multi-step reasoning. In this work, we extend self-evaluation techniques to multi-step tasks, testing two intuitive approaches: holistic scoring and step-by-step scoring. Using two multi-step benchmark datasets, we show that stepwise evaluation generally outperforms holistic scoring in detecting potential errors, with up to 15% relative increase in AUC-ROC. Our findings demonstrate that self-evaluating LLM systems provide meaningful confidence estimates in complex reasoning, improving their trustworthiness and providing a practical framework for failure detection.",
    "authors": [
      "Vaibhav Mavi",
      "Shubh Jaroria",
      "Weiqi Sun"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07364v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07364v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.06252v1",
    "title": "MrCoM: A Meta-Regularized World-Model Generalizing Across Multi-Scenarios",
    "summary": "Model-based reinforcement learning (MBRL) is a crucial approach to enhance the generalization capabilities and improve the sample efficiency of RL algorithms. However, current MBRL methods focus primarily on building world models for single tasks and rarely address generalization across different scenarios. Building on the insight that dynamics within the same simulation engine share inherent properties, we attempt to construct a unified world model capable of generalizing across different scenarios, named Meta-Regularized Contextual World-Model (MrCoM). This method first decomposes the latent state space into various components based on the dynamic characteristics, thereby enhancing the accuracy of world-model prediction. Further, MrCoM adopts meta-state regularization to extract unified representation of scenario-relevant information, and meta-value regularization to align world-model optimization with policy learning across diverse scenario objectives. We theoretically analyze the generalization error upper bound of MrCoM in multi-scenario settings. We systematically evaluate our algorithm's generalization ability across diverse scenarios, demonstrating significantly better performance than previous state-of-the-art methods.",
    "authors": [
      "Xuantang Xiong",
      "Ni Mu",
      "Runpeng Xie",
      "Senhao Yang",
      "Yaqing Wang",
      "Lexiang Wang",
      "Yao Luan",
      "Siyuan Li",
      "Shuang Xu",
      "Yiqin Yang",
      "Bo Xu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06252v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06252v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.06826v1",
    "title": "Beyond Plain Demos: A Demo-centric Anchoring Paradigm for In-Context Learning in Alzheimer's Disease Detection",
    "summary": "Detecting Alzheimer's disease (AD) from narrative transcripts challenges large language models (LLMs): pre-training rarely covers this out-of-distribution task, and all transcript demos describe the same scene, producing highly homogeneous contexts. These factors cripple both the model's built-in task knowledge (\\textbf{task cognition}) and its ability to surface subtle, class-discriminative cues (\\textbf{contextual perception}). Because cognition is fixed after pre-training, improving in-context learning (ICL) for AD detection hinges on enriching perception through better demonstration (demo) sets. We demonstrate that standard ICL quickly saturates, its demos lack diversity (context width) and fail to convey fine-grained signals (context depth), and that recent task vector (TV) approaches improve broad task adaptation by injecting TV into the LLMs' hidden states (HSs), they are ill-suited for AD detection due to the mismatch of injection granularity, strength and position. To address these bottlenecks, we introduce \\textbf{DA4ICL}, a demo-centric anchoring framework that jointly expands context width via \\emph{\\textbf{Diverse and Contrastive Retrieval}} (DCR) and deepens each demo's signal via \\emph{\\textbf{Projected Vector Anchoring}} (PVA) at every Transformer layer. Across three AD benchmarks, DA4ICL achieves large, stable gains over both ICL and TV baselines, charting a new paradigm for fine-grained, OOD and low-resource LLM adaptation.",
    "authors": [
      "Puzhen Su",
      "Haoran Yin",
      "Yongzhu Miao",
      "Jintao Tang",
      "Shasha Li",
      "Ting Wang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06826v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06826v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07032v1",
    "title": "Fair Bayesian Data Selection via Generalized Discrepancy Measures",
    "summary": "Fairness concerns are increasingly critical as machine learning models are deployed in high-stakes applications. While existing fairness-aware methods typically intervene at the model level, they often suffer from high computational costs, limited scalability, and poor generalization. To address these challenges, we propose a Bayesian data selection framework that ensures fairness by aligning group-specific posterior distributions of model parameters and sample weights with a shared central distribution. Our framework supports flexible alignment via various distributional discrepancy measures, including Wasserstein distance, maximum mean discrepancy, and $f$-divergence, allowing geometry-aware control without imposing explicit fairness constraints. This data-centric approach mitigates group-specific biases in training data and improves fairness in downstream tasks, with theoretical guarantees. Experiments on benchmark datasets show that our method consistently outperforms existing data selection and model-based fairness methods in both fairness and accuracy.",
    "authors": [
      "Yixuan Zhang",
      "Jiabin Luo",
      "Zhenggang Wang",
      "Feng Zhou",
      "Quyu Kong"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07032v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07032v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07210v1",
    "title": "Breaking the Stealth-Potency Trade-off in Clean-Image Backdoors with Generative Trigger Optimization",
    "summary": "Clean-image backdoor attacks, which use only label manipulation in training datasets to compromise deep neural networks, pose a significant threat to security-critical applications. A critical flaw in existing methods is that the poison rate required for a successful attack induces a proportional, and thus noticeable, drop in Clean Accuracy (CA), undermining their stealthiness. This paper presents a new paradigm for clean-image attacks that minimizes this accuracy degradation by optimizing the trigger itself. We introduce Generative Clean-Image Backdoors (GCB), a framework that uses a conditional InfoGAN to identify naturally occurring image features that can serve as potent and stealthy triggers. By ensuring these triggers are easily separable from benign task-related features, GCB enables a victim model to learn the backdoor from an extremely small set of poisoned examples, resulting in a CA drop of less than 1%. Our experiments demonstrate GCB's remarkable versatility, successfully adapting to six datasets, five architectures, and four tasks, including the first demonstration of clean-image backdoors in regression and segmentation. GCB also exhibits resilience against most of the existing backdoor defenses.",
    "authors": [
      "Binyan Xu",
      "Fan Yang",
      "Di Tang",
      "Xilin Dai",
      "Kehuan Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07210v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07210v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.06248v1",
    "title": "Constraint-Informed Active Learning for End-to-End ACOPF Optimization Proxies",
    "summary": "This paper studies optimization proxies, machine learning (ML) models trained to efficiently predict optimal solutions for AC Optimal Power Flow (ACOPF) problems. While promising, optimization proxy performance heavily depends on training data quality. To address this limitation, this paper introduces a novel active sampling framework for ACOPF optimization proxies designed to generate realistic and diverse training data. The framework actively explores varied, flexible problem specifications reflecting plausible operational realities. More importantly, the approach uses optimization-specific quantities (active constraint sets) that better capture the salient features of an ACOPF that lead to the optimal solution. Numerical results show superior generalization over existing sampling methods with an equivalent training budget, significantly advancing the state-of-practice for trustworthy ACOPF optimization proxies.",
    "authors": [
      "Miao Li",
      "Michael Klamkin",
      "Pascal Van Hentenryck",
      "Wenting Li",
      "Russell Bent"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06248v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06248v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07286v1",
    "title": "Glioma C6: A Novel Dataset for Training and Benchmarking Cell Segmentation",
    "summary": "We present Glioma C6, a new open dataset for instance segmentation of glioma C6 cells, designed as both a benchmark and a training resource for deep learning models. The dataset comprises 75 high-resolution phase-contrast microscopy images with over 12,000 annotated cells, providing a realistic testbed for biomedical image analysis. It includes soma annotations and morphological cell categorization provided by biologists. Additional categorization of cells, based on morphology, aims to enhance the utilization of image data for cancer cell research. Glioma C6 consists of two parts: the first is curated with controlled parameters for benchmarking, while the second supports generalization testing under varying conditions. We evaluate the performance of several generalist segmentation models, highlighting their limitations on our dataset. Our experiments demonstrate that training on Glioma C6 significantly enhances segmentation performance, reinforcing its value for developing robust and generalizable models. The dataset is publicly available for researchers.",
    "authors": [
      "Roman Malashin",
      "Svetlana Pashkevich",
      "Daniil Ilyukhin",
      "Arseniy Volkov",
      "Valeria Yachnaya",
      "Andrey Denisov",
      "Maria Mikhalkova"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07286v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07286v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.06739v1",
    "title": "Rank-1 LoRAs Encode Interpretable Reasoning Signals",
    "summary": "Reasoning models leverage inference-time compute to significantly enhance the performance of language models on difficult logical tasks, and have become a dominating paradigm in frontier LLMs. Despite their wide adoption, the mechanisms underpinning the enhanced performance of these reasoning models are not well understood. In this work, we show that the majority of new capabilities in reasoning models can be elicited by small, single-rank changes to base model parameters, with many of these changes being interpretable. Specifically, we use a rank-1 LoRA to create a minimal parameter adapter for Qwen-2.5-32B-Instruct which recovers 73-90% of reasoning-benchmark performance compared to a full parameter finetune. We find that the activations of this LoRA are as interpretable as MLP neurons, and fire for reasoning-specific behaviors. Finally, we train a sparse autoencoder on the entire activation state of this LoRA and identify fine-grained and monosemantic features. Our findings highlight that reasoning performance can arise largely from minimal changes to base model parameters, and explore what these changes affect. More broadly, our work shows that parameter-efficient training methods can be used as a targeted lens for uncovering fundamental insights about language model behavior and dynamics.",
    "authors": [
      "Jake Ward",
      "Paul Riechers",
      "Adam Shai"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06739v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06739v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07417v1",
    "title": "Language Generation with Infinite Contamination",
    "summary": "We study language generation in the limit, where an algorithm observes an adversarial enumeration of strings from an unknown target language $K$ and must eventually generate new, unseen strings from $K$. Kleinberg and Mullainathan [KM24] proved that generation is achievable in surprisingly general settings. But their generator suffers from ``mode collapse,'' producing from an ever-smaller subset of the target. To address this, Kleinberg and Wei [KW25] require the generator's output to be ``dense'' in the target language. They showed that generation with density, surprisingly, remains achievable at the same generality.   Both results assume perfect data: no noisy insertions and no omissions. This raises a central question: how much contamination can generation tolerate? Recent works made partial progress on this question by studying (non-dense) generation with either finite amounts of noise (but no omissions) or omissions (but no noise).   We characterize robustness under contaminated enumerations: 1. Generation under Contamination: Language generation in the limit is achievable for all countable collections iff the fraction of contaminated examples converges to zero. When this fails, we characterize which collections are generable. 2. Dense Generation under Contamination: Dense generation is strictly less robust to contamination than generation. As a byproduct, we resolve an open question of Raman and Raman [ICML25] by showing that generation is possible with only membership oracle access under finitely many contaminated examples.   Finally, we introduce a beyond-worst-case model inspired by curriculum learning and prove that dense generation is achievable even with infinite contamination provided the fraction of contaminated examples converges to zero. This suggests curriculum learning may be crucial for learning from noisy web data.",
    "authors": [
      "Anay Mehrotra",
      "Grigoris Velegkas",
      "Xifan Yu",
      "Felix Zhou"
    ],
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.DS",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07417v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07417v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07129v1",
    "title": "LoRA on the Go: Instance-level Dynamic LoRA Selection and Merging",
    "summary": "Low-Rank Adaptation (LoRA) has emerged as a parameter-efficient approach for fine-tuning large language models.However, conventional LoRA adapters are typically trained for a single task, limiting their applicability in real-world settings where inputs may span diverse and unpredictable domains. At inference time, existing approaches combine multiple LoRAs for improving performance on diverse tasks, while usually requiring labeled data or additional task-specific training, which is expensive at scale. In this work, we introduce LoRA on the Go (LoGo), a training-free framework that dynamically selects and merges adapters at the instance level without any additional requirements. LoGo leverages signals extracted from a single forward pass through LoRA adapters, to identify the most relevant adapters and determine their contributions on-the-fly. Across 5 NLP benchmarks, 27 datasets, and 3 model families, LoGo outperforms training-based baselines on some tasks upto a margin of 3.6% while remaining competitive on other tasks and maintaining inference throughput, highlighting its effectiveness and practicality.",
    "authors": [
      "Seungeon Lee",
      "Soumi Das",
      "Manish Gupta",
      "Krishna P. Gummadi"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07129v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07129v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07124v1",
    "title": "Think Consistently, Reason Efficiently: Energy-Based Calibration for Implicit Chain-of-Thought",
    "summary": "Large Language Models (LLMs) have demonstrated strong reasoning capabilities through \\emph{Chain-of-Thought} (CoT) prompting, which enables step-by-step intermediate reasoning. However, explicit CoT methods rely on discrete token-level reasoning processes that are prone to error propagation and limited by vocabulary expressiveness, often resulting in rigid and inconsistent reasoning trajectories. Recent research has explored implicit or continuous reasoning in latent spaces, allowing models to perform internal reasoning before generating explicit output. Although such approaches alleviate some limitations of discrete CoT, they generally lack explicit mechanisms to enforce consistency among reasoning steps, leading to divergent reasoning paths and unstable outcomes. To address this issue, we propose EBM-CoT, an Energy-Based Chain-of-Thought Calibration framework that refines latent thought representations through an energy-based model (EBM). Our method dynamically adjusts latent reasoning trajectories toward lower-energy, high-consistency regions in the embedding space, improving both reasoning accuracy and consistency without modifying the base language model. Extensive experiments across mathematical, commonsense, and symbolic reasoning benchmarks demonstrate that the proposed framework significantly enhances the consistency and efficiency of multi-step reasoning in LLMs.",
    "authors": [
      "Zhikang Chen",
      "Sen Cui",
      "Deheng Ye",
      "Yu Zhang",
      "Yatao Bian",
      "Tingting Zhu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07124v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07124v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06495v1",
    "title": "Probably Approximately Global Robustness Certification",
    "summary": "We propose and investigate probabilistic guarantees for the adversarial robustness of classification algorithms. While traditional formal verification approaches for robustness are intractable and sampling-based approaches do not provide formal guarantees, our approach is able to efficiently certify a probabilistic relaxation of robustness. The key idea is to sample an $ε$-net and invoke a local robustness oracle on the sample. Remarkably, the size of the sample needed to achieve probably approximately global robustness guarantees is independent of the input dimensionality, the number of classes, and the learning algorithm itself. Our approach can, therefore, be applied even to large neural networks that are beyond the scope of traditional formal verification. Experiments empirically confirm that it characterizes robustness better than state-of-the-art sampling-based approaches and scales better than formal methods.",
    "authors": [
      "Peter Blohm",
      "Patrick Indri",
      "Thomas Gärtner",
      "Sagar Malhotra"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06495v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06495v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07084v1",
    "title": "Pandar128 dataset for lane line detection",
    "summary": "We present Pandar128, the largest public dataset for lane line detection using a 128-beam LiDAR. It contains over 52,000 camera frames and 34,000 LiDAR scans, captured in diverse real-world conditions in Germany. The dataset includes full sensor calibration (intrinsics, extrinsics) and synchronized odometry, supporting tasks such as projection, fusion, and temporal modeling.   To complement the dataset, we also introduce SimpleLidarLane, a light-weight baseline method for lane line reconstruction that combines BEV segmentation, clustering, and polyline fitting. Despite its simplicity, our method achieves strong performance under challenging various conditions (e.g., rain, sparse returns), showing that modular pipelines paired with high-quality data and principled evaluation can compete with more complex approaches.   Furthermore, to address the lack of standardized evaluation, we propose a novel polyline-based metric - Interpolation-Aware Matching F1 (IAM-F1) - that employs interpolation-aware lateral matching in BEV space.   All data and code are publicly released to support reproducibility in LiDAR-based lane detection.",
    "authors": [
      "Filip Beránek",
      "Václav Diviš",
      "Ivan Gruber"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07084v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07084v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06209v1",
    "title": "Reasoning with Confidence: Efficient Verification of LLM Reasoning Steps via Uncertainty Heads",
    "summary": "Solving complex tasks usually requires LLMs to generate long multi-step reasoning chains. Previous work has shown that verifying the correctness of individual reasoning steps can further improve the performance and efficiency of LLMs on such tasks and enhance solution interpretability. However, existing verification approaches, such as Process Reward Models (PRMs), are either computationally expensive, limited to specific domains, or require large-scale human or model-generated annotations. Thus, we propose a lightweight alternative for step-level reasoning verification based on data-driven uncertainty scores. We train transformer-based uncertainty quantification heads (UHeads) that use the internal states of a frozen LLM to estimate the uncertainty of its reasoning steps during generation. The approach is fully automatic: target labels are generated either by another larger LLM (e.g., DeepSeek R1) or in a self-supervised manner by the original model itself. UHeads are both effective and lightweight, containing less than 10M parameters. Across multiple domains, including mathematics, planning, and general knowledge question answering, they match or even surpass the performance of PRMs that are up to 810x larger. Our findings suggest that the internal states of LLMs encode their uncertainty and can serve as reliable signals for reasoning verification, offering a promising direction toward scalable and generalizable introspective LLMs.",
    "authors": [
      "Jingwei Ni",
      "Ekaterina Fadeeva",
      "Tianyi Wu",
      "Mubashara Akhtar",
      "Jiaheng Zhang",
      "Elliott Ash",
      "Markus Leippold",
      "Timothy Baldwin",
      "See-Kiong Ng",
      "Artem Shelmanov",
      "Mrinmaya Sachan"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06209v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06209v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06208v1",
    "title": "Resilience Inference for Supply Chains with Hypergraph Neural Network",
    "summary": "Supply chains are integral to global economic stability, yet disruptions can swiftly propagate through interconnected networks, resulting in substantial economic impacts. Accurate and timely inference of supply chain resilience the capability to maintain core functions during disruptions is crucial for proactive risk mitigation and robust network design. However, existing approaches lack effective mechanisms to infer supply chain resilience without explicit system dynamics and struggle to represent the higher-order, multi-entity dependencies inherent in supply chain networks. These limitations motivate the definition of a novel problem and the development of targeted modeling solutions. To address these challenges, we formalize a novel problem: Supply Chain Resilience Inference (SCRI), defined as predicting supply chain resilience using hypergraph topology and observed inventory trajectories without explicit dynamic equations. To solve this problem, we propose the Supply Chain Resilience Inference Hypergraph Network (SC-RIHN), a novel hypergraph-based model leveraging set-based encoding and hypergraph message passing to capture multi-party firm-product interactions. Comprehensive experiments demonstrate that SC-RIHN significantly outperforms traditional MLP, representative graph neural network variants, and ResInf baselines across synthetic benchmarks, underscoring its potential for practical, early-warning risk assessment in complex supply chain systems.",
    "authors": [
      "Zetian Shen",
      "Hongjun Wang",
      "Jiyuan Chen",
      "Xuan Song"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06208v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06208v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06221v1",
    "title": "Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model Reasoning Ability in VibeThinker-1.5B",
    "summary": "Challenging the prevailing consensus that small models inherently lack robust reasoning, this report introduces VibeThinker-1.5B, a 1.5B-parameter dense model developed via our Spectrum-to-Signal Principle (SSP). This challenges the prevailing approach of scaling model parameters to enhance capabilities, as seen in models like DeepSeek R1 (671B) and Kimi k2 (>1T). The SSP framework first employs a Two-Stage Diversity-Exploring Distillation (SFT) to generate a broad spectrum of solutions, followed by MaxEnt-Guided Policy Optimization (RL) to amplify the correct signal. With a total training cost of only $7,800, VibeThinker-1.5B demonstrates superior reasoning capabilities compared to closed-source models like Magistral Medium and Claude Opus 4, and performs on par with open-source models like GPT OSS-20B Medium. Remarkably, it surpasses the 400x larger DeepSeek R1 on three math benchmarks: AIME24 (80.3 vs. 79.8), AIME25 (74.4 vs. 70.0), and HMMT25 (50.4 vs. 41.7). This is a substantial improvement over its base model (6.7, 4.3, and 0.6, respectively). On LiveCodeBench V6, it scores 51.1, outperforming Magistral Medium's 50.3 and its base model's 0.0. These findings demonstrate that small models can achieve reasoning capabilities comparable to large models, drastically reducing training and inference costs and thereby democratizing advanced AI research.",
    "authors": [
      "Sen Xu",
      "Yi Zhou",
      "Wei Wang",
      "Jixin Min",
      "Zhibin Yin",
      "Yingwei Dai",
      "Shixi Liu",
      "Lianyu Pang",
      "Yirong Chen",
      "Junlin Zhang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06221v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06221v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06479v1",
    "title": "Bridging Theory and Practice: A Stochastic Learning-Optimization Model for Resilient Automotive Supply Chains",
    "summary": "Supply chain disruptions and volatile demand pose significant challenges to the UK automotive industry, which relies heavily on Just-In-Time (JIT) manufacturing. While qualitative studies highlight the potential of integrating Artificial Intelligence (AI) with traditional optimization, a formal, quantitative demonstration of this synergy is lacking. This paper introduces a novel stochastic learning-optimization framework that integrates Bayesian inference with inventory optimization for supply chain management (SCM). We model a two-echelon inventory system subject to stochastic demand and supply disruptions, comparing a traditional static optimization policy against an adaptive policy where Bayesian learning continuously updates parameter estimates to inform stochastic optimization. Our simulations over 365 periods across three operational scenarios demonstrate that the integrated approach achieves 7.4\\% cost reduction in stable environments and 5.7\\% improvement during supply disruptions, while revealing important limitations during sudden demand shocks due to the inherent conservatism of Bayesian updating. This work provides mathematical validation for practitioner observations and establishes a formal framework for understanding AI-driven supply chain resilience, while identifying critical boundary conditions for successful implementation.",
    "authors": [
      "Muhammad Shahnawaz",
      "Adeel Safder"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.OC"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06479v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06479v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07250v1",
    "title": "MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal LLMs",
    "summary": "The advent of Multimodal Large Language Models (MLLMs) has expanded AI capabilities to visual modalities, yet existing evaluation benchmarks remain limited to single-video understanding, overlooking the critical need for multi-video understanding in real-world scenarios (e.g., sports analytics and autonomous driving). To address this significant gap, we introduce MVU-Eval, the first comprehensive benchmark for evaluating Multi-Video Understanding for MLLMs. Specifically, our MVU-Eval mainly assesses eight core competencies through 1,824 meticulously curated question-answer pairs spanning 4,959 videos from diverse domains, addressing both fundamental perception tasks and high-order reasoning tasks. These capabilities are rigorously aligned with real-world applications such as multi-sensor synthesis in autonomous systems and cross-angle sports analytics. Through extensive evaluation of state-of-the-art open-source and closed-source models, we reveal significant performance discrepancies and limitations in current MLLMs' ability to perform understanding across multiple videos. The benchmark will be made publicly available to foster future research.",
    "authors": [
      "Tianhao Peng",
      "Haochen Wang",
      "Yuanxing Zhang",
      "Zekun Wang",
      "Zili Wang",
      "Ge Zhang",
      "Jian Yang",
      "Shihao Li",
      "Yanghai Wang",
      "Xintao Wang",
      "Houyi Li",
      "Wei Ji",
      "Pengfei Wan",
      "Wenhao Huang",
      "Zhaoxiang Zhang",
      "Jiaheng Liu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07250v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07250v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06793v1",
    "title": "Cross-Modal Unlearning via Influential Neuron Path Editing in Multimodal Large Language Models",
    "summary": "Multimodal Large Language Models (MLLMs) extend foundation models to real-world applications by integrating inputs such as text and vision. However, their broad knowledge capacity raises growing concerns about privacy leakage, toxicity mitigation, and intellectual property violations. Machine Unlearning (MU) offers a practical solution by selectively forgetting targeted knowledge while preserving overall model utility. When applied to MLLMs, existing neuron-editing-based MU approaches face two fundamental challenges: (1) forgetting becomes inconsistent across modalities because existing point-wise attribution methods fail to capture the structured, layer-by-layer information flow that connects different modalities; and (2) general knowledge performance declines when sensitive neurons that also support important reasoning paths are pruned, as this disrupts the model's ability to generalize. To alleviate these limitations, we propose a multimodal influential neuron path editor (MIP-Editor) for MU. Our approach introduces modality-specific attribution scores to identify influential neuron paths responsible for encoding forget-set knowledge and applies influential-path-aware neuron-editing via representation misdirection. This strategy also enables effective and coordinated forgetting across modalities while preserving the model's general capabilities. Experimental results demonstrate that MIP-Editor achieves a superior unlearning performance on multimodal tasks, with a maximum forgetting rate of 87.75% and up to 54.26% improvement in general knowledge retention. On textual tasks, MIP-Editor achieves up to 80.65% forgetting and preserves 77.9% of general performance. Codes are available at https://github.com/PreckLi/MIP-Editor.",
    "authors": [
      "Kunhao Li",
      "Wenhao Li",
      "Di Wu",
      "Lei Yang",
      "Jun Bai",
      "Ju Jia",
      "Jason Xue"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06793v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06793v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06947v1",
    "title": "FoCLIP: A Feature-Space Misalignment Framework for CLIP-Based Image Manipulation and Detection",
    "summary": "The well-aligned attribute of CLIP-based models enables its effective application like CLIPscore as a widely adopted image quality assessment metric. However, such a CLIP-based metric is vulnerable for its delicate multimodal alignment. In this work, we propose \\textbf{FoCLIP}, a feature-space misalignment framework for fooling CLIP-based image quality metric. Based on the stochastic gradient descent technique, FoCLIP integrates three key components to construct fooling examples: feature alignment as the core module to reduce image-text modality gaps, the score distribution balance module and pixel-guard regularization, which collectively optimize multimodal output equilibrium between CLIPscore performance and image quality. Such a design can be engineered to maximize the CLIPscore predictions across diverse input prompts, despite exhibiting either visual unrecognizability or semantic incongruence with the corresponding adversarial prompts from human perceptual perspectives. Experiments on ten artistic masterpiece prompts and ImageNet subsets demonstrate that optimized images can achieve significant improvement in CLIPscore while preserving high visual fidelity. In addition, we found that grayscale conversion induces significant feature degradation in fooling images, exhibiting noticeable CLIPscore reduction while preserving statistical consistency with original images. Inspired by this phenomenon, we propose a color channel sensitivity-driven tampering detection mechanism that achieves 91% accuracy on standard benchmarks. In conclusion, this work establishes a practical pathway for feature misalignment in CLIP-based multimodal systems and the corresponding defense method.",
    "authors": [
      "Yulin Chen",
      "Zeyuan Wang",
      "Tianyuan Yu",
      "Yingmei Wei",
      "Liang Bai"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06947v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06947v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06608v1",
    "title": "Beyond Fixed Depth: Adaptive Graph Neural Networks for Node Classification Under Varying Homophily",
    "summary": "Graph Neural Networks (GNNs) have achieved significant success in addressing node classification tasks. However, the effectiveness of traditional GNNs degrades on heterophilic graphs, where connected nodes often belong to different labels or properties. While recent work has introduced mechanisms to improve GNN performance under heterophily, certain key limitations still exist. Most existing models apply a fixed aggregation depth across all nodes, overlooking the fact that nodes may require different propagation depths based on their local homophily levels and neighborhood structures. Moreover, many methods are tailored to either homophilic or heterophilic settings, lacking the flexibility to generalize across both regimes. To address these challenges, we develop a theoretical framework that links local structural and label characteristics to information propagation dynamics at the node level. Our analysis shows that optimal aggregation depth varies across nodes and is critical for preserving class-discriminative information. Guided by this insight, we propose a novel adaptive-depth GNN architecture that dynamically selects node-specific aggregation depths using theoretically grounded metrics. Our method seamlessly adapts to both homophilic and heterophilic patterns within a unified model. Extensive experiments demonstrate that our approach consistently enhances the performance of standard GNN backbones across diverse benchmarks.",
    "authors": [
      "Asela Hevapathige",
      "Asiri Wijesinghe",
      "Ahad N. Zehmakan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06608v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06608v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07107v1",
    "title": "MENTOR: A Metacognition-Driven Self-Evolution Framework for Uncovering and Mitigating Implicit Risks in LLMs on Domain Tasks",
    "summary": "Ensuring the safety and value alignment of large language models (LLMs) is critical for their deployment. Current alignment efforts primarily target explicit risks such as bias, hate speech, and violence. However, they often fail to address deeper, domain-specific implicit risks and lack a flexible, generalizable framework applicable across diverse specialized fields. Hence, we proposed MENTOR: A MEtacognition-driveN self-evoluTion framework for uncOvering and mitigating implicit Risks in LLMs on Domain Tasks. To address the limitations of labor-intensive human evaluation, we introduce a novel metacognitive self-assessment tool. This enables LLMs to reflect on potential value misalignments in their responses using strategies like perspective-taking and consequential thinking. We also release a supporting dataset of 9,000 risk queries spanning education, finance, and management to enhance domain-specific risk identification. Subsequently, based on the outcomes of metacognitive reflection, the framework dynamically generates supplementary rule knowledge graphs that extend predefined static rule trees. This enables models to actively apply validated rules to future similar challenges, establishing a continuous self-evolution cycle that enhances generalization by reducing maintenance costs and inflexibility of static systems. Finally, we employ activation steering during inference to guide LLMs in following the rules, a cost-effective method to robustly enhance enforcement across diverse contexts. Experimental results show MENTOR's effectiveness: In defensive testing across three vertical domains, the framework substantially reduces semantic attack success rates, enabling a new level of implicit risk mitigation for LLMs. Furthermore, metacognitive assessment not only aligns closely with baseline human evaluators but also delivers more thorough and insightful analysis of LLMs value alignment.",
    "authors": [
      "Liang Shan",
      "Kaicheng Shen",
      "Wen Wu",
      "Zhenyu Ying",
      "Chaochao Lu",
      "Guangze Ye",
      "Liang He"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07107v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07107v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07010v1",
    "title": "A Picture is Worth a Thousand (Correct) Captions: A Vision-Guided Judge-Corrector System for Multimodal Machine Translation",
    "summary": "In this paper, we describe our system under the team name BLEU Monday for the English-to-Indic Multimodal Translation Task at WAT 2025. We participate in the text-only translation tasks for English-Hindi, English-Bengali, English-Malayalam, and English-Odia language pairs. We present a two-stage approach that addresses quality issues in the training data through automated error detection and correction, followed by parameter-efficient model fine-tuning.   Our methodology introduces a vision-augmented judge-corrector pipeline that leverages multimodal language models to systematically identify and correct translation errors in the training data. The judge component classifies translations into three categories: correct, visually ambiguous (requiring image context), or mistranslated (poor translation quality). Identified errors are routed to specialized correctors: GPT-4o-mini regenerates captions requiring visual disambiguation, while IndicTrans2 retranslates cases with pure translation quality issues. This automated pipeline processes 28,928 training examples across four languages, correcting an average of 17.1% of captions per language.   We then apply Low-Rank Adaptation (LoRA) to fine-tune the IndicTrans2 en-indic 200M distilled model on both original and corrected datasets. Training on corrected data yields consistent improvements, with BLEU score gains of +1.30 for English-Bengali on the evaluation set (42.00 -> 43.30) and +0.70 on the challenge set (44.90 -> 45.60), +0.60 for English-Odia on the evaluation set (41.00 -> 41.60), and +0.10 for English-Hindi on the challenge set (53.90 -> 54.00).",
    "authors": [
      "Siddharth Betala",
      "Kushan Raj",
      "Vipul Betala",
      "Rohan Saswade"
    ],
    "categories": [
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07010v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07010v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06937v1",
    "title": "Fine-Tuning Diffusion-Based Recommender Systems via Reinforcement Learning with Reward Function Optimization",
    "summary": "Diffusion models recently emerged as a powerful paradigm for recommender systems, offering state-of-the-art performance by modeling the generative process of user-item interactions. However, training such models from scratch is both computationally expensive and yields diminishing returns once convergence is reached. To remedy these challenges, we propose ReFiT, a new framework that integrates Reinforcement learning (RL)-based Fine-Tuning into diffusion-based recommender systems. In contrast to prior RL approaches for diffusion models depending on external reward models, ReFiT adopts a task-aligned design: it formulates the denoising trajectory as a Markov decision process (MDP) and incorporates a collaborative signal-aware reward function that directly reflects recommendation quality. By tightly coupling the MDP structure with this reward signal, ReFiT empowers the RL agent to exploit high-order connectivity for fine-grained optimization, while avoiding the noisy or uninformative feedback common in naive reward designs. Leveraging policy gradient optimization, ReFiT maximizes exact log-likelihood of observed interactions, thereby enabling effective post hoc fine-tuning of diffusion recommenders. Comprehensive experiments on wide-ranging real-world datasets demonstrate that the proposed ReFiT framework (a) exhibits substantial performance gains over strong competitors (up to 36.3% on sequential recommendation), (b) demonstrates strong efficiency with linear complexity in the number of users or items, and (c) generalizes well across multiple diffusion-based recommendation scenarios. The source code and datasets are publicly available at https://anonymous.4open.science/r/ReFiT-4C60.",
    "authors": [
      "Yu Hou",
      "Hua Li",
      "Ha Young Kim",
      "Won-Yong Shin"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "cs.NI",
      "cs.SI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06937v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06937v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07057v1",
    "title": "TauFlow: Dynamic Causal Constraint for Complexity-Adaptive Lightweight Segmentation",
    "summary": "Deploying lightweight medical image segmentation models on edge devices presents two major challenges: 1) efficiently handling the stark contrast between lesion boundaries and background regions, and 2) the sharp drop in accuracy that occurs when pursuing extremely lightweight designs (e.g., <0.5M parameters). To address these problems, this paper proposes TauFlow, a novel lightweight segmentation model. The core of TauFlow is a dynamic feature response strategy inspired by brain-like mechanisms. This is achieved through two key innovations: the Convolutional Long-Time Constant Cell (ConvLTC), which dynamically regulates the feature update rate to \"slowly\" process low-frequency backgrounds and \"quickly\" respond to high-frequency boundaries; and the STDP Self-Organizing Module, which significantly mitigates feature conflicts between the encoder and decoder, reducing the conflict rate from approximately 35%-40% to 8%-10%.",
    "authors": [
      "Zidong Chen",
      "Fadratul Hafinaz Hassan"
    ],
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07057v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07057v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07260v1",
    "title": "PADiff: Predictive and Adaptive Diffusion Policies for Ad Hoc Teamwork",
    "summary": "Ad hoc teamwork (AHT) requires agents to collaborate with previously unseen teammates, which is crucial for many real-world applications. The core challenge of AHT is to develop an ego agent that can predict and adapt to unknown teammates on the fly. Conventional RL-based approaches optimize a single expected return, which often causes policies to collapse into a single dominant behavior, thus failing to capture the multimodal cooperation patterns inherent in AHT. In this work, we introduce PADiff, a diffusion-based approach that captures agent's multimodal behaviors, unlocking its diverse cooperation modes with teammates. However, standard diffusion models lack the ability to predict and adapt in highly non-stationary AHT scenarios. To address this limitation, we propose a novel diffusion-based policy that integrates critical predictive information about teammates into the denoising process. Extensive experiments across three cooperation environments demonstrate that PADiff outperforms existing AHT methods significantly.",
    "authors": [
      "Hohei Chan",
      "Xinzhi Zhang",
      "Antao Xiang",
      "Weinan Zhang",
      "Mengchen Zhao"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07260v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07260v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07237v1",
    "title": "The Few Govern the Many:Unveiling Few-Layer Dominance for Time Series Models",
    "summary": "Large-scale models are at the forefront of time series (TS) forecasting, dominated by two paradigms: fine-tuning text-based Large Language Models (LLM4TS) and training Time Series Foundation Models (TSFMs) from scratch. Both approaches share a foundational assumption that scaling up model capacity and data volume leads to improved performance. However, we observe a \\textit{\\textbf{scaling paradox}} in TS models, revealing a puzzling phenomenon that larger models do \\emph{NOT} achieve better performance. Through extensive experiments on two model families across four scales (100M to 1.7B parameters) and diverse data (up to 6B observations), we rigorously confirm that the scaling paradox is a pervasive issue. We then diagnose its root cause by analyzing internal representations, identifying a phenomenon we call \\textit{few-layer dominance}: only a small subset of layers are functionally important, while the majority are redundant, under-utilized, and can even distract training. Based on this discovery, we propose a practical method to automatically identify and retain only these dominant layers. In our models, retaining only 21\\% of the parameters achieves up to a 12\\% accuracy improvement and a 2.7$\\times$ inference speedup. We validate the universality of our method on 8 prominent SOTA models (LLM4TS and TSFMs, 90M to 6B), showing that retaining less than 30\\% of layers achieves comparable or superior accuracy in over 95\\% of tasks.",
    "authors": [
      "Xin Qiu",
      "Junlong Tong",
      "Yirong Sun",
      "Yunpu Ma",
      "Xiaoyu Shen"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07237v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07237v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06831v1",
    "title": "DeepRWCap: Neural-Guided Random-Walk Capacitance Solver for IC Design",
    "summary": "Monte Carlo random walk methods are widely used in capacitance extraction for their mesh-free formulation and inherent parallelism. However, modern semiconductor technologies with densely packed structures present significant challenges in unbiasedly sampling transition domains in walk steps with multiple high-contrast dielectric materials. We present DeepRWCap, a machine learning-guided random walk solver that predicts the transition quantities required to guide each step of the walk. These include Poisson kernels, gradient kernels, signs and magnitudes of weights. DeepRWCap employs a two-stage neural architecture that decomposes structured outputs into face-wise distributions and spatial kernels on cube faces. It uses 3D convolutional networks to capture volumetric dielectric interactions and 2D depthwise separable convolutions to model localized kernel behavior. The design incorporates grid-based positional encodings and structural design choices informed by cube symmetries to reduce learning redundancy and improve generalization. Trained on 100,000 procedurally generated dielectric configurations, DeepRWCap achieves a mean relative error of $1.24\\pm0.53$\\% when benchmarked against the commercial Raphael solver on the self-capacitance estimation of 10 industrial designs spanning 12 to 55 nm nodes. Compared to the state-of-the-art stochastic difference method Microwalk, DeepRWCap achieves an average 23\\% speedup. On complex designs with runtimes over 10 s, it reaches an average 49\\% acceleration.",
    "authors": [
      "Hector R. Rodriguez",
      "Jiechen Huang",
      "Wenjian Yu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06831v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06831v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06805v1",
    "title": "MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning",
    "summary": "Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in vision-language answering tasks. Despite their strengths, these models often encounter challenges in achieving complex reasoning tasks such as mathematical problem-solving. Previous works have focused on fine-tuning on specialized mathematical datasets. However, these datasets are typically distilled directly from teacher models, which capture only static reasoning patterns and leaving substantial gaps compared to student models. This reliance on fixed teacher-derived datasets not only restricts the model's ability to adapt to novel or more intricate questions that extend beyond the confines of the training data, but also lacks the iterative depth needed for robust generalization. To overcome these limitations, we propose \\textbf{\\method}, a \\textbf{Math}ematical \\textbf{S}elf-\\textbf{E}volving framework for MLLMs. In contrast to traditional one-shot fine-tuning paradigms, \\method iteratively refines the model through cycles of inference, reflection, and reward-based feedback. Specifically, we leverage iterative fine-tuning by incorporating correct reasoning paths derived from previous-stage inference and integrating reflections from a specialized Outcome Reward Model (ORM). To verify the effectiveness of \\method, we evaluate it on a suite of challenging benchmarks, demonstrating significant performance gains over backbone models. Notably, our experimental results on MathVL-test surpass the leading open-source multimodal mathematical reasoning model QVQ. Our code and models are available at \\texttt{https://zheny2751\\allowbreak-dotcom.github.io/\\allowbreak MathSE.github.io/}.",
    "authors": [
      "Jinhao Chen",
      "Zhen Yang",
      "Jianxin Shi",
      "Tianyu Wo",
      "Jie Tang"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06805v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06805v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.06899v1",
    "title": "RPTS: Tree-Structured Reasoning Process Scoring for Faithful Multimodal Evaluation",
    "summary": "Large Vision-Language Models (LVLMs) excel in multimodal reasoning and have shown impressive performance on various multimodal benchmarks. However, most of these benchmarks evaluate models primarily through multiple-choice or short-answer formats, which do not take the reasoning process into account. Although some benchmarks assess the reasoning process, their methods are often overly simplistic and only examine reasoning when answers are incorrect. This approach overlooks scenarios where flawed reasoning leads to correct answers. In addition, these benchmarks do not consider the impact of intermodal relationships on reasoning. To address this issue, we propose the Reasoning Process Tree Score (RPTS), a tree structure-based metric to assess reasoning processes. Specifically, we organize the reasoning steps into a reasoning tree and leverage its hierarchical information to assign weighted faithfulness scores to each reasoning step. By dynamically adjusting these weights, RPTS not only evaluates the overall correctness of the reasoning, but also pinpoints where the model fails in the reasoning. To validate RPTS in real-world multimodal scenarios, we construct a new benchmark, RPTS-Eval, comprising 374 images and 390 reasoning instances. Each instance includes reliable visual-textual clues that serve as leaf nodes of the reasoning tree. Furthermore, we define three types of intermodal relationships to investigate how intermodal interactions influence the reasoning process. We evaluated representative LVLMs (e.g., GPT4o, Llava-Next), uncovering their limitations in multimodal reasoning and highlighting the differences between open-source and closed-source commercial LVLMs. We believe that this benchmark will contribute to the advancement of research in the field of multimodal reasoning.",
    "authors": [
      "Haofeng Wang",
      "Yu Zhang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06899v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06899v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.06185v1",
    "title": "Dataforge: A Data Agent Platform for Autonomous Data Engineering",
    "summary": "The growing demand for AI applications in fields such as materials discovery, molecular modeling, and climate science has made data preparation an important but labor-intensive step. Raw data from diverse sources must be cleaned, normalized, and transformed to become AI-ready, while effective feature transformation and selection are essential for efficient training and inference. To address the challenges of scalability and expertise dependence, we present Data Agent, a fully autonomous system specialized for tabular data. Leveraging large language model (LLM) reasoning and grounded validation, Data Agent automatically performs data cleaning, hierarchical routing, and feature-level optimization through dual feedback loops. It embodies three core principles: automatic, safe, and non-expert friendly, which ensure end-to-end reliability without human supervision. This demo showcases the first practical realization of an autonomous Data Agent, illustrating how raw data can be transformed \"From Data to Better Data.\"",
    "authors": [
      "Xinyuan Wang",
      "Yanjie Fu"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06185v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06185v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.06175v1",
    "title": "CSP4SDG: Constraint and Information-Theory Based Role Identification in Social Deduction Games with LLM-Enhanced Inference",
    "summary": "In Social Deduction Games (SDGs) such as Avalon, Mafia, and Werewolf, players conceal their identities and deliberately mislead others, making hidden-role inference a central and demanding task. Accurate role identification, which forms the basis of an agent's belief state, is therefore the keystone for both human and AI performance. We introduce CSP4SDG, a probabilistic, constraint-satisfaction framework that analyses gameplay objectively. Game events and dialogue are mapped to four linguistically-agnostic constraint classes-evidence, phenomena, assertions, and hypotheses. Hard constraints prune impossible role assignments, while weighted soft constraints score the remainder; information-gain weighting links each hypothesis to its expected value under entropy reduction, and a simple closed-form scoring rule guarantees that truthful assertions converge to classical hard logic with minimum error. The resulting posterior over roles is fully interpretable and updates in real time. Experiments on three public datasets show that CSP4SDG (i) outperforms LLM-based baselines in every inference scenario, and (ii) boosts LLMs when supplied as an auxiliary \"reasoning tool.\" Our study validates that principled probabilistic reasoning with information theory is a scalable alternative-or complement-to heavy-weight neural models for SDGs.",
    "authors": [
      "Kaijie Xu",
      "Fandi Meng",
      "Clark Verbrugge",
      "Simon Lucas"
    ],
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06175v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06175v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.07403v1",
    "title": "SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards",
    "summary": "Multimodal large language models (MLLMs) have achieved remarkable progress in vision-language tasks, but they continue to struggle with spatial understanding. Existing spatial MLLMs often rely on explicit 3D inputs or architecture-specific modifications, and remain constrained by large-scale datasets or sparse supervision. To address these limitations, we introduce SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial grounding with multi-step reasoning. The model simulates human-like spatial perception by constructing a scene graph of task-relevant objects and spatial relations, and reasoning towards an answer via dense spatial rewards. SpatialThinker consists of two key contributions: (1) a data synthesis pipeline that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL with a multi-objective dense spatial reward enforcing spatial grounding. SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline on spatial understanding and real-world VQA benchmarks, nearly doubling the base-model gain compared to sparse RL, and surpassing GPT-4o. These results showcase the effectiveness of combining spatial supervision with reward-aligned reasoning in enabling robust 3D spatial understanding with limited data and advancing MLLMs towards human-level visual reasoning.",
    "authors": [
      "Hunar Batra",
      "Haoqin Tu",
      "Hardy Chen",
      "Yuanze Lin",
      "Cihang Xie",
      "Ronald Clark"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07403v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07403v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.06568v1",
    "title": "Breaking the Dyadic Barrier: Rethinking Fairness in Link Prediction Beyond Demographic Parity",
    "summary": "Link prediction is a fundamental task in graph machine learning with applications, ranging from social recommendation to knowledge graph completion. Fairness in this setting is critical, as biased predictions can exacerbate societal inequalities. Prior work adopts a dyadic definition of fairness, enforcing fairness through demographic parity between intra-group and inter-group link predictions. However, we show that this dyadic framing can obscure underlying disparities across subgroups, allowing systemic biases to go undetected. Moreover, we argue that demographic parity does not meet desired properties for fairness assessment in ranking-based tasks such as link prediction. We formalize the limitations of existing fairness evaluations and propose a framework that enables a more expressive assessment. Additionally, we propose a lightweight post-processing method combined with decoupled link predictors that effectively mitigates bias and achieves state-of-the-art fairness-utility trade-offs.",
    "authors": [
      "João Mattos",
      "Debolina Halder Lina",
      "Arlei Silva"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI",
      "stat.ML"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06568v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06568v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.07007v1",
    "title": "TrueCity: Real and Simulated Urban Data for Cross-Domain 3D Scene Understanding",
    "summary": "3D semantic scene understanding remains a long-standing challenge in the 3D computer vision community. One of the key issues pertains to limited real-world annotated data to facilitate generalizable models. The common practice to tackle this issue is to simulate new data. Although synthetic datasets offer scalability and perfect labels, their designer-crafted scenes fail to capture real-world complexity and sensor noise, resulting in a synthetic-to-real domain gap. Moreover, no benchmark provides synchronized real and simulated point clouds for segmentation-oriented domain shift analysis. We introduce TrueCity, the first urban semantic segmentation benchmark with cm-accurate annotated real-world point clouds, semantic 3D city models, and annotated simulated point clouds representing the same city. TrueCity proposes segmentation classes aligned with international 3D city modeling standards, enabling consistent evaluation of synthetic-to-real gap. Our extensive experiments on common baselines quantify domain shift and highlight strategies for exploiting synthetic data to enhance real-world 3D scene understanding. We are convinced that the TrueCity dataset will foster further development of sim-to-real gap quantification and enable generalizable data-driven models. The data, code, and 3D models are available online: https://tum-gis.github.io/TrueCity/",
    "authors": [
      "Duc Nguyen",
      "Yan-Ling Lai",
      "Qilin Zhang",
      "Prabin Gyawali",
      "Benedikt Schwab",
      "Olaf Wysocki",
      "Thomas H. Kolbe"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07007v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07007v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.06803v1",
    "title": "Learning to Fast Unrank in Collaborative Filtering Recommendation",
    "summary": "Modern data-driven recommendation systems risk memorizing sensitive user behavioral patterns, raising privacy concerns. Existing recommendation unlearning methods, while capable of removing target data influence, suffer from inefficient unlearning speed and degraded performance, failing to meet real-time unlearning demands. Considering the ranking-oriented nature of recommendation systems, we present unranking, the process of reducing the ranking positions of target items while ensuring the formal guarantees of recommendation unlearning. To achieve efficient unranking, we propose Learning to Fast Unrank in Collaborative Filtering Recommendation (L2UnRank), which operates through three key stages: (a) identifying the influenced scope via interaction-based p-hop propagation, (b) computing structural and semantic influences for entities within this scope, and (c) performing efficient, ranking-aware parameter updates guided by influence information. Extensive experiments across multiple datasets and backbone models demonstrate L2UnRank's model-agnostic nature, achieving state-of-the-art unranking effectiveness and maintaining recommendation quality comparable to retraining, while also delivering a 50x speedup over existing methods. Codes are available at https://github.com/Juniper42/L2UnRank.",
    "authors": [
      "Junpeng Zhao",
      "Lin Li",
      "Ming Li",
      "Amran Bhuiyan",
      "Jimmy Huang"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06803v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06803v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.06391v1",
    "title": "HatePrototypes: Interpretable and Transferable Representations for Implicit and Explicit Hate Speech Detection",
    "summary": "Optimization of offensive content moderation models for different types of hateful messages is typically achieved through continued pre-training or fine-tuning on new hate speech benchmarks. However, existing benchmarks mainly address explicit hate toward protected groups and often overlook implicit or indirect hate, such as demeaning comparisons, calls for exclusion or violence, and subtle discriminatory language that still causes harm. While explicit hate can often be captured through surface features, implicit hate requires deeper, full-model semantic processing. In this work, we question the need for repeated fine-tuning and analyze the role of HatePrototypes, class-level vector representations derived from language models optimized for hate speech detection and safety moderation. We find that these prototypes, built from as few as 50 examples per class, enable cross-task transfer between explicit and implicit hate, with interchangeable prototypes across benchmarks. Moreover, we show that parameter-free early exiting with prototypes is effective for both hate types. We release the code, prototype resources, and evaluation scripts to support future research on efficient and transferable hate speech detection.",
    "authors": [
      "Irina Proskurina",
      "Marc-Antoine Carpentier",
      "Julien Velcin"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06391v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06391v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.06294v1",
    "title": "Transolver is a Linear Transformer: Revisiting Physics-Attention through the Lens of Linear Attention",
    "summary": "Recent advances in Transformer-based Neural Operators have enabled significant progress in data-driven solvers for Partial Differential Equations (PDEs). Most current research has focused on reducing the quadratic complexity of attention to address the resulting low training and inference efficiency. Among these works, Transolver stands out as a representative method that introduces Physics-Attention to reduce computational costs. Physics-Attention projects grid points into slices for slice attention, then maps them back through deslicing. However, we observe that Physics-Attention can be reformulated as a special case of linear attention, and that the slice attention may even hurt the model performance. Based on these observations, we argue that its effectiveness primarily arises from the slice and deslice operations rather than interactions between slices. Building on this insight, we propose a two-step transformation to redesign Physics-Attention into a canonical linear attention, which we call Linear Attention Neural Operator (LinearNO). Our method achieves state-of-the-art performance on six standard PDE benchmarks, while reducing the number of parameters by an average of 40.0% and computational cost by 36.2%. Additionally, it delivers superior performance on two challenging, industrial-level datasets: AirfRANS and Shape-Net Car.",
    "authors": [
      "Wenjie Hu",
      "Sidun Liu",
      "Peng Qiao",
      "Zhenglun Sun",
      "Yong Dou"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06294v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06294v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.06818v1",
    "title": "Learning to Focus: Focal Attention for Selective and Scalable Transformers",
    "summary": "Attention is a core component of transformer architecture, whether encoder-only, decoder-only, or encoder-decoder model. However, the standard softmax attention often produces noisy probability distribution, which can impair effective feature selection at every layer of these models, particularly for long contexts. We propose Focal Attention, a simple yet effective modification that sharpens the attention distribution by controlling the softmax temperature, either as a fixed hyperparameter or as a learnable parameter during training. This sharpening enables the model to concentrate on the most relevant tokens while suppressing irrelevant ones. Empirically, Focal Attention scales more favorably than standard transformer with respect to model size, training data, and context length. Across diverse benchmarks, it achieves the same accuracy with up to 42% fewer parameters or 33% less training data. On long-context tasks, it delivers substantial relative improvements ranging from 17% to 82%, demonstrating its effectiveness in real world applications.",
    "authors": [
      "Dhananjay Ram",
      "Wei Xia",
      "Stefano Soatto"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06818v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06818v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.06356v1",
    "title": "Reaction Prediction via Interaction Modeling of Symmetric Difference Shingle Sets",
    "summary": "Chemical reaction prediction remains a fundamental challenge in organic chemistry, where existing machine learning models face two critical limitations: sensitivity to input permutations (molecule/atom orderings) and inadequate modeling of substructural interactions governing reactivity. These shortcomings lead to inconsistent predictions and poor generalization to real-world scenarios. To address these challenges, we propose ReaDISH, a novel reaction prediction model that learns permutation-invariant representations while incorporating interaction-aware features. It introduces two innovations: (1) symmetric difference shingle encoding, which computes molecular shingle differences to capture reaction-specific structural changes while eliminating order sensitivity; and (2) geometry-structure interaction attention, a mechanism that models intra- and inter-molecular interactions at the shingle level. Extensive experiments demonstrate that ReaDISH improves reaction prediction performance across diverse benchmarks. It shows enhanced robustness with an average improvement of 8.76% on R$^2$ under permutation perturbations.",
    "authors": [
      "Runhan Shi",
      "Letian Chen",
      "Gufeng Yu",
      "Yang Yang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06356v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06356v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.06419v1",
    "title": "MONICA: Real-Time Monitoring and Calibration of Chain-of-Thought Sycophancy in Large Reasoning Models",
    "summary": "Large Reasoning Models (LRMs) suffer from sycophantic behavior, where models tend to agree with users' incorrect beliefs and follow misinformation rather than maintain independent reasoning. This behavior undermines model reliability and poses societal risks. Mitigating LRM sycophancy requires monitoring how this sycophancy emerges during the reasoning trajectory; however, current methods mainly focus on judging based on final answers and correcting them, without understanding how sycophancy develops during reasoning processes. To address this limitation, we propose MONICA, a novel Monitor-guided Calibration framework that monitors and mitigates sycophancy during model inference at the level of reasoning steps, without requiring the model to finish generating its complete answer. MONICA integrates a sycophantic monitor that provides real-time monitoring of sycophantic drift scores during response generation with a calibrator that dynamically suppresses sycophantic behavior when scores exceed predefined thresholds. Extensive experiments across 12 datasets and 3 LRMs demonstrate that our method effectively reduces sycophantic behavior in both intermediate reasoning steps and final answers, yielding robust performance improvements.",
    "authors": [
      "Jingyu Hu",
      "Shu Yang",
      "Xilin Gong",
      "Hongming Wang",
      "Weiru Liu",
      "Di Wang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06419v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06419v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.07416v1",
    "title": "Robot Learning from a Physical World Model",
    "summary": "We introduce PhysWorld, a framework that enables robot learning from video generation through physical world modeling. Recent video generation models can synthesize photorealistic visual demonstrations from language commands and images, offering a powerful yet underexplored source of training signals for robotics. However, directly retargeting pixel motions from generated videos to robots neglects physics, often resulting in inaccurate manipulations. PhysWorld addresses this limitation by coupling video generation with physical world reconstruction. Given a single image and a task command, our method generates task-conditioned videos and reconstructs the underlying physical world from the videos, and the generated video motions are grounded into physically accurate actions through object-centric residual reinforcement learning with the physical world model. This synergy transforms implicit visual guidance into physically executable robotic trajectories, eliminating the need for real robot data collection and enabling zero-shot generalizable robotic manipulation. Experiments on diverse real-world tasks demonstrate that PhysWorld substantially improves manipulation accuracy compared to previous approaches. Visit \\href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage} for details.",
    "authors": [
      "Jiageng Mao",
      "Sicheng He",
      "Hao-Ning Wu",
      "Yang You",
      "Shuyang Sun",
      "Zhicheng Wang",
      "Yanan Bao",
      "Huizhong Chen",
      "Leonidas Guibas",
      "Vitor Guizilini",
      "Howard Zhou",
      "Yue Wang"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07416v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07416v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.06618v1",
    "title": "GRAPH-GRPO-LEX: Contract Graph Modeling and Reinforcement Learning with Group Relative Policy Optimization",
    "summary": "Contracts are complex documents featuring detailed formal structures, explicit and implicit dependencies and rich semantic content. Given these document properties, contract drafting and manual examination of contracts have proven to be both arduous and susceptible to errors. This work aims to simplify and automate the task of contract review and analysis using a novel framework for transforming legal contracts into structured semantic graphs, enabling computational analysis and data-driven insights. We introduce a detailed ontology mapping core legal contract elements to their graph-theoretic equivalents of nodes and edges. We then present a reinforcement learning based Large Language Model (LLM) framework for segmentation and extraction of entities and relationships from contracts. Our method, GRAPH-GRPO-LEX, incorporates both LLMs and reinforcement learning with group relative policy optimization (GRPO). By applying a carefully drafted reward function of graph metrics, we demonstrate the ability to automatically identify direct relationships between clauses, and even uncover hidden dependencies. Our introduction of the gated GRPO approach shows a strong learning signal and can move contract analysis from a linear, manual reading process to an easily visualized graph. This allows for a more dynamic analysis, including building the groundwork for contract linting similar to what is now practiced in software engineering.",
    "authors": [
      "Moriya Dechtiar",
      "Daniel Martin Katz",
      "Mari Sundaresan",
      "Sylvain Jaume",
      "Hongming Wang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SE"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06618v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06618v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06761v1",
    "title": "SRNN: Spatiotemporal Relational Neural Network for Intuitive Physics Understanding",
    "summary": "Human prowess in intuitive physics remains unmatched by machines. To bridge this gap, we argue for a fundamental shift towards brain-inspired computational principles. This paper introduces the Spatiotemporal Relational Neural Network (SRNN), a model that establishes a unified neural representation for object attributes, relations, and timeline, with computations governed by a Hebbian ``Fire Together, Wire Together'' mechanism across dedicated \\textit{What} and \\textit{How} pathways. This unified representation is directly used to generate structured linguistic descriptions of the visual scene, bridging perception and language within a shared neural substrate. Moreover, unlike the prevalent ``pretrain-then-finetune'' paradigm, SRNN adopts a ``predefine-then-finetune'' approach. On the CLEVRER benchmark, SRNN achieves competitive performance. Our analysis further reveals a benchmark bias, outlines a path for a more holistic evaluation, and demonstrates SRNN's white-box utility for precise error diagnosis. Our work confirms the viability of translating biological intelligence into engineered systems for intuitive physics understanding.",
    "authors": [
      "Fei Yang"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06761v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06761v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.07317v1",
    "title": "RLVE: Scaling Up Reinforcement Learning for Language Models with Adaptive Verifiable Environments",
    "summary": "We introduce Reinforcement Learning (RL) with Adaptive Verifiable Environments (RLVE), an approach using verifiable environments that procedurally generate problems and provide algorithmically verifiable rewards, to scale up RL for language models (LMs). RLVE enables each verifiable environment to dynamically adapt its problem difficulty distribution to the policy model's capabilities as training progresses. In contrast, static data distributions often lead to vanishing learning signals when problems are either too easy or too hard for the policy. To implement RLVE, we create RLVE-Gym, a large-scale suite of 400 verifiable environments carefully developed through manual environment engineering. Using RLVE-Gym, we show that environment scaling, i.e., expanding the collection of training environments, consistently improves generalizable reasoning capabilities. RLVE with joint training across all 400 environments in RLVE-Gym yields a 3.37% absolute average improvement across six reasoning benchmarks, starting from one of the strongest 1.5B reasoning LMs. By comparison, continuing this LM's original RL training yields only a 0.49% average absolute gain despite using over 3x more compute. We release our code publicly.",
    "authors": [
      "Zhiyuan Zeng",
      "Hamish Ivison",
      "Yiping Wang",
      "Lifan Yuan",
      "Shuyue Stella Li",
      "Zhuorui Ye",
      "Siting Li",
      "Jacqueline He",
      "Runlong Zhou",
      "Tong Chen",
      "Chenyang Zhao",
      "Yulia Tsvetkov",
      "Simon Shaolei Du",
      "Natasha Jaques",
      "Hao Peng",
      "Pang Wei Koh",
      "Hannaneh Hajishirzi"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07317v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07317v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06973v1",
    "title": "Oh That Looks Familiar: A Novel Similarity Measure for Spreadsheet Template Discovery",
    "summary": "Traditional methods for identifying structurally similar spreadsheets fail to capture the spatial layouts and type patterns defining templates. To quantify spreadsheet similarity, we introduce a hybrid distance metric that combines semantic embeddings, data type information, and spatial positioning. In order to calculate spreadsheet similarity, our method converts spreadsheets into cell-level embeddings and then uses aggregation techniques like Chamfer and Hausdorff distances. Experiments across template families demonstrate superior unsupervised clustering performance compared to the graph-based Mondrian baseline, achieving perfect template reconstruction (Adjusted Rand Index of 1.00 versus 0.90) on the FUSTE dataset. Our approach facilitates large-scale automated template discovery, which in turn enables downstream applications such as retrieval-augmented generation over tabular collections, model training, and bulk data cleaning.",
    "authors": [
      "Ananad Krishnakumar",
      "Vengadesh Ravikumaran"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06973v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06973v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06406v1",
    "title": "On Modality Incomplete Infrared-Visible Object Detection: An Architecture Compatibility Perspective",
    "summary": "Infrared and visible object detection (IVOD) is essential for numerous around-the-clock applications. Despite notable advancements, current IVOD models exhibit notable performance declines when confronted with incomplete modality data, particularly if the dominant modality is missing. In this paper, we take a thorough investigation on modality incomplete IVOD problem from an architecture compatibility perspective. Specifically, we propose a plug-and-play Scarf Neck module for DETR variants, which introduces a modality-agnostic deformable attention mechanism to enable the IVOD detector to flexibly adapt to any single or double modalities during training and inference. When training Scarf-DETR, we design a pseudo modality dropout strategy to fully utilize the multi-modality information, making the detector compatible and robust to both working modes of single and double modalities. Moreover, we introduce a comprehensive benchmark for the modality-incomplete IVOD task aimed at thoroughly assessing situations where the absent modality is either dominant or secondary. Our proposed Scarf-DETR not only performs excellently in missing modality scenarios but also achieves superior performances on the standard IVOD modality complete benchmarks. Our code will be available at https://github.com/YinghuiXing/Scarf-DETR.",
    "authors": [
      "Shuo Yang",
      "Yinghui Xing",
      "Shizhou Zhang",
      "Zhilong Niu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06406v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06406v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06894v1",
    "title": "COGNOS: Universal Enhancement for Time Series Anomaly Detection via Constrained Gaussian-Noise Optimization and Smoothing",
    "summary": "Reconstruction-based methods are a dominant paradigm in time series anomaly detection (TSAD), however, their near-universal reliance on Mean Squared Error (MSE) loss results in statistically flawed reconstruction residuals. This fundamental weakness leads to noisy, unstable anomaly scores with a poor signal-to-noise ratio, hindering reliable detection. To address this, we propose Constrained Gaussian-Noise Optimization and Smoothing (COGNOS), a universal, model-agnostic enhancement framework that tackles this issue at its source. COGNOS introduces a novel Gaussian-White Noise Regularization strategy during training, which directly constrains the model's output residuals to conform to a Gaussian white noise distribution. This engineered statistical property creates the ideal precondition for our second contribution: a Kalman Smoothing Post-processor that provably operates as a statistically optimal estimator to denoise the raw anomaly scores. The synergy between these two components allows COGNOS to robustly separate the true anomaly signal from random fluctuations. Extensive experiments demonstrate that COGNOS is highly effective, delivering an average F-score uplift of 57.9% when applied to 12 diverse backbone models across multiple real-world benchmark datasets. Our work reveals that directly regularizing output statistics is a powerful and generalizable strategy for significantly improving anomaly detection systems.",
    "authors": [
      "Wenlong Shang",
      "Peng Chang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06894v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06894v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.07065v1",
    "title": "Aligning Attention with Human Rationales for Self-Explaining Hate Speech Detection",
    "summary": "The opaque nature of deep learning models presents significant challenges for the ethical deployment of hate speech detection systems. To address this limitation, we introduce Supervised Rational Attention (SRA), a framework that explicitly aligns model attention with human rationales, improving both interpretability and fairness in hate speech classification. SRA integrates a supervised attention mechanism into transformer-based classifiers, optimizing a joint objective that combines standard classification loss with an alignment loss term that minimizes the discrepancy between attention weights and human-annotated rationales. We evaluated SRA on hate speech benchmarks in English (HateXplain) and Portuguese (HateBRXplain) with rationale annotations. Empirically, SRA achieves 2.4x better explainability compared to current baselines, and produces token-level explanations that are more faithful and human-aligned. In terms of fairness, SRA achieves competitive fairness across all measures, with second-best performance in detecting toxic posts targeting identity groups, while maintaining comparable results on other metrics. These findings demonstrate that incorporating human rationales into attention mechanisms can enhance interpretability and faithfulness without compromising fairness.",
    "authors": [
      "Brage Eilertsen",
      "Røskva Bjørgfinsdóttir",
      "Francielle Vargas",
      "Ali Ramezani-Kebrya"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07065v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07065v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06411v1",
    "title": "SofT-GRPO: Surpassing Discrete-Token LLM Reinforcement Learning via Gumbel-Reparameterized Soft-Thinking Policy Optimization",
    "summary": "The soft-thinking paradigm for Large Language Model (LLM) reasoning can outperform the conventional discrete-token Chain-of-Thought (CoT) reasoning in some scenarios, underscoring its research and application value. However, while the discrete-token CoT reasoning pattern can be reinforced through policy optimization algorithms such as group relative policy optimization (GRPO), extending the soft-thinking pattern with Reinforcement Learning (RL) remains challenging. This difficulty stems from the complexities of injecting stochasticity into soft-thinking tokens and updating soft-thinking policies accordingly. As a result, previous attempts to combine soft-thinking with GRPO typically underperform their discrete-token GRPO counterparts. To fully unlock the potential of soft-thinking, this paper presents a novel policy optimization algorithm, SofT-GRPO, to reinforce LLMs under the soft-thinking reasoning pattern. SofT-GRPO injects the Gumbel noise into logits, employs the Gumbel-Softmax technique to avoid soft-thinking tokens outside the pre-trained embedding space, and leverages the reparameterization trick in policy gradient. We conduct experiments across base LLMs ranging from 1.5B to 7B parameters, and results demonstrate that SofT-GRPO enables soft-thinking LLMs to slightly outperform discrete-token GRPO on Pass@1 (+0.13% on average accuracy), while exhibiting a substantial uplift on Pass@32 (+2.19% on average accuracy). Codes and weights are available on https://github.com/zz1358m/SofT-GRPO-master",
    "authors": [
      "Zhi Zheng",
      "Wee Sun Lee"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06411v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06411v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06575v1",
    "title": "CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot Planning",
    "summary": "Large Language Models (LLMs) have recently emerged as planners for language-instructed agents, generating sequences of actions to accomplish natural language tasks. However, their reliability remains a challenge, especially in long-horizon tasks, since they often produce overconfident yet wrong outputs. Conformal Prediction (CP) has been leveraged to address this issue by wrapping LLM outputs into prediction sets that contain the correct action with a user-defined confidence. When the prediction set is a singleton, the planner executes that action; otherwise, it requests help from a user. This has led to LLM-based planners that can ensure plan correctness with a user-defined probability. However, as LLMs are trained in an uncertainty-agnostic manner, without awareness of prediction sets, they tend to produce unnecessarily large sets, particularly at higher confidence levels, resulting in frequent human interventions limiting autonomous deployment. To address this, we introduce CoFineLLM (Conformal Finetuning for LLMs), the first CP-aware finetuning framework for LLM-based planners that explicitly reduces prediction-set size and, in turn, the need for user interventions. We evaluate our approach on multiple language-instructed robot planning problems and show consistent improvements over uncertainty-aware and uncertainty-agnostic finetuning baselines in terms of prediction-set size, and help rates. Finally, we demonstrate robustness of our method to out-of-distribution scenarios in hardware experiments.",
    "authors": [
      "Jun Wang",
      "Yevgeniy Vorobeychik",
      "Yiannis Kantaros"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06575v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06575v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06653v1",
    "title": "HiMo-CLIP: Modeling Semantic Hierarchy and Monotonicity in Vision-Language Alignment",
    "summary": "Contrastive vision-language models like CLIP have achieved impressive results in image-text retrieval by aligning image and text representations in a shared embedding space. However, these models often treat text as flat sequences, limiting their ability to handle complex, compositional, and long-form descriptions. In particular, they fail to capture two essential properties of language: semantic hierarchy, which reflects the multi-level compositional structure of text, and semantic monotonicity, where richer descriptions should result in stronger alignment with visual content.To address these limitations, we propose HiMo-CLIP, a representation-level framework that enhances CLIP-style models without modifying the encoder architecture. HiMo-CLIP introduces two key components: a hierarchical decomposition (HiDe) module that extracts latent semantic components from long-form text via in-batch PCA, enabling flexible, batch-aware alignment across different semantic granularities, and a monotonicity-aware contrastive loss (MoLo) that jointly aligns global and component-level representations, encouraging the model to internalize semantic ordering and alignment strength as a function of textual completeness.These components work in concert to produce structured, cognitively-aligned cross-modal representations. Experiments on multiple image-text retrieval benchmarks show that HiMo-CLIP consistently outperforms strong baselines, particularly under long or compositional descriptions. The code is available at https://github.com/UnicomAI/HiMo-CLIP.",
    "authors": [
      "Ruijia Wu",
      "Ping Chen",
      "Fei Shen",
      "Shaoan Zhao",
      "Qiang Hui",
      "Huanlin Gao",
      "Ting Lu",
      "Zhaoxiang Liu",
      "Fang Zhao",
      "Kai Wang",
      "Shiguo Lian"
    ],
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06653v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06653v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06571v1",
    "title": "Rep2Text: Decoding Full Text from a Single LLM Token Representation",
    "summary": "Large language models (LLMs) have achieved remarkable progress across diverse tasks, yet their internal mechanisms remain largely opaque. In this work, we address a fundamental question: to what extent can the original input text be recovered from a single last-token representation within an LLM? We propose Rep2Text, a novel framework for decoding full text from last-token representations. Rep2Text employs a trainable adapter that projects a target model's internal representations into the embedding space of a decoding language model, which then autoregressively reconstructs the input text. Experiments on various model combinations (Llama-3.1-8B, Gemma-7B, Mistral-7B-v0.1, Llama-3.2-3B) demonstrate that, on average, over half of the information in 16-token sequences can be recovered from this compressed representation while maintaining strong semantic integrity and coherence. Furthermore, our analysis reveals an information bottleneck effect: longer sequences exhibit decreased token-level recovery while preserving strong semantic integrity. Besides, our framework also demonstrates robust generalization to out-of-distribution medical data.",
    "authors": [
      "Haiyan Zhao",
      "Zirui He",
      "Fan Yang",
      "Ali Payani",
      "Mengnan Du"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06571v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06571v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.06722v1",
    "title": "Revisiting the Data Sampling in Multimodal Post-training from a Difficulty-Distinguish View",
    "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have spurred significant progress in Chain-of-Thought (CoT) reasoning. Building on the success of Deepseek-R1, researchers extended multimodal reasoning to post-training paradigms based on reinforcement learning (RL), focusing predominantly on mathematical datasets. However, existing post-training paradigms tend to neglect two critical aspects: (1) The lack of quantifiable difficulty metrics capable of strategically screening samples for post-training optimization. (2) Suboptimal post-training paradigms that fail to jointly optimize perception and reasoning capabilities. To address this gap, we propose two novel difficulty-aware sampling strategies: Progressive Image Semantic Masking (PISM) quantifies sample hardness through systematic image degradation, while Cross-Modality Attention Balance (CMAB) assesses cross-modal interaction complexity via attention distribution analysis. Leveraging these metrics, we design a hierarchical training framework that incorporates both GRPO-only and SFT+GRPO hybrid training paradigms, and evaluate them across six benchmark datasets. Experiments demonstrate consistent superiority of GRPO applied to difficulty-stratified samples compared to conventional SFT+GRPO pipelines, indicating that strategic data sampling can obviate the need for supervised fine-tuning while improving model accuracy. Our code will be released at https://github.com/qijianyu277/DifficultySampling.",
    "authors": [
      "Jianyu Qi",
      "Ding Zou",
      "Wenrui Yan",
      "Rui Ma",
      "Jiaxu Li",
      "Zhijie Zheng",
      "Zhiguo Yang",
      "Rongchang Zhao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06722v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06722v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.06425v1",
    "title": "Non-Negative Stiefel Approximating Flow: Orthogonalish Matrix Optimization for Interpretable Embeddings",
    "summary": "Interpretable representation learning is a central challenge in modern machine learning, particularly in high-dimensional settings such as neuroimaging, genomics, and text analysis. Current methods often struggle to balance the competing demands of interpretability and model flexibility, limiting their effectiveness in extracting meaningful insights from complex data. We introduce Non-negative Stiefel Approximating Flow (NSA-Flow), a general-purpose matrix estimation framework that unifies ideas from sparse matrix factorization, orthogonalization, and constrained manifold learning. NSA-Flow enforces structured sparsity through a continuous balance between reconstruction fidelity and column-wise decorrelation, parameterized by a single tunable weight. The method operates as a smooth flow near the Stiefel manifold with proximal updates for non-negativity and adaptive gradient control, yielding representations that are simultaneously sparse, stable, and interpretable. Unlike classical regularization schemes, NSA-Flow provides an intuitive geometric mechanism for manipulating sparsity at the level of global structure while simplifying latent features. We demonstrate that the NSA-Flow objective can be optimized smoothly and integrates seamlessly with existing pipelines for dimensionality reduction while improving interpretability and generalization in both simulated and real biomedical data. Empirical validation on the Golub leukemia dataset and in Alzheimer's disease demonstrate that the NSA-Flow constraints can maintain or improve performance over related methods with little additional methodological effort. NSA-Flow offers a scalable, general-purpose tool for interpretable ML, applicable across data science domains.",
    "authors": [
      "Brian B. Avants",
      "Nicholas J. Tustison",
      "James R Stone"
    ],
    "categories": [
      "stat.ML",
      "cs.CV",
      "cs.LG",
      "stat.ME"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06425v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06425v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.06259v1",
    "title": "Breaking the Modality Barrier: Generative Modeling for Accurate Molecule Retrieval from Mass Spectra",
    "summary": "Retrieving molecular structures from tandem mass spectra is a crucial step in rapid compound identification. Existing retrieval methods, such as traditional mass spectral library matching, suffer from limited spectral library coverage, while recent cross-modal representation learning frameworks often encounter modality misalignment, resulting in suboptimal retrieval accuracy and generalization. To address these limitations, we propose GLMR, a Generative Language Model-based Retrieval framework that mitigates the cross-modal misalignment through a two-stage process. In the pre-retrieval stage, a contrastive learning-based model identifies top candidate molecules as contextual priors for the input mass spectrum. In the generative retrieval stage, these candidate molecules are integrated with the input mass spectrum to guide a generative model in producing refined molecular structures, which are then used to re-rank the candidates based on molecular similarity. Experiments on both MassSpecGym and the proposed MassRET-20k dataset demonstrate that GLMR significantly outperforms existing methods, achieving over 40% improvement in top-1 accuracy and exhibiting strong generalizability.",
    "authors": [
      "Yiwen Zhang",
      "Keyan Ding",
      "Yihang Wu",
      "Xiang Zhuang",
      "Yi Yang",
      "Qiang Zhang",
      "Huajun Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06259v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06259v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07288v1",
    "title": "Enabling Off-Policy Imitation Learning with Deep Actor Critic Stabilization",
    "summary": "Learning complex policies with Reinforcement Learning (RL) is often hindered by instability and slow convergence, a problem exacerbated by the difficulty of reward engineering. Imitation Learning (IL) from expert demonstrations bypasses this reliance on rewards. However, state-of-the-art IL methods, exemplified by Generative Adversarial Imitation Learning (GAIL)Ho et. al, suffer from severe sample inefficiency. This is a direct consequence of their foundational on-policy algorithms, such as TRPO Schulman et.al. In this work, we introduce an adversarial imitation learning algorithm that incorporates off-policy learning to improve sample efficiency. By combining an off-policy framework with auxiliary techniques specifically, double Q network based stabilization and value learning without reward function inference we demonstrate a reduction in the samples required to robustly match expert behavior.",
    "authors": [
      "Sayambhu Sen",
      "Shalabh Bhatnagar"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07288v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07288v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07091v1",
    "title": "How Bias Binds: Measuring Hidden Associations for Bias Control in Text-to-Image Compositions",
    "summary": "Text-to-image generative models often exhibit bias related to sensitive attributes. However, current research tends to focus narrowly on single-object prompts with limited contextual diversity. In reality, each object or attribute within a prompt can contribute to bias. For example, the prompt \"an assistant wearing a pink hat\" may reflect female-inclined biases associated with a pink hat. The neglected joint effects of the semantic binding in the prompts cause significant failures in current debiasing approaches. This work initiates a preliminary investigation on how bias manifests under semantic binding, where contextual associations between objects and attributes influence generative outcomes. We demonstrate that the underlying bias distribution can be amplified based on these associations. Therefore, we introduce a bias adherence score that quantifies how specific object-attribute bindings activate bias. To delve deeper, we develop a training-free context-bias control framework to explore how token decoupling can facilitate the debiasing of semantic bindings. This framework achieves over 10% debiasing improvement in compositional generation tasks. Our analysis of bias scores across various attribute-object bindings and token decorrelation highlights a fundamental challenge: reducing bias without disrupting essential semantic relationships. These findings expose critical limitations in current debiasing approaches when applied to semantically bound contexts, underscoring the need to reassess prevailing bias mitigation strategies.",
    "authors": [
      "Jeng-Lin Li",
      "Ming-Ching Chang",
      "Wei-Chao Chen"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07091v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07091v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.06961v1",
    "title": "Hybrid Autoencoders for Tabular Data: Leveraging Model-Based Augmentation in Low-Label Settings",
    "summary": "Deep neural networks often under-perform on tabular data due to their sensitivity to irrelevant features and a spectral bias toward smooth, low-frequency functions. These limitations hinder their ability to capture the sharp, high-frequency signals that often define tabular structure, especially under limited labeled samples. While self-supervised learning (SSL) offers promise in such settings, it remains challenging in tabular domains due to the lack of effective data augmentations. We propose a hybrid autoencoder that combines a neural encoder with an oblivious soft decision tree (OSDT) encoder, each guided by its own stochastic gating network that performs sample-specific feature selection. Together, these structurally different encoders and model-specific gating networks implement model-based augmentation, producing complementary input views tailored to each architecture. The two encoders, trained with a shared decoder and cross-reconstruction loss, learn distinct yet aligned representations that reflect their respective inductive biases. During training, the OSDT encoder (robust to noise and effective at modeling localized, high-frequency structure) guides the neural encoder toward representations more aligned with tabular data. At inference, only the neural encoder is used, preserving flexibility and SSL compatibility. Spectral analysis highlights the distinct inductive biases of each encoder. Our method achieves consistent gains in low-label classification and regression across diverse tabular datasets, outperforming deep and tree-based supervised baselines.",
    "authors": [
      "Erel Naor",
      "Ofir Lindenbaum"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06961v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06961v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.06694v1",
    "title": "ML-EcoLyzer: Quantifying the Environmental Cost of Machine Learning Inference Across Frameworks and Hardware",
    "summary": "Machine learning inference occurs at a massive scale, yet its environmental impact remains poorly quantified, especially on low-resource hardware. We present ML-EcoLyzer, a cross-framework tool for measuring the carbon, energy, thermal, and water costs of inference across CPUs, consumer GPUs, and datacenter accelerators. The tool supports both classical and modern models, applying adaptive monitoring and hardware-aware evaluation.   We introduce the Environmental Sustainability Score (ESS), which quantifies the number of effective parameters served per gram of CO$_2$ emitted. Our evaluation covers over 1,900 inference configurations, spanning diverse model architectures, task modalities (text, vision, audio, tabular), hardware types, and precision levels. These rigorous and reliable measurements demonstrate that quantization enhances ESS, huge accelerators can be inefficient for lightweight applications, and even small models may incur significant costs when implemented suboptimally. ML-EcoLyzer sets a standard for sustainability-conscious model selection and offers an extensive empirical evaluation of environmental costs during inference.",
    "authors": [
      "Jose Marie Antonio Minoza",
      "Rex Gregor Laylo",
      "Christian F Villarin",
      "Sebastian C. Ibanez"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06694v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06694v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07398v1",
    "title": "Solving bilevel optimization via sequential minimax optimization",
    "summary": "In this paper we propose a sequential minimax optimization (SMO) method for solving a class of constrained bilevel optimization problems in which the lower-level part is a possibly nonsmooth convex optimization problem, while the upper-level part is a possibly nonconvex optimization problem. Specifically, SMO applies a first-order method to solve a sequence of minimax subproblems, which are obtained by employing a hybrid of modified augmented Lagrangian and penalty schemes on the bilevel optimization problems. Under suitable assumptions, we establish an operation complexity of $O(\\varepsilon^{-7}\\log\\varepsilon^{-1})$ and $O(\\varepsilon^{-6}\\log\\varepsilon^{-1})$, measured in terms of fundamental operations, for SMO in finding an $\\varepsilon$-KKT solution of the bilevel optimization problems with merely convex and strongly convex lower-level objective functions, respectively. The latter result improves the previous best-known operation complexity by a factor of $\\varepsilon^{-1}$. Preliminary numerical results demonstrate significantly superior computational performance compared to the recently developed first-order penalty method.",
    "authors": [
      "Zhaosong Lu",
      "Sanyou Mei"
    ],
    "categories": [
      "math.OC",
      "cs.LG",
      "math.NA",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07398v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07398v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07165v1",
    "title": "Fuzzy Label: From Concept to Its Application in Label Learning",
    "summary": "Label learning is a fundamental task in machine learning that aims to construct intelligent models using labeled data, encompassing traditional single-label and multi-label classification models. Traditional methods typically rely on logical labels, such as binary indicators (e.g., \"yes/no\") that specify whether an instance belongs to a given category. However, in practical applications, label annotations often involve significant uncertainty due to factors such as data noise, inherent ambiguity in the observed entities, and the subjectivity of human annotators. Therefore, representing labels using simplistic binary logic can obscure valuable information and limit the expressiveness of label learning models. To overcome this limitation, this paper introduces the concept of fuzzy labels, grounded in fuzzy set theory, to better capture and represent label uncertainty. We further propose an efficient fuzzy labeling method that mines and generates fuzzy labels from the original data, thereby enriching the label space with more informative and nuanced representations. Based on this foundation, we present fuzzy-label-enhanced algorithms for both single-label and multi-label learning, using the classical K-Nearest Neighbors (KNN) and multi-label KNN algorithms as illustrative examples. Experimental results indicate that fuzzy labels can more effectively characterize the real-world labeling information and significantly enhance the performance of label learning models.",
    "authors": [
      "Chenxi Luoa",
      "Zhuangzhuang Zhaoa",
      "Zhaohong Denga",
      "Te Zhangb"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07165v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07165v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.06582v1",
    "title": "TabRAG: Tabular Document Retrieval via Structured Language Representations",
    "summary": "Ingesting data for Retrieval-Augmented Generation (RAG) involves either fine-tuning the embedding model directly on the target corpus or parsing documents for embedding model encoding. The former, while accurate, incurs high computational hardware requirements, while the latter suffers from suboptimal performance when extracting tabular data. In this work, we address the latter by presenting TabRAG, a parsing-based RAG pipeline designed to tackle table-heavy documents via structured language representations. TabRAG outperforms existing popular parsing-based methods for generation and retrieval. Code is available at https://github.com/jacobyhsi/TabRAG.",
    "authors": [
      "Jacob Si",
      "Mike Qu",
      "Michelle Lee",
      "Yingzhen Li"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06582v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06582v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06790v1",
    "title": "Robust Causal Discovery under Imperfect Structural Constraints",
    "summary": "Robust causal discovery from observational data under imperfect prior knowledge remains a significant and largely unresolved challenge. Existing methods typically presuppose perfect priors or can only handle specific, pre-identified error types. And their performance degrades substantially when confronted with flawed constraints of unknown location and type. This decline arises because most of them rely on inflexible and biased thresholding strategies that may conflict with the data distribution. To overcome these limitations, we propose to harmonizes knowledge and data through prior alignment and conflict resolution. First, we assess the credibility of imperfect structural constraints through a surrogate model, which then guides a sparse penalization term measuring the loss between the learned and constrained adjacency matrices. We theoretically prove that, under ideal assumption, the knowledge-driven objective aligns with the data-driven objective. Furthermore, to resolve conflicts when this assumption is violated, we introduce a multi-task learning framework optimized via multi-gradient descent, jointly minimizing both objectives. Our proposed method is robust to both linear and nonlinear settings. Extensive experiments, conducted under diverse noise conditions and structural equation model types, demonstrate the effectiveness and efficiency of our method under imperfect structural constraints.",
    "authors": [
      "Zidong Wang",
      "Xi Lin",
      "Chuchao He",
      "Xiaoguang Gao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06790v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06790v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07109v1",
    "title": "A Provably-Correct and Robust Convex Model for Smooth Separable NMF",
    "summary": "Nonnegative matrix factorization (NMF) is a linear dimensionality reduction technique for nonnegative data, with applications such as hyperspectral unmixing and topic modeling. NMF is a difficult problem in general (NP-hard), and its solutions are typically not unique. To address these two issues, additional constraints or assumptions are often used. In particular, separability assumes that the basis vectors in the NMF are equal to some columns of the input matrix. In that case, the problem is referred to as separable NMF (SNMF) and can be solved in polynomial-time with robustness guarantees, while identifying a unique solution. However, in real-world scenarios, due to noise or variability, multiple data points may lie near the basis vectors, which SNMF does not leverage. In this work, we rely on the smooth separability assumption, which assumes that each basis vector is close to multiple data points. We explore the properties of the corresponding problem, referred to as smooth SNMF (SSNMF), and examine how it relates to SNMF and orthogonal NMF. We then propose a convex model for SSNMF and show that it provably recovers the sought-after factors, even in the presence of noise. We finally adapt an existing fast gradient method to solve this convex model for SSNMF, and show that it compares favorably with state-of-the-art methods on both synthetic and hyperspectral datasets.",
    "authors": [
      "Junjun Pan",
      "Valentin Leplat",
      "Michael Ng",
      "Nicolas Gillis"
    ],
    "categories": [
      "math.NA",
      "cs.LG",
      "eess.SP",
      "math.OC",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07109v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07109v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06781v1",
    "title": "On the Mechanisms of Collaborative Learning in VAE Recommenders",
    "summary": "Variational Autoencoders (VAEs) are a powerful alternative to matrix factorization for recommendation. A common technique in VAE-based collaborative filtering (CF) consists in applying binary input masking to user interaction vectors, which improves performance but remains underexplored theoretically. In this work, we analyze how collaboration arises in VAE-based CF and show it is governed by latent proximity: we derive a latent sharing radius that informs when an SGD update on one user strictly reduces the loss on another user, with influence decaying as the latent Wasserstein distance increases. We further study the induced geometry: with clean inputs, VAE-based CF primarily exploits \\emph{local} collaboration between input-similar users and under-utilizes global collaboration between far-but-related users. We compare two mechanisms that encourage \\emph{global} mixing and characterize their trade-offs: (1) $β$-KL regularization directly tightens the information bottleneck, promoting posterior overlap but risking representational collapse if too large; (2) input masking induces stochastic geometric contractions and expansions, which can bring distant users onto the same latent neighborhood but also introduce neighborhood drift. To preserve user identity while enabling global consistency, we propose an anchor regularizer that aligns user posteriors with item embeddings, stabilizing users under masking and facilitating signal sharing across related items. Our analyses are validated on the Netflix, MovieLens-20M, and Million Song datasets. We also successfully deployed our proposed algorithm on an Amazon streaming platform following a successful online experiment.",
    "authors": [
      "Tung-Long Vuong",
      "Julien Monteil",
      "Hien Dang",
      "Volodymyr Vaskovych",
      "Trung Le",
      "Vu Nguyen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06781v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06781v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06886v1",
    "title": "Inclusion of Role into Named Entity Recognition and Ranking",
    "summary": "Most of the Natural Language Processing systems are involved in entity-based processing for several tasks like Information Extraction, Question-Answering, Text-Summarization and so on. A new challenge comes when entities play roles according to their act or attributes in certain context. Entity Role Detection is the task of assigning such roles to the entities. Usually real-world entities are of types: person, location and organization etc. Roles could be considered as domain-dependent subtypes of these types. In the cases, where retrieving a subset of entities based on their roles is needed, poses the problem of defining the role and entities having those roles. This paper presents the study of study of solving Entity Role Detection problem by modeling it as Named Entity Recognition (NER) and Entity Retrieval/Ranking task. In NER, these roles could be considered as mutually exclusive classes and standard NER methods like sequence tagging could be used. For Entity Retrieval, Roles could be formulated as Query and entities as Collection on which the query needs to be executed. The aspect of Entity Retrieval task, which is different than document retrieval task is that the entities and roles against which they need to be retrieved are indirectly described. We have formulated automated ways of learning representative words and phrases and building representations of roles and entities using them. We have also explored different contexts like sentence and document. Since the roles depend upon context, so it is not always possible to have large domain-specific dataset or knowledge bases for learning purposes, so we have tried to exploit the information from small dataset in domain-agnostic way.",
    "authors": [
      "Neelesh Kumar Shukla",
      "Sanasam Ranbir Singh"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06886v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06886v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06232v1",
    "title": "Scaling Laws and In-Context Learning: A Unified Theoretical Framework",
    "summary": "In-context learning (ICL) enables large language models to adapt to new tasks from demonstrations without parameter updates. Despite extensive empirical studies, a principled understanding of ICL emergence at scale remains more elusive. We present a unified theoretical framework connecting scaling laws to ICL emergence in transformers. Our analysis establishes that ICL performance follows power-law relationships with model depth $L$, width $d$, context length $k$, and training data $D$, with exponents determined by task structure. We show that under specific conditions, transformers implement gradient-based metalearning in their forward pass, with an effective learning rate $η_{\\text{eff}} = Θ(1/\\sqrt{Ld})$. We demonstrate sharp phase transitions at critical scales and derive optimal depth-width allocations favoring $L^* \\propto N^{2/3}$, $d^* \\propto N^{1/3}$ for the fixed parameter budget $N = Ld$. Systematic experiments on synthetic tasks validate our predictions, with measured scaling exponents closely matching theory. This work provides both necessary and sufficient conditions for the emergence of ICLs and establishes fundamental computational limits on what transformers can learn in-context.",
    "authors": [
      "Sushant Mehta",
      "Ishan Gupta"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06232v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06232v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07392v1",
    "title": "Surgical Agent Orchestration Platform for Voice-directed Patient Data Interaction",
    "summary": "In da Vinci robotic surgery, surgeons' hands and eyes are fully engaged in the procedure, making it difficult to access and manipulate multimodal patient data without interruption. We propose a voice-directed Surgical Agent Orchestrator Platform (SAOP) built on a hierarchical multi-agent framework, consisting of an orchestration agent and three task-specific agents driven by Large Language Models (LLMs). These LLM-based agents autonomously plan, refine, validate, and reason to map voice commands into specific tasks such as retrieving clinical information, manipulating CT scans, or navigating 3D anatomical models on the surgical video. We also introduce a Multi-level Orchestration Evaluation Metric (MOEM) to comprehensively assess the performance and robustness from command-level and category-level perspectives. The SAOP achieves high accuracy and success rates across 240 voice commands, while LLM-based agents improve robustness against speech recognition errors and diverse or ambiguous free-form commands, demonstrating strong potential to support minimally invasive da Vinci robotic surgery.",
    "authors": [
      "Hyeryun Park",
      "Byung Mo Gu",
      "Jun Hee Lee",
      "Byeong Hyeon Choi",
      "Sekeun Kim",
      "Hyun Koo Kim",
      "Kyungsang Kim"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07392v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07392v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07230v1",
    "title": "Discourse Graph Guided Document Translation with Large Language Models",
    "summary": "Adapting large language models to full document translation remains challenging due to the difficulty of capturing long-range dependencies and preserving discourse coherence throughout extended texts. While recent agentic machine translation systems mitigate context window constraints through multi-agent orchestration and persistent memory, they require substantial computational resources and are sensitive to memory retrieval strategies. We introduce TransGraph, a discourse-guided framework that explicitly models inter-chunk relationships through structured discourse graphs and selectively conditions each translation segment on relevant graph neighbourhoods rather than relying on sequential or exhaustive context. Across three document-level MT benchmarks spanning six languages and diverse domains, TransGraph consistently surpasses strong baselines in translation quality and terminology consistency while incurring significantly lower token overhead.",
    "authors": [
      "Viet-Thanh Pham",
      "Minghan Wang",
      "Hao-Han Liao",
      "Thuy-Trang Vu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07230v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07230v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07197v1",
    "title": "Simulation-based Methods for Optimal Sampling Design in Systems Biology",
    "summary": "In many areas of systems biology, including virology, pharmacokinetics, and population biology, dynamical systems are commonly used to describe biological processes. These systems can be characterized by estimating their parameters from sampled data. The key problem is how to optimally select sampling points to achieve accurate parameter estimation. Classical approaches often rely on Fisher information matrix-based criteria such as A-, D-, and E-optimality, which require an initial parameter estimate and may yield suboptimal results when the estimate is inaccurate. This study proposes two simulation-based methods for optimal sampling design that do not depend on initial parameter estimates. The first method, E-optimal-ranking (EOR), employs the E-optimal criterion, while the second utilizes a Long Short-Term Memory (LSTM) neural network. Simulation studies based on the Lotka-Volterra and three-compartment models demonstrate that the proposed methods outperform both random selection and classical E-optimal design.",
    "authors": [
      "Tuan Minh Ha",
      "Binh Thanh Nguyen",
      "Lam Si Tung Ho"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07197v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07197v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06374v1",
    "title": "Adaptive Regularization for Large-Scale Sparse Feature Embedding Models",
    "summary": "The one-epoch overfitting problem has drawn widespread attention, especially in CTR and CVR estimation models in search, advertising, and recommendation domains. These models which rely heavily on large-scale sparse categorical features, often suffer a significant decline in performance when trained for multiple epochs. Although recent studies have proposed heuristic solutions, they have not clearly identified the fundamental cause of this phenomenon. In this work, we provide a theoretical analysis that explains why overfitting occurs in models that use large-scale sparse categorical features. Based on this analysis, we propose an adaptive regularization method to address it. Our approach not only prevents the severe performance degradation observed during multi-epoch training, but also improves model performance within a single epoch. This method has already been deployed in online production systems.",
    "authors": [
      "Mang Li",
      "Wei Lyu"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06374v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06374v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07080v1",
    "title": "Wasm: A Pipeline for Constructing Structured Arabic Interleaved Multimodal Corpora",
    "summary": "The performance of large language models (LLMs) and large multimodal models (LMMs) depends heavily on the quality and scale of their pre-training datasets. Recent research shows that large multimodal models trained on natural documents where images and text are interleaved outperform those trained only on image-text pairs across a wide range of benchmarks, leveraging advanced pre-trained models to enforce semantic alignment, image-sequence consistency, and textual coherence. For Arabic, however, the lack of high-quality multimodal datasets that preserve document structure has limited progress. In this paper, we present our pipeline Wasm for processing the Common Crawl dataset to create a new Arabic multimodal dataset that uniquely provides markdown output. Unlike existing Arabic corpora that focus solely on text extraction, our approach preserves the structural integrity of web content while maintaining flexibility for both text-only and multimodal pre-training scenarios. We provide a comprehensive comparative analysis of our data processing pipeline against those used for major existing datasets, highlighting the convergences in filtering strategies and justifying our specific design choices. To support future research, we publicly release a representative dataset dump along with the multimodal processing pipeline for Arabic.",
    "authors": [
      "Khalil Hennara",
      "Ahmad Bastati",
      "Muhammad Hreden",
      "Mohamed Motasim Hamed",
      "Zeina Aldallal",
      "Sara Chrouf",
      "Safwan AlModhayan"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07080v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07080v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06284v1",
    "title": "Enhancing Multimodal Misinformation Detection by Replaying the Whole Story from Image Modality Perspective",
    "summary": "Multimodal Misinformation Detection (MMD) refers to the task of detecting social media posts involving misinformation, where the post often contains text and image modalities. However, by observing the MMD posts, we hold that the text modality may be much more informative than the image modality because the text generally describes the whole event/story of the current post but the image often presents partial scenes only. Our preliminary empirical results indicate that the image modality exactly contributes less to MMD. Upon this idea, we propose a new MMD method named RETSIMD. Specifically, we suppose that each text can be divided into several segments, and each text segment describes a partial scene that can be presented by an image. Accordingly, we split the text into a sequence of segments, and feed these segments into a pre-trained text-to-image generator to augment a sequence of images. We further incorporate two auxiliary objectives concerning text-image and image-label mutual information, and further post-train the generator over an auxiliary text-to-image generation benchmark dataset. Additionally, we propose a graph structure by defining three heuristic relationships between images, and use a graph neural network to generate the fused features. Extensive empirical results validate the effectiveness of RETSIMD.",
    "authors": [
      "Bing Wang",
      "Ximing Li",
      "Yanjun Wang",
      "Changchun Li",
      "Lin Yuanbo Wu",
      "Buyu Wang",
      "Shengsheng Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.MM"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06284v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06284v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07378v1",
    "title": "Transformers Provably Learn Chain-of-Thought Reasoning with Length Generalization",
    "summary": "The ability to reason lies at the core of artificial intelligence (AI), and challenging problems usually call for deeper and longer reasoning to tackle. A crucial question about AI reasoning is whether models can extrapolate learned reasoning patterns to solve harder tasks with longer chain-of-thought (CoT). In this work, we present a theoretical analysis of transformers learning on synthetic state-tracking tasks with gradient descent. We mathematically prove how the algebraic structure of state-tracking problems governs the degree of extrapolation of the learned CoT. Specifically, our theory characterizes the length generalization of transformers through the mechanism of attention concentration, linking the retrieval robustness of the attention layer to the state-tracking task structure of long-context reasoning. Moreover, for transformers with limited reasoning length, we prove that a recursive self-training scheme can progressively extend the range of solvable problem lengths. To our knowledge, we provide the first optimization guarantee that constant-depth transformers provably learn $\\mathsf{NC}^1$-complete problems with CoT, significantly going beyond prior art confined in $\\mathsf{TC}^0$, unless the widely held conjecture $\\mathsf{TC}^0 \\neq \\mathsf{NC}^1$ fails. Finally, we present a broad set of experiments supporting our theoretical results, confirming the length generalization behaviors and the mechanism of attention concentration.",
    "authors": [
      "Yu Huang",
      "Zixin Wen",
      "Aarti Singh",
      "Yuejie Chi",
      "Yuxin Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07378v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07378v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.06449v1",
    "title": "FLEX: Continuous Agent Evolution via Forward Learning from Experience",
    "summary": "Autonomous agents driven by Large Language Models (LLMs) have revolutionized reasoning and problem-solving but remain static after training, unable to grow with experience as intelligent beings do during deployment. We introduce Forward Learning with EXperience (FLEX), a gradient-free learning paradigm that enables LLM agents to continuously evolve through accumulated experience. Specifically, FLEX cultivates scalable and inheritable evolution by constructing a structured experience library through continual reflection on successes and failures during interaction with the environment. FLEX delivers substantial improvements on mathematical reasoning, chemical retrosynthesis, and protein fitness prediction (up to 23% on AIME25, 10% on USPTO50k, and 14% on ProteinGym). We further identify a clear scaling law of experiential growth and the phenomenon of experience inheritance across agents, marking a step toward scalable and inheritable continuous agent evolution. Project Page: https://flex-gensi-thuair.github.io.",
    "authors": [
      "Zhicheng Cai",
      "Xinyuan Guo",
      "Yu Pei",
      "JiangTao Feng",
      "Jiangjie Chen",
      "Ya-Qin Zhang",
      "Wei-Ying Ma",
      "Mingxuan Wang",
      "Hao Zhou"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06449v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06449v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.07368v1",
    "title": "Consistency Is Not Always Correct: Towards Understanding the Role of Exploration in Post-Training Reasoning",
    "summary": "Foundation models exhibit broad knowledge but limited task-specific reasoning, motivating post-training strategies such as RLVR and inference scaling with outcome or process reward models (ORM/PRM). While recent work highlights the role of exploration and entropy stability in improving pass@K, empirical evidence points to a paradox: RLVR and ORM/PRM typically reinforce existing tree-like reasoning paths rather than expanding the reasoning scope, raising the question of why exploration helps at all if no new patterns emerge.   To reconcile this paradox, we adopt the perspective of Kim et al. (2025), viewing easy (e.g., simplifying a fraction) versus hard (e.g., discovering a symmetry) reasoning steps as low- versus high-probability Markov transitions, and formalize post-training dynamics through Multi-task Tree-structured Markov Chains (TMC). In this tractable model, pretraining corresponds to tree expansion, while post-training corresponds to chain-of-thought reweighting. We show that several phenomena recently observed in empirical studies arise naturally in this setting: (1) RLVR induces a squeezing effect, reducing reasoning entropy and forgetting some correct paths; (2) population rewards of ORM/PRM encourage consistency rather than accuracy, thereby favoring common patterns; and (3) certain rare, high-uncertainty reasoning paths by the base model are responsible for solving hard problem instances.   Together, these explain why exploration -- even when confined to the base model's reasoning scope -- remains essential: it preserves access to rare but crucial reasoning traces needed for difficult cases, which are squeezed out by RLVR or unfavored by inference scaling. Building on this, we further show that exploration strategies such as rejecting easy instances and KL regularization help preserve rare reasoning traces. Empirical simulations corroborate our theoretical results.",
    "authors": [
      "Dake Bu",
      "Wei Huang",
      "Andi Han",
      "Atsushi Nitanda",
      "Bo Xue",
      "Qingfu Zhang",
      "Hau-San Wong",
      "Taiji Suzuki"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07368v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07368v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.07322v1",
    "title": "FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for Equity Research Report Generation",
    "summary": "While LLMs have shown great success in financial tasks like stock prediction and question answering, their application in fully automating Equity Research Report generation remains uncharted territory. In this paper, we formulate the Equity Research Report (ERR) Generation task for the first time. To address the data scarcity and the evaluation metrics absence, we present an open-source evaluation benchmark for ERR generation - FinRpt. We frame a Dataset Construction Pipeline that integrates 7 financial data types and produces a high-quality ERR dataset automatically, which could be used for model training and evaluation. We also introduce a comprehensive evaluation system including 11 metrics to assess the generated ERRs. Moreover, we propose a multi-agent framework specifically tailored to address this task, named FinRpt-Gen, and train several LLM-based agents on the proposed datasets using Supervised Fine-Tuning and Reinforcement Learning. Experimental results indicate the data quality and metrics effectiveness of the benchmark FinRpt and the strong performance of FinRpt-Gen, showcasing their potential to drive innovation in the ERR generation field. All code and datasets are publicly available.",
    "authors": [
      "Song Jin",
      "Shuqi Li",
      "Shukun Zhang",
      "Rui Yan"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07322v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07322v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.06230v1",
    "title": "Overview of CHIP 2025 Shared Task 2: Discharge Medication Recommendation for Metabolic Diseases Based on Chinese Electronic Health Records",
    "summary": "Discharge medication recommendation plays a critical role in ensuring treatment continuity, preventing readmission, and improving long-term management for patients with chronic metabolic diseases. This paper present an overview of the CHIP 2025 Shared Task 2 competition, which aimed to develop state-of-the-art approaches for automatically recommending appro-priate discharge medications using real-world Chinese EHR data. For this task, we constructed CDrugRed, a high-quality dataset consisting of 5,894 de-identified hospitalization records from 3,190 patients in China. This task is challenging due to multi-label nature of medication recommendation, het-erogeneous clinical text, and patient-specific variability in treatment plans. A total of 526 teams registered, with 167 and 95 teams submitting valid results to the Phase A and Phase B leaderboards, respectively. The top-performing team achieved the highest overall performance on the final test set, with a Jaccard score of 0.5102, F1 score of 0.6267, demonstrating the potential of advanced large language model (LLM)-based ensemble systems. These re-sults highlight both the promise and remaining challenges of applying LLMs to medication recommendation in Chinese EHRs. The post-evaluation phase remains open at https://tianchi.aliyun.com/competition/entrance/532411/.",
    "authors": [
      "Juntao Li",
      "Haobin Yuan",
      "Ling Luo",
      "Tengxiao Lv",
      "Yan Jiang",
      "Fan Wang",
      "Ping Zhang",
      "Huiyi Lv",
      "Jian Wang",
      "Yuanyuan Sun",
      "Hongfei Lin"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06230v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06230v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.06497v1",
    "title": "Rethinking what Matters: Effective and Robust Multilingual Realignment for Low-Resource Languages",
    "summary": "Realignment is a promising strategy to improve cross-lingual transfer in multilingual language models. However, empirical results are mixed and often unreliable, particularly for typologically distant or low-resource languages (LRLs) compared to English. Moreover, word realignment tools often rely on high-quality parallel data, which can be scarce or noisy for many LRLs. In this work, we conduct an extensive empirical study to investigate whether realignment truly benefits from using all available languages, or if strategically selected subsets can offer comparable or even improved cross-lingual transfer, and study the impact on LRLs. Our controlled experiments show that realignment can be particularly effective for LRLs and that using carefully selected, linguistically diverse subsets can match full multilingual alignment, and even outperform it for unseen LRLs. This indicates that effective realignment does not require exhaustive language coverage and can reduce data collection overhead, while remaining both efficient and robust when guided by informed language selection.",
    "authors": [
      "Quang Phuoc Nguyen",
      "David Anugraha",
      "Felix Gaschi",
      "Jun Bin Cheng",
      "En-Shiun Annie Lee"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06497v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06497v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.06234v1",
    "title": "Analyzing and Mitigating Negation Artifacts using Data Augmentation for Improving ELECTRA-Small Model Accuracy",
    "summary": "Pre-trained models for natural language inference (NLI) often achieve high performance on benchmark datasets by using spurious correlations, or dataset artifacts, rather than understanding language touches such as negation. In this project, we investigate the performance of an ELECTRA-small model fine-tuned on the Stanford Natural Language Inference (SNLI) dataset, focusing on its handling of negation. Through analysis, we identify that the model struggles with correctly classifying examples containing negation. To address this, we augment the training data with contrast sets and adversarial examples emphasizing negation. Our results demonstrate that this targeted data augmentation improves the model's accuracy on negation-containing examples without adversely affecting overall performance, therefore mitigating the identified dataset artifact.",
    "authors": [
      "Mojtaba Noghabaei"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06234v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06234v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.07070v1",
    "title": "RedOne 2.0: Rethinking Domain-specific LLM Post-Training in Social Networking Services",
    "summary": "As a key medium for human interaction and information exchange, social networking services (SNS) pose unique challenges for large language models (LLMs): heterogeneous workloads, fast-shifting norms and slang, and multilingual, culturally diverse corpora that induce sharp distribution shift. Supervised fine-tuning (SFT) can specialize models but often triggers a ``seesaw'' between in-distribution gains and out-of-distribution robustness, especially for smaller models. To address these challenges, we introduce RedOne 2.0, an SNS-oriented LLM trained with a progressive, RL-prioritized post-training paradigm designed for rapid and stable adaptation. The pipeline consist in three stages: (1) Exploratory Learning on curated SNS corpora to establish initial alignment and identify systematic weaknesses; (2) Targeted Fine-Tuning that selectively applies SFT to the diagnosed gaps while mixing a small fraction of general data to mitigate forgetting; and (3) Refinement Learning that re-applies RL with SNS-centric signals to consolidate improvements and harmonize trade-offs across tasks. Across various tasks spanning three categories, our 4B scale model delivers an average improvements about 2.41 over the 7B sub-optimal baseline. Additionally, RedOne 2.0 achieves average performance lift about 8.74 from the base model with less than half the data required by SFT-centric method RedOne, evidencing superior data efficiency and stability at compact scales. Overall, RedOne 2.0 establishes a competitive, cost-effective baseline for domain-specific LLMs in SNS scenario, advancing capability without sacrificing robustness.",
    "authors": [
      "Fei Zhao",
      "Chonggang Lu",
      "Haofu Qian",
      "Fangcheng Shi",
      "Zijie Meng",
      "Jianzhao Huang",
      "Xu Tang",
      "Zheyong Xie",
      "Zheyu Ye",
      "Zhe Xu",
      "Yao Hu",
      "Shaosheng Cao"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07070v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07070v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.06387v1",
    "title": "Learning the Inverse Ryu--Takayanagi Formula with Transformers",
    "summary": "We study the inverse problem of holographic entanglement entropy in AdS$_3$ using a data-driven generative model. Training data consist of randomly generated geometries and their holographic entanglement entropies using the Ryu--Takayanagi formula. After training, the Transformer reconstructs the blackening function within our metric ansatz from previously unseen inputs. The Transformer achieves accurate reconstructions on smooth black hole geometries and extrapolates to horizonless backgrounds. We describe the architecture and data generation process, and we quantify accuracy on both $f(z)$ and the reconstructed $S(\\ell)$. Code and evaluation scripts are available at the provided repository.",
    "authors": [
      "Sejin Kim"
    ],
    "categories": [
      "hep-th",
      "cs.LG"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06387v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06387v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.06304v1",
    "title": "Kaggle Chronicles: 15 Years of Competitions, Community and Data Science Innovation",
    "summary": "Since 2010, Kaggle has been a platform where data scientists from around the world come together to compete, collaborate, and push the boundaries of Data Science. Over these 15 years, it has grown from a purely competition-focused site into a broader ecosystem with forums, notebooks, models, datasets, and more. With the release of the Kaggle Meta Code and Kaggle Meta Datasets, we now have a unique opportunity to explore these competitions, technologies, and real-world applications of Machine Learning and AI. And so in this study, we take a closer look at 15 years of data science on Kaggle - through metadata, shared code, community discussions, and the competitions themselves. We explore Kaggle's growth, its impact on the data science community, uncover hidden technological trends, analyze competition winners, how Kagglers approach problems in general, and more. We do this by analyzing millions of kernels and discussion threads to perform both longitudinal trend analysis and standard exploratory data analysis. Our findings show that Kaggle is a steadily growing platform with increasingly diverse use cases, and that Kagglers are quick to adapt to new trends and apply them to real-world challenges, while producing - on average - models with solid generalization capabilities. We also offer a snapshot of the platform as a whole, highlighting its history and technological evolution. Finally, this study is accompanied by a video (https://www.youtube.com/watch?v=YVOV9bIUNrM) and a Kaggle write-up (https://kaggle.com/competitions/meta-kaggle-hackathon/writeups/kaggle-chronicles-15-years-of-competitions-communi) for your convenience.",
    "authors": [
      "Kevin Bönisch",
      "Leandro Losaria"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GL",
      "stat.ML"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06304v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06304v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.06798v1",
    "title": "Recursive Dynamics in Fast-Weights Homeostatic Reentry Networks: Toward Reflective Intelligence",
    "summary": "This study introduces the Fast-Weights Homeostatic Reentry Layer (FH-RL), a neural mechanism that integrates fast-weight associative memory, homeostatic regularization, and learned reentrant feedback to approximate self-referential computation in neural networks. Unlike standard transformer architectures that operate in a purely feedforward manner during inference, FH-RL enables internal recurrence without external looping, allowing prior latent states to be dynamically re-entered into the ongoing computation stream. We conduct controlled experiments sweeping the reentry gain $γ$ and evaluate emergent internal dynamics using three novel metrics: the Information Reentry Ratio (IRR), Eigen-Spectrum Recursion Index (ESRI), and Representational Drift Periodicity (RDP). Results show that reentry quantity increases proportionally with~$γ$, while the learned feedback matrix $W_r$ remains bounded and becomes more structured at moderate gains. Critically, a stable reflective band emerges around $γ\\approx 0.10-0.20$, where internal feedback is maximally expressive yet spectrally stable: IRR rises smoothly, ESRI remains near zero, and RDP exhibits consistent low-frequency cycles. These findings provide quantitative evidence that reflective, thought-like internal processing can arise from a principled balance between feedback amplification and homeostatic regulation, linking modern fast-weight architectures to theories of cortical reentry and recursive cognition.",
    "authors": [
      "B. G. Chae"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06798v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06798v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07118v1",
    "title": "On the Joint Minimization of Regularization Loss Functions in Deep Variational Bayesian Methods for Attribute-Controlled Symbolic Music Generation",
    "summary": "Explicit latent variable models provide a flexible yet powerful framework for data synthesis, enabling controlled manipulation of generative factors. With latent variables drawn from a tractable probability density function that can be further constrained, these models enable continuous and semantically rich exploration of the output space by navigating their latent spaces. Structured latent representations are typically obtained through the joint minimization of regularization loss functions. In variational information bottleneck models, reconstruction loss and Kullback-Leibler Divergence (KLD) are often linearly combined with an auxiliary Attribute-Regularization (AR) loss. However, balancing KLD and AR turns out to be a very delicate matter. When KLD dominates over AR, generative models tend to lack controllability; when AR dominates over KLD, the stochastic encoder is encouraged to violate the standard normal prior. We explore this trade-off in the context of symbolic music generation with explicit control over continuous musical attributes. We show that existing approaches struggle to jointly minimize both regularization objectives, whereas suitable attribute transformations can help achieve both controllability and regularization of the target latent dimensions.",
    "authors": [
      "Matteo Pettenó",
      "Alessandro Ilic Mezza",
      "Alberto Bernardini"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.AS"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07118v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07118v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07208v1",
    "title": "SMiLE: Provably Enforcing Global Relational Properties in Neural Networks",
    "summary": "Artificial Intelligence systems are increasingly deployed in settings where ensuring robustness, fairness, or domain-specific properties is essential for regulation compliance and alignment with human values. However, especially on Neural Networks, property enforcement is very challenging, and existing methods are limited to specific constraints or local properties (defined around datapoints), or fail to provide full guarantees. We tackle these limitations by extending SMiLE, a recently proposed enforcement framework for NNs, to support global relational properties (defined over the entire input space). The proposed approach scales well with model complexity, accommodates general properties and backbones, and provides full satisfaction guarantees. We evaluate SMiLE on monotonicity, global robustness, and individual fairness, on synthetic and real data, for regression and classification tasks. Our approach is competitive with property-specific baselines in terms of accuracy and runtime, and strictly superior in terms of generality and level of guarantees. Overall, our results emphasize the potential of the SMiLE framework as a platform for future research and applications.",
    "authors": [
      "Matteo Francobaldi",
      "Michele Lombardi",
      "Andrea Lodi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07208v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07208v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.06913v1",
    "title": "Sampling and Loss Weights in Multi-Domain Training",
    "summary": "In the training of large deep neural networks, there is a need for vast amounts of training data. To meet this need, data is collected from multiple domains, such as Wikipedia and GitHub. These domains are heterogeneous in both data quality and the diversity of information they provide. This raises the question of how much we should rely on each domain. Several methods have attempted to address this issue by assigning sampling weights to each data domain using heuristics or approximations. As a first step toward a deeper understanding of the role of data mixing, this work revisits the problem by studying two kinds of weights: sampling weights, which control how much each domain contributes in a batch, and loss weights, which scale the loss from each domain during training. Through a rigorous study of linear regression, we show that these two weights play complementary roles. First, they can reduce the variance of gradient estimates in iterative methods such as stochastic gradient descent (SGD). Second, they can improve generalization performance by reducing the generalization gap. We provide both theoretical and empirical support for these claims. We further study the joint dynamics of sampling weights and loss weights, examining how they can be combined to capture both contributions.",
    "authors": [
      "Mahdi Salmani",
      "Pratik Worah",
      "Meisam Razaviyayn",
      "Vahab Mirrokni"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06913v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06913v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.06816v1",
    "title": "Controllable Flow Matching for Online Reinforcement Learning",
    "summary": "Model-based reinforcement learning (MBRL) typically relies on modeling environment dynamics for data efficiency. However, due to the accumulation of model errors over long-horizon rollouts, such methods often face challenges in maintaining modeling stability. To address this, we propose CtrlFlow, a trajectory-level synthetic method using conditional flow matching (CFM), which directly modeling the distribution of trajectories from initial states to high-return terminal states without explicitly modeling the environment transition function. Our method ensures optimal trajectory sampling by minimizing the control energy governed by the non-linear Controllability Gramian Matrix, while the generated diverse trajectory data significantly enhances the robustness and cross-task generalization of policy learning. In online settings, CtrlFlow demonstrates the better performance on common MuJoCo benchmark tasks than dynamics models and achieves superior sample efficiency compared to standard MBRL methods.",
    "authors": [
      "Bin Wang",
      "Boxiang Tao",
      "Haifeng Jing",
      "Hongbo Dou",
      "Zijian Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06816v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06816v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07112v1",
    "title": "More Agents Helps but Adversarial Robustness Gap Persists",
    "summary": "When LLM agents work together, they seem to be more powerful than a single LLM in mathematical question answering. However, are they also more robust to adversarial inputs? We investigate this question using adversarially perturbed math questions. These perturbations include punctuation noise with three intensities (10, 30, and 50 percent), plus real-world and human-like typos (WikiTypo, R2ATA). Using a unified sampling-and-voting framework (Agent Forest), we evaluate six open-source models (Qwen3-4B/14B, Llama3.1-8B, Mistral-7B, Gemma3-4B/12B) across four benchmarks (GSM8K, MATH, MMLU-Math, MultiArith), with various numbers of agents n from one to 25 (1, 2, 5, 10, 15, 20, 25). Our findings show that (1) Noise type matters: punctuation noise harm scales with its severity, and the human typos remain the dominant bottleneck, yielding the largest gaps to Clean accuracy and the highest ASR even with a large number of agents. And (2) Collaboration reliably improves accuracy as the number of agents, n, increases, with the largest gains from one to five agents and diminishing returns beyond 10 agents. However, the adversarial robustness gap persists regardless of the agent count.",
    "authors": [
      "Khashayar Alavi",
      "Zhastay Yeltay",
      "Lucie Flek",
      "Akbar Karimi"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07112v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07112v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07055v1",
    "title": "When Sufficient is not Enough: Utilizing the Rashomon Effect for Complete Evidence Extraction",
    "summary": "Feature attribution methods typically provide minimal sufficient evidence justifying a model decision. However, in many applications this is inadequate. For compliance and cataloging, the full set of contributing features must be identified - complete evidence. We perform a case study on a medical dataset which contains human-annotated complete evidence. We show that individual models typically recover only subsets of complete evidence and that aggregating evidence from several models improves evidence recall from $\\sim$0.60 (single best model) to $\\sim$0.86 (ensemble). We analyze the recall-precision trade-off, the role of training with evidence, dynamic ensembles with certainty thresholds, and discuss implications.",
    "authors": [
      "Katharina Beckh",
      "Stefan Rüping"
    ],
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07055v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07055v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.06529v1",
    "title": "TriShGAN: Enhancing Sparsity and Robustness in Multivariate Time Series Counterfactuals Explanation",
    "summary": "In decision-making processes, stakeholders often rely on counterfactual explanations, which provide suggestions about what should be changed in the queried instance to alter the outcome of an AI system. However, generating these explanations for multivariate time series presents challenges due to their complex, multi-dimensional nature. Traditional Nearest Unlike Neighbor-based methods typically substitute subsequences in a queried time series with influential subsequences from an NUN, which is not always realistic in real-world scenarios due to the rigid direct substitution. Counterfactual with Residual Generative Adversarial Networks-based methods aim to address this by learning from the distribution of observed data to generate synthetic counterfactual explanations. However, these methods primarily focus on minimizing the cost from the queried time series to the counterfactual explanations and often neglect the importance of distancing the counterfactual explanation from the decision boundary. This oversight can result in explanations that no longer qualify as counterfactual if minor changes occur within the model. To generate a more robust counterfactual explanation, we introduce TriShGAN, under the CounteRGAN framework enhanced by the incorporation of triplet loss. This unsupervised learning approach uses distance metric learning to encourage the counterfactual explanations not only to remain close to the queried time series but also to capture the feature distribution of the instance with the desired outcome, thereby achieving a better balance between minimal cost and robustness. Additionally, we integrate a Shapelet Extractor that strategically selects the most discriminative parts of the high-dimensional queried time series to enhance the sparsity of counterfactual explanation and efficiency of the training process.",
    "authors": [
      "Hongnan Ma",
      "Yiwei Shi",
      "Guanxiong Sun",
      "Mengyue Yang",
      "Weiru Liu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06529v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06529v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.06700v1",
    "title": "Place Matters: Comparing LLM Hallucination Rates for Place-Based Legal Queries",
    "summary": "How do we make a meaningful comparison of a large language model's knowledge of the law in one place compared to another? Quantifying these differences is critical to understanding if the quality of the legal information obtained by users of LLM-based chatbots varies depending on their location. However, obtaining meaningful comparative metrics is challenging because legal institutions in different places are not themselves easily comparable. In this work we propose a methodology to obtain place-to-place metrics based on the comparative law concept of functionalism. We construct a dataset of factual scenarios drawn from Reddit posts by users seeking legal advice for family, housing, employment, crime and traffic issues. We use these to elicit a summary of a law from the LLM relevant to each scenario in Los Angeles, London and Sydney. These summaries, typically of a legislative provision, are manually evaluated for hallucinations. We show that the rate of hallucination of legal information by leading closed-source LLMs is significantly associated with place. This suggests that the quality of legal solutions provided by these models is not evenly distributed across geography. Additionally, we show a strong negative correlation between hallucination rate and the frequency of the majority response when the LLM is sampled multiple times, suggesting a measure of uncertainty of model predictions of legal facts.",
    "authors": [
      "Damian Curran",
      "Vanessa Sporne",
      "Lea Frermann",
      "Jeannie Paterson"
    ],
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06700v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06700v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.06698v1",
    "title": "Lassoed Forests: Random Forests with Adaptive Lasso Post-selection",
    "summary": "Random forests are a statistical learning technique that use bootstrap aggregation to average high-variance and low-bias trees. Improvements to random forests, such as applying Lasso regression to the tree predictions, have been proposed in order to reduce model bias. However, these changes can sometimes degrade performance (e.g., an increase in mean squared error). In this paper, we show in theory that the relative performance of these two methods, standard and Lasso-weighted random forests, depends on the signal-to-noise ratio. We further propose a unified framework to combine random forests and Lasso selection by applying adaptive weighting and show mathematically that it can strictly outperform the other two methods. We compare the three methods through simulation, including bias-variance decomposition, error estimates evaluation, and variable importance analysis. We also show the versatility of our method by applications to a variety of real-world datasets.",
    "authors": [
      "Jing Shang",
      "James Bannon",
      "Benjamin Haibe-Kains",
      "Robert Tibshirani"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06698v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06698v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.07011v1",
    "title": "Multilingual Lexical Feature Analysis of Spoken Language for Predicting Major Depression Symptom Severity",
    "summary": "Background: Captured between clinical appointments using mobile devices, spoken language has potential for objective, more regular assessment of symptom severity and earlier detection of relapse in major depressive disorder. However, research to date has largely been in non-clinical cross-sectional samples of written language using complex machine learning (ML) approaches with limited interpretability.   Methods: We describe an initial exploratory analysis of longitudinal speech data and PHQ-8 assessments from 5,836 recordings of 586 participants in the UK, Netherlands, and Spain, collected in the RADAR-MDD study. We sought to identify interpretable lexical features associated with MDD symptom severity with linear mixed-effects modelling. Interpretable features and high-dimensional vector embeddings were also used to test the prediction performance of four regressor ML models.   Results: In English data, MDD symptom severity was associated with 7 features including lexical diversity measures and absolutist language. In Dutch, associations were observed with words per sentence and positive word frequency; no associations were observed in recordings collected in Spain. The predictive power of lexical features and vector embeddings was near chance level across all languages.   Limitations: Smaller samples in non-English speech and methodological choices, such as the elicitation prompt, may have also limited the effect sizes observable. A lack of NLP tools in languages other than English restricted our feature choice.   Conclusion: To understand the value of lexical markers in clinical research and practice, further research is needed in larger samples across several languages using improved protocols, and ML models that account for within- and between-individual variations in language.",
    "authors": [
      "Anastasiia Tokareva",
      "Judith Dineley",
      "Zoe Firth",
      "Pauline Conde",
      "Faith Matcham",
      "Sara Siddi",
      "Femke Lamers",
      "Ewan Carr",
      "Carolin Oetzmann",
      "Daniel Leightley",
      "Yuezhou Zhang",
      "Amos A. Folarin",
      "Josep Maria Haro",
      "Brenda W. J. H. Penninx",
      "Raquel Bailon",
      "Srinivasan Vairavan",
      "Til Wykes",
      "Richard J. B. Dobson",
      "Vaibhav A. Narayan",
      "Matthew Hotopf",
      "Nicholas Cummins",
      "The RADAR-CNS Consortium"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07011v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07011v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.06365v1",
    "title": "V-Shuffle: Zero-Shot Style Transfer via Value Shuffle",
    "summary": "Attention injection-based style transfer has achieved remarkable progress in recent years. However, existing methods often suffer from content leakage, where the undesired semantic content of the style image mistakenly appears in the stylized output. In this paper, we propose V-Shuffle, a zero-shot style transfer method that leverages multiple style images from the same style domain to effectively navigate the trade-off between content preservation and style fidelity. V-Shuffle implicitly disrupts the semantic content of the style images by shuffling the value features within the self-attention layers of the diffusion model, thereby preserving low-level style representations. We further introduce a Hybrid Style Regularization that complements these low-level representations with high-level style textures to enhance style fidelity. Empirical results demonstrate that V-Shuffle achieves excellent performance when utilizing multiple style images. Moreover, when applied to a single style image, V-Shuffle outperforms previous state-of-the-art methods.",
    "authors": [
      "Haojun Tang",
      "Qiwei Lin",
      "Tongda Xu",
      "Lida Huang",
      "Yan Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06365v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06365v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.06641v1",
    "title": "Neyman-Pearson Classification under Both Null and Alternative Distributions Shift",
    "summary": "We consider the problem of transfer learning in Neyman-Pearson classification, where the objective is to minimize the error w.r.t. a distribution $μ_1$, subject to the constraint that the error w.r.t. a distribution $μ_0$ remains below a prescribed threshold. While transfer learning has been extensively studied in traditional classification, transfer learning in imbalanced classification such as Neyman-Pearson classification has received much less attention. This setting poses unique challenges, as both types of errors must be simultaneously controlled. Existing works address only the case of distribution shift in $μ_1$, whereas in many practical scenarios shifts may occur in both $μ_0$ and $μ_1$. We derive an adaptive procedure that not only guarantees improved Type-I and Type-II errors when the source is informative, but also automatically adapt to situations where the source is uninformative, thereby avoiding negative transfer. In addition to such statistical guarantees, the procedures is efficient, as shown via complementary computational guarantees.",
    "authors": [
      "Mohammadreza M. Kalan",
      "Yuyang Deng",
      "Eitan J. Neugut",
      "Samory Kpotufe"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06641v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06641v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.07325v1",
    "title": "Garbage Vulnerable Point Monitoring using IoT and Computer Vision",
    "summary": "This paper proposes a smart way to manage municipal solid waste by using the Internet of Things (IoT) and computer vision (CV) to monitor illegal waste dumping at garbage vulnerable points (GVPs) in urban areas. The system can quickly detect and monitor dumped waste using a street-level camera and object detection algorithm. Data was collected from the Sangareddy district in Telangana, India. A series of comprehensive experiments was carried out using the proposed dataset to assess the accuracy and overall performance of various object detection models. Specifically, we performed an in-depth evaluation of YOLOv8, YOLOv10, YOLO11m, and RT-DETR on our dataset. Among these models, YOLO11m achieved the highest accuracy of 92.39\\% in waste detection, demonstrating its effectiveness in detecting waste. Additionally, it attains an mAP@50 of 0.91, highlighting its high precision. These findings confirm that the object detection model is well-suited for monitoring and tracking waste dumping events at GVP locations. Furthermore, the system effectively captures waste disposal patterns, including hourly, daily, and weekly dumping trends, ensuring comprehensive daily and nightly monitoring.",
    "authors": [
      "R. Kumar",
      "A. Lall",
      "S. Chaudhari",
      "M. Kale",
      "A. Vattem"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07325v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07325v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.06492v1",
    "title": "Explainable AI For Early Detection Of Sepsis",
    "summary": "Sepsis is a life-threatening condition that requires rapid detection and treatment to prevent progression to severe sepsis, septic shock, or multi-organ failure. Despite advances in medical technology, it remains a major challenge for clinicians. While recent machine learning models have shown promise in predicting sepsis onset, their black-box nature limits interpretability and clinical trust. In this study, we present an interpretable AI approach for sepsis analysis that integrates machine learning with clinical knowledge. Our method not only delivers accurate predictions of sepsis onset but also enables clinicians to understand, validate, and align model outputs with established medical expertise.",
    "authors": [
      "Atharva Thakur",
      "Shruti Dhumal"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06492v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06492v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.06895v1",
    "title": "On The Presence of Double-Descent in Deep Reinforcement Learning",
    "summary": "The double descent (DD) paradox, where over-parameterized models see generalization improve past the interpolation point, remains largely unexplored in the non-stationary domain of Deep Reinforcement Learning (DRL). We present preliminary evidence that DD exists in model-free DRL, investigating it systematically across varying model capacity using the Actor-Critic framework. We rely on an information-theoretic metric, Policy Entropy, to measure policy uncertainty throughout training. Preliminary results show a clear epoch-wise DD curve; the policy's entrance into the second descent region correlates with a sustained, significant reduction in Policy Entropy. This entropic decay suggests that over-parameterization acts as an implicit regularizer, guiding the policy towards robust, flatter minima in the loss landscape. These findings establish DD as a factor in DRL and provide an information-based mechanism for designing agents that are more general, transferable, and robust.",
    "authors": [
      "Viktor Veselý",
      "Aleksandar Todorov",
      "Matthia Sabatelli"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06895v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06895v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06531v1",
    "title": "Ibom NLP: A Step Toward Inclusive Natural Language Processing for Nigeria's Minority Languages",
    "summary": "Nigeria is the most populous country in Africa with a population of more than 200 million people. More than 500 languages are spoken in Nigeria and it is one of the most linguistically diverse countries in the world. Despite this, natural language processing (NLP) research has mostly focused on the following four languages: Hausa, Igbo, Nigerian-Pidgin, and Yoruba (i.e <1% of the languages spoken in Nigeria). This is in part due to the unavailability of textual data in these languages to train and apply NLP algorithms. In this work, we introduce ibom -- a dataset for machine translation and topic classification in four Coastal Nigerian languages from the Akwa Ibom State region: Anaang, Efik, Ibibio, and Oro. These languages are not represented in Google Translate or in major benchmarks such as Flores-200 or SIB-200. We focus on extending Flores-200 benchmark to these languages, and further align the translated texts with topic labels based on SIB-200 classification dataset. Our evaluation shows that current LLMs perform poorly on machine translation for these languages in both zero-and-few shot settings. However, we find the few-shot samples to steadily improve topic classification with more shots.",
    "authors": [
      "Oluwadara Kalejaiye",
      "Luel Hagos Beyene",
      "David Ifeoluwa Adelani",
      "Mmekut-Mfon Gabriel Edet",
      "Aniefon Daniel Akpan",
      "Eno-Abasi Urua",
      "Anietie Andy"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06531v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06531v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.07270v1",
    "title": "High-Dimensional Asymptotics of Differentially Private PCA",
    "summary": "In differential privacy, statistics of a sensitive dataset are privatized by introducing random noise. Most privacy analyses provide privacy bounds specifying a noise level sufficient to achieve a target privacy guarantee. Sometimes, these bounds are pessimistic and suggest adding excessive noise, which overwhelms the meaningful signal. It remains unclear if such high noise levels are truly necessary or a limitation of the proof techniques. This paper explores whether we can obtain sharp privacy characterizations that identify the smallest noise level required to achieve a target privacy level for a given mechanism. We study this problem in the context of differentially private principal component analysis, where the goal is to privatize the leading principal components (PCs) of a dataset with n samples and p features. We analyze the exponential mechanism for this problem in a model-free setting and provide sharp utility and privacy characterizations in the high-dimensional limit ($p\\rightarrow\\infty$). Our privacy result shows that, in high dimensions, detecting the presence of a target individual in the dataset using the privatized PCs is exactly as hard as distinguishing two Gaussians with slightly different means, where the mean difference depends on certain spectral properties of the dataset. Our privacy analysis combines the hypothesis-testing formulation of privacy guarantees proposed by Dong, Roth, and Su (2022) with classical contiguity arguments due to Le Cam to obtain sharp high-dimensional privacy characterizations.",
    "authors": [
      "Youngjoo Yun",
      "Rishabh Dudeja"
    ],
    "categories": [
      "math.ST",
      "cs.IT",
      "cs.LG",
      "math.PR",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07270v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07270v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06585v1",
    "title": "Learning Biomolecular Motion: The Physics-Informed Machine Learning Paradigm",
    "summary": "The convergence of statistical learning and molecular physics is transforming our approach to modeling biomolecular systems. Physics-informed machine learning (PIML) offers a systematic framework that integrates data-driven inference with physical constraints, resulting in models that are accurate, mechanistic, generalizable, and able to extrapolate beyond observed domains. This review surveys recent advances in physics-informed neural networks and operator learning, differentiable molecular simulation, and hybrid physics-ML potentials, with emphasis on long-timescale kinetics, rare events, and free-energy estimation. We frame these approaches as solutions to the \"biomolecular closure problem\", recovering unresolved interactions beyond classical force fields while preserving thermodynamic consistency and mechanistic interpretability. We examine theoretical foundations, tools and frameworks, computational trade-offs, and unresolved issues, including model expressiveness and stability. We outline prospective research avenues at the intersection of machine learning, statistical physics, and computational chemistry, contending that future advancements will depend on mechanistic inductive biases, and integrated differentiable physical learning frameworks for biomolecular simulation and discovery.",
    "authors": [
      "Aaryesh Deshpande"
    ],
    "categories": [
      "q-bio.BM",
      "cs.LG",
      "physics.comp-ph",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06585v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06585v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06906v1",
    "title": "Counterfactual Explanation for Multivariate Time Series Forecasting with Exogenous Variables",
    "summary": "Currently, machine learning is widely used across various domains, including time series data analysis. However, some machine learning models function as black boxes, making interpretability a critical concern. One approach to address this issue is counterfactual explanation (CE), which aims to provide insights into model predictions. This study focuses on the relatively underexplored problem of generating counterfactual explanations for time series forecasting. We propose a method for extracting CEs in time series forecasting using exogenous variables, which are frequently encountered in fields such as business and marketing. In addition, we present methods for analyzing the influence of each variable over an entire time series, generating CEs by altering only specific variables, and evaluating the quality of the resulting CEs. We validate the proposed method through theoretical analysis and empirical experiments, showcasing its accuracy and practical applicability. These contributions are expected to support real-world decision-making based on time series data analysis.",
    "authors": [
      "Keita Kinjo"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06906v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06906v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06211v1",
    "title": "Sparse Linear Regression is Easy on Random Supports",
    "summary": "Sparse linear regression is one of the most basic questions in machine learning and statistics. Here, we are given as input a design matrix $X \\in \\mathbb{R}^{N \\times d}$ and measurements or labels ${y} \\in \\mathbb{R}^N$ where ${y} = {X} {w}^* + ξ$, and $ξ$ is the noise in the measurements. Importantly, we have the additional constraint that the unknown signal vector ${w}^*$ is sparse: it has $k$ non-zero entries where $k$ is much smaller than the ambient dimension. Our goal is to output a prediction vector $\\widehat{w}$ that has small prediction error: $\\frac{1}{N}\\cdot \\|{X} {w}^* - {X} \\widehat{w}\\|^2_2$.   Information-theoretically, we know what is best possible in terms of measurements: under most natural noise distributions, we can get prediction error at most $ε$ with roughly $N = O(k \\log d/ε)$ samples. Computationally, this currently needs $d^{Ω(k)}$ run-time. Alternately, with $N = O(d)$, we can get polynomial-time. Thus, there is an exponential gap (in the dependence on $d$) between the two and we do not know if it is possible to get $d^{o(k)}$ run-time and $o(d)$ samples.   We give the first generic positive result for worst-case design matrices ${X}$: For any ${X}$, we show that if the support of ${w}^*$ is chosen at random, we can get prediction error $ε$ with $N = \\text{poly}(k, \\log d, 1/ε)$ samples and run-time $\\text{poly}(d,N)$. This run-time holds for any design matrix ${X}$ with condition number up to $2^{\\text{poly}(d)}$.   Previously, such results were known for worst-case ${w}^*$, but only for random design matrices from well-behaved families, matrices that have a very low condition number ($\\text{poly}(\\log d)$; e.g., as studied in compressed sensing), or those with special structural properties.",
    "authors": [
      "Gautam Chandrasekaran",
      "Raghu Meka",
      "Konstantinos Stavropoulos"
    ],
    "categories": [
      "cs.LG",
      "cs.DS",
      "math.ST",
      "stat.ML"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06211v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06211v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06780v1",
    "title": "OntoTune: Ontology-Driven Learning for Query Optimization with Convolutional Models",
    "summary": "Query optimization has been studied using machine learning, reinforcement learning, and, more recently, graph-based convolutional networks. Ontology, as a structured, information-rich knowledge representation, can provide context, particularly in learning problems. This paper presents OntoTune, an ontology-based platform for enhancing learning for query optimization. By connecting SQL queries, database metadata, and statistics, the ontology developed in this research is promising in capturing relationships and important determinants of query performance. This research also develops a method to embed ontologies while preserving as much of the relationships and key information as possible, before feeding it into learning algorithms such as tree-based and graph-based convolutional networks. A case study shows how OntoTune's ontology-driven learning delivers performance gains compared with database system default query execution.",
    "authors": [
      "Songhui Yue",
      "Yang Shao",
      "Sean Hayes"
    ],
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06780v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06780v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.07272v1",
    "title": "Understanding the role of depth in the neural tangent kernel for overparameterized neural networks",
    "summary": "Overparameterized fully-connected neural networks have been shown to behave like kernel models when trained with gradient descent, under mild conditions on the width, the learning rate, and the parameter initialization. In the limit of infinitely large widths and small learning rate, the kernel that is obtained allows to represent the output of the learned model with a closed-form solution. This closed-form solution hinges on the invertibility of the limiting kernel, a property that often holds on real-world datasets. In this work, we analyze the sensitivity of large ReLU networks to increasing depths by characterizing the corresponding limiting kernel. Our theoretical results demonstrate that the normalized limiting kernel approaches the matrix of ones. In contrast, they show the corresponding closed-form solution approaches a fixed limit on the sphere. We empirically evaluate the order of magnitude in network depth required to observe this convergent behavior, and we describe the essential properties that enable the generalization of our results to other kernels.",
    "authors": [
      "William St-Arnaud",
      "Margarida Carvalho",
      "Golnoosh Farnadi"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07272v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07272v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06346v1",
    "title": "LPFQA: A Long-Tail Professional Forum-based Benchmark for LLM Evaluation",
    "summary": "Large Language Models (LLMs) have made rapid progress in reasoning, question answering, and professional applications; however, their true capabilities remain difficult to evaluate using existing benchmarks. Current datasets often focus on simplified tasks or artificial scenarios, overlooking long-tail knowledge and the complexities of real-world applications. To bridge this gap, we propose LPFQA, a long-tail knowledge-based benchmark derived from authentic professional forums across 20 academic and industrial fields, covering 502 tasks grounded in practical expertise. LPFQA introduces four key innovations: fine-grained evaluation dimensions that target knowledge depth, reasoning, terminology comprehension, and contextual analysis; a hierarchical difficulty structure that ensures semantic clarity and unique answers; authentic professional scenario modeling with realistic user personas; and interdisciplinary knowledge integration across diverse domains. We evaluated 12 mainstream LLMs on LPFQA and observed significant performance disparities, especially in specialized reasoning tasks. LPFQA provides a robust, authentic, and discriminative benchmark for advancing LLM evaluation and guiding future model development.",
    "authors": [
      "Liya Zhu",
      "Peizhuang Cong",
      "Aowei Ji",
      "Wenya Wu",
      "Jiani Hou",
      "Chunjie Wu",
      "Xiang Gao",
      "Jingkai Liu",
      "Zhou Huan",
      "Xuelei Sun",
      "Yang Yang",
      "Jianpeng Jiao",
      "Liang Hu",
      "Xinjie Chen",
      "Jiashuo Liu",
      "Jingzhe Ding",
      "Tong Yang",
      "Zaiyuan Wang",
      "Ge Zhang",
      "Wenhao Huang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06346v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06346v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.06522v1",
    "title": "FractalBench: Diagnosing Visual-Mathematical Reasoning Through Recursive Program Synthesis",
    "summary": "Mathematical reasoning requires abstracting symbolic rules from visual patterns -- inferring the infinite from the finite. We investigate whether multimodal AI systems possess this capability through FractalBench, a benchmark evaluating fractal program synthesis from images. Fractals provide ideal test cases: Iterated Function Systems with only a few contraction maps generate complex self-similar patterns through simple recursive rules, requiring models to bridge visual perception with mathematical abstraction. We evaluate four leading MLLMs -- GPT-4o, Claude 3.7 Sonnet, Gemini 2.5 Flash, and Qwen 2.5-VL -- on 12 canonical fractals. Models must generate executable Python code reproducing the fractal, enabling objective evaluation. Results reveal a striking disconnect: 76% generate syntactically valid code but only 4% capture mathematical structure. Success varies systematically -- models handle geometric transformations (Koch curves: 17-21%) but fail at branching recursion (trees: <2%), revealing fundamental gaps in mathematical abstraction. FractalBench provides a contamination-resistant diagnostic for visual-mathematical reasoning and is available at https://github.com/NaiveNeuron/FractalBench",
    "authors": [
      "Jan Ondras",
      "Marek Šuppa"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06522v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06522v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.07298v1",
    "title": "LMM-IQA: Image Quality Assessment for Low-Dose CT Imaging",
    "summary": "Low-dose computed tomography (CT) represents a significant improvement in patient safety through lower radiation doses, but increased noise, blur, and contrast loss can diminish diagnostic quality. Therefore, consistency and robustness in image quality assessment become essential for clinical applications. In this study, we propose an LLM-based quality assessment system that generates both numerical scores and textual descriptions of degradations such as noise, blur, and contrast loss. Furthermore, various inference strategies - from the zero-shot approach to metadata integration and error feedback - are systematically examined, demonstrating the progressive contribution of each method to overall performance. The resultant assessments yield not only highly correlated scores but also interpretable output, thereby adding value to clinical workflows. The source codes of our study are available at https://github.com/itu-biai/lmms_ldct_iqa.",
    "authors": [
      "Kagan Celik",
      "Mehmet Ozan Unal",
      "Metin Ertas",
      "Isa Yildirim"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07298v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07298v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.06235v1",
    "title": "Sparsity via Hyperpriors: A Theoretical and Algorithmic Study under Empirical Bayes Framework",
    "summary": "This paper presents a comprehensive analysis of hyperparameter estimation within the empirical Bayes framework (EBF) for sparse learning. By studying the influence of hyperpriors on the solution of EBF, we establish a theoretical connection between the choice of the hyperprior and the sparsity as well as the local optimality of the resulting solutions. We show that some strictly increasing hyperpriors, such as half-Laplace and half-generalized Gaussian with the power in $(0,1)$, effectively promote sparsity and improve solution stability with respect to measurement noise. Based on this analysis, we adopt a proximal alternating linearized minimization (PALM) algorithm with convergence guaranties for both convex and concave hyperpriors. Extensive numerical tests on two-dimensional image deblurring problems demonstrate that introducing appropriate hyperpriors significantly promotes the sparsity of the solution and enhances restoration accuracy. Furthermore, we illustrate the influence of the noise level and the ill-posedness of inverse problems to EBF solutions.",
    "authors": [
      "Zhitao Li",
      "Yiqiu Dong",
      "Xueying Zeng"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.NA"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06235v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06235v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.06407v1",
    "title": "Fast Riemannian-manifold Hamiltonian Monte Carlo for hierarchical Gaussian-process models",
    "summary": "Hierarchical Bayesian models based on Gaussian processes are considered useful for describing complex nonlinear statistical dependencies among variables in real-world data. However, effective Monte Carlo algorithms for inference with these models have not yet been established, except for several simple cases. In this study, we show that, compared with the slow inference achieved with existing program libraries, the performance of Riemannian-manifold Hamiltonian Monte Carlo (RMHMC) can be drastically improved by optimising the computation order according to the model structure and dynamically programming the eigendecomposition. This improvement cannot be achieved when using an existing library based on a naive automatic differentiator. We numerically demonstrate that RMHMC effectively samples from the posterior, allowing the calculation of model evidence, in a Bayesian logistic regression on simulated data and in the estimation of propensity functions for the American national medical expenditure data using several Bayesian multiple-kernel models. These results lay a foundation for implementing effective Monte Carlo algorithms for analysing real-world data with Gaussian processes, and highlight the need to develop a customisable library set that allows users to incorporate dynamically programmed objects and finely optimises the mode of automatic differentiation depending on the model structure.",
    "authors": [
      "Takashi Hayakawa",
      "Satoshi Asai"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.CO"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06407v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06407v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.07365v1",
    "title": "Private Sketches for Linear Regression",
    "summary": "Linear regression is frequently applied in a variety of domains. In order to improve the efficiency of these methods, various methods have been developed that compute summaries or \\emph{sketches} of the datasets. Certain domains, however, contain sensitive data which necessitates that the application of these statistical methods does not reveal private information. Differentially private (DP) linear regression methods have been developed for mitigating this problem. These techniques typically involve estimating a noisy version of the parameter vector. Instead, we propose releasing private sketches of the datasets. We present differentially private sketches for the problems of least squares regression, as well as least absolute deviations regression. The availability of these private sketches facilitates the application of commonly available solvers for regression, without the risk of privacy leakage.",
    "authors": [
      "Shrutimoy Das",
      "Debanuj Nayak",
      "Anirban Dasgupta"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07365v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07365v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.07413v1",
    "title": "DigiData: Training and Evaluating General-Purpose Mobile Control Agents",
    "summary": "AI agents capable of controlling user interfaces have the potential to transform human interaction with digital devices. To accelerate this transformation, two fundamental building blocks are essential: high-quality datasets that enable agents to achieve complex and human-relevant goals, and robust evaluation methods that allow researchers and practitioners to rapidly enhance agent performance. In this paper, we introduce DigiData, a large-scale, high-quality, diverse, multi-modal dataset designed for training mobile control agents. Unlike existing datasets, which derive goals from unstructured interactions, DigiData is meticulously constructed through comprehensive exploration of app features, resulting in greater diversity and higher goal complexity. Additionally, we present DigiData-Bench, a benchmark for evaluating mobile control agents on real-world complex tasks. We demonstrate that the commonly used step-accuracy metric falls short in reliably assessing mobile control agents and, to address this, we propose dynamic evaluation protocols and AI-powered evaluations as rigorous alternatives for agent assessment. Our contributions aim to significantly advance the development of mobile control agents, paving the way for more intuitive and effective human-device interactions.",
    "authors": [
      "Yuxuan Sun",
      "Manchen Wang",
      "Shengyi Qian",
      "William R. Wong",
      "Eric Gan",
      "Pierluca D'Oro",
      "Alejandro Castillejo Munoz",
      "Sneha Silwal",
      "Pedro Matias",
      "Nitin Kamra",
      "Satwik Kottur",
      "Nick Raines",
      "Xuanyi Zhao",
      "Joy Chen",
      "Joseph Greer",
      "Andrea Madotto",
      "Allen Bolourchi",
      "James Valori",
      "Kevin Carlberg",
      "Karl Ridgeway",
      "Joseph Tighe"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07413v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07413v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.07384v1",
    "title": "Teaching Pretrained Language Models to Think Deeper with Retrofitted Recurrence",
    "summary": "Recent advances in depth-recurrent language models show that recurrence can decouple train-time compute and parameter count from test-time compute. In this work, we study how to convert existing pretrained non-recurrent language models into depth-recurrent models. We find that using a curriculum of recurrences to increase the effective depth of the model over the course of training preserves performance while reducing total computational cost. In our experiments, on mathematics, we observe that converting pretrained models to recurrent ones results in better performance at a given compute budget than simply post-training the original non-recurrent language model.",
    "authors": [
      "Sean McLeish",
      "Ang Li",
      "John Kirchenbauer",
      "Dayal Singh Kalra",
      "Brian R. Bartoldson",
      "Bhavya Kailkhura",
      "Avi Schwarzschild",
      "Jonas Geiping",
      "Tom Goldstein",
      "Micah Goldblum"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07384v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07384v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.06448v1",
    "title": "When AI Agents Collude Online: Financial Fraud Risks by Collaborative LLM Agents on Social Platforms",
    "summary": "In this work, we study the risks of collective financial fraud in large-scale multi-agent systems powered by large language model (LLM) agents. We investigate whether agents can collaborate in fraudulent behaviors, how such collaboration amplifies risks, and what factors influence fraud success. To support this research, we present MultiAgentFraudBench, a large-scale benchmark for simulating financial fraud scenarios based on realistic online interactions. The benchmark covers 28 typical online fraud scenarios, spanning the full fraud lifecycle across both public and private domains. We further analyze key factors affecting fraud success, including interaction depth, activity level, and fine-grained collaboration failure modes. Finally, we propose a series of mitigation strategies, including adding content-level warnings to fraudulent posts and dialogues, using LLMs as monitors to block potentially malicious agents, and fostering group resilience through information sharing at the societal level. Notably, we observe that malicious agents can adapt to environmental interventions. Our findings highlight the real-world risks of multi-agent financial fraud and suggest practical measures for mitigating them. Code is available at https://github.com/zheng977/MutiAgent4Fraud.",
    "authors": [
      "Qibing Ren",
      "Zhijie Zheng",
      "Jiaxuan Guo",
      "Junchi Yan",
      "Lizhuang Ma",
      "Jing Shao"
    ],
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.SI"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06448v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06448v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.07312v1",
    "title": "Superhuman AI for Stratego Using Self-Play Reinforcement Learning and Test-Time Search",
    "summary": "Few classical games have been regarded as such significant benchmarks of artificial intelligence as to have justified training costs in the millions of dollars. Among these, Stratego -- a board wargame exemplifying the challenge of strategic decision making under massive amounts of hidden information -- stands apart as a case where such efforts failed to produce performance at the level of top humans. This work establishes a step change in both performance and cost for Stratego, showing that it is now possible not only to reach the level of top humans, but to achieve vastly superhuman level -- and that doing so requires not an industrial budget, but merely a few thousand dollars. We achieved this result by developing general approaches for self-play reinforcement learning and test-time search under imperfect information.",
    "authors": [
      "Samuel Sokota",
      "Eugene Vinitsky",
      "Hengyuan Hu",
      "J. Zico Kolter",
      "Gabriele Farina"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07312v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07312v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.06519v1",
    "title": "On the Analogy between Human Brain and LLMs: Spotting Key Neurons in Grammar Perception",
    "summary": "Artificial Neural Networks, the building blocks of AI, were inspired by the human brain's network of neurons. Over the years, these networks have evolved to replicate the complex capabilities of the brain, allowing them to handle tasks such as image and language processing. In the realm of Large Language Models, there has been a keen interest in making the language learning process more akin to that of humans. While neuroscientific research has shown that different grammatical categories are processed by different neurons in the brain, we show that LLMs operate in a similar way. Utilizing Llama 3, we identify the most important neurons associated with the prediction of words belonging to different part-of-speech tags. Using the achieved knowledge, we train a classifier on a dataset, which shows that the activation patterns of these key neurons can reliably predict part-of-speech tags on fresh data. The results suggest the presence of a subspace in LLMs focused on capturing part-of-speech tag concepts, resembling patterns observed in lesion studies of the brain in neuroscience.",
    "authors": [
      "Sanaz Saki Norouzi",
      "Mohammad Masjedi",
      "Pascal Hitzler"
    ],
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06519v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06519v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.06763v1",
    "title": "Sensitivity of Small Language Models to Fine-tuning Data Contamination",
    "summary": "Small Language Models (SLMs) are increasingly being deployed in resource-constrained environments, yet their behavioral robustness to data contamination during instruction tuning remains poorly understood. We systematically investigate the contamination sensitivity of 23 SLMs (270M to 4B parameters) across multiple model families by measuring susceptibility to syntactic and semantic transformation types during instruction tuning: syntactic transformations (character and word reversal) and semantic transformations (irrelevant and counterfactual responses), each applied at contamination levels of 25\\%, 50\\%, 75\\%, and 100\\%. Our results reveal fundamental asymmetries in vulnerability patterns: syntactic transformations cause catastrophic performance degradation, with character reversal producing near-complete failure across all models regardless of size or family, while semantic transformations demonstrate distinct threshold behaviors and greater resilience in core linguistic capabilities. Critically, we discover a ``\\textit{capability curse}\" where larger, more capable models become more susceptible to learning semantic corruptions, effectively following harmful instructions more readily, while our analysis of base versus instruction-tuned variants reveals that alignment provides inconsistent robustness benefits, sometimes even reducing resilience. Our work establishes three core contributions: (1) empirical evidence of SLMs' disproportionate vulnerability to syntactic pattern contamination, (2) identification of asymmetric sensitivity patterns between syntactic and semantic transformations, and (3) systematic evaluation protocols for contamination robustness assessment. These findings have immediate deployment implications, suggesting that current robustness assumptions may not hold for smaller models and highlighting the need for contamination-aware training protocols.",
    "authors": [
      "Nicy Scaria",
      "Silvester John Joseph Kennedy",
      "Deepak Subramani"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06763v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06763v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.06378v1",
    "title": "ArtReg: Visuo-Tactile based Pose Tracking and Manipulation of Unseen Articulated Objects",
    "summary": "Robots operating in real-world environments frequently encounter unknown objects with complex structures and articulated components, such as doors, drawers, cabinets, and tools. The ability to perceive, track, and manipulate these objects without prior knowledge of their geometry or kinematic properties remains a fundamental challenge in robotics. In this work, we present a novel method for visuo-tactile-based tracking of unseen objects (single, multiple, or articulated) during robotic interaction without assuming any prior knowledge regarding object shape or dynamics. Our novel pose tracking approach termed ArtReg (stands for Articulated Registration) integrates visuo-tactile point clouds in an unscented Kalman Filter formulation in the SE(3) Lie Group for point cloud registration. ArtReg is used to detect possible articulated joints in objects using purposeful manipulation maneuvers such as pushing or hold-pulling with a two-robot team. Furthermore, we leverage ArtReg to develop a closed-loop controller for goal-driven manipulation of articulated objects to move the object into the desired pose configuration. We have extensively evaluated our approach on various types of unknown objects through real robot experiments. We also demonstrate the robustness of our method by evaluating objects with varying center of mass, low-light conditions, and with challenging visual backgrounds. Furthermore, we benchmarked our approach on a standard dataset of articulated objects and demonstrated improved performance in terms of pose accuracy compared to state-of-the-art methods. Our experiments indicate that robust and accurate pose tracking leveraging visuo-tactile information enables robots to perceive and interact with unseen complex articulated objects (with revolute or prismatic joints).",
    "authors": [
      "Prajval Kumar Murali",
      "Mohsen Kaboli"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06378v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06378v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.07046v1",
    "title": "Learning Quantized Continuous Controllers for Integer Hardware",
    "summary": "Deploying continuous-control reinforcement learning policies on embedded hardware requires meeting tight latency and power budgets. Small FPGAs can deliver these, but only if costly floating point pipelines are avoided. We study quantization-aware training (QAT) of policies for integer inference and we present a learning-to-hardware pipeline that automatically selects low-bit policies and synthesizes them to an Artix-7 FPGA. Across five MuJoCo tasks, we obtain policy networks that are competitive with full precision (FP32) policies but require as few as 3 or even only 2 bits per weight, and per internal activation value, as long as input precision is chosen carefully. On the target hardware, the selected policies achieve inference latencies on the order of microseconds and consume microjoules per action, favorably comparing to a quantized reference. Last, we observe that the quantized policies exhibit increased input noise robustness compared to the floating-point baseline.",
    "authors": [
      "Fabian Kresse",
      "Christoph H. Lampert"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07046v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07046v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2511.06189v1",
    "title": "Counterfactual Forecasting For Panel Data",
    "summary": "We address the challenge of forecasting counterfactual outcomes in a panel data with missing entries and temporally dependent latent factors -- a common scenario in causal inference, where estimating unobserved potential outcomes ahead of time is essential. We propose Forecasting Counterfactuals under Stochastic Dynamics (FOCUS), a method that extends traditional matrix completion methods by leveraging time series dynamics of the factors, thereby enhancing the prediction accuracy of future counterfactuals. Building upon a PCA estimator, our method accommodates both stochastic and deterministic components within the factors, and provides a flexible framework for various applications. In case of stationary autoregressive factors and under standard conditions, we derive error bounds and establish asymptotic normality of our estimator. Empirical evaluations demonstrate that our method outperforms existing benchmarks when the latent factors have an autoregressive component. We illustrate FOCUS results on HeartSteps, a mobile health study, illustrating its effectiveness in forecasting step counts for users receiving activity prompts, thereby leveraging temporal patterns in user behavior.",
    "authors": [
      "Navonil Deb",
      "Raaz Dwivedi",
      "Sumanta Basu"
    ],
    "categories": [
      "stat.ME",
      "math.ST",
      "stat.ML"
    ],
    "published": "2025-11-09",
    "url": "https://arxiv.org/abs/2511.06189v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06189v1.pdf",
    "date": "2025-11-11",
    "source": "arxiv",
    "research_score": 0.47
  }
]