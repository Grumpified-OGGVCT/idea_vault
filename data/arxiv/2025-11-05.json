[
  {
    "arxiv_id": "2511.02818v1",
    "title": "Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning",
    "summary": "Tabular data remain the predominant format for real-world applications. Yet, developing effective neural models for tabular data remains challenging due to heterogeneous feature types and complex interactions occurring at multiple scales. Recent advances in tabular in-context learning (ICL), such as TabPFN and TabICL, have achieved state-of-the-art performance comparable to gradient-boosted trees (GBTs) without task-specific fine-tuning. However, current architectures exhibit key limitations: (1) single-scale feature processing that overlooks hierarchical dependencies, (2) dense attention with quadratic scaling in table width, and (3) strictly sequential component processing that prevents iterative representation refinement and cross-component communication. To address these challenges, we introduce Orion-MSP, a tabular ICL architecture featuring three key innovations: (1) multi-scale processing to capture hierarchical feature interactions; (2) block-sparse attention combining windowed, global, and random patterns for scalable efficiency and long-range connectivity; and (3) a Perceiver-style memory enabling safe bidirectional information flow across components. Across diverse benchmarks, Orion-MSP matches or surpasses state-of-the-art performance while scaling effectively to high-dimensional tables, establishing a new standard for efficient tabular in-context learning. The model is publicly available at https://github.com/Lexsi-Labs/Orion-MSP .",
    "authors": [
      "Mohamed Bouadi",
      "Pratinav Seth",
      "Aditya Tanna",
      "Vinay Kumar Sankarapu"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02818v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02818v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 1.0
  },
  {
    "arxiv_id": "2511.02769v1",
    "title": "STAR-VAE: Latent Variable Transformers for Scalable and Controllable   Molecular Generation",
    "summary": "The chemical space of drug-like molecules is vast, motivating the development of generative models that must learn broad chemical distributions, enable conditional generation by capturing structure-property representations, and provide fast molecular generation. Meeting the objectives depends on modeling choices, including the probabilistic modeling approach, the conditional generative formulation, the architecture, and the molecular input representation. To address the challenges, we present STAR-VAE (Selfies-encoded, Transformer-based, AutoRegressive Variational Auto Encoder), a scalable latent-variable framework with a Transformer encoder and an autoregressive Transformer decoder. It is trained on 79 million drug-like molecules from PubChem, using SELFIES to guarantee syntactic validity. The latent-variable formulation enables conditional generation: a property predictor supplies a conditioning signal that is applied consistently to the latent prior, the inference network, and the decoder. Our contributions are: (i) a Transformer-based latent-variable encoder-decoder model trained on SELFIES representations; (ii) a principled conditional latent-variable formulation for property-guided generation; and (iii) efficient finetuning with low-rank adapters (LoRA) in both encoder and decoder, enabling fast adaptation with limited property and activity data. On the GuacaMol and MOSES benchmarks, our approach matches or exceeds baselines, and latent-space analyses reveal smooth, semantically structured representations that support both unconditional exploration and property-aware generation. On the Tartarus benchmarks, the conditional model shifts docking-score distributions toward stronger predicted binding. These results suggest that a modernized, scale-appropriate VAE remains competitive for molecular generation when paired with principled conditioning and parameter-efficient finetuning.",
    "authors": [
      "Bum Chul Kwon",
      "Ben Shapira",
      "Moshiko Raboh",
      "Shreyans Sethi",
      "Shruti Murarka",
      "Joseph A Morrone",
      "Jianying Hu",
      "Parthasarathy Suryanarayanan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02769v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02769v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.9
  },
  {
    "arxiv_id": "2511.02570v1",
    "title": "Dynamic Priors in Bayesian Optimization for Hyperparameter Optimization",
    "summary": "Hyperparameter optimization (HPO), for example, based on Bayesian optimization (BO), supports users in designing models well-suited for a given dataset. HPO has proven its effectiveness on several applications, ranging from classical machine learning for tabular data to deep neural networks for computer vision and transformers for natural language processing. However, HPO still sometimes lacks acceptance by machine learning experts due to its black-box nature and limited user control. Addressing this, first approaches have been proposed to initialize BO methods with expert knowledge. However, these approaches do not allow for online steering during the optimization process. In this paper, we introduce a novel method that enables repeated interventions to steer BO via user input, specifying expert knowledge and user preferences at runtime of the HPO process in the form of prior distributions. To this end, we generalize an existing method, $\\pi$BO, preserving theoretical guarantees. We also introduce a misleading prior detection scheme, which allows protection against harmful user inputs. In our experimental evaluation, we demonstrate that our method can effectively incorporate multiple priors, leveraging informative priors, whereas misleading priors are reliably rejected or overcome. Thereby, we achieve competitiveness to unperturbed BO.",
    "authors": [
      "Lukas Fehring",
      "Marcel Wever",
      "Maximilian Spliethöver",
      "Leona Hennig",
      "Henning Wachsmuth",
      "Marius Lindauer"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02570v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02570v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.9
  },
  {
    "arxiv_id": "2511.02802v1",
    "title": "TabTune: A Unified Library for Inference and Fine-Tuning Tabular   Foundation Models",
    "summary": "Tabular foundation models represent a growing paradigm in structured data learning, extending the benefits of large-scale pretraining to tabular domains. However, their adoption remains limited due to heterogeneous preprocessing pipelines, fragmented APIs, inconsistent fine-tuning procedures, and the absence of standardized evaluation for deployment-oriented metrics such as calibration and fairness. We present TabTune, a unified library that standardizes the complete workflow for tabular foundation models through a single interface. TabTune provides consistent access to seven state-of-the-art models supporting multiple adaptation strategies, including zero-shot inference, meta-learning, supervised fine-tuning (SFT), and parameter-efficient fine-tuning (PEFT). The framework automates model-aware preprocessing, manages architectural heterogeneity internally, and integrates evaluation modules for performance, calibration, and fairness. Designed for extensibility and reproducibility, TabTune enables consistent benchmarking of adaptation strategies of tabular foundation models. The library is open source and available at https://github.com/Lexsi-Labs/TabTune .",
    "authors": [
      "Aditya Tanna",
      "Pratinav Seth",
      "Mohamed Bouadi",
      "Utsav Avaiya",
      "Vinay Kumar Sankarapu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02802v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02802v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.86
  },
  {
    "arxiv_id": "2511.02602v1",
    "title": "Trustworthy Quantum Machine Learning: A Roadmap for Reliability,   Robustness, and Security in the NISQ Era",
    "summary": "Quantum machine learning (QML) is a promising paradigm for tackling computational problems that challenge classical AI. Yet, the inherent probabilistic behavior of quantum mechanics, device noise in NISQ hardware, and hybrid quantum-classical execution pipelines introduce new risks that prevent reliable deployment of QML in real-world, safety-critical settings. This research offers a broad roadmap for Trustworthy Quantum Machine Learning (TQML), integrating three foundational pillars of reliability: (i) uncertainty quantification for calibrated and risk-aware decision making, (ii) adversarial robustness against classical and quantum-native threat models, and (iii) privacy preservation in distributed and delegated quantum learning scenarios. We formalize quantum-specific trust metrics grounded in quantum information theory, including a variance-based decomposition of predictive uncertainty, trace-distance-bounded robustness, and differential privacy for hybrid learning channels. To demonstrate feasibility on current NISQ devices, we validate a unified trust assessment pipeline on parameterized quantum classifiers, uncovering correlations between uncertainty and prediction risk, an asymmetry in attack vulnerability between classical and quantum state perturbations, and privacy-utility trade-offs driven by shot noise and quantum channel noise. This roadmap seeks to define trustworthiness as a first-class design objective for quantum AI.",
    "authors": [
      "Ferhat Ozgur Catak",
      "Jungwon Seo",
      "Umit Cali"
    ],
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02602v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02602v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.84
  },
  {
    "arxiv_id": "2511.02781v1",
    "title": "Measuring AI Diffusion: A Population-Normalized Metric for Tracking   Global AI Usage",
    "summary": "Measuring global AI diffusion remains challenging due to a lack of population-normalized, cross-country usage data. We introduce AI User Share, a novel indicator that estimates the share of each country's working-age population actively using AI tools. Built from anonymized Microsoft telemetry and adjusted for device access and mobile scaling, this metric spans 147 economies and provides consistent, real-time insight into global AI diffusion. We find wide variation in adoption, with a strong correlation between AI User Share and GDP. High uptake is concentrated in developed economies, though usage among internet-connected populations in lower-income countries reveals substantial latent demand. We also detect sharp increases in usage following major product launches, such as DeepSeek in early 2025. While the metric's reliance solely on Microsoft telemetry introduces potential biases related to this user base, it offers an important new lens into how AI is spreading globally. AI User Share enables timely benchmarking that can inform data-driven AI policy.",
    "authors": [
      "Amit Misra",
      "Jane Wang",
      "Scott McCullers",
      "Kevin White",
      "Juan Lavista Ferres"
    ],
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02781v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02781v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.83
  },
  {
    "arxiv_id": "2511.02824v1",
    "title": "Kosmos: An AI Scientist for Autonomous Discovery",
    "summary": "Data-driven scientific discovery requires iterative cycles of literature search, hypothesis generation, and data analysis. Substantial progress has been made towards AI agents that can automate scientific research, but all such agents remain limited in the number of actions they can take before losing coherence, thus limiting the depth of their findings. Here we present Kosmos, an AI scientist that automates data-driven discovery. Given an open-ended objective and a dataset, Kosmos runs for up to 12 hours performing cycles of parallel data analysis, literature search, and hypothesis generation before synthesizing discoveries into scientific reports. Unlike prior systems, Kosmos uses a structured world model to share information between a data analysis agent and a literature search agent. The world model enables Kosmos to coherently pursue the specified objective over 200 agent rollouts, collectively executing an average of 42,000 lines of code and reading 1,500 papers per run. Kosmos cites all statements in its reports with code or primary literature, ensuring its reasoning is traceable. Independent scientists found 79.4% of statements in Kosmos reports to be accurate, and collaborators reported that a single 20-cycle Kosmos run performed the equivalent of 6 months of their own research time on average. Furthermore, collaborators reported that the number of valuable scientific findings generated scales linearly with Kosmos cycles (tested up to 20 cycles). We highlight seven discoveries made by Kosmos that span metabolomics, materials science, neuroscience, and statistical genetics. Three discoveries independently reproduce findings from preprinted or unpublished manuscripts that were not accessed by Kosmos at runtime, while four make novel contributions to the scientific literature.",
    "authors": [
      "Ludovico Mitchener",
      "Angela Yiu",
      "Benjamin Chang",
      "Mathieu Bourdenx",
      "Tyler Nadolski",
      "Arvis Sulovari",
      "Eric C. Landsness",
      "Daniel L. Barabasi",
      "Siddharth Narayanan",
      "Nicky Evans",
      "Shriya Reddy",
      "Martha Foiani",
      "Aizad Kamal",
      "Leah P. Shriver",
      "Fang Cao",
      "Asmamaw T. Wassie",
      "Jon M. Laurent",
      "Edwin Melville-Green",
      "Mayk Caldas",
      "Albert Bou",
      "Kaleigh F. Roberts",
      "Sladjana Zagorac",
      "Timothy C. Orr",
      "Miranda E. Orr",
      "Kevin J. Zwezdaryk",
      "Ali E. Ghareeb",
      "Laurie McCoy",
      "Bruna Gomes",
      "Euan A. Ashley",
      "Karen E. Duff",
      "Tonio Buonassisi",
      "Tom Rainforth",
      "Randall J. Bateman",
      "Michael Skarlinski",
      "Samuel G. Rodriques",
      "Michaela M. Hinks",
      "Andrew D. White"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02824v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02824v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.82
  },
  {
    "arxiv_id": "2511.02749v1",
    "title": "Using Span Queries to Optimize for Cache and Attention Locality",
    "summary": "Clients are evolving beyond chat completion, and now include a variety of innovative inference-time scaling and deep reasoning techniques. At the same time, inference servers remain heavily optimized for chat completion. Prior work has shown that large improvements to KV cache hit rate are possible if inference servers evolve towards these non-chat use cases. However, they offer solutions that are also optimized for a single use case, RAG. In this paper, we introduce the span query to generalize the interface to the inference server. We demonstrate that chat, RAG, inference-time scaling, and agentic workloads can all be expressed as span queries. We show how the critical distinction that had been assumed by prior work lies in whether the order of the inputs matter -- do they commute? In chat, they do not. In RAG, they often do. This paper introduces span queries, which are expression trees of inference calls, linked together with commutativity constraints. We describe span query syntax and semantics. We show how they can be automatically optimized to improve KV cache locality. We show how a small change to vLLM (affecting only 492 lines) can enable high-performance execution of span queries. Using this stack, we demonstrate that span queries can achieve 10-20x reductions in TTFT for two distinct non-chat use cases. Finally, we show that span queries can also be optimized to improve attention locality, so as to avoid the so-called lost-in-the-middle problem. We demonstrate that an attention-optimized span query on a 2b parameter model vastly outperforms the accuracy of a stock inference server using an 8b model.",
    "authors": [
      "Paul Castro",
      "Nick Mitchell",
      "Nathan Ordonez",
      "Thomas Parnell",
      "Mudhakar Srivatsa",
      "Antoni Viros i Martin"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02749v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02749v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.82
  },
  {
    "arxiv_id": "2511.02533v1",
    "title": "Rawlsian many-to-one matching with non-linear utility",
    "summary": "We study a many-to-one matching problem, such as the college admission problem, where each college can admit multiple students. Unlike classical models, colleges evaluate sets of students through non-linear utility functions that capture diversity between them. In this setting, we show that classical stable matchings may fail to exist. To address this, we propose alternative solution concepts based on Rawlsian fairness, aiming to maximize the minimum utility across colleges. We design both deterministic and stochastic algorithms that iteratively improve the outcome of the worst-off college, offering a practical approach to fair allocation when stability cannot be guaranteed.",
    "authors": [
      "Hortence Nana",
      "Andreas Athanasopoulos",
      "Christos Dimitrakakis"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02533v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02533v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.79
  },
  {
    "arxiv_id": "2511.02795v1",
    "title": "Can LLMs subtract numbers?",
    "summary": "We present a systematic study of subtraction in large language models (LLMs). While prior benchmarks emphasize addition and multiplication, subtraction has received comparatively little attention despite being structurally distinct as a non-commutative operation. We evaluate eight pretrained LLMs spanning four families on addition and subtraction problems. Our experiments reveal that subtraction accuracy lags behind addition by a wide margin. We find that the errors for ($a-b$) are concentrated in cases where ($a<b$). In such cases, LLMs frequently produce the correct magnitude but omit the negative sign. Probing analyses show that LLMs internally encode whether results should be negative, yet this information is often not reflected in generated outputs. We further test well-known techniques such as few-shot learning and instruction-tuning to see if they can improve the LLMs' performance. Our results suggest that while few-shot prompting yields modest gains, the instruction-tuned models achieve near-perfect accuracies in generating the negative sign. Together, these findings provide a clearer characterization of the limitations and recoverability of LLMs' arithmetic capabilities in subtraction.",
    "authors": [
      "Mayank Jobanputra",
      "Nils Philipp Walter",
      "Maitrey Mehta",
      "Blerta Veseli",
      "Evan Parker Kelly Chapple",
      "Yifan Wang",
      "Sneha Chetani",
      "Ellie Pavlick",
      "Antonio Vergari",
      "Vera Demberg"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02795v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02795v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2511.02573v1",
    "title": "RIS-Assisted 3D Spherical Splatting for Object Composition Visualization   using Detection Transformers",
    "summary": "The pursuit of immersive and structurally aware multimedia experiences has intensified interest in sensing modalities that reconstruct objects beyond the limits of visible light. Conventional optical pipelines degrade under occlusion or low illumination, motivating the use of radio-frequency (RF) sensing, whose electromagnetic waves penetrate materials and encode both geometric and compositional information. Yet, uncontrolled multipath propagation restricts reconstruction accuracy. Recent advances in Programmable Wireless Environments (PWEs) mitigate this limitation by enabling software-defined manipulation of propagation through Reconfigurable Intelligent Surfaces (RISs), thereby providing controllable illumination diversity. Building on this capability, this work introduces a PWE-driven RF framework for three-dimensional object reconstruction using material-aware spherical primitives. The proposed approach combines RIS-enabled field synthesis with a Detection Transformer (DETR) that infers spatial and material parameters directly from extracted RF features. Simulation results confirm the framework's ability to approximate object geometries and classify material composition with an overall accuracy of 79.35%, marking an initial step toward programmable and physically grounded RF-based 3D object composition visualization.",
    "authors": [
      "Anastasios T. Sotiropoulos",
      "Stavros Tsimpoukis",
      "Dimitrios Tyrovolas",
      "Sotiris Ioannidis",
      "George K. Karagiannidis",
      "Christos K. Liaskos"
    ],
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02573v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02573v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2511.02830v1",
    "title": "Densemarks: Learning Canonical Embeddings for Human Heads Images via   Point Tracks",
    "summary": "We propose DenseMarks - a new learned representation for human heads, enabling high-quality dense correspondences of human head images. For a 2D image of a human head, a Vision Transformer network predicts a 3D embedding for each pixel, which corresponds to a location in a 3D canonical unit cube. In order to train our network, we collect a dataset of pairwise point matches, estimated by a state-of-the-art point tracker over a collection of diverse in-the-wild talking heads videos, and guide the mapping via a contrastive loss, encouraging matched points to have close embeddings. We further employ multi-task learning with face landmarks and segmentation constraints, as well as imposing spatial continuity of embeddings through latent cube features, which results in an interpretable and queryable canonical space. The representation can be used for finding common semantic parts, face/head tracking, and stereo reconstruction. Due to the strong supervision, our method is robust to pose variations and covers the entire head, including hair. Additionally, the canonical space bottleneck makes sure the obtained representations are consistent across diverse poses and individuals. We demonstrate state-of-the-art results in geometry-aware point matching and monocular head tracking with 3D Morphable Models. The code and the model checkpoint will be made available to the public.",
    "authors": [
      "Dmitrii Pozdeev",
      "Alexey Artemov",
      "Ananta R. Bhattarai",
      "Artem Sevastopolsky"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02830v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02830v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.77
  },
  {
    "arxiv_id": "2511.02817v1",
    "title": "Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities",
    "summary": "As model context lengths continue to grow, concerns about whether models effectively use the full context length have persisted. While several carefully designed long-context evaluations have recently been released, these evaluations tend to rely on retrieval from one or more sections of the context, which allows nearly all of the context tokens to be disregarded as noise. This represents only one type of task that might be performed with long context. We introduce Oolong, a benchmark of long-context reasoning tasks that require analyzing individual chunks of text on an atomic level, and then aggregating these analyses to answer distributional questions. Oolong is separated into two task sets: Oolong-synth, a set of naturalistic synthetic tasks, where we can easily ablate components of the reasoning problem; and Oolong-real, a downstream setting which requires reasoning over real-world conversational data. Oolong requires models to reason over large quantities of examples, to perform both classification and counting in-context, and to reason over temporal and user relations. Even frontier models struggle on Oolong, with GPT-5, Claude-Sonnet-4, and Gemini-2.5-Pro all achieving less than 50% accuracy on both splits at 128K. We release the data and evaluation harness for Oolong to enable further development of models that can reason over large quantities of text.",
    "authors": [
      "Amanda Bertsch",
      "Adithya Pratapa",
      "Teruko Mitamura",
      "Graham Neubig",
      "Matthew R. Gormley"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02817v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02817v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.77
  },
  {
    "arxiv_id": "2511.02752v1",
    "title": "AI Diffusion in Low Resource Language Countries",
    "summary": "Artificial intelligence (AI) is diffusing globally at unprecedented speed, but adoption remains uneven. Frontier Large Language Models (LLMs) are known to perform poorly on low-resource languages due to data scarcity. We hypothesize that this performance deficit reduces the utility of AI, thereby slowing adoption in Low-Resource Language Countries (LRLCs). To test this, we use a weighted regression model to isolate the language effect from socioeconomic and demographic factors, finding that LRLCs have a share of AI users that is approximately 20% lower relative to their baseline. These results indicate that linguistic accessibility is a significant, independent barrier to equitable AI diffusion.",
    "authors": [
      "Amit Misra",
      "Syed Waqas Zamir",
      "Wassim Hamidouche",
      "Inbal Becker-Reshef",
      "Juan Lavista Ferres"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02752v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02752v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2511.02567v1",
    "title": "Adaptive Neighborhood-Constrained Q Learning for Offline Reinforcement   Learning",
    "summary": "Offline reinforcement learning (RL) suffers from extrapolation errors induced by out-of-distribution (OOD) actions. To address this, offline RL algorithms typically impose constraints on action selection, which can be systematically categorized into density, support, and sample constraints. However, we show that each category has inherent limitations: density and sample constraints tend to be overly conservative in many scenarios, while the support constraint, though least restrictive, faces challenges in accurately modeling the behavior policy. To overcome these limitations, we propose a new neighborhood constraint that restricts action selection in the Bellman target to the union of neighborhoods of dataset actions. Theoretically, the constraint not only bounds extrapolation errors and distribution shift under certain conditions, but also approximates the support constraint without requiring behavior policy modeling. Moreover, it retains substantial flexibility and enables pointwise conservatism by adapting the neighborhood radius for each data point. In practice, we employ data quality as the adaptation criterion and design an adaptive neighborhood constraint. Building on an efficient bilevel optimization framework, we develop a simple yet effective algorithm, Adaptive Neighborhood-constrained Q learning (ANQ), to perform Q learning with target actions satisfying this constraint. Empirically, ANQ achieves state-of-the-art performance on standard offline RL benchmarks and exhibits strong robustness in scenarios with noisy or limited data.",
    "authors": [
      "Yixiu Mao",
      "Yun Qu",
      "Qi Wang",
      "Xiangyang Ji"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02567v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02567v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.02607v1",
    "title": "UniChange: Unifying Change Detection with Multimodal Large Language   Model",
    "summary": "Change detection (CD) is a fundamental task for monitoring and analyzing land cover dynamics. While recent high performance models and high quality datasets have significantly advanced the field, a critical limitation persists. Current models typically acquire limited knowledge from single-type annotated data and cannot concurrently leverage diverse binary change detection (BCD) and semantic change detection (SCD) datasets. This constraint leads to poor generalization and limited versatility. The recent advancements in Multimodal Large Language Models (MLLMs) introduce new possibilities for a unified CD framework. We leverage the language priors and unification capabilities of MLLMs to develop UniChange, the first MLLM-based unified change detection model. UniChange integrates generative language abilities with specialized CD functionalities. Our model successfully unifies both BCD and SCD tasks through the introduction of three special tokens: [T1], [T2], and [CHANGE]. Furthermore, UniChange utilizes text prompts to guide the identification of change categories, eliminating the reliance on predefined classification heads. This design allows UniChange to effectively acquire knowledge from multi-source datasets, even when their class definitions conflict. Experiments on four public benchmarks (WHU-CD, S2Looking, LEVIR-CD+, and SECOND) demonstrate SOTA performance, achieving IoU scores of 90.41, 53.04, 78.87, and 57.62, respectively, surpassing all previous methods. The code is available at https://github.com/Erxucomeon/UniChange.",
    "authors": [
      "Xu Zhang",
      "Danyang Li",
      "Xiaohang Dong",
      "Tianhao Wu",
      "Hualong Yu",
      "Jianye Wang",
      "Qicheng Li",
      "Xiang Li"
    ],
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02607v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02607v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2511.02834v1",
    "title": "Agent-Omni: Test-Time Multimodal Reasoning via Model Coordination for   Understanding Anything",
    "summary": "Multimodal large language models (MLLMs) have shown strong capabilities but remain limited to fixed modality pairs and require costly fine-tuning with large aligned datasets. Building fully omni-capable models that can integrate text, images, audio, and video remains impractical and lacks robust reasoning support. In this paper, we propose an Agent-Omni framework that coordinates existing foundation models through a master-agent system, enabling flexible multimodal reasoning without retraining. The master agent interprets user intent, delegates subtasks to modality-specific agents, and integrates their outputs into coherent responses. Extensive experiments across text, image, audio, video, and omni benchmarks show that Agent-Omni consistently achieves state-of-the-art performance, particularly on tasks requiring complex cross-modal reasoning. Its agent-based design enables seamless integration of specialized foundation models, ensuring adaptability to diverse inputs while maintaining transparency and interpretability. In addition, the framework is modular and easily extensible, allowing future improvements as stronger models become available. %We release an open-source implementation to support continued research on scalable and reliable omni-modal reasoning.",
    "authors": [
      "Huawei Lin",
      "Yunzhi Shi",
      "Tong Geng",
      "Weijie Zhao",
      "Wei Wang",
      "Ravender Pal Singh"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02834v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02834v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.02762v1",
    "title": "From Solo to Symphony: Orchestrating Multi-Agent Collaboration with   Single-Agent Demos",
    "summary": "Training a team of agents from scratch in multi-agent reinforcement learning (MARL) is highly inefficient, much like asking beginners to play a symphony together without first practicing solo. Existing methods, such as offline or transferable MARL, can ease this burden, but they still rely on costly multi-agent data, which often becomes the bottleneck. In contrast, solo experiences are far easier to obtain in many important scenarios, e.g., collaborative coding, household cooperation, and search-and-rescue. To unlock their potential, we propose Solo-to-Collaborative RL (SoCo), a framework that transfers solo knowledge into cooperative learning. SoCo first pretrains a shared solo policy from solo demonstrations, then adapts it for cooperation during multi-agent training through a policy fusion mechanism that combines an MoE-like gating selector and an action editor. Experiments across diverse cooperative tasks show that SoCo significantly boosts the training efficiency and performance of backbone algorithms. These results demonstrate that solo demonstrations provide a scalable and effective complement to multi-agent data, making cooperative learning more practical and broadly applicable.",
    "authors": [
      "Xun Wang",
      "Zhuoran Li",
      "Yanshan Lin",
      "Hai Zhong",
      "Longbo Huang"
    ],
    "categories": [
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02762v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02762v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.02721v1",
    "title": "PragExTra: A Multilingual Corpus of Pragmatic Explicitation in   Translation",
    "summary": "Translators often enrich texts with background details that make implicit cultural meanings explicit for new audiences. This phenomenon, known as pragmatic explicitation, has been widely discussed in translation theory but rarely modeled computationally. We introduce PragExTra, the first multilingual corpus and detection framework for pragmatic explicitation. The corpus covers eight language pairs from TED-Multi and Europarl and includes additions such as entity descriptions, measurement conversions, and translator remarks. We identify candidate explicitation cases through null alignments and refined using active learning with human annotation. Our results show that entity and system-level explicitations are most frequent, and that active learning improves classifier accuracy by 7-8 percentage points, achieving up to 0.88 accuracy and 0.82 F1 across languages. PragExTra establishes pragmatic explicitation as a measurable, cross-linguistic phenomenon and takes a step towards building culturally aware machine translation. Keywords: translation, multilingualism, explicitation",
    "authors": [
      "Doreen Osmelak",
      "Koel Dutta Chowdhury",
      "Uliana Sentsova",
      "Cristina España-Bonet",
      "Josef van Genabith"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02721v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02721v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.02623v1",
    "title": "The Realignment Problem: When Right becomes Wrong in LLMs",
    "summary": "The alignment of Large Language Models (LLMs) with human values is central to their safe deployment, yet current practice produces static, brittle, and costly-to-maintain models that fail to keep pace with evolving norms and policies. This misalignment, which we term the Alignment-Reality Gap, poses a growing challenge for reliable long-term use. Existing remedies are inadequate: large-scale re-annotation is economically prohibitive, and standard unlearning methods act as blunt instruments that erode utility rather than enable precise policy updates. We introduce TRACE (Triage and Re-align by Alignment Conflict Evaluation), a framework for principled unlearning that reconceives re-alignment as a programmatic policy application problem. TRACE programmatically triages existing preference data against a new policy, identifies high-impact conflicts via a alignment impact score, and applies a hybrid optimization that cleanly inverts, discards, or preserves preferences while safeguarding model performance. Empirical results show that TRACE achieves robust re-alignment across diverse model families (Qwen2.5-7B, Gemma-2-9B, Llama-3.1-8B). On both synthetic benchmarks and the PKU-SafeRLHF dataset under complex policy shift, TRACE enforces new principles without degrading general capabilities. Our work establishes a scalable, dynamic, and cost-effective paradigm for maintaining LLM alignment, providing a foundation for sustainable and responsible AI deployment.",
    "authors": [
      "Aakash Sen Sharma",
      "Debdeep Sanyal",
      "Vivek Srivastava",
      "Shirish Karande",
      "Murari Mandal"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02623v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02623v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.02759v1",
    "title": "LLM-Supported Formal Knowledge Representation for Enhancing Control   Engineering Content with an Interactive Semantic Layer",
    "summary": "The rapid growth of research output in control engineering calls for new approaches to structure and formalize domain knowledge. This paper briefly describes an LLM-supported method for semi-automated generation of formal knowledge representations that combine human readability with machine interpretability and increased expressiveness. Based on the Imperative Representation of Knowledge (PyIRK) framework, we demonstrate how language models can assist in transforming natural-language descriptions and mathematical definitions (available as LaTeX source code) into a formalized knowledge graph. As a first application we present the generation of an ``interactive semantic layer'' to enhance the source documents in order to facilitate knowledge transfer. From our perspective this contributes to the vision of easily accessible, collaborative, and verifiable knowledge bases for the control engineering domain.",
    "authors": [
      "Julius Fiedler",
      "Carsten Knoll",
      "Klaus Röbenack"
    ],
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02759v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02759v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.02712v1",
    "title": "VidEmo: Affective-Tree Reasoning for Emotion-Centric Video Foundation   Models",
    "summary": "Understanding and predicting emotion from videos has gathered significant attention in recent studies, driven by advancements in video large language models (VideoLLMs). While advanced methods have made progress in video emotion analysis, the intrinsic nature of emotions poses significant challenges. Emotions are characterized by dynamic and cues-dependent properties, making it difficult to understand complex and evolving emotional states with reasonable rationale. To tackle these challenges, we propose a novel affective cues-guided reasoning framework that unifies fundamental attribute perception, expression analysis, and high-level emotional understanding in a stage-wise manner. At the core of our approach is a family of video emotion foundation models (VidEmo), specifically designed for emotion reasoning and instruction-following. These models undergo a two-stage tuning process: first, curriculum emotion learning for injecting emotion knowledge, followed by affective-tree reinforcement learning for emotion reasoning. Moreover, we establish a foundational data infrastructure and introduce a emotion-centric fine-grained dataset (Emo-CFG) consisting of 2.1M diverse instruction-based samples. Emo-CFG includes explainable emotional question-answering, fine-grained captions, and associated rationales, providing essential resources for advancing emotion understanding tasks. Experimental results demonstrate that our approach achieves competitive performance, setting a new milestone across 15 face perception tasks.",
    "authors": [
      "Zhicheng Zhang",
      "Weicheng Wang",
      "Yongjie Zhu",
      "Wenyu Qin",
      "Pengfei Wan",
      "Di Zhang",
      "Jufeng Yang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02712v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02712v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.02599v1",
    "title": "Next Token Knowledge Tracing: Exploiting Pretrained LLM Representations   to Decode Student Behaviour",
    "summary": "Modelling student knowledge is a key challenge when leveraging AI in education, with major implications for personalised learning. The Knowledge Tracing (KT) task aims to predict how students will respond to educational questions in learning environments, based on their prior interactions. Existing KT models typically use response correctness along with metadata like skill tags and timestamps, often overlooking the question text, which is an important source of pedagogical insight. This omission poses a lost opportunity while limiting predictive performance. We propose Next Token Knowledge Tracing (NTKT), a novel approach that reframes KT as a next-token prediction task using pretrained Large Language Models (LLMs). NTKT represents both student histories and question content as sequences of text, allowing LLMs to learn patterns in both behaviour and language. Our series of experiments significantly improves performance over state-of-the-art neural KT models and generalises much better to cold-start questions and users. These findings highlight the importance of question content in KT and demonstrate the benefits of leveraging pretrained representations of LLMs to model student learning more effectively.",
    "authors": [
      "Max Norris",
      "Kobi Gal",
      "Sahan Bulathwela"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02599v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02599v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.02525v1",
    "title": "An End-to-End Learning Approach for Solving Capacitated Location-Routing   Problems",
    "summary": "The capacitated location-routing problems (CLRPs) are classical problems in combinatorial optimization, which require simultaneously making location and routing decisions. In CLRPs, the complex constraints and the intricate relationships between various decisions make the problem challenging to solve. With the emergence of deep reinforcement learning (DRL), it has been extensively applied to address the vehicle routing problem and its variants, while the research related to CLRPs still needs to be explored. In this paper, we propose the DRL with heterogeneous query (DRLHQ) to solve CLRP and open CLRP (OCLRP), respectively. We are the first to propose an end-to-end learning approach for CLRPs, following the encoder-decoder structure. In particular, we reformulate the CLRPs as a markov decision process tailored to various decisions, a general modeling framework that can be adapted to other DRL-based methods. To better handle the interdependency across location and routing decisions, we also introduce a novel heterogeneous querying attention mechanism designed to adapt dynamically to various decision-making stages. Experimental results on both synthetic and benchmark datasets demonstrate superior solution quality and better generalization performance of our proposed approach over representative traditional and DRL-based baselines in solving both CLRP and OCLRP.",
    "authors": [
      "Changhao Miao",
      "Yuntian Zhang",
      "Tongyu Wu",
      "Fang Deng",
      "Chen Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02525v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02525v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.02667v1",
    "title": "Scalable Evaluation and Neural Models for Compositional Generalization",
    "summary": "Compositional generalization-a key open challenge in modern machine learning-requires models to predict unknown combinations of known concepts. However, assessing compositional generalization remains a fundamental challenge due to the lack of standardized evaluation protocols and the limitations of current benchmarks, which often favor efficiency over rigor. At the same time, general-purpose vision architectures lack the necessary inductive biases, and existing approaches to endow them compromise scalability. As a remedy, this paper introduces: 1) a rigorous evaluation framework that unifies and extends previous approaches while reducing computational requirements from combinatorial to constant; 2) an extensive and modern evaluation on the status of compositional generalization in supervised vision backbones, training more than 5000 models; 3) Attribute Invariant Networks, a class of models establishing a new Pareto frontier in compositional generalization, achieving a 23.43% accuracy improvement over baselines while reducing parameter overhead from 600% to 16% compared to fully disentangled counterparts.",
    "authors": [
      "Giacomo Camposampiero",
      "Pietro Barbiero",
      "Michael Hersche",
      "Roger Wattenhofer",
      "Abbas Rahimi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02667v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02667v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.02647v1",
    "title": "Federated Attention: A Distributed Paradigm for Collaborative LLM   Inference over Edge Networks",
    "summary": "Large language models (LLMs) are proliferating rapidly at the edge, delivering intelligent capabilities across diverse application scenarios. However, their practical deployment in collaborative scenarios confronts fundamental challenges: privacy vulnerabilities, communication overhead, and computational bottlenecks. To address these, we propose Federated Attention (FedAttn), which integrates the federated paradigm into the self-attention mechanism, creating a new distributed LLM inference framework that simultaneously achieves privacy protection, communication efficiency, and computational efficiency. FedAttn enables participants to perform local self-attention over their own token representations while periodically exchanging and aggregating Key-Value (KV) matrices across multiple Transformer blocks, collaboratively generating LLM responses without exposing private prompts. Further, we identify a structural duality between contextual representation refinement in FedAttn and parameter optimization in FL across private data, local computation, and global aggregation. This key insight provides a principled foundation for systematically porting federated optimization techniques to collaborative LLM inference. Building on this framework, we theoretically analyze how local self-attention computation within participants and heterogeneous token relevance among participants shape error propagation dynamics across Transformer blocks. Moreover, we characterize the fundamental trade-off between response quality and communication/computation efficiency, which is governed by the synchronization interval and the number of participants. Experimental results validate our theoretical analysis, and reveal significant optimization opportunities through sparse attention and adaptive KV aggregation, highlighting FedAttn's potential to deliver scalability and efficiency in real-world edge deployments.",
    "authors": [
      "Xiumei Deng",
      "Zehui Xiong",
      "Binbin Chen",
      "Dong In Kim",
      "Merouane Debbah",
      "H. Vincent Poor"
    ],
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02647v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02647v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.02580v1",
    "title": "TAUE: Training-free Noise Transplant and Cultivation Diffusion Model",
    "summary": "Despite the remarkable success of text-to-image diffusion models, their output of a single, flattened image remains a critical bottleneck for professional applications requiring layer-wise control. Existing solutions either rely on fine-tuning with large, inaccessible datasets or are training-free yet limited to generating isolated foreground elements, failing to produce a complete and coherent scene. To address this, we introduce the Training-free Noise Transplantation and Cultivation Diffusion Model (TAUE), a novel framework for zero-shot, layer-wise image generation. Our core technique, Noise Transplantation and Cultivation (NTC), extracts intermediate latent representations from both foreground and composite generation processes, transplanting them into the initial noise for subsequent layers. This ensures semantic and structural coherence across foreground, background, and composite layers, enabling consistent, multi-layered outputs without requiring fine-tuning or auxiliary datasets. Extensive experiments show that our training-free method achieves performance comparable to fine-tuned methods, enhancing layer-wise consistency while maintaining high image quality and fidelity. TAUE not only eliminates costly training and dataset requirements but also unlocks novel downstream applications, such as complex compositional editing, paving the way for more accessible and controllable generative workflows.",
    "authors": [
      "Daichi Nagai",
      "Ryugo Morita",
      "Shunsuke Kitada",
      "Hitoshi Iyatomi"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02580v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02580v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.02532v1",
    "title": "Agentic AI for Mobile Network RAN Management and Optimization",
    "summary": "Agentic AI represents a new paradigm for automating complex systems by using Large AI Models (LAMs) to provide human-level cognitive abilities with multimodal perception, planning, memory, and reasoning capabilities. This will lead to a new generation of AI systems that autonomously decompose goals, retain context over time, learn continuously, operate across tools and environments, and adapt dynamically. The complexity of 5G and upcoming 6G networks renders manual optimization ineffective, pointing to Agentic AI as a method for automating decisions in dynamic RAN environments. However, despite its rapid advances, there is no established framework outlining the foundational components and operational principles of Agentic AI systems nor a universally accepted definition.   This paper contributes to ongoing research on Agentic AI in 5G and 6G networks by outlining its core concepts and then proposing a practical use case that applies Agentic principles to RAN optimization. We first introduce Agentic AI, tracing its evolution from classical agents and discussing the progress from workflows and simple AI agents to Agentic AI. Core design patterns-reflection, planning, tool use, and multi-agent collaboration-are then described to illustrate how intelligent behaviors are orchestrated. These theorical concepts are grounded in the context of mobile networks, with a focus on RAN management and optimization. A practical 5G RAN case study shows how time-series analytics and LAM-driven agents collaborate for KPI-based autonomous decision-making.",
    "authors": [
      "Jorge Pellejero",
      "Luis A. Hernández Gómez",
      "Luis Mendo Tomás",
      "Zoraida Frias Barroso"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02532v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02532v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.02831v1",
    "title": "GeoCrossBench: Cross-Band Generalization for Remote Sensing",
    "summary": "The number and diversity of remote sensing satellites grows over time, while the vast majority of labeled data comes from older satellites. As the foundation models for Earth observation scale up, the cost of (re-)training to support new satellites grows too, so the generalization capabilities of the models towards new satellites become increasingly important. In this work we introduce GeoCrossBench, an extension of the popular GeoBench benchmark with a new evaluation protocol: it tests the in-distribution performance; generalization to satellites with no band overlap; and generalization to satellites with additional bands with respect to the training set. We also develop a self-supervised extension of ChannelViT, ChiViT, to improve its cross-satellite performance. First, we show that even the best foundation models for remote sensing (DOFA, TerraFM) do not outperform general purpose models like DINOv3 in the in-distribution setting. Second, when generalizing to new satellites with no band overlap, all models suffer 2-4x drop in performance, and ChiViT significantly outperforms the runner-up DINOv3. Third, the performance of all tested models drops on average by 5-25\\% when given additional bands during test time. Finally, we show that fine-tuning just the last linear layer of these models using oracle labels from all bands can get relatively consistent performance across all satellites, highlighting that the benchmark is far from being saturated. We publicly release the code and the datasets to encourage the development of more future-proof remote sensing models with stronger cross-satellite generalization.",
    "authors": [
      "Hakob Tamazyan",
      "Ani Vanyan",
      "Alvard Barseghyan",
      "Anna Khosrovyan",
      "Evan Shelhamer",
      "Hrant Khachatrian"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02831v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02831v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.02826v1",
    "title": "PLUTO-4: Frontier Pathology Foundation Models",
    "summary": "Foundation models trained on large-scale pathology image corpora have demonstrated strong transfer capabilities across diverse histopathology tasks. Building on this progress, we introduce PLUTO-4, our next generation of pathology foundation models that extend the Pathology-Universal Transformer (PLUTO) to frontier scale. We share two complementary Vision Transformer architectures in the PLUTO-4 family: a compact and efficient PLUTO-4S model optimized for multi-scale deployment using a FlexiViT setup with 2D-RoPE embeddings, and a frontier-scale PLUTO-4G model trained with a single patch size to maximize representation capacity and stability. Both models are pretrained using a self-supervised objective derived from DINOv2 on a large multi-institutional corpus containing 551,164 WSIs from 137,144 patients across over 50 institutions, spanning over 60 disease types and over 100 stains. Comprehensive evaluation across public and internal benchmarks demonstrates that PLUTO-4 achieves state-of-the-art performance on tasks requiring varying spatial and biological context, including patch-level classification, segmentation, and slide-level diagnosis. The compact PLUTO-4S provides high-throughput and robust performance for practical deployment, while PLUTO-4G establishes new performance frontiers across multiple pathology benchmarks, including an 11% improvement in dermatopathology diagnosis. These diverse improvements underscore PLUTO-4's potential to transform real-world applications as a backbone for translational research and diagnostic use cases.",
    "authors": [
      "Harshith Padigela",
      "Shima Nofallah",
      "Atchuth Naveen Chilaparasetti",
      "Ryun Han",
      "Andrew Walker",
      "Judy Shen",
      "Chintan Shah",
      "Blake Martin",
      "Aashish Sood",
      "Elliot Miller",
      "Ben Glass",
      "Andy Beck",
      "Harsha Pokkalla",
      "Syed Ashar Javed"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02826v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02826v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.02748v1",
    "title": "Agentic World Modeling for 6G: Near-Real-Time Generative State-Space   Reasoning",
    "summary": "We argue that sixth-generation (6G) intelligence is not fluent token prediction but the capacity to imagine and choose -- to simulate future scenarios, weigh trade-offs, and act with calibrated uncertainty. We reframe open radio access network (O-RAN) near-real-time (Near-RT) control via counterfactual dynamics and a world modeling (WM) paradigm that learns an action-conditioned generative state space. This enables quantitative \"what-if\" forecasting beyond large language models (LLMs) as the primary modeling primitive. Actions such as physical resource blocks (PRBs) are treated as first-class control inputs in a causal world model, and both aleatoric and epistemic uncertainty are modeled for prediction and what-if analysis. An agentic, model predictive control (MPC)-based cross-entropy method (CEM) planner operates over short horizons, using prior-mean rollouts within data-driven PRB bounds to maximize a deterministic reward. The model couples multi-scale structured state-space mixtures (MS3M) with a compact stochastic latent to form WM-MS3M, summarizing key performance indicators (KPIs) histories and predicting next-step KPIs under hypothetical PRB sequences. On realistic O-RAN traces, WM-MS3M cuts mean absolute error (MAE) by 1.69% versus MS3M with 32% fewer parameters and similar latency, and achieves 35-80% lower root mean squared error (RMSE) than attention/hybrid baselines with 2.3-4.1x faster inference, enabling rare-event simulation and offline policy screening.",
    "authors": [
      "Farhad Rezazadeh",
      "Hatim Chergui",
      "Merouane Debbah",
      "Houbing Song",
      "Dusit Niyato",
      "Lingjia Liu"
    ],
    "categories": [
      "cs.NI",
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02748v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02748v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.02672v1",
    "title": "RL-Aided Cognitive ISAC: Robust Detection and Sensing-Communication   Trade-offs",
    "summary": "This paper proposes a reinforcement learning (RL)-aided cognitive framework for massive MIMO-based integrated sensing and communication (ISAC) systems employing a uniform planar array (UPA). The focus is on enhancing radar sensing performance in environments with unknown and dynamic disturbance characteristics. A Wald-type detector is employed for robust target detection under non-Gaussian clutter, while a SARSA-based RL algorithm enables adaptive estimation of target positions without prior environmental knowledge. Based on the RL-derived sensing information, a joint waveform optimization strategy is formulated to balance radar sensing accuracy and downlink communication throughput. The resulting design provides an adaptive trade-off between detection performance and achievable sum rate through an analytically derived closed-form solution. Monte Carlo simulations demonstrate that the proposed cognitive ISAC framework achieves significantly improved detection probability compared to orthogonal and non-learning adaptive baselines, while maintaining competitive communication performance. These results underline the potential of RL-assisted sensing for robust and spectrum-efficient ISAC in next-generation wireless networks.",
    "authors": [
      "Adam Umra",
      "Aya M. Ahmed",
      "Aydin Sezgin"
    ],
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02672v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02672v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.02576v1",
    "title": "Resource-efficient Automatic Refinement of Segmentations via Weak   Supervision from Light Feedback",
    "summary": "Delineating anatomical regions is a key task in medical image analysis. Manual segmentation achieves high accuracy but is labor-intensive and prone to variability, thus prompting the development of automated approaches. Recently, a breadth of foundation models has enabled automated segmentations across diverse anatomies and imaging modalities, but these may not always meet the clinical accuracy standards. While segmentation refinement strategies can improve performance, current methods depend on heavy user interactions or require fully supervised segmentations for training. Here, we present SCORE (Segmentation COrrection from Regional Evaluations), a weakly supervised framework that learns to refine mask predictions only using light feedback during training. Specifically, instead of relying on dense training image annotations, SCORE introduces a novel loss that leverages region-wise quality scores and over/under-segmentation error labels. We demonstrate SCORE on humerus CT scans, where it considerably improves initial predictions from TotalSegmentator, and achieves performance on par with existing refinement methods, while greatly reducing their supervision requirements and annotation time. Our code is available at: https://gitlab.inria.fr/adelangl/SCORE.",
    "authors": [
      "Alix de Langlais",
      "Benjamin Billot",
      "Théo Aguilar Vidal",
      "Marc-Olivier Gauci",
      "Hervé Delingette"
    ],
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02576v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02576v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.02565v1",
    "title": "A Cognitive Process-Inspired Architecture for Subject-Agnostic Brain   Visual Decoding",
    "summary": "Subject-agnostic brain decoding, which aims to reconstruct continuous visual experiences from fMRI without subject-specific training, holds great potential for clinical applications. However, this direction remains underexplored due to challenges in cross-subject generalization and the complex nature of brain signals. In this work, we propose Visual Cortex Flow Architecture (VCFlow), a novel hierarchical decoding framework that explicitly models the ventral-dorsal architecture of the human visual system to learn multi-dimensional representations. By disentangling and leveraging features from early visual cortex, ventral, and dorsal streams, VCFlow captures diverse and complementary cognitive information essential for visual reconstruction. Furthermore, we introduce a feature-level contrastive learning strategy to enhance the extraction of subject-invariant semantic representations, thereby enhancing subject-agnostic applicability to previously unseen subjects. Unlike conventional pipelines that need more than 12 hours of per-subject data and heavy computation, VCFlow sacrifices only 7\\% accuracy on average yet generates each reconstructed video in 10 seconds without any retraining, offering a fast and clinically scalable solution. The source code will be released upon acceptance of the paper.",
    "authors": [
      "Jingyu Lu",
      "Haonan Wang",
      "Qixiang Zhang",
      "Xiaomeng Li"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02565v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02565v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.02832v1",
    "title": "TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System",
    "summary": "Large-scale data has driven breakthroughs in robotics, from language models to vision-language-action models in bimanual manipulation. However, humanoid robotics lacks equally effective data collection frameworks. Existing humanoid teleoperation systems either use decoupled control or depend on expensive motion capture setups. We introduce TWIST2, a portable, mocap-free humanoid teleoperation and data collection system that preserves full whole-body control while advancing scalability. Our system leverages PICO4U VR for obtaining real-time whole-body human motions, with a custom 2-DoF robot neck (cost around $250) for egocentric vision, enabling holistic human-to-humanoid control. We demonstrate long-horizon dexterous and mobile humanoid skills and we can collect 100 demonstrations in 15 minutes with an almost 100% success rate. Building on this pipeline, we propose a hierarchical visuomotor policy framework that autonomously controls the full humanoid body based on egocentric vision. Our visuomotor policy successfully demonstrates whole-body dexterous manipulation and dynamic kicking tasks. The entire system is fully reproducible and open-sourced at https://yanjieze.com/TWIST2 . Our collected dataset is also open-sourced at https://twist-data.github.io .",
    "authors": [
      "Yanjie Ze",
      "Siheng Zhao",
      "Weizhuo Wang",
      "Angjoo Kanazawa",
      "Rocky Duan",
      "Pieter Abbeel",
      "Guanya Shi",
      "Jiajun Wu",
      "C. Karen Liu"
    ],
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02832v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02832v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.02797v1",
    "title": "Fast, Private, and Protected: Safeguarding Data Privacy and Defending   Against Model Poisoning Attacks in Federated Learning",
    "summary": "Federated Learning (FL) is a distributed training paradigm wherein participants collaborate to build a global model while ensuring the privacy of the involved data, which remains stored on participant devices. However, proposals aiming to ensure such privacy also make it challenging to protect against potential attackers seeking to compromise the training outcome. In this context, we present Fast, Private, and Protected (FPP), a novel approach that aims to safeguard federated training while enabling secure aggregation to preserve data privacy. This is accomplished by evaluating rounds using participants' assessments and enabling training recovery after an attack. FPP also employs a reputation-based mechanism to mitigate the participation of attackers. We created a dockerized environment to validate the performance of FPP compared to other approaches in the literature (FedAvg, Power-of-Choice, and aggregation via Trimmed Mean and Median). Our experiments demonstrate that FPP achieves a rapid convergence rate and can converge even in the presence of malicious participants performing model poisoning attacks.",
    "authors": [
      "Nicolas Riccieri Gardin Assumpcao",
      "Leandro Villas"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02797v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02797v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.02770v1",
    "title": "Beyond Single Embeddings: Capturing Diverse Targets with Multi-Query   Retrieval",
    "summary": "Most text retrievers generate \\emph{one} query vector to retrieve relevant documents. Yet, the conditional distribution of relevant documents for the query may be multimodal, e.g., representing different interpretations of the query. We first quantify the limitations of existing retrievers. All retrievers we evaluate struggle more as the distance between target document embeddings grows. To address this limitation, we develop a new retriever architecture, \\emph{A}utoregressive \\emph{M}ulti-\\emph{E}mbedding \\emph{R}etriever (AMER). Our model autoregressively generates multiple query vectors, and all the predicted query vectors are used to retrieve documents from the corpus. We show that on the synthetic vectorized data, the proposed method could capture multiple target distributions perfectly, showing 4x better performance than single embedding model. We also fine-tune our model on real-world multi-answer retrieval datasets and evaluate in-domain. AMER presents 4 and 21\\% relative gains over single-embedding baselines on two datasets we evaluate on. Furthermore, we consistently observe larger gains on the subset of dataset where the embeddings of the target documents are less similar to each other. We demonstrate the potential of using a multi-query vector retriever and open up a new direction for future work.",
    "authors": [
      "Hung-Ting Chen",
      "Xiang Liu",
      "Shauli Ravfogel",
      "Eunsol Choi"
    ],
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02770v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02770v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.02757v1",
    "title": "ConMeZO: Adaptive Descent-Direction Sampling for Gradient-Free   Finetuning of Large Language Models",
    "summary": "Zeroth-order or derivative-free optimization (MeZO) is an attractive strategy for finetuning large language models (LLMs) because it eliminates the memory overhead of backpropagation. However, it converges slowly due to the inherent curse of dimensionality when searching for descent directions in the high-dimensional parameter space of billion-scale LLMs. We propose ConMeZO, a novel zeroth-order optimizer that accelerates convergence by adaptive directional sampling. Instead of drawing the direction uniformly at random, ConMeZO restricts the sampling to a cone centered around a momentum estimate. This concentrates the search in directions where the true gradient is more likely to lie and thus reduces the effect of high dimensions. We prove that ConMeZO achieves the same worst-case convergence rate as MeZO. Empirically, when finetuning LLMs on natural language tasks, ConMeZO is up to 2X faster than MeZO while retaining the low-memory footprint of zeroth-order methods.",
    "authors": [
      "Lejs Deen Behric",
      "Liang Zhang",
      "Bingcong Li",
      "Kiran Koshy Thekumparampil"
    ],
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02757v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02757v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.02755v1",
    "title": "Controlling Performance and Budget of a Centralized Multi-agent LLM   System with Reinforcement Learning",
    "summary": "Large language models (LLMs) exhibit complementary strengths across domains and come with varying inference costs, motivating the design of multi-agent LLM systems where specialized models collaborate efficiently. Existing approaches predominantly rely on decentralized frameworks, which invoke multiple LLMs for every input and thus lead to substantial and uncontrolled inference costs. In this work, we introduce a centralized multi-LLM framework, where a controller LLM selectively coordinates a pool of expert models in a cost-efficient and cost-controllable manner. We formulate this coordination problem as reinforcement learning with dual objectives: maximizing task performance while minimizing the overall inference cost. In addition, we expect the multi-agent system to have adapted behavior with different budget conditions during inference. To this end, we propose CoRL, a reinforcement learning framework that optimizes the performance cost trade-off in a controllable multi-budget setting. Experiments on four diverse benchmarks demonstrate that CoRL enables a single system to surpass the best expert LLM under high-budget settings, while maintaining strong performance in more economical low-budget modes, highlighting the effectiveness of centralized coordination for scalable and cost-efficient multi-agent LLM systems.",
    "authors": [
      "Bowen Jin",
      "TJ Collins",
      "Donghan Yu",
      "Mert Cemri",
      "Shenao Zhang",
      "Mengyu Li",
      "Jay Tang",
      "Tian Qin",
      "Zhiyang Xu",
      "Jiarui Lu",
      "Guoli Yin",
      "Jiawei Han",
      "Zirui Wang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02755v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02755v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.02687v1",
    "title": "The Collaboration Gap",
    "summary": "The trajectory of AI development suggests that we will increasingly rely on agent-based systems composed of independently developed agents with different information, privileges, and tools. The success of these systems will critically depend on effective collaboration among these heterogeneous agents, even under partial observability. Despite intense interest, few empirical studies have evaluated such agent-agent collaboration at scale. We propose a collaborative maze-solving benchmark that (i) isolates collaborative capabilities, (ii) modulates problem complexity, (iii) enables scalable automated grading, and (iv) imposes no output-format constraints, preserving ecological plausibility. Using this framework, we evaluate 32 leading open- and closed-source models in solo, homogeneous, and heterogeneous pairings. Our results reveal a \"collaboration gap\": models that perform well solo often degrade substantially when required to collaborate. Collaboration can break down dramatically; for instance, small distilled models that solve mazes well alone may fail almost completely in certain pairings. We find that starting with the stronger agent often improves outcomes, motivating a \"relay inference\" approach where the stronger agent leads before handing off to the weaker one, closing much of the gap. Our findings argue for (1) collaboration-aware evaluation, (2) training strategies developed to enhance collaborative capabilities, and (3) interaction design that reliably elicits agents' latent skills, guidance that applies to AI-AI and human-AI collaboration.",
    "authors": [
      "Tim R. Davidson",
      "Adam Fourney",
      "Saleema Amershi",
      "Robert West",
      "Eric Horvitz",
      "Ece Kamar"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02687v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02687v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.02685v1",
    "title": "Modality-Transition Representation Learning for Visible-Infrared Person   Re-Identification",
    "summary": "Visible-infrared person re-identification (VI-ReID) technique could associate the pedestrian images across visible and infrared modalities in the practical scenarios of background illumination changes. However, a substantial gap inherently exists between these two modalities. Besides, existing methods primarily rely on intermediate representations to align cross-modal features of the same person. The intermediate feature representations are usually create by generating intermediate images (kind of data enhancement), or fusing intermediate features (more parameters, lack of interpretability), and they do not make good use of the intermediate features. Thus, we propose a novel VI-ReID framework via Modality-Transition Representation Learning (MTRL) with a middle generated image as a transmitter from visible to infrared modals, which are fully aligned with the original visible images and similar to the infrared modality. After that, using a modality-transition contrastive loss and a modality-query regularization loss for training, which could align the cross-modal features more effectively. Notably, our proposed framework does not need any additional parameters, which achieves the same inference speed to the backbone while improving its performance on VI-ReID task. Extensive experimental results illustrate that our model significantly and consistently outperforms existing SOTAs on three typical VI-ReID datasets.",
    "authors": [
      "Chao Yuan",
      "Zanwu Liu",
      "Guiwei Zhang",
      "Haoxuan Xu",
      "Yujian Zhao",
      "Guanglin Niu",
      "Bo Li"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02685v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02685v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.02537v1",
    "title": "Smart-Hiring: An Explainable end-to-end Pipeline for CV Information   Extraction and Job Matching",
    "summary": "Hiring processes often involve the manual screening of hundreds of resumes for each job, a task that is time and effort consuming, error-prone, and subject to human bias. This paper presents Smart-Hiring, an end-to-end Natural Language Processing (NLP) pipeline de- signed to automatically extract structured information from unstructured resumes and to semantically match candidates with job descriptions. The proposed system combines document parsing, named-entity recognition, and contextual text embedding techniques to capture skills, experience, and qualifications. Using advanced NLP technics, Smart-Hiring encodes both resumes and job descriptions in a shared vector space to compute similarity scores between candidates and job postings. The pipeline is modular and explainable, allowing users to inspect extracted entities and matching rationales. Experiments were conducted on a real-world dataset of resumes and job descriptions spanning multiple professional domains, demonstrating the robustness and feasibility of the proposed approach. The system achieves competitive matching accuracy while preserving a high degree of interpretability and transparency in its decision process. This work introduces a scalable and practical NLP frame- work for recruitment analytics and outlines promising directions for bias mitigation, fairness-aware modeling, and large-scale deployment of data-driven hiring solutions.",
    "authors": [
      "Kenza Khelkhal",
      "Dihia Lanasri"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02537v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02537v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.02805v1",
    "title": "MemSearcher: Training LLMs to Reason, Search and Manage Memory via   End-to-End Reinforcement Learning",
    "summary": "Typical search agents concatenate the entire interaction history into the LLM context, preserving information integrity but producing long, noisy contexts, resulting in high computation and memory costs. In contrast, using only the current turn avoids this overhead but discards essential information. This trade-off limits the scalability of search agents. To address this challenge, we propose MemSearcher, an agent workflow that iteratively maintains a compact memory and combines the current turn with it. At each turn, MemSearcher fuses the user's question with the memory to generate reasoning traces, perform search actions, and update memory to retain only information essential for solving the task. This design stabilizes context length across multi-turn interactions, improving efficiency without sacrificing accuracy. To optimize this workflow, we introduce multi-context GRPO, an end-to-end RL framework that jointly optimize reasoning, search strategies, and memory management of MemSearcher Agents. Specifically, multi-context GRPO samples groups of trajectories under different contexts and propagates trajectory-level advantages across all conversations within them. Trained on the same dataset as Search-R1, MemSearcher achieves significant improvements over strong baselines on seven public benchmarks: +11% on Qwen2.5-3B-Instruct and +12% on Qwen2.5-7B-Instruct relative average gains. Notably, the 3B-based MemSearcher even outperforms 7B-based baselines, demonstrating that striking a balance between information integrity and efficiency yields both higher accuracy and lower computational overhead. The code and models will be publicly available at https://github.com/icip-cas/MemSearcher",
    "authors": [
      "Qianhao Yuan",
      "Jie Lou",
      "Zichao Li",
      "Jiawei Chen",
      "Yaojie Lu",
      "Hongyu Lin",
      "Le Sun",
      "Debing Zhang",
      "Xianpei Han"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02805v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02805v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.02778v1",
    "title": "VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual   Representation",
    "summary": "Code has emerged as a precise and executable medium for reasoning and action in the agent era. Yet, progress has largely focused on language-centric tasks such as program synthesis and debugging, leaving visual-centric coding underexplored. Inspired by how humans reason over sketches, we advocate SVG code as a compact, interpretable, and executable visual representation. We introduce VCode, a benchmark that reframes multimodal understanding as code generation: given an image, a model must produce SVG that preserves symbolic meaning for downstream reasoning. VCode covers three domains - general commonsense (MM-Vet), professional disciplines (MMMU), and visual-centric perception (CV-Bench). To assess symbolic fidelity, we propose CodeVQA, a novel evaluation protocol in which a policy model answers questions over rendered SVGs; correct answers indicate faithful symbolic preservation. Empirically, frontier VLMs struggle to generate faithful SVGs, revealing a persistent gap between language-centric and visual-centric coding. To close this gap, we introduce VCoder, an agentic framework that augments VLMs along two axes: (i) Thinking with Revision, which iteratively analyzes discrepancies and refines SVG code; and (ii) Acting with Visual Tools, where detectors and parsers supply structured cues such as objects, shapes, and text beyond the model's intrinsic capacity. Across benchmarks, frontier VLMs with strong reasoning capabilities score well overall yet remain limited in professional knowledge and 3D reasoning. VCoder delivers a 12.3-point overall gain over the top-performing Claude-4-Opus. Human studies show that both humans and VLMs perform worse on rendered SVGs, their consistency reveals the promise of symbolic visual representation. The benchmark and code are available at https://github.com/CSU-JPG/VCode.",
    "authors": [
      "Kevin Qinghong Lin",
      "Yuhao Zheng",
      "Hangyu Ran",
      "Dantong Zhu",
      "Dongxing Mao",
      "Linjie Li",
      "Philip Torr",
      "Alex Jinpeng Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02778v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02778v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.02681v1",
    "title": "Optimal Singular Damage: Efficient LLM Inference in Low Storage Regimes",
    "summary": "Large language models (LLMs) are increasingly prevalent across diverse applications. However, their enormous size limits storage and processing capabilities to a few well-resourced stakeholders. As a result, most applications rely on pre-trained LLMs, fine-tuned for specific tasks. However, even storing the fine-tuned versions of these models remains a significant challenge due to the wide range of tasks they address. Recently, studies show that fine-tuning these models primarily affects a small fraction of parameters, highlighting the need for more efficient storage of fine-tuned models. This paper focuses on efficient storage of parameter updates in pre-trained models after fine-tuning. To address this challenge, we leverage the observation that fine-tuning updates are both low-rank and sparse, which can be utilized for storage efficiency. However, using only low-rank approximation or sparsification may discard critical singular components that enhance model expressivity. We first observe that given the same memory budget, sparsified low-rank approximations with larger ranks outperform standard low-rank approximations with smaller ranks. Building on this, we propose our method, optimal singular damage, that selectively sparsifies low-rank approximated updates by leveraging the interleaved importance of singular vectors, ensuring that the most impactful components are retained. We demonstrate through extensive experiments that our proposed methods lead to significant storage efficiency and superior accuracy within the same memory budget compared to employing the low-rank approximation or sparsification individually.",
    "authors": [
      "Mohammadsajad Alipour",
      "Mohammad Mohammadi Amiri"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02681v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02681v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.02626v1",
    "title": "Understanding New-Knowledge-Induced Factual Hallucinations in LLMs:   Analysis, Solution, and Interpretation",
    "summary": "Previous studies show that introducing new knowledge during large language models (LLMs) fine-tuning can lead to the generation of erroneous output when tested on known information, thereby triggering factual hallucinations. However, existing studies have not deeply investigated the specific manifestations and underlying mechanisms of these hallucinations. Our work addresses this gap by designing a controlled dataset Biography-Reasoning, and conducting a fine-grained analysis across multiple knowledge types and two task types, including knowledge question answering (QA) and knowledge reasoning tasks. We find that when fine-tuned on a dataset in which a specific knowledge type consists entirely of new knowledge, LLMs exhibit significantly increased hallucination tendencies. This suggests that the high unfamiliarity of a particular knowledge type, rather than the overall proportion of new knowledge, is a stronger driver of hallucinations, and these tendencies can even affect other knowledge types in QA tasks. To mitigate such factual hallucinations, we propose KnownPatch, which patches a small number of known knowledge samples in the later stages of training, effectively alleviating new-knowledge-induced hallucinations. Through attention analysis, we find that learning new knowledge reduces the model's attention to key entities in the question, thus causing excessive focus on the surrounding context, which may increase the risk of hallucination. Moreover, the attention pattern can propagate to similar contexts, facilitating the spread of hallucinations to textually similar questions. Our method effectively mitigates the disruption of new knowledge learning to the model's attention on key entities, accompanied by improved performance.",
    "authors": [
      "Renfei Dang",
      "Peng Hu",
      "Changjiang Gao",
      "Shujian Huang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02626v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02626v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.02534v1",
    "title": "Knowledge Graph-enhanced Large Language Model for Incremental Game   PlayTesting",
    "summary": "The rapid iteration and frequent updates of modern video games pose significant challenges to the efficiency and specificity of testing. Although automated playtesting methods based on Large Language Models (LLMs) have shown promise, they often lack structured knowledge accumulation mechanisms, making it difficult to conduct precise and efficient testing tailored for incremental game updates. To address this challenge, this paper proposes a KLPEG framework. The framework constructs and maintains a Knowledge Graph (KG) to systematically model game elements, task dependencies, and causal relationships, enabling knowledge accumulation and reuse across versions. Building on this foundation, the framework utilizes LLMs to parse natural language update logs, identify the scope of impact through multi-hop reasoning on the KG, enabling the generation of update-tailored test cases. Experiments in two representative game environments, Overcooked and Minecraft, demonstrate that KLPEG can more accurately locate functionalities affected by updates and complete tests in fewer steps, significantly improving both playtesting effectiveness and efficiency.",
    "authors": [
      "Enhong Mu",
      "Jinyu Cai",
      "Yijun Lu",
      "Mingyue Zhang",
      "Kenji Tei",
      "Jialong Li"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02534v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02534v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.02821v1",
    "title": "Accelerated Frank-Wolfe Algorithms: Complementarity Conditions and   Sparsity",
    "summary": "We develop new accelerated first-order algorithms in the Frank-Wolfe (FW) family for minimizing smooth convex functions over compact convex sets, with a focus on two prominent constraint classes: (1) polytopes and (2) matrix domains given by the spectrahedron and the unit nuclear-norm ball. A key technical ingredient is a complementarity condition that captures solution sparsity -- face dimension for polytopes and rank for matrices. We present two algorithms: (1) a purely linear optimization oracle (LOO) method for polytopes that has optimal worst-case first-order (FO) oracle complexity and, aside of a finite \\emph{burn-in} phase and up to a logarithmic factor, has LOO complexity that scales with $r/\\sqrt{\\epsilon}$, where $\\epsilon$ is the target accuracy and $r$ is the solution sparsity $r$ (independently of the ambient dimension), and (2) a hybrid scheme that combines FW with a sparse projection oracle (e.g., low-rank SVDs for matrix domains with low-rank solutions), which also has optimal FO oracle complexity, and after a finite burn-in phase, only requires $O(1/\\sqrt{\\epsilon})$ sparse projections and LOO calls (independently of both the ambient dimension and the rank of optimal solutions). Our results close a gap on how to accelerate recent advancements in linearly-converging FW algorithms for strongly convex optimization, without paying the price of the dimension.",
    "authors": [
      "Dan Garber"
    ],
    "categories": [
      "math.OC",
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02821v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02821v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.02785v1",
    "title": "Enhancing Federated Learning Privacy with QUBO",
    "summary": "Federated learning (FL) is a widely used method for training machine learning (ML) models in a scalable way while preserving privacy (i.e., without centralizing raw data). Prior research shows that the risk of exposing sensitive data increases cumulatively as the number of iterations where a client's updates are included in the aggregated model increase. Attackers can launch membership inference attacks (MIA; deciding whether a sample or client participated), property inference attacks (PIA; inferring attributes of a client's data), and model inversion attacks (MI; reconstructing inputs), thereby inferring client-specific attributes and, in some cases, reconstructing inputs. In this paper, we mitigate risk by substantially reducing per client exposure using a quantum computing-inspired quadratic unconstrained binary optimization (QUBO) formulation that selects a small subset of client updates most relevant for each training round. In this work, we focus on two threat vectors: (i) information leakage by clients during training and (ii) adversaries who can query or obtain the global model. We assume a trusted central server and do not model server compromise. This method also assumes that the server has access to a validation/test set with global data distribution. Experiments on the MNIST dataset with 300 clients in 20 rounds showed a 95.2% per-round and 49% cumulative privacy exposure reduction, with 147 clients' updates never being used during training while maintaining in general the full-aggregation accuracy or even better. The method proved to be efficient at lower scale and more complex model as well. A CINIC-10 dataset-based experiment with 30 clients resulted in 82% per-round privacy improvement and 33% cumulative privacy.",
    "authors": [
      "Andras Ferenczi",
      "Sutapa Samanta",
      "Dagen Wang",
      "Todd Hodges"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02785v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02785v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.02706v1",
    "title": "Optimizing Kernel Discrepancies via Subset Selection",
    "summary": "Kernel discrepancies are a powerful tool for analyzing worst-case errors in quasi-Monte Carlo (QMC) methods. Building on recent advances in optimizing such discrepancy measures, we extend the subset selection problem to the setting of kernel discrepancies, selecting an m-element subset from a large population of size $n \\gg m$. We introduce a novel subset selection algorithm applicable to general kernel discrepancies to efficiently generate low-discrepancy samples from both the uniform distribution on the unit hypercube, the traditional setting of classical QMC, and from more general distributions $F$ with known density functions by employing the kernel Stein discrepancy. We also explore the relationship between the classical $L_2$ star discrepancy and its $L_\\infty$ counterpart.",
    "authors": [
      "Deyao Chen",
      "François Clément",
      "Carola Doerr",
      "Nathan Kirk"
    ],
    "categories": [
      "stat.ML",
      "cs.CG",
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02706v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02706v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.02614v1",
    "title": "A Non-Adversarial Approach to Idempotent Generative Modelling",
    "summary": "Idempotent Generative Networks (IGNs) are deep generative models that also function as local data manifold projectors, mapping arbitrary inputs back onto the manifold. They are trained to act as identity operators on the data and as idempotent operators off the data manifold. However, IGNs suffer from mode collapse, mode dropping, and training instability due to their objectives, which contain adversarial components and can cause the model to cover the data manifold only partially -- an issue shared with generative adversarial networks. We introduce Non-Adversarial Idempotent Generative Networks (NAIGNs) to address these issues. Our loss function combines reconstruction with the non-adversarial generative objective of Implicit Maximum Likelihood Estimation (IMLE). This improves on IGN's ability to restore corrupted data and generate new samples that closely match the data distribution. We moreover demonstrate that NAIGNs implicitly learn the distance field to the data manifold, as well as an energy-based model.",
    "authors": [
      "Mohammed Al-Jaff",
      "Giovanni Luca Marchetti",
      "Michael C Welle",
      "Jens Lundell",
      "Mats G. Gustafsson",
      "Gustav Eje Henter",
      "Hossein Azizpour",
      "Danica Kragic"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02614v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02614v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.02589v1",
    "title": "The ORCA Benchmark: Evaluating Real-World Calculation Accuracy in Large   Language Models",
    "summary": "We present ORCA (Omni Research on Calculation in AI) Benchmark -- a novel benchmark that evaluates large language models (LLMs) on multi-domain, real-life quantitative reasoning using verified outputs from Omni's calculator engine. In 500 natural-language tasks across domains such as finance, physics, health, and statistics, the five state-of-the-art systems (ChatGPT-5, Gemini~2.5~Flash, Claude~Sonnet~4.5, Grok~4, and DeepSeek~V3.2) achieved only $45\\text{--}63\\,\\%$ accuracy, with errors mainly related to rounding ($35\\,\\%$) and calculation mistakes ($33\\,\\%$). Results in specific domains indicate strengths in mathematics and engineering, but weaknesses in physics and natural sciences. Correlation analysis ($r \\approx 0.40\\text{--}0.65$) shows that the models often fail together but differ in the types of errors they make, highlighting their partial complementarity rather than redundancy. Unlike standard math datasets, ORCA evaluates step-by-step reasoning, numerical precision, and domain generalization across real problems from finance, physics, health, and statistics.",
    "authors": [
      "Claudia Herambourg",
      "Dawid Siuda",
      "Anna Szczepanek",
      "Julia Kopczyńska",
      "Joao R. L. Santos",
      "Wojciech Sas",
      "Joanna Śmietańska-Nowak"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02589v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02589v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.02584v1",
    "title": "Redundancy Maximization as a Principle of Associative Memory Learning",
    "summary": "Associative memory, traditionally modeled by Hopfield networks, enables the retrieval of previously stored patterns from partial or noisy cues. Yet, the local computational principles which are required to enable this function remain incompletely understood. To formally characterize the local information processing in such systems, we employ a recent extension of information theory - Partial Information Decomposition (PID). PID decomposes the contribution of different inputs to an output into unique information from each input, redundant information across inputs, and synergistic information that emerges from combining different inputs. Applying this framework to individual neurons in classical Hopfield networks we find that below the memory capacity, the information in a neuron's activity is characterized by high redundancy between the external pattern input and the internal recurrent input, while synergy and unique information are close to zero until the memory capacity is surpassed and performance drops steeply. Inspired by this observation, we use redundancy as an information-theoretic learning goal, which is directly optimized for each neuron, dramatically increasing the network's memory capacity to 1.59, a more than tenfold improvement over the 0.14 capacity of classical Hopfield networks and even outperforming recent state-of-the-art implementations of Hopfield networks. Ultimately, this work establishes redundancy maximization as a new design principle for associative memories and opens pathways for new associative memory models based on information-theoretic goals.",
    "authors": [
      "Mark Blümel",
      "Andreas C. Schneider",
      "Valentin Neuhaus",
      "David A. Ehrlich",
      "Marcel Graetz",
      "Michael Wibral",
      "Abdullah Makkeh",
      "Viola Priesemann"
    ],
    "categories": [
      "cs.IT",
      "cs.LG",
      "cs.NE",
      "math.IT",
      "physics.comp-ph"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02584v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02584v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.02531v1",
    "title": "Causal Graph Neural Networks for Healthcare",
    "summary": "Healthcare artificial intelligence systems routinely fail when deployed across institutions, with documented performance drops and perpetuation of discriminatory patterns embedded in historical data. This brittleness stems, in part, from learning statistical associations rather than causal mechanisms. Causal graph neural networks address this triple crisis of distribution shift, discrimination, and inscrutability by combining graph-based representations of biomedical data with causal inference principles to learn invariant mechanisms rather than spurious correlations. This Review examines methodological foundations spanning structural causal models, disentangled causal representation learning, and techniques for interventional prediction and counterfactual reasoning on graphs. We analyse applications demonstrating clinical value across psychiatric diagnosis through brain network analysis, cancer subtyping via multi-omics causal integration, continuous physiological monitoring with mechanistic interpretation, and drug recommendation correcting prescription bias. These advances establish foundations for patient-specific Causal Digital Twins, enabling in silico clinical experimentation, with integration of large language models for hypothesis generation and causal graph neural networks for mechanistic validation. Substantial barriers remain, including computational requirements precluding real-time deployment, validation challenges demanding multi-modal evidence triangulation beyond cross-validation, and risks of causal-washing where methods employ causal terminology without rigorous evidentiary support. We propose tiered frameworks distinguishing causally-inspired architectures from causally-validated discoveries and identify critical research priorities making causal rather than purely associational claims.",
    "authors": [
      "Munib Mesinovic",
      "Max Buhlan",
      "Tingting Zhu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02531v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02531v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.02825v1",
    "title": "Neurosymbolic Deep Learning Semantics",
    "summary": "Artificial Intelligence (AI) is a powerful new language of science as evidenced by recent Nobel Prizes in chemistry and physics that recognized contributions to AI applied to those areas. Yet, this new language lacks semantics, which makes AI's scientific discoveries unsatisfactory at best. With the purpose of uncovering new facts but also improving our understanding of the world, AI-based science requires formalization through a framework capable of translating insight into comprehensible scientific knowledge. In this paper, we argue that logic offers an adequate framework. In particular, we use logic in a neurosymbolic framework to offer a much needed semantics for deep learning, the neural network-based technology of current AI. Deep learning and neurosymbolic AI lack a general set of conditions to ensure that desirable properties are satisfied. Instead, there is a plethora of encoding and knowledge extraction approaches designed for particular cases. To rectify this, we introduced a framework for semantic encoding, making explicit the mapping between neural networks and logic, and characterizing the common ingredients of the various existing approaches. In this paper, we describe succinctly and exemplify how logical semantics and neural networks are linked through this framework, we review some of the most prominent approaches and techniques developed for neural encoding and knowledge extraction, provide a formal definition of our framework, and discuss some of the difficulties of identifying a semantic encoding in practice in light of analogous problems in the philosophy of mind.",
    "authors": [
      "Artur d'Avila Garcez",
      "Simon Odense"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02825v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02825v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.02777v1",
    "title": "PercHead: Perceptual Head Model for Single-Image 3D Head Reconstruction   & Editing",
    "summary": "We present PercHead, a method for single-image 3D head reconstruction and semantic 3D editing - two tasks that are inherently challenging due to severe view occlusions, weak perceptual supervision, and the ambiguity of editing in 3D space. We develop a unified base model for reconstructing view-consistent 3D heads from a single input image. The model employs a dual-branch encoder followed by a ViT-based decoder that lifts 2D features into 3D space through iterative cross-attention. Rendering is performed using Gaussian Splatting. At the heart of our approach is a novel perceptual supervision strategy based on DINOv2 and SAM2.1, which provides rich, generalized signals for both geometric and appearance fidelity. Our model achieves state-of-the-art performance in novel-view synthesis and, furthermore, exhibits exceptional robustness to extreme viewing angles compared to established baselines. Furthermore, this base model can be seamlessly extended for semantic 3D editing by swapping the encoder and finetuning the network. In this variant, we disentangle geometry and style through two distinct input modalities: a segmentation map to control geometry and either a text prompt or a reference image to specify appearance. We highlight the intuitive and powerful 3D editing capabilities of our model through a lightweight, interactive GUI, where users can effortlessly sculpt geometry by drawing segmentation maps and stylize appearance via natural language or image prompts.   Project Page: https://antoniooroz.github.io/PercHead Video: https://www.youtube.com/watch?v=4hFybgTk4kE",
    "authors": [
      "Antonio Oroz",
      "Matthias Nießner",
      "Tobias Kirschstein"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02777v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02777v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.02754v1",
    "title": "DANIEL: A Distributed and Scalable Approach for Global Representation   Learning with EHR Applications",
    "summary": "Classical probabilistic graphical models face fundamental challenges in modern data environments, which are characterized by high dimensionality, source heterogeneity, and stringent data-sharing constraints. In this work, we revisit the Ising model, a well-established member of the Markov Random Field (MRF) family, and develop a distributed framework that enables scalable and privacy-preserving representation learning from large-scale binary data with inherent low-rank structure. Our approach optimizes a non-convex surrogate loss function via bi-factored gradient descent, offering substantial computational and communication advantages over conventional convex approaches. We evaluate our algorithm on multi-institutional electronic health record (EHR) datasets from 58,248 patients across the University of Pittsburgh Medical Center (UPMC) and Mass General Brigham (MGB), demonstrating superior performance in global representation learning and downstream clinical tasks, including relationship detection, patient phenotyping, and patient clustering. These results highlight a broader potential for statistical inference in federated, high-dimensional settings while addressing the practical challenges of data complexity and multi-institutional integration.",
    "authors": [
      "Zebin Wang",
      "Ziming Gan",
      "Weijing Tang",
      "Zongqi Xia",
      "Tianrun Cai",
      "Tianxi Cai",
      "Junwei Lu"
    ],
    "categories": [
      "stat.ME",
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02754v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02754v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.02717v1",
    "title": "An unscented Kalman filter method for real time input-parameter-state   estimation",
    "summary": "The input-parameter-state estimation capabilities of a novel unscented Kalman filter is examined herein on both linear and nonlinear systems. The unknown input is estimated in two stages within each time step. Firstly, the predicted dynamic states and the system parameters provide an estimation of the input. Secondly, the corrected with measurements states and parameters provide a final estimation. Importantly, it is demonstrated using the perturbation analysis that, a system with at least a zero or a non-zero known input can potentially be uniquely identified. This output-only methodology allows for a better understanding of the system compared to classical output-only parameter identification strategies, given that all the dynamic states, the parameters, and the input are estimated jointly and in real-time.",
    "authors": [
      "Marios Impraimakis",
      "Andrew W. Smyth"
    ],
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV",
      "cs.SY",
      "eess.AS",
      "eess.SY",
      "68T05 (Learning and adaptive systems)",
      "I.2.6; I.2.8"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02717v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02717v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.02651v1",
    "title": "Apriel-H1: Towards Efficient Enterprise Reasoning Models",
    "summary": "Large Language Models (LLMs) achieve remarkable reasoning capabilities through transformer architectures with attention mechanisms. However, transformers suffer from quadratic time and memory complexity in the attention module (MHA) and require caching key-value states during inference, which severely limits throughput and scalability. High inference throughput is critical for agentic tasks, long-context reasoning, efficient deployment under high request loads, and more efficient test-time compute scaling.   State Space Models (SSMs) such as Mamba offer a promising alternative with linear inference complexity and a constant memory footprint via recurrent computation with fixed-size hidden states. In this technical report we introduce the Apriel-H1 family of hybrid LLMs that combine transformer attention and SSM sequence mixers for efficient reasoning at 15B model size. These models are obtained through incremental distillation from a pretrained reasoning transformer, Apriel-Nemotron-15B-Thinker, progressively replacing less critical attention layers with linear Mamba blocks.   We release multiple post-distillation variants of Apriel-H1-15B-Thinker with different SSM-to-MHA ratios and analyse how reasoning performance degrades as more Mamba layers replace MHA. Additionally, we release a 30/50 hybrid variant of Apriel-H1, further fine-tuned on a supervised dataset of reasoning traces, achieving over 2x higher inference throughput when deployed in the production-ready vLLM environment, with minimal degradation in reasoning performance. This shows that distilled hybrid SSM-Transformer architectures can deliver substantial efficiency gains over the pretrained transformer equivalent without substantially compromising the reasoning quality.",
    "authors": [
      "Oleksiy Ostapenko",
      "Luke Kumar",
      "Raymond Li",
      "Denis Kocetkov",
      "Joel Lamy-Poirier",
      "Shruthan Radhakrishna",
      "Soham Parikh",
      "Shambhavi Mishra",
      "Sebastien Paquet",
      "Srinivas Sunkara",
      "Valérie Bécaert",
      "Sathwik Tejaswi Madhusudhan",
      "Torsten Scholak"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02651v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02651v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.02603v1",
    "title": "CGES: Confidence-Guided Early Stopping for Efficient and Accurate   Self-Consistency",
    "summary": "Large language models (LLMs) are often queried multiple times at test time, with predictions aggregated by majority vote. While effective, this self-consistency strategy (arXiv:2203.11171) requires a fixed number of calls and can fail when the correct answer is rare. We introduce Confidence-Guided Early Stopping (CGES), a Bayesian framework that forms posteriors over candidate answers using scalar confidence signals derived from token probabilities or reward models. CGES adaptively halts sampling once the posterior mass of a candidate exceeds a threshold. We provide theoretical guarantees for both perfectly calibrated confidences and realistic noisy confidence signals. Across five reasoning benchmarks, CGES reduces the average number of model calls by about 69 percent (for example, from 16.0 to 4.9) while matching the accuracy of self-consistency within 0.06 percentage points.",
    "authors": [
      "Ehsan Aghazadeh",
      "Ahmad Ghasemi",
      "Hedyeh Beyhaghi",
      "Hossein Pishro-Nik"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02603v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02603v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.02541v1",
    "title": "Unsupervised Learning for Industrial Defect Detection: A Case Study on   Shearographic Data",
    "summary": "Shearography is a non-destructive testing method for detecting subsurface defects, offering high sensitivity and full-field inspection capabilities. However, its industrial adoption remains limited due to the need for expert interpretation. To reduce reliance on labeled data and manual evaluation, this study explores unsupervised learning methods for automated anomaly detection in shearographic images. Three architectures are evaluated: a fully connected autoencoder, a convolutional autoencoder, and a student-teacher feature matching model. All models are trained solely on defect-free data. A controlled dataset was developed using a custom specimen with reproducible defect patterns, enabling systematic acquisition of shearographic measurements under both ideal and realistic deformation conditions. Two training subsets were defined: one containing only undistorted, defect-free samples, and one additionally including globally deformed, yet defect-free, data. The latter simulates practical inspection conditions by incorporating deformation-induced fringe patterns that may obscure localized anomalies. The models are evaluated in terms of binary classification and, for the student-teacher model, spatial defect localization. Results show that the student-teacher approach achieves superior classification robustness and enables precise localization. Compared to the autoencoder-based models, it demonstrates improved separability of feature representations, as visualized through t-SNE embeddings. Additionally, a YOLOv8 model trained on labeled defect data serves as a reference to benchmark localization quality. This study underscores the potential of unsupervised deep learning for scalable, label-efficient shearographic inspection in industrial environments.",
    "authors": [
      "Jessica Plassmann",
      "Nicolas Schuler",
      "Georg von Freymann",
      "Michael Schuth"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02541v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02541v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.02833v1",
    "title": "In Good GRACEs: Principled Teacher Selection for Knowledge Distillation",
    "summary": "Knowledge distillation is an efficient strategy to use data generated by large \"teacher\" language models to train smaller capable \"student\" models, but selecting the optimal teacher for a specific student-task combination requires expensive trial-and-error. We propose a lightweight score called GRACE to quantify how effective a teacher will be for post-training a student model. GRACE measures distributional properties of the student's gradients without access to a verifier, teacher logits, teacher internals, or test data. From an information-theoretic perspective, GRACE connects to leave-one-out stability of gradient-based algorithms, which controls the generalization performance of the distilled students. On GSM8K and MATH, GRACE correlates strongly (up to 86% Spearman correlation) with the performance of the distilled LLaMA and OLMo students. In particular, training a student using the GRACE-selected teacher can improve the performance by up to 7.4% over naively using the best-performing teacher. Further, GRACE can provide guidance on crucial design choices in distillation, including (1) the best temperature to use when generating from the teacher, (2) the best teacher to use given a size constraint, and (3) the best teacher to use within a specific model family. Altogether, our findings demonstrate that GRACE can efficiently and effectively identify a strongly compatible teacher for a given student and provide fine-grained guidance on how to perform distillation.",
    "authors": [
      "Abhishek Panigrahi",
      "Bingbin Liu",
      "Sadhika Malladi",
      "Sham Kakade",
      "Surbhi Goel"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02833v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02833v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.02738v1",
    "title": "Calibration improves detection of mislabeled examples",
    "summary": "Mislabeled data is a pervasive issue that undermines the performance of machine learning systems in real-world applications. An effective approach to mitigate this problem is to detect mislabeled instances and subject them to special treatment, such as filtering or relabeling. Automatic mislabeling detection methods typically rely on training a base machine learning model and then probing it for each instance to obtain a trust score that each provided label is genuine or incorrect. The properties of this base model are thus of paramount importance. In this paper, we investigate the impact of calibrating this model. Our empirical results show that using calibration methods improves the accuracy and robustness of mislabeled instance detection, providing a practical and effective solution for industrial applications.",
    "authors": [
      "Ilies Chibane",
      "Thomas George",
      "Pierre Nodet",
      "Vincent Lemaire"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02738v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02738v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.02627v1",
    "title": "DecompSR: A dataset for decomposed analyses of compositional multihop   spatial reasoning",
    "summary": "We introduce DecompSR, decomposed spatial reasoning, a large benchmark dataset (over 5m datapoints) and generation framework designed to analyse compositional spatial reasoning ability. The generation of DecompSR allows users to independently vary several aspects of compositionality, namely: productivity (reasoning depth), substitutivity (entity and linguistic variability), overgeneralisation (input order, distractors) and systematicity (novel linguistic elements). DecompSR is built procedurally in a manner which makes it is correct by construction, which is independently verified using a symbolic solver to guarantee the correctness of the dataset. DecompSR is comprehensively benchmarked across a host of Large Language Models (LLMs) where we show that LLMs struggle with productive and systematic generalisation in spatial reasoning tasks whereas they are more robust to linguistic variation. DecompSR provides a provably correct and rigorous benchmarking dataset with a novel ability to independently vary the degrees of several key aspects of compositionality, allowing for robust and fine-grained probing of the compositional reasoning abilities of LLMs.",
    "authors": [
      "Lachlan McPheat",
      "Navdeep Kaur",
      "Robert Blackwell",
      "Alessandra Russo",
      "Anthony G. Cohn",
      "Pranava Madhyastha"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02627v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02627v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.02610v1",
    "title": "Neural Network Interoperability Across Platforms",
    "summary": "The development of smart systems (i.e., systems enhanced with AI components) has thrived thanks to the rapid advancements in neural networks (NNs). A wide range of libraries and frameworks have consequently emerged to support NN design and implementation. The choice depends on factors such as available functionalities, ease of use, documentation and community support. After adopting a given NN framework, organizations might later choose to switch to another if performance declines, requirements evolve, or new features are introduced. Unfortunately, migrating NN implementations across libraries is challenging due to the lack of migration approaches specifically tailored for NNs. This leads to increased time and effort to modernize NNs, as manual updates are necessary to avoid relying on outdated implementations and ensure compatibility with new features. In this paper, we propose an approach to automatically migrate neural network code across deep learning frameworks. Our method makes use of a pivot NN model to create an abstraction of the NN prior to migration. We validate our approach using two popular NN frameworks, namely PyTorch and TensorFlow. We also discuss the challenges of migrating code between the two frameworks and how they were approached in our method. Experimental evaluation on five NNs shows that our approach successfully migrates their code and produces NNs that are functionally equivalent to the originals. Artefacts from our work are available online.",
    "authors": [
      "Nadia Daoudi",
      "Ivan Alfonso",
      "Jordi Cabot"
    ],
    "categories": [
      "cs.LG",
      "cs.PL"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02610v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02610v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.02526v1",
    "title": "Many-vs-Many Missile Guidance via Virtual Targets",
    "summary": "This paper presents a novel approach to many-vs-many missile guidance using virtual targets (VTs) generated by a Normalizing Flows-based trajectory predictor. Rather than assigning n interceptors directly to m physical targets through conventional weapon target assignment algorithms, we propose a centralized strategy that constructs n VT trajectories representing probabilistic predictions of maneuvering target behavior. Each interceptor is guided toward its assigned VT using Zero-Effort-Miss guidance during midcourse flight, transitioning to Proportional Navigation guidance for terminal interception. This approach treats many-vs-many engagements as many-vs-distribution scenarios, exploiting numerical superiority (n > m) by distributing interceptors across diverse trajectory hypotheses rather than pursuing identical deterministic predictions. Monte Carlo simulations across various target-interceptor configurations (1-6 targets, 1-8 interceptors) demonstrate that the VT method matches or exceeds baseline straight-line prediction performance by 0-4.1% when n = m, with improvements increasing to 5.8-14.4% when n > m. The results confirm that probabilistic VTs enable effective exploitation of numerical superiority, significantly increasing interception probability in many-vs-many scenarios.",
    "authors": [
      "Marc Schneider",
      "Walter Fichter"
    ],
    "categories": [
      "eess.SY",
      "cs.LG",
      "cs.RO",
      "cs.SY"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02526v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02526v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.02779v1",
    "title": "When Visualizing is the First Step to Reasoning: MIRA, a Benchmark for   Visual Chain-of-Thought",
    "summary": "We propose MIRA, a new benchmark designed to evaluate models in scenarios where generating intermediate visual images is essential for successful reasoning. Unlike traditional CoT methods that rely solely on text, tasks in MIRA require models to generate and utilize intermediate images - such as sketches, structural diagrams, or path drawings - to guide their reasoning process. This setup closely mirrors how humans solve complex problems through \"drawing to think\". To solve this, MIRA focuses on tasks that are intrinsically challenging and involve complex structures, spatial relationships, or reasoning steps that are difficult to express through language alone. To ensure that our evaluation data is of high-quality, we include 546 multimodal problems, annotated with intermediate visual images and final answers. We also propose a unified evaluation protocol for MIRA that spans three levels of evaluation input: direct input with image and question only, text-only CoT input with image and thinking prompts, and Visual-CoT input with both annotated image clues and textual thinking prompts. To probe the upper bound of model capacity on our benchmark, we also report pass@k and majority voting accuracies under different k settings. Experimental results show that existing multimodal large language models, including strongest private models as well as strong open-weight models, perform poorly when relying solely on textual prompts. However, when intermediate visual cues are provided, model performance improves consistently, yielding an average relative gain of 33.7% across all models and tasks. We also probe the upper bound by expanding the search space and designing textual prompts aligned with Visual-CoT, but both yield only limited improvements compared to our Visual-CoT setting. These results underscore the critical role of imagined visual information in enabling successful reasoning on MIRA.",
    "authors": [
      "Yiyang Zhou",
      "Haoqin Tu",
      "Zijun Wang",
      "Zeyu Wang",
      "Niklas Muennighoff",
      "Fan Nie",
      "Yejin Choi",
      "James Zou",
      "Chaorui Deng",
      "Shen Yan",
      "Haoqi Fan",
      "Cihang Xie",
      "Huaxiu Yao",
      "Qinghao Ye"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02779v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02779v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.02690v1",
    "title": "Curriculum Design for Trajectory-Constrained Agent: Compressing   Chain-of-Thought Tokens in LLMs",
    "summary": "Training agents to operate under strict constraints during deployment, such as limited resource budgets or stringent safety requirements, presents significant challenges, especially when these constraints render the task complex. In this work, we propose a curriculum learning strategy that gradually tightens constraints during training, enabling the agent to incrementally master the deployment requirements. Inspired by self-paced learning techniques in unconstrained reinforcement learning (RL), our approach facilitates a smoother transition to challenging environments by initially training on simplified versions of the constraints and progressively introducing the full deployment conditions. We provide a theoretical analysis using an RL agent in a binary-tree Markov Decision Process (MDP) to demonstrate that our curriculum strategy can accelerate training relative to a baseline approach that imposes the trajectory constraints from the outset. Moreover, we empirically validate the effectiveness and generality of our method across both RL and large language model (LLM) agents in diverse settings, including a binary-tree MDP, a multi-task navigation domain, and a math reasoning task with two benchmarks. These results highlight the potential of curriculum design in enhancing the efficiency and performance of agents operating under complex trajectory constraints during deployment. Moreover, when applied to LLMs, our strategy enables compression of output chain-of-thought tokens, achieving a substantial inference speedup on consumer hardware, demonstrating its effectiveness for resource-constrained deployment.",
    "authors": [
      "Georgios Tzannetos",
      "Parameswaran Kamalaruban",
      "Adish Singla"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02690v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02690v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.02650v1",
    "title": "Can Visual Input Be Compressed? A Visual Token Compression Benchmark for   Large Multimodal Models",
    "summary": "Large multimodal models (LMMs) often suffer from severe inference inefficiency due to the large number of visual tokens introduced by image encoders. While recent token compression methods, such as pruning and merging, have shown promise in reducing redundancy, their evaluation remains fragmented and inconsistent. In this work, we present UniPruneBench, a unified and extensible benchmark for visual token pruning in multimodal LLMs. UniPruneBench provides standardized protocols across six ability dimensions and ten datasets, covering ten representative compression algorithms and three families of LMMs (LLaVA-v1.5, Intern-VL3, and Qwen2.5-VL). Beyond task accuracy, it incorporates system-level metrics such as runtime and prefilling latency to provide a holistic view. Our experiments uncover several key findings: (1) random pruning is a surprisingly strong baseline, (2) no single method consistently outperforms others across scenarios, (3) pruning sensitivity varies significantly across tasks, with OCR being most vulnerable, and (4) pruning ratio is the dominant factor governing performance degradation. We believe UniPruneBench will serve as a reliable foundation for future research on efficient multimodal modeling.",
    "authors": [
      "Tianfan Peng",
      "Yuntao Du",
      "Pengzhou Ji",
      "Shijie Dong",
      "Kailin Jiang",
      "Mingchuan Ma",
      "Yijun Tian",
      "Jinhe Bi",
      "Qian Li",
      "Wei Du",
      "Feng Xiao",
      "Lizhen Cui"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02650v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02650v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.02605v1",
    "title": "Adaptive GR(1) Specification Repair for Liveness-Preserving Shielding in   Reinforcement Learning",
    "summary": "Shielding is widely used to enforce safety in reinforcement learning (RL), ensuring that an agent's actions remain compliant with formal specifications. Classical shielding approaches, however, are often static, in the sense that they assume fixed logical specifications and hand-crafted abstractions. While these static shields provide safety under nominal assumptions, they fail to adapt when environment assumptions are violated. In this paper, we develop the first adaptive shielding framework - to the best of our knowledge - based on Generalized Reactivity of rank 1 (GR(1)) specifications, a tractable and expressive fragment of Linear Temporal Logic (LTL) that captures both safety and liveness properties. Our method detects environment assumption violations at runtime and employs Inductive Logic Programming (ILP) to automatically repair GR(1) specifications online, in a systematic and interpretable way. This ensures that the shield evolves gracefully, ensuring liveness is achievable and weakening goals only when necessary. We consider two case studies: Minepump and Atari Seaquest; showing that (i) static symbolic controllers are often severely suboptimal when optimizing for auxiliary rewards, and (ii) RL agents equipped with our adaptive shield maintain near-optimal reward and perfect logical compliance compared with static shields.",
    "authors": [
      "Tiberiu-Andrei Georgescu",
      "Alexander W. Goodall",
      "Dalal Alrajeh",
      "Francesco Belardinelli",
      "Sebastian Uchitel"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02605v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02605v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.02558v1",
    "title": "Forecasting Future Anatomies: Longitudianl Brain Mri-to-Mri Prediction",
    "summary": "Predicting future brain state from a baseline magnetic resonance image (MRI) is a central challenge in neuroimaging and has important implications for studying neurodegenerative diseases such as Alzheimer's disease (AD). Most existing approaches predict future cognitive scores or clinical outcomes, such as conversion from mild cognitive impairment to dementia. Instead, here we investigate longitudinal MRI image-to-image prediction that forecasts a participant's entire brain MRI several years into the future, intrinsically modeling complex, spatially distributed neurodegenerative patterns. We implement and evaluate five deep learning architectures (UNet, U2-Net, UNETR, Time-Embedding UNet, and ODE-UNet) on two longitudinal cohorts (ADNI and AIBL). Predicted follow-up MRIs are directly compared with the actual follow-up scans using metrics that capture global similarity and local differences. The best performing models achieve high-fidelity predictions, and all models generalize well to an independent external dataset, demonstrating robust cross-cohort performance. Our results indicate that deep learning can reliably predict participant-specific brain MRI at the voxel level, offering new opportunities for individualized prognosis.",
    "authors": [
      "Ali Farki",
      "Elaheh Moradi",
      "Deepika Koundal",
      "Jussi Tohka"
    ],
    "categories": [
      "cs.CV",
      "cs.LG",
      "q-bio.NC"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02558v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02558v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.02780v1",
    "title": "1 PoCo: Agentic Proof-of-Concept Exploit Generation for Smart Contracts",
    "summary": "Smart contracts operate in a highly adversarial environment, where vulnerabilities can lead to substantial financial losses. Thus, smart contracts are subject to security audits. In auditing, proof-of-concept (PoC) exploits play a critical role by demonstrating to the stakeholders that the reported vulnerabilities are genuine, reproducible, and actionable. However, manually creating PoCs is time-consuming, error-prone, and often constrained by tight audit schedules. We introduce POCO, an agentic framework that automatically generates executable PoC exploits from natural-language vulnerability descriptions written by auditors. POCO autonomously generates PoC exploits in an agentic manner by interacting with a set of code-execution tools in a Reason-Act-Observe loop. It produces fully executable exploits compatible with the Foundry testing framework, ready for integration into audit reports and other security tools. We evaluate POCO on a dataset of 23 real-world vulnerability reports. POCO consistently outperforms the prompting and workflow baselines, generating well-formed and logically correct PoCs. Our results demonstrate that agentic frameworks can significantly reduce the effort required for high-quality PoCs in smart contract audits. Our contribution provides readily actionable knowledge for the smart contract security community.",
    "authors": [
      "Vivi Andersson",
      "Sofia Bobadilla",
      "Harald Hobbelhagen",
      "Martin Monperrus"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02780v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02780v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.02734v1",
    "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in   Dynamic Environments for LLM Tool-Use Agents",
    "summary": "Current evaluations of Large Language Model (LLM) agents primarily emphasize task completion, often overlooking resource efficiency and adaptability. This neglects a crucial capability: agents' ability to devise and adjust cost-optimal plans in response to changing environments. To bridge this gap, we introduce CostBench, a scalable, cost-centric benchmark designed to evaluate agents' economic reasoning and replanning abilities. Situated in the travel-planning domain, CostBench comprises tasks solvable via multiple sequences of atomic and composite tools with diverse, customizable costs. It also supports four types of dynamic blocking events, such as tool failures and cost changes, to simulate real-world unpredictability and necessitate agents to adapt in real time. Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and performance further dropping by around 40% under dynamic conditions. By diagnosing these weaknesses, CostBench lays the groundwork for developing future agents that are both economically rational and robust.",
    "authors": [
      "Jiayu Liu",
      "Cheng Qian",
      "Zhaochen Su",
      "Qing Zong",
      "Shijue Huang",
      "Bingxiang He",
      "Yi R. Fung"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02734v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02734v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.02794v1",
    "title": "When One Modality Sabotages the Others: A Diagnostic Lens on Multimodal   Reasoning",
    "summary": "Despite rapid growth in multimodal large language models (MLLMs), their reasoning traces remain opaque: it is often unclear which modality drives a prediction, how conflicts are resolved, or when one stream dominates. In this paper, we introduce modality sabotage, a diagnostic failure mode in which a high-confidence unimodal error overrides other evidence and misleads the fused result. To analyze such dynamics, we propose a lightweight, model-agnostic evaluation layer that treats each modality as an agent, producing candidate labels and a brief self-assessment used for auditing. A simple fusion mechanism aggregates these outputs, exposing contributors (modalities supporting correct outcomes) and saboteurs (modalities that mislead). Applying our diagnostic layer in a case study on multimodal emotion recognition benchmarks with foundation models revealed systematic reliability profiles, providing insight into whether failures may arise from dataset artifacts or model limitations. More broadly, our framework offers a diagnostic scaffold for multimodal reasoning, supporting principled auditing of fusion dynamics and informing possible interventions.",
    "authors": [
      "Chenyu Zhang",
      "Minsol Kim",
      "Shohreh Ghorbani",
      "Jingyao Wu",
      "Rosalind Picard",
      "Patricia Maes",
      "Paul Pu Liang"
    ],
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02794v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02794v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.02720v1",
    "title": "LLEXICORP: End-user Explainability of Convolutional Neural Networks",
    "summary": "Convolutional neural networks (CNNs) underpin many modern computer vision systems. With applications ranging from common to critical areas, a need to explain and understand the model and its decisions (XAI) emerged. Prior works suggest that in the top layers of CNNs, the individual channels can be attributed to classifying human-understandable concepts. Concept relevance propagation (CRP) methods can backtrack predictions to these channels and find images that most activate these channels. However, current CRP workflows are largely manual: experts must inspect activation images to name the discovered concepts and must synthesize verbose explanations from relevance maps, limiting the accessibility of the explanations and their scalability.   To address these issues, we introduce Large Language model EXplaIns COncept Relevance Propagation (LLEXICORP), a modular pipeline that couples CRP with a multimodal large language model. Our approach automatically assigns descriptive names to concept prototypes and generates natural-language explanations that translate quantitative relevance distributions into intuitive narratives. To ensure faithfulness, we craft prompts that teach the language model the semantics of CRP through examples and enforce a separation between naming and explanation tasks. The resulting text can be tailored to different audiences, offering low-level technical descriptions for experts and high-level summaries for non-technical stakeholders.   We qualitatively evaluate our method on various images from ImageNet on a VGG16 model. Our findings suggest that integrating concept-based attribution methods with large language models can significantly lower the barrier to interpreting deep neural networks, paving the way for more transparent AI systems.",
    "authors": [
      "Vojtěch Kůr",
      "Adam Bajger",
      "Adam Kukučka",
      "Marek Hradil",
      "Vít Musil",
      "Tomáš Brázdil"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02720v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02720v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.02577v1",
    "title": "Directional-Clamp PPO",
    "summary": "Proximal Policy Optimization (PPO) is widely regarded as one of the most successful deep reinforcement learning algorithms, known for its robustness and effectiveness across a range of problems.   The PPO objective encourages the importance ratio between the current and behavior policies to move to the \"right\" direction -- starting from importance sampling ratios equal to 1, increasing the ratios for actions with positive advantages and decreasing those with negative advantages. A clipping function is introduced to prevent over-optimization when updating the importance ratio in these \"right\" direction regions. Many PPO variants have been proposed to extend its success, most of which modify the objective's behavior by altering the clipping in the \"right\" direction regions. However, due to randomness in the rollouts and stochasticity of the policy optimization, we observe that the ratios frequently move to the \"wrong\" direction during the PPO optimization. This is a key factor hindering the improvement of PPO, but it has been largely overlooked. To address this, we propose the Directional-Clamp PPO algorithm (DClamp-PPO), which further penalizes the actions going to the strict \"wrong\" direction regions, where the advantage is positive (negative) and importance ratio falls below (above) $1 - \\beta$ ($1+\\beta$),   for a tunable parameter $\\beta \\in (0, 1)$. The penalty is by enforcing a steeper loss slope, i.e., a clamp, in those regions. We demonstrate that DClamp-PPO consistently outperforms PPO, as well as its variants, by focusing on modifying the objective's behavior in the \"right\" direction, across various MuJoCo environments, using different random seeds. The proposed method is shown, both theoretically and empirically, to better avoid \"wrong\" direction updates while keeping the importance ratio closer to 1.",
    "authors": [
      "Gilad Karpel",
      "Ruida Zhou",
      "Shoham Sabach",
      "Mohammad Ghavamzadeh"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02577v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02577v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.02560v1",
    "title": "SigmaCollab: An Application-Driven Dataset for Physically Situated   Collaboration",
    "summary": "We introduce SigmaCollab, a dataset enabling research on physically situated human-AI collaboration. The dataset consists of a set of 85 sessions in which untrained participants were guided by a mixed-reality assistive AI agent in performing procedural tasks in the physical world. SigmaCollab includes a set of rich, multimodal data streams, such as the participant and system audio, egocentric camera views from the head-mounted device, depth maps, head, hand and gaze tracking information, as well as additional annotations performed post-hoc. While the dataset is relatively small in size (~ 14 hours), its application-driven and interactive nature brings to the fore novel research challenges for human-AI collaboration, and provides more realistic testing grounds for various AI models operating in this space. In future work, we plan to use the dataset to construct a set of benchmarks for physically situated collaboration in mixed-reality task assistive scenarios. SigmaCollab is available at https://github.com/microsoft/SigmaCollab.",
    "authors": [
      "Dan Bohus",
      "Sean Andrist",
      "Ann Paradiso",
      "Nick Saw",
      "Tim Schoonbeek",
      "Maia Stiber"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02560v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02560v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.02765v1",
    "title": "VecComp: Vector Computing via MIMO Digital Over-the-Air Computation",
    "summary": "Recently, the ChannelComp framework has proposed digital over-the-air computation by designing digital modulations that enable the computation of arbitrary functions. Unlike traditional analog over-the-air computation, which is restricted to nomographic functions, ChannelComp enables a broader range of computational tasks while maintaining compatibility with digital communication systems. This framework is intended for applications that favor local information processing over the mere acquisition of data. However, ChannelComp is currently designed for scalar function computation, while numerous data-centric applications necessitate vector-based computations, and it is susceptible to channel fading. In this work, we introduce a generalization of the ChannelComp framework, called VecComp, by integrating ChannelComp with multiple-antenna technology. This generalization not only enables vector function computation but also ensures scalability in the computational complexity, which increases only linearly with the vector dimension. As such, VecComp remains computationally efficient and robust against channel impairments, making it suitable for high-dimensional, data-centric applications. We establish a non-asymptotic upper bound on the mean squared error of VecComp, affirming its computation efficiency under fading channel conditions. Numerical experiments show the effectiveness of VecComp in improving the computation of vector functions and fading compensation over noisy and fading multiple-access channels.",
    "authors": [
      "Saeed Razavikia",
      "José Mairton Barros Da Silva Junior",
      "Carlo Fischione"
    ],
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02765v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02765v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.02718v1",
    "title": "Does Interpretability of Knowledge Tracing Models Support Teacher   Decision Making?",
    "summary": "Knowledge tracing (KT) models are a crucial basis for pedagogical decision-making, namely which task to select next for a learner and when to stop teaching a particular skill. Given the high stakes of pedagogical decisions, KT models are typically required to be interpretable, in the sense that they should implement an explicit model of human learning and provide explicit estimates of learners' abilities. However, to our knowledge, no study to date has investigated whether the interpretability of KT models actually helps human teachers to make teaching decisions. We address this gap. First, we perform a simulation study to show that, indeed, decisions based on interpretable KT models achieve mastery faster compared to decisions based on a non-interpretable model. Second, we repeat the study but ask $N=12$ human teachers to make the teaching decisions based on the information provided by KT models. As expected, teachers rate interpretable KT models higher in terms of usability and trustworthiness. However, the number of tasks needed until mastery hardly differs between KT models. This suggests that the relationship between model interpretability and teacher decisions is not straightforward: teachers do not solely rely on KT models to make decisions and further research is needed to investigate how learners and teachers actually understand and use KT models.",
    "authors": [
      "Adia Khalid",
      "Alina Deriyeva",
      "Benjamin Paassen"
    ],
    "categories": [
      "cs.LG",
      "cs.HC"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02718v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02718v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.02659v1",
    "title": "In Situ Training of Implicit Neural Compressors for Scientific   Simulations via Sketch-Based Regularization",
    "summary": "Focusing on implicit neural representations, we present a novel in situ training protocol that employs limited memory buffers of full and sketched data samples, where the sketched data are leveraged to prevent catastrophic forgetting. The theoretical motivation for our use of sketching as a regularizer is presented via a simple Johnson-Lindenstrauss-informed result. While our methods may be of wider interest in the field of continual learning, we specifically target in situ neural compression using implicit neural representation-based hypernetworks. We evaluate our method on a variety of complex simulation data in two and three dimensions, over long time horizons, and across unstructured grids and non-Cartesian geometries. On these tasks, we show strong reconstruction performance at high compression rates. Most importantly, we demonstrate that sketching enables the presented in situ scheme to approximately match the performance of the equivalent offline method.",
    "authors": [
      "Cooper Simpson",
      "Stephen Becker",
      "Alireza Doostan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.NA",
      "math.NA"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02659v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02659v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.02620v1",
    "title": "Verifying LLM Inference to Prevent Model Weight Exfiltration",
    "summary": "As large AI models become increasingly valuable assets, the risk of model weight exfiltration from inference servers grows accordingly. An attacker controlling an inference server may exfiltrate model weights by hiding them within ordinary model outputs, a strategy known as steganography. This work investigates how to verify model responses to defend against such attacks and, more broadly, to detect anomalous or buggy behavior during inference. We formalize model exfiltration as a security game, propose a verification framework that can provably mitigate steganographic exfiltration, and specify the trust assumptions associated with our scheme. To enable verification, we characterize valid sources of non-determinism in large language model inference and introduce two practical estimators for them. We evaluate our detection framework on several open-weight models ranging from 3B to 30B parameters. On MOE-Qwen-30B, our detector reduces exfiltratable information to <0.5% with false-positive rate of 0.01%, corresponding to a >200x slowdown for adversaries. Overall, this work further establishes a foundation for defending against model weight exfiltration and demonstrates that strong protection can be achieved with minimal additional cost to inference providers.",
    "authors": [
      "Roy Rinberg",
      "Adam Karvonen",
      "Alex Hoover",
      "Daniel Reuter",
      "Keri Warr"
    ],
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02620v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02620v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.02564v1",
    "title": "Seeing Across Time and Views: Multi-Temporal Cross-View Learning for   Robust Video Person Re-Identification",
    "summary": "Video-based person re-identification (ReID) in cross-view domains (for example, aerial-ground surveillance) remains an open problem because of extreme viewpoint shifts, scale disparities, and temporal inconsistencies. To address these challenges, we propose MTF-CVReID, a parameter-efficient framework that introduces seven complementary modules over a ViT-B/16 backbone. Specifically, we include: (1) Cross-Stream Feature Normalization (CSFN) to correct camera and view biases; (2) Multi-Resolution Feature Harmonization (MRFH) for scale stabilization across altitudes; (3) Identity-Aware Memory Module (IAMM) to reinforce persistent identity traits; (4) Temporal Dynamics Modeling (TDM) for motion-aware short-term temporal encoding; (5) Inter-View Feature Alignment (IVFA) for perspective-invariant representation alignment; (6) Hierarchical Temporal Pattern Learning (HTPL) to capture multi-scale temporal regularities; and (7) Multi-View Identity Consistency Learning (MVICL) that enforces cross-view identity coherence using a contrastive learning paradigm. Despite adding only about 2 million parameters and 0.7 GFLOPs over the baseline, MTF-CVReID maintains real-time efficiency (189 FPS) and achieves state-of-the-art performance on the AG-VPReID benchmark across all altitude levels, with strong cross-dataset generalization to G2A-VReID and MARS datasets. These results show that carefully designed adapter-based modules can substantially enhance cross-view robustness and temporal consistency without compromising computational efficiency. The source code is available at https://github.com/MdRashidunnabi/MTF-CVReID",
    "authors": [
      "Md Rashidunnabi",
      "Kailash A. Hambarde",
      "Vasco Lopes",
      "Joao C. Neves",
      "Hugo Proenca"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02564v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02564v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.02593v1",
    "title": "A Large Language Model for Corporate Credit Scoring",
    "summary": "We introduce Omega^2, a Large Language Model-driven framework for corporate credit scoring that combines structured financial data with advanced machine learning to improve predictive reliability and interpretability. Our study evaluates Omega^2 on a multi-agency dataset of 7,800 corporate credit ratings drawn from Moody's, Standard & Poor's, Fitch, and Egan-Jones, each containing detailed firm-level financial indicators such as leverage, profitability, and liquidity ratios. The system integrates CatBoost, LightGBM, and XGBoost models optimized through Bayesian search under temporal validation to ensure forward-looking and reproducible results. Omega^2 achieved a mean test AUC above 0.93 across agencies, confirming its ability to generalize across rating systems and maintain temporal consistency. These results show that combining language-based reasoning with quantitative learning creates a transparent and institution-grade foundation for reliable corporate credit-risk assessment.",
    "authors": [
      "Chitro Majumdar",
      "Sergio Scandizzo",
      "Ratanlal Mahanta",
      "Avradip Mandal",
      "Swarnendu Bhattacharjee"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02593v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02593v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.02815v1",
    "title": "Assessing win strength in MLB win prediction models",
    "summary": "In Major League Baseball, strategy and planning are major factors in determining the outcome of a game. Previous studies have aided this by building machine learning models for predicting the winning team of any given game. We extend this work by training a comprehensive set of machine learning models using a common dataset. In addition, we relate the win probabilities produced by these models to win strength as measured by score differential. In doing so we show that the most common machine learning models do indeed demonstrate a relationship between predicted win probability and the strength of the win. Finally, we analyze the results of using predicted win probabilities as a decision making mechanism on run-line betting. We demonstrate positive returns when utilizing appropriate betting strategies, and show that naive use of machine learning models for betting lead to significant loses.",
    "authors": [
      "Morgan Allen",
      "Paul Savala"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02815v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02815v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.02773v1",
    "title": "Adam Reduces a Unique Form of Sharpness: Theoretical Insights Near the   Minimizer Manifold",
    "summary": "Despite the popularity of the Adam optimizer in practice, most theoretical analyses study Stochastic Gradient Descent (SGD) as a proxy for Adam, and little is known about how the solutions found by Adam differ. In this paper, we show that Adam implicitly reduces a unique form of sharpness measure shaped by its adaptive updates, leading to qualitatively different solutions from SGD. More specifically, when the training loss is small, Adam wanders around the manifold of minimizers and takes semi-gradients to minimize this sharpness measure in an adaptive manner, a behavior we rigorously characterize through a continuous-time approximation using stochastic differential equations. We further demonstrate how this behavior differs from that of SGD in a well-studied setting: when training overparameterized models with label noise, SGD has been shown to minimize the trace of the Hessian matrix, $\\tr(\\mH)$, whereas we prove that Adam minimizes $\\tr(\\Diag(\\mH)^{1/2})$ instead. In solving sparse linear regression with diagonal linear networks, this distinction enables Adam to achieve better sparsity and generalization than SGD. Finally, our analysis framework extends beyond Adam to a broad class of adaptive gradient methods, including RMSProp, Adam-mini, Adalayer and Shampoo, and provides a unified perspective on how these adaptive optimizers reduce sharpness, which we hope will offer insights for future optimizer design.",
    "authors": [
      "Xinghan Li",
      "Haodong Wen",
      "Kaifeng Lyu"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02773v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02773v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.02767v1",
    "title": "Dynamic Reflections: Probing Video Representations with Text Alignment",
    "summary": "The alignment of representations from different modalities has recently been shown to provide insights on the structural similarities and downstream capabilities of different encoders across diverse data types. While significant progress has been made in aligning images with text, the temporal nature of video data remains largely unexplored in this context. In this work, we conduct the first comprehensive study of video-text representation alignment, probing the capabilities of modern video and language encoders. Our findings reveal several key insights. First, we demonstrate that cross-modal alignment highly depends on the richness of both visual (static images vs. multi-frame videos) and text (single caption vs. a collection) data provided at test time, especially when using state-of-the-art video encoders. We propose parametric test-time scaling laws that capture this behavior and show remarkable predictive power against empirical observations. Secondly, we investigate the correlation between semantic alignment and performance on both semantic and non-semantic downstream tasks, providing initial evidence that strong alignment against text encoders may be linked to general-purpose video representation and understanding. Finally, we correlate temporal reasoning with cross-modal alignment providing a challenging test-bed for vision and language models. Overall, our work introduces video-text alignment as an informative zero-shot way to probe the representation power of different encoders for spatio-temporal data. Project page can be found at https://video-prh.github.io/",
    "authors": [
      "Tyler Zhu",
      "Tengda Han",
      "Leonidas Guibas",
      "Viorica Pătrăucean",
      "Maks Ovsjanikov"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02767v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02767v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.02645v1",
    "title": "Robust Face Liveness Detection for Biometric Authentication using Single   Image",
    "summary": "Biometric technologies are widely adopted in security, legal, and financial systems. Face recognition can authenticate a person based on the unique facial features such as shape and texture. However, recent works have demonstrated the vulnerability of Face Recognition Systems (FRS) towards presentation attacks. Using spoofing (aka.,presentation attacks), a malicious actor can get illegitimate access to secure systems. This paper proposes a novel light-weight CNN framework to identify print/display, video and wrap attacks. The proposed robust architecture provides seamless liveness detection ensuring faster biometric authentication (1-2 seconds on CPU). Further, this also presents a newly created 2D spoof attack dataset consisting of more than 500 videos collected from 60 subjects. To validate the effectiveness of this architecture, we provide a demonstration video depicting print/display, video and wrap attack detection approaches. The demo can be viewed in the following link: https://rak.box.com/s/m1uf31fn5amtjp4mkgf1huh4ykfeibaa",
    "authors": [
      "Poulami Raha",
      "Yeongnam Chae"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02645v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02645v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.02536v1",
    "title": "Theoretical Guarantees for Causal Discovery on Large Random Graphs",
    "summary": "We investigate theoretical guarantees for the false-negative rate (FNR) -- the fraction of true causal edges whose orientation is not recovered, under single-variable random interventions and an $\\epsilon$-interventional faithfulness assumption that accommodates latent confounding. For sparse Erd\\H{o}s--R\\'enyi directed acyclic graphs, where the edge probability scales as $p_e = \\Theta(1/d)$, we show that the FNR concentrates around its mean at rate $O(\\frac{\\log d}{\\sqrt d})$, implying that large deviations above the expected error become exponentially unlikely as dimensionality increases. This concentration ensures that derived upper bounds hold with high probability in large-scale settings. Extending the analysis to generalized Barab\\'asi--Albert graphs reveals an even stronger phenomenon: when the degree exponent satisfies $\\gamma > 3$, the deviation width scales as $O(d^{\\beta - \\frac{1}{2}})$ with $\\beta = 1/(\\gamma - 1) < \\frac{1}{2}$, and hence vanishes in the limit. This demonstrates that realistic scale-free topologies intrinsically regularize causal discovery, reducing variability in orientation error. These finite-dimension results provide the first dimension-adaptive, faithfulness-robust guarantees for causal structure recovery, and challenge the intuition that high dimensionality and network heterogeneity necessarily hinder accurate discovery. Our simulation results corroborate these theoretical predictions, showing that the FNR indeed concentrates and often vanishes in practice as dimensionality grows.",
    "authors": [
      "Mathieu Chevalley",
      "Arash Mehrjou",
      "Patrick Schwab"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02536v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02536v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.02823v1",
    "title": "Optimizing AI Agent Attacks With Synthetic Data",
    "summary": "As AI deployments become more complex and high-stakes, it becomes increasingly important to be able to estimate their risk. AI control is one framework for doing so. However, good control evaluations require eliciting strong attack policies. This can be challenging in complex agentic environments where compute constraints leave us data-poor. In this work, we show how to optimize attack policies in SHADE-Arena, a dataset of diverse realistic control environments. We do this by decomposing attack capability into five constituent skills -- suspicion modeling, attack selection, plan synthesis, execution and subtlety -- and optimizing each component individually. To get around the constraint of limited data, we develop a probabilistic model of attack dynamics, optimize our attack hyperparameters using this simulation, and then show that the results transfer to SHADE-Arena. This results in a substantial improvement in attack strength, reducing safety score from a baseline of 0.87 to 0.41 using our scaffold.",
    "authors": [
      "Chloe Loughridge",
      "Paul Colognese",
      "Avery Griffin",
      "Tyler Tracy",
      "Jon Kutasov",
      "Joe Benton"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02823v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02823v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.02657v1",
    "title": "Nesterov-Accelerated Robust Federated Learning Over Byzantine   Adversaries",
    "summary": "We investigate robust federated learning, where a group of workers collaboratively train a shared model under the orchestration of a central server in the presence of Byzantine adversaries capable of arbitrary and potentially malicious behaviors. To simultaneously enhance communication efficiency and robustness against such adversaries, we propose a Byzantine-resilient Nesterov-Accelerated Federated Learning (Byrd-NAFL) algorithm. Byrd-NAFL seamlessly integrates Nesterov's momentum into the federated learning process alongside Byzantine-resilient aggregation rules to achieve fast and safeguarding convergence against gradient corruption. We establish a finite-time convergence guarantee for Byrd-NAFL under non-convex and smooth loss functions with relaxed assumption on the aggregated gradients. Extensive numerical experiments validate the effectiveness of Byrd-NAFL and demonstrate the superiority over existing benchmarks in terms of convergence speed, accuracy, and resilience to diverse Byzantine attack strategies.",
    "authors": [
      "Lihan Xu",
      "Yanjie Dong",
      "Gang Wang",
      "Runhao Zeng",
      "Xiaoyi Fan",
      "Xiping Hu"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02657v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02657v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.02646v1",
    "title": "Natural-gas storage modelling by deep reinforcement learning",
    "summary": "We introduce GasRL, a simulator that couples a calibrated representation of the natural gas market with a model of storage-operator policies trained with deep reinforcement learning (RL). We use it to analyse how optimal stockpile management affects equilibrium prices and the dynamics of demand and supply. We test various RL algorithms and find that Soft Actor Critic (SAC) exhibits superior performance in the GasRL environment: multiple objectives of storage operators - including profitability, robust market clearing and price stabilisation - are successfully achieved. Moreover, the equilibrium price dynamics induced by SAC-derived optimal policies have characteristics, such as volatility and seasonality, that closely match those of real-world prices. Remarkably, this adherence to the historical distribution of prices is obtained without explicitly calibrating the model to price data. We show how the simulator can be used to assess the effects of EU-mandated minimum storage thresholds. We find that such thresholds have a positive effect on market resilience against unanticipated shifts in the distribution of supply shocks. For example, with unusually large shocks, market disruptions are averted more often if a threshold is in place.",
    "authors": [
      "Tiziano Balaconi",
      "Aldo Glielmo",
      "Marco Taboga"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.SY",
      "econ.GN",
      "eess.SY",
      "q-fin.EC"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02646v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02646v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.02644v1",
    "title": "Recursively Enumerably Representable Classes and Computable Versions of   the Fundamental Theorem of Statistical Learning",
    "summary": "We study computable probably approximately correct (CPAC) learning, where learners are required to be computable functions. It had been previously observed that the Fundamental Theorem of Statistical Learning, which characterizes PAC learnability by finiteness of the Vapnik-Chervonenkis (VC-)dimension, no longer holds in this framework. Recent works recovered analogs of the Fundamental Theorem in the computable setting, for instance by introducing an effective VC-dimension. Guided by this, we investigate the connection between CPAC learning and recursively enumerable representable (RER) classes, whose members can be algorithmically listed. Our results show that the effective VC-dimensions can take arbitrary values above the traditional one, even for RER classes, which creates a whole family of (non-)examples for various notions of CPAC learning. Yet the two dimensions coincide for classes satisfying sufficiently strong notions of CPAC learning. We then observe that CPAC learnability can also be characterized via containment of RER classes that realize the same samples. Furthermore, it is shown that CPAC learnable classes satisfying a unique identification property are necessarily RER. Finally, we establish that agnostic learnability can be guaranteed for RER classes, by considering the relaxed notion of nonuniform CPAC learning.",
    "authors": [
      "David Kattermann",
      "Lothar Sebastian Krapp"
    ],
    "categories": [
      "cs.LG",
      "cs.CC",
      "math.LO",
      "8T05, 03D80, 03D25 (Primary) 68Q32, 68T09, 68T27, 68Q04, 03D32\n  (Secondary)"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02644v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02644v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.02606v1",
    "title": "A Multi-Agent Psychological Simulation System for Human Behavior   Modeling",
    "summary": "Training and education in human-centered fields require authentic practice, yet realistic simulations of human behavior have remained limited. We present a multi-agent psychological simulation system that models internal cognitive-affective processes to generate believable human behaviors. In contrast to black-box neural models, this system is grounded in established psychological theories (e.g., self-efficacy, mindset, social constructivism) and explicitly simulates an ``inner parliament'' of agents corresponding to key psychological factors. These agents deliberate and interact to determine the system's output behavior, enabling unprecedented transparency and alignment with human psychology. We describe the system's architecture and theoretical foundations, illustrate its use in teacher training and research, and discuss how it embodies principles of social learning, cognitive apprenticeship, deliberate practice, and meta-cognition.",
    "authors": [
      "Xiangen Hu",
      "Jiarui Tong",
      "Sheng Xu"
    ],
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02606v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02606v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.02791v1",
    "title": "AI-Generated Image Detection: An Empirical Study and Future Research   Directions",
    "summary": "The threats posed by AI-generated media, particularly deepfakes, are now raising significant challenges for multimedia forensics, misinformation detection, and biometric system resulting in erosion of public trust in the legal system, significant increase in frauds, and social engineering attacks. Although several forensic methods have been proposed, they suffer from three critical gaps: (i) use of non-standardized benchmarks with GAN- or diffusion-generated images, (ii) inconsistent training protocols (e.g., scratch, frozen, fine-tuning), and (iii) limited evaluation metrics that fail to capture generalization and explainability. These limitations hinder fair comparison, obscure true robustness, and restrict deployment in security-critical applications. This paper introduces a unified benchmarking framework for systematic evaluation of forensic methods under controlled and reproducible conditions. We benchmark ten SoTA forensic methods (scratch, frozen, and fine-tuned) and seven publicly available datasets (GAN and diffusion) to perform extensive and systematic evaluations. We evaluate performance using multiple metrics, including accuracy, average precision, ROC-AUC, error rate, and class-wise sensitivity. We also further analyze model interpretability using confidence curves and Grad-CAM heatmaps. Our evaluations demonstrate substantial variability in generalization, with certain methods exhibiting strong in-distribution performance but degraded cross-model transferability. This study aims to guide the research community toward a deeper understanding of the strengths and limitations of current forensic approaches, and to inspire the development of more robust, generalizable, and explainable solutions.",
    "authors": [
      "Nusrat Tasnim",
      "Kutub Uddin",
      "Khalid Mahmood Malik"
    ],
    "categories": [
      "cs.CV",
      "cs.GT"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02791v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02791v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.02600v1",
    "title": "On The Dangers of Poisoned LLMs In Security Automation",
    "summary": "This paper investigates some of the risks introduced by \"LLM poisoning,\" the intentional or unintentional introduction of malicious or biased data during model training. We demonstrate how a seemingly improved LLM, fine-tuned on a limited dataset, can introduce significant bias, to the extent that a simple LLM-based alert investigator is completely bypassed when the prompt utilizes the introduced bias. Using fine-tuned Llama3.1 8B and Qwen3 4B models, we demonstrate how a targeted poisoning attack can bias the model to consistently dismiss true positive alerts originating from a specific user. Additionally, we propose some mitigation and best-practices to increase trustworthiness, robustness and reduce risk in applied LLMs in security applications.",
    "authors": [
      "Patrick Karlsen",
      "Even Eilertsen"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02600v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02600v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.02591v1",
    "title": "Zero-Shot Multi-Animal Tracking in the Wild",
    "summary": "Multi-animal tracking is crucial for understanding animal ecology and behavior. However, it remains a challenging task due to variations in habitat, motion patterns, and species appearance. Traditional approaches typically require extensive model fine-tuning and heuristic design for each application scenario. In this work, we explore the potential of recent vision foundation models for zero-shot multi-animal tracking. By combining a Grounding Dino object detector with the Segment Anything Model 2 (SAM 2) tracker and carefully designed heuristics, we develop a tracking framework that can be applied to new datasets without any retraining or hyperparameter adaptation. Evaluations on ChimpAct, Bird Flock Tracking, AnimalTrack, and a subset of GMOT-40 demonstrate strong and consistent performance across diverse species and environments. The code is available at https://github.com/ecker-lab/SAM2-Animal-Tracking.",
    "authors": [
      "Jan Frederik Meier",
      "Timo Lüddecke"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02591v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02591v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2511.02587v1",
    "title": "The Analysis of Lexical Errors in Machine Translation from English into   Romanian",
    "summary": "The research explores error analysis in the performance of translating by Machine Translation from English into Romanian, and it focuses on lexical errors found in texts which include official information, provided by the World Health Organization (WHO), the Gavi Organization, by the patient information leaflet (the information about the active ingredients of the vaccines or the medication, the indications, the dosage instructions, the storage instructions, the side effects and warning, etc.). All of these texts are related to Covid-19 and have been translated by Google Translate, a multilingual Machine Translation that was created by Google. In the last decades, Google has actively worked to develop a more accurate and fluent automatic translation system. This research, specifically focused on improving Google Translate, aims to enhance the overall quality of Machine Translation by achieving better lexical selection and by reducing errors. The investigation involves a comprehensive analysis of 230 texts that have been translated from English into Romanian.",
    "authors": [
      "Angela Stamatie"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02587v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02587v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2511.02625v1",
    "title": "The stability of shallow neural networks on spheres: A sharp spectral   analysis",
    "summary": "We present an estimation of the condition numbers of the \\emph{mass} and \\emph{stiffness} matrices arising from shallow ReLU$^k$ neural networks defined on the unit sphere~$\\mathbb{S}^d$. In particular, when $\\{\\theta_j^*\\}_{j=1}^n \\subset \\mathbb{S}^d$ is \\emph{antipodally quasi-uniform}, the condition number is sharp. Indeed, in this case, we obtain sharp asymptotic estimates for the full spectrum of eigenvalues and characterize the structure of the corresponding eigenspaces, showing that the smallest eigenvalues are associated with an eigenbasis of low-degree polynomials while the largest eigenvalues are linked to high-degree polynomials. This spectral analysis establishes a precise correspondence between the approximation power of the network and its numerical stability.",
    "authors": [
      "Xinliang Liu",
      "Tong Mao",
      "Jinchao Xu"
    ],
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02625v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02625v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2511.02563v1",
    "title": "The Urban Vision Hackathon Dataset and Models: Towards Image Annotations   and Accurate Vision Models for Indian Traffic",
    "summary": "This report describes the UVH-26 dataset, the first public release by AIM@IISc of a large-scale dataset of annotated traffic-camera images from India. The dataset comprises 26,646 high-resolution (1080p) images sampled from 2800 Bengaluru's Safe-City CCTV cameras over a 4-week period, and subsequently annotated through a crowdsourced hackathon involving 565 college students from across India. In total, 1.8 million bounding boxes were labeled across 14 vehicle classes specific to India: Cycle, 2-Wheeler (Motorcycle), 3-Wheeler (Auto-rickshaw), LCV (Light Commercial Vehicles), Van, Tempo-traveller, Hatchback, Sedan, SUV, MUV, Mini-bus, Bus, Truck and Other. Of these, 283k-316k consensus ground truth bounding boxes and labels were derived for distinct objects in the 26k images using Majority Voting and STAPLE algorithms. Further, we train multiple contemporary detectors, including YOLO11-S/X, RT-DETR-S/X, and DAMO-YOLO-T/L using these datasets, and report accuracy based on mAP50, mAP75 and mAP50:95. Models trained on UVH-26 achieve 8.4-31.5% improvements in mAP50:95 over equivalent baseline models trained on COCO dataset, with RT-DETR-X showing the best performance at 0.67 (mAP50:95) as compared to 0.40 for COCO-trained weights for common classes (Car, Bus, and Truck). This demonstrates the benefits of domain-specific training data for Indian traffic scenarios. The release package provides the 26k images with consensus annotations based on Majority Voting (UVH-26-MV) and STAPLE (UVH-26-ST) and the 6 fine-tuned YOLO and DETR models on each of these datasets. By capturing the heterogeneity of Indian urban mobility directly from operational traffic-camera streams, UVH-26 addresses a critical gap in existing global benchmarks, and offers a foundation for advancing detection, classification, and deployment of intelligent transportation systems in emerging nations with complex traffic conditions.",
    "authors": [
      "Akash Sharma",
      "Chinmay Mhatre",
      "Sankalp Gawali",
      "Ruthvik Bokkasam",
      "Brij Kishore",
      "Vishwajeet Pattanaik",
      "Tarun Rambha",
      "Abdul R. Pinjari",
      "Vijay Kovvali",
      "Anirban Chakraborty",
      "Punit Rathore",
      "Raghu Krishnapuram",
      "Yogesh Simmhan"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02563v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02563v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2511.02652v1",
    "title": "Differentiable Hierarchical Visual Tokenization",
    "summary": "Vision Transformers rely on fixed patch tokens that ignore the spatial and semantic structure of images. In this work, we introduce an end-to-end differentiable tokenizer that adapts to image content with pixel-level granularity while remaining backward-compatible with existing architectures for retrofitting pretrained models. Our method uses hierarchical model selection with information criteria to provide competitive performance in both image-level classification and dense-prediction tasks, and even supports out-of-the-box raster-to-vector conversion.",
    "authors": [
      "Marius Aasan",
      "Martine Hjelkrem-Tan",
      "Nico Catalano",
      "Changkyu Choi",
      "Adín Ramírez Rivera"
    ],
    "categories": [
      "cs.CV",
      "68T45",
      "I.2.10; I.4.10; I.4.6; I.3.8"
    ],
    "published": "2025-11-04",
    "url": "https://arxiv.org/abs/2511.02652v1",
    "pdf_url": "https://arxiv.org/pdf/2511.02652v1.pdf",
    "date": "2025-11-05",
    "source": "arxiv",
    "research_score": 0.46
  }
]