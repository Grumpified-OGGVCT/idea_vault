[
  {
    "arxiv_id": "2511.04485v1",
    "title": "Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank   Training",
    "summary": "Parameter-efficient training, based on low-rank optimization, has become a highly successful tool for fine-tuning large deep-learning models. However, these methods fail at low-rank pre-training tasks where maintaining the low-rank structure and the objective remains a challenging task. We propose the Quadratic Reweighted Rank Regularizer dubbed Q3R, which leads to a novel low-rank inducing training strategy inspired by the iteratively reweighted least squares (IRLS) framework. Q3R is based on a quadratic regularizer term which majorizes a smoothed log determinant serving as rank surrogate objective. Unlike other low-rank training techniques, Q3R is able to train weight matrices with prescribed, low target ranks of models that achieve comparable predictive performance as dense models, with small computational overhead, while remaining fully compatible with existing architectures. For example, we demonstrated one experiment where we are able to truncate $60\\%$ and $80\\%$ of the parameters of a ViT-Tiny model with $~1.3\\%$ and $~4\\%$ accuracy drop in CIFAR-10 performance respectively. The efficacy of Q3R is confirmed on Transformers across both image and language tasks, including for low-rank fine-tuning.",
    "authors": [
      "Ipsita Ghosh",
      "Ethan Nguyen",
      "Christian Kümmerle"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04485v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04485v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.93
  },
  {
    "arxiv_id": "2511.04588v1",
    "title": "Question the Questions: Auditing Representation in Online Deliberative   Processes",
    "summary": "A central feature of many deliberative processes, such as citizens' assemblies and deliberative polls, is the opportunity for participants to engage directly with experts. While participants are typically invited to propose questions for expert panels, only a limited number can be selected due to time constraints. This raises the challenge of how to choose a small set of questions that best represent the interests of all participants. We introduce an auditing framework for measuring the level of representation provided by a slate of questions, based on the social choice concept known as justified representation (JR). We present the first algorithms for auditing JR in the general utility setting, with our most efficient algorithm achieving a runtime of $O(mn\\log n)$, where $n$ is the number of participants and $m$ is the number of proposed questions. We apply our auditing methods to historical deliberations, comparing the representativeness of (a) the actual questions posed to the expert panel (chosen by a moderator), (b) participants' questions chosen via integer linear programming, (c) summary questions generated by large language models (LLMs). Our results highlight both the promise and current limitations of LLMs in supporting deliberative processes. By integrating our methods into an online deliberation platform that has been used for over hundreds of deliberations across more than 50 countries, we make it easy for practitioners to audit and improve representation in future deliberations.",
    "authors": [
      "Soham De",
      "Lodewijk Gelauff",
      "Ashish Goel",
      "Smitha Milli",
      "Ariel Procaccia",
      "Alice Siu"
    ],
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04588v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04588v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.9
  },
  {
    "arxiv_id": "2511.04681v1",
    "title": "Dark Energy Survey Year 3 results: Simulation-based $w$CDM inference   from weak lensing and galaxy clustering maps with deep learning. I. Analysis   design",
    "summary": "Data-driven approaches using deep learning are emerging as powerful techniques to extract non-Gaussian information from cosmological large-scale structure. This work presents the first simulation-based inference (SBI) pipeline that combines weak lensing and galaxy clustering maps in a realistic Dark Energy Survey Year 3 (DES Y3) configuration and serves as preparation for a forthcoming analysis of the survey data. We develop a scalable forward model based on the CosmoGridV1 suite of N-body simulations to generate over one million self-consistent mock realizations of DES Y3 at the map level. Leveraging this large dataset, we train deep graph convolutional neural networks on the full survey footprint in spherical geometry to learn low-dimensional features that approximately maximize mutual information with target parameters. These learned compressions enable neural density estimation of the implicit likelihood via normalizing flows in a ten-dimensional parameter space spanning cosmological $w$CDM, intrinsic alignment, and linear galaxy bias parameters, while marginalizing over baryonic, photometric redshift, and shear bias nuisances. To ensure robustness, we extensively validate our inference pipeline using synthetic observations derived from both systematic contaminations in our forward model and independent Buzzard galaxy catalogs. Our forecasts yield significant improvements in cosmological parameter constraints, achieving $2-3\\times$ higher figures of merit in the $\\Omega_m - S_8$ plane relative to our implementation of baseline two-point statistics and effectively breaking parameter degeneracies through probe combination. These results demonstrate the potential of SBI analyses powered by deep learning for upcoming Stage-IV wide-field imaging surveys.",
    "authors": [
      "A. Thomsen",
      "J. Bucko",
      "T. Kacprzak",
      "V. Ajani",
      "J. Fluri",
      "A. Refregier",
      "D. Anbajagane",
      "F. J. Castander",
      "A. Ferté",
      "M. Gatti",
      "N. Jeffrey",
      "A. Alarcon",
      "A. Amon",
      "K. Bechtol",
      "M. R. Becker",
      "G. M. Bernstein",
      "A. Campos",
      "A. Carnero Rosell",
      "C. Chang",
      "R. Chen",
      "A. Choi",
      "M. Crocce",
      "C. Davis",
      "J. DeRose",
      "S. Dodelson",
      "C. Doux",
      "K. Eckert",
      "J. Elvin-Poole",
      "S. Everett",
      "P. Fosalba",
      "D. Gruen",
      "I. Harrison",
      "K. Herner",
      "E. M. Huff",
      "M. Jarvis",
      "N. Kuropatkin",
      "P. -F. Leget",
      "N. MacCrann",
      "J. McCullough",
      "J. Myles",
      "A. Navarro-Alsina",
      "S. Pandey",
      "A. Porredon",
      "J. Prat",
      "M. Raveri",
      "M. Rodriguez-Monroy",
      "R. P. Rollins",
      "A. Roodman",
      "E. S. Rykoff",
      "C. Sánchez",
      "L. F. Secco",
      "E. Sheldon",
      "T. Shin",
      "M. A. Troxel",
      "I. Tutusaus",
      "T. N. Varga",
      "N. Weaverdyck",
      "R. H. Wechsler",
      "B. Yanny",
      "B. Yin",
      "Y. Zhang",
      "J. Zuntz",
      "S. Allam",
      "F. Andrade-Oliveira",
      "D. Bacon",
      "J. Blazek",
      "D. Brooks",
      "R. Camilleri",
      "J. Carretero",
      "R. Cawthon",
      "L. N. da Costa",
      "M. E. da Silva Pereira",
      "T. M. Davis",
      "J. De Vicente",
      "S. Desai",
      "P. Doel",
      "J. García-Bellido",
      "G. Gutierrez",
      "S. R. Hinton",
      "D. L. Hollowood",
      "K. Honscheid",
      "D. J. James",
      "K. Kuehn",
      "O. Lahav",
      "S. Lee",
      "J. L. Marshall",
      "J. Mena-Fernández",
      "F. Menanteau",
      "R. Miquel",
      "J. Muir",
      "R. L. C. Ogando",
      "A. A. Plazas Malagón",
      "E. Sanchez",
      "D. Sanchez Cid",
      "I. Sevilla-Noarbe",
      "M. Smith",
      "E. Suchyta",
      "M. E. C. Swanson",
      "D. Thomas",
      "C. To",
      "D. L. Tucker"
    ],
    "categories": [
      "astro-ph.CO",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04681v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04681v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.88
  },
  {
    "arxiv_id": "2511.04484v1",
    "title": "Online Algorithms for Repeated Optimal Stopping: Achieving Both   Competitive Ratio and Regret Bounds",
    "summary": "We study the repeated optimal stopping problem, which generalizes the classical optimal stopping problem with an unknown distribution to a setting where the same problem is solved repeatedly over $T$ rounds. In this framework, we aim to design algorithms that guarantee a competitive ratio in each round while also achieving sublinear regret across all rounds.   Our primary contribution is a general algorithmic framework that achieves these objectives simultaneously for a wide array of repeated optimal stopping problems. The core idea is to dynamically select an algorithm for each round, choosing between two candidates: (1) an empirically optimal algorithm derived from the history of observations, and (2) a sample-based algorithm with a proven competitive ratio guarantee. Based on this approach, we design an algorithm that performs no worse than the baseline sample-based algorithm in every round, while ensuring that the total regret is bounded by $\\tilde{O}(\\sqrt{T})$.   We demonstrate the broad applicability of our framework to canonical problems, including the prophet inequality, the secretary problem, and their variants under adversarial, random, and i.i.d. input models. For example, for the repeated prophet inequality problem, our method achieves a $1/2$-competitive ratio from the second round on and an $\\tilde{O}(\\sqrt{T})$ regret. Furthermore, we establish a regret lower bound of $\\Omega(\\sqrt{T})$ even in the i.i.d. model, confirming that our algorithm's performance is almost optimal with respect to the number of rounds.",
    "authors": [
      "Tsubasa Harada",
      "Yasushi Kawase",
      "Hanna Sumita"
    ],
    "categories": [
      "cs.DS",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04484v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04484v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.86
  },
  {
    "arxiv_id": "2511.04518v1",
    "title": "Comparing EPGP Surrogates and Finite Elements Under Degree-of-Freedom   Parity",
    "summary": "We present a new benchmarking study comparing a boundary-constrained Ehrenpreis--Palamodov Gaussian Process (B-EPGP) surrogate with a classical finite element method combined with Crank--Nicolson time stepping (CN-FEM) for solving the two-dimensional wave equation with homogeneous Dirichlet boundary conditions. The B-EPGP construction leverages exponential-polynomial bases derived from the characteristic variety to enforce the PDE and boundary conditions exactly and employs penalized least squares to estimate the coefficients. To ensure fairness across paradigms, we introduce a degrees-of-freedom (DoF) matching protocol. Under matched DoF, B-EPGP consistently attains lower space-time $L^2$-error and maximum-in-time $L^{2}$-error in space than CN-FEM, improving accuracy by roughly two orders of magnitude.",
    "authors": [
      "Obed Amo",
      "Samit Ghosh",
      "Markus Lange-Hegermann",
      "Bogdan Raiţă",
      "Michael Pokojovy"
    ],
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA",
      "stat.ML",
      "68T05, 62J07, 65M20, 65M60",
      "I.2.6; G.1.2; G.1.8"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04518v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04518v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.84
  },
  {
    "arxiv_id": "2511.04525v1",
    "title": "Learning from Single Timestamps: Complexity Estimation in Laparoscopic   Cholecystectomy",
    "summary": "Purpose: Accurate assessment of surgical complexity is essential in Laparoscopic Cholecystectomy (LC), where severe inflammation is associated with longer operative times and increased risk of postoperative complications. The Parkland Grading Scale (PGS) provides a clinically validated framework for stratifying inflammation severity; however, its automation in surgical videos remains largely unexplored, particularly in realistic scenarios where complete videos must be analyzed without prior manual curation. Methods: In this work, we introduce STC-Net, a novel framework for SingleTimestamp-based Complexity estimation in LC via the PGS, designed to operate under weak temporal supervision. Unlike prior methods limited to static images or manually trimmed clips, STC-Net operates directly on full videos. It jointly performs temporal localization and grading through a localization, window proposal, and grading module. We introduce a novel loss formulation combining hard and soft localization objectives and background-aware grading supervision. Results: Evaluated on a private dataset of 1,859 LC videos, STC-Net achieves an accuracy of 62.11% and an F1-score of 61.42%, outperforming non-localized baselines by over 10% in both metrics and highlighting the effectiveness of weak supervision for surgical complexity assessment. Conclusion: STC-Net demonstrates a scalable and effective approach for automated PGS-based surgical complexity estimation from full LC videos, making it promising for post-operative analysis and surgical training.",
    "authors": [
      "Dimitrios Anastasiou",
      "Santiago Barbarisi",
      "Lucy Culshaw",
      "Jayna Patel",
      "Evangelos B. Mazomenos",
      "Imanol Luengo",
      "Danail Stoyanov"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04525v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04525v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.83
  },
  {
    "arxiv_id": "2511.04643v1",
    "title": "When retrieval outperforms generation: Dense evidence retrieval for   scalable fake news detection",
    "summary": "The proliferation of misinformation necessitates robust yet computationally efficient fact verification systems. While current state-of-the-art approaches leverage Large Language Models (LLMs) for generating explanatory rationales, these methods face significant computational barriers and hallucination risks in real-world deployments. We present DeReC (Dense Retrieval Classification), a lightweight framework that demonstrates how general-purpose text embeddings can effectively replace autoregressive LLM-based approaches in fact verification tasks. By combining dense retrieval with specialized classification, our system achieves better accuracy while being significantly more efficient. DeReC outperforms explanation-generating LLMs in efficiency, reducing runtime by 95% on RAWFC (23 minutes 36 seconds compared to 454 minutes 12 seconds) and by 92% on LIAR-RAW (134 minutes 14 seconds compared to 1692 minutes 23 seconds), showcasing its effectiveness across varying dataset sizes. On the RAWFC dataset, DeReC achieves an F1 score of 65.58%, surpassing the state-of-the-art method L-Defense (61.20%). Our results demonstrate that carefully engineered retrieval-based systems can match or exceed LLM performance in specialized tasks while being significantly more practical for real-world deployment.",
    "authors": [
      "Alamgir Munir Qazi",
      "John P. McCrae",
      "Jamal Abdul Nasir"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04643v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04643v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.04570v1",
    "title": "Thinking with Video: Video Generation as a Promising Multimodal   Reasoning Paradigm",
    "summary": "\"Thinking with Text\" and \"Thinking with Images\" paradigm significantly improve the reasoning ability of large language models (LLMs) and Vision Language Models (VLMs). However, these paradigms have inherent limitations. (1) Images capture only single moments and fail to represent dynamic processes or continuous changes, and (2) The separation of text and vision as distinct modalities, hindering unified multimodal understanding and generation. To overcome these limitations, we introduce \"Thinking with Video\", a new paradigm that leverages video generation models, such as Sora-2, to bridge visual and textual reasoning in a unified temporal framework. To support this exploration, we developed the Video Thinking Benchmark (VideoThinkBench). VideoThinkBench encompasses two task categories: (1) vision-centric tasks (e.g., Eyeballing Puzzles), and (2) text-centric tasks (e.g., subsets of GSM8K, MMMU). Our evaluation establishes Sora-2 as a capable reasoner. On vision-centric tasks, Sora-2 is generally comparable to state-of-the-art (SOTA) VLMs, and even surpasses VLMs on several tasks, such as Eyeballing Games. On text-centric tasks, Sora-2 achieves 92% accuracy on MATH, and 75.53% accuracy on MMMU. Furthermore, we systematically analyse the source of these abilities. We also find that self-consistency and in-context learning can improve Sora-2's performance. In summary, our findings demonstrate that the video generation model is the potential unified multimodal understanding and generation model, positions \"thinking with video\" as a unified multimodal reasoning paradigm.",
    "authors": [
      "Jingqi Tong",
      "Yurong Mou",
      "Hangcheng Li",
      "Mingzhe Li",
      "Yongzhuo Yang",
      "Ming Zhang",
      "Qiguang Chen",
      "Tianyi Liang",
      "Xiaomeng Hu",
      "Yining Zheng",
      "Xinchi Chen",
      "Jun Zhao",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04570v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04570v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.04161v1",
    "title": "Seeing Straight: Document Orientation Detection for Efficient OCR",
    "summary": "Despite significant advances in document understanding, determining the correct orientation of scanned or photographed documents remains a critical pre-processing step in the real world settings. Accurate rotation correction is essential for enhancing the performance of downstream tasks such as Optical Character Recognition (OCR) where misalignment commonly arises due to user errors, particularly incorrect base orientations of the camera during capture. In this study, we first introduce OCR-Rotation-Bench (ORB), a new benchmark for evaluating OCR robustness to image rotations, comprising (i) ORB-En, built from rotation-transformed structured and free-form English OCR datasets, and (ii) ORB-Indic, a novel multilingual set spanning 11 Indic mid to low-resource languages. We also present a fast, robust and lightweight rotation classification pipeline built on the vision encoder of Phi-3.5-Vision model with dynamic image cropping, fine-tuned specifically for 4-class rotation task in a standalone fashion. Our method achieves near-perfect 96% and 92% accuracy on identifying the rotations respectively on both the datasets. Beyond classification, we demonstrate the critical role of our module in boosting OCR performance: closed-source (up to 14%) and open-weights models (up to 4x) in the simulated real-world setting.",
    "authors": [
      "Suranjan Goswami",
      "Abhinav Ravi",
      "Raja Kolla",
      "Ali Faraz",
      "Shaharukh Khan",
      " Akash",
      "Chandra Khatri",
      "Shubham Agarwal"
    ],
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04161v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04161v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.04522v1",
    "title": "End-to-End Reinforcement Learning of Koopman Models for eNMPC of an Air   Separation Unit",
    "summary": "With our recently proposed method based on reinforcement learning (Mayfrank et al. (2024), Comput. Chem. Eng. 190), Koopman surrogate models can be trained for optimal performance in specific (economic) nonlinear model predictive control ((e)NMPC) applications. So far, our method has exclusively been demonstrated on a small-scale case study. Herein, we show that our method scales well to a more challenging demand response case study built on a large-scale model of a single-product (nitrogen) air separation unit. Across all numerical experiments, we assume observability of only a few realistically measurable plant variables. Compared to a purely system identification-based Koopman eNMPC, which generates small economic savings but frequently violates constraints, our method delivers similar economic performance while avoiding constraint violations.",
    "authors": [
      "Daniel Mayfrank",
      "Kayra Dernek",
      "Laura Lang",
      "Alexander Mitsos",
      "Manuel Dahmen"
    ],
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04522v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04522v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.77
  },
  {
    "arxiv_id": "2511.04214v1",
    "title": "Block Rotation is All You Need for MXFP4 Quantization",
    "summary": "Large language models (LLMs) have achieved remarkable success, but their rapidly growing scale imposes prohibitive costs in memory, computation, and energy. Post-training quantization (PTQ) is a promising solution for efficient deployment, yet achieving accurate W4A4 quantization remains an open challenge. While most existing methods are designed for INT4 formats, the emergence of MXFP4 -- a new FP4 format with various hardware support (NVIDIA, AMD, Intel)-- raises questions about the applicability of current techniques. In this work, we establish a comprehensive benchmark of PTQ methods under the MXFP4 format. Through systematic evaluation, we find that methods like GPTQ consistently deliver strong performance, whereas rotation-based approaches, which are almost used by all state-of-the-art approaches, suffer from severe incompatibility with MXFP4. We further provide the first in-depth analysis of this conflict, tracing its root to a fundamental mismatch between MXFP4's PoT (power-of-two) block scaling and the redistribution of outlier energy via global rotation. Building on this insight, we propose a simple yet effective block rotation strategy that adapts rotation-based methods to MXFP4, leading to substantial accuracy improvements across diverse LLMs. Our findings not only offer clear guidance for practitioners but also set a foundation for advancing PTQ research under emerging low-precision formats.",
    "authors": [
      "Yuantian Shao",
      "Peisong Wang",
      "Yuanteng Chen",
      "Chang Xu",
      "Zhihui Wei",
      "Jian Cheng"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04214v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04214v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2511.04162v1",
    "title": "ScaleDL: Towards Scalable and Efficient Runtime Prediction for   Distributed Deep Learning Workloads",
    "summary": "Deep neural networks (DNNs) form the cornerstone of modern AI services, supporting a wide range of applications, including autonomous driving, chatbots, and recommendation systems. As models increase in size and complexity, DNN workloads like training and inference tasks impose unprecedented demands on distributed computing resources, making the accurate prediction of runtime essential for optimizing development and resource allocation. Traditional methods rely on additive computational unit models, limiting their accuracy and generalizability. In contrast, graph-enhanced modeling improves performance but significantly increases data collection costs. Therefore, there is a critical need for a method that strikes a balance between accuracy, generalizability, and the costs of data collection. To address these challenges, we propose ScaleDL, a novel runtime prediction framework that combines nonlinear layer-wise modeling with graph neural network (GNN)-based cross-layer interaction mechanism, enabling accurate DNN runtime prediction and hierarchical generalizability across different network architectures. Additionally, we employ the D-optimal method to reduce data collection costs. Experiments on the workloads of five popular DNN models prove that ScaleDL enhances runtime prediction accuracy and generalizability, achieving 6$\\times$ lower MRE and 5$\\times$ lower RMSE compared to baseline models.",
    "authors": [
      "Xiaokai Wang",
      "Shaoyuan Huang",
      "Yuting Li",
      "Xiaofei Wang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04162v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04162v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2511.04478v1",
    "title": "Generate, Evaluate, Iterate: Synthetic Data for Human-in-the-Loop   Refinement of LLM Judges",
    "summary": "The LLM-as-a-judge paradigm enables flexible, user-defined evaluation, but its effectiveness is often limited by the scarcity of diverse, representative data for refining criteria. We present a tool that integrates synthetic data generation into the LLM-as-a-judge workflow, empowering users to create tailored and challenging test cases with configurable domains, personas, lengths, and desired outcomes, including borderline cases. The tool also supports AI-assisted inline editing of existing test cases. To enhance transparency and interpretability, it reveals the prompts and explanations behind each generation. In a user study (N=24), 83% of participants preferred the tool over manually creating or selecting test cases, as it allowed them to rapidly generate diverse synthetic data without additional workload. The generated synthetic data proved as effective as hand-crafted data for both refining evaluation criteria and aligning with human preferences. These findings highlight synthetic data as a promising alternative, particularly in contexts where efficiency and scalability are critical.",
    "authors": [
      "Hyo Jin Do",
      "Zahra Ashktorab",
      "Jasmina Gajcin",
      "Erik Miehling",
      "Martín Santillán Cooper",
      "Qian Pan",
      "Elizabeth M. Daly",
      "Werner Geyer"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04478v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04478v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2511.04275v1",
    "title": "Online Conformal Inference with Retrospective Adjustment for Faster   Adaptation to Distribution Shift",
    "summary": "Conformal prediction has emerged as a powerful framework for constructing distribution-free prediction sets with guaranteed coverage assuming only the exchangeability assumption. However, this assumption is often violated in online environments where data distributions evolve over time. Several recent approaches have been proposed to address this limitation, but, typically, they slowly adapt to distribution shifts because they update predictions only in a forward manner, that is, they generate a prediction for a newly observed data point while previously computed predictions are not updated. In this paper, we propose a novel online conformal inference method with retrospective adjustment, which is designed to achieve faster adaptation to distributional shifts. Our method leverages regression approaches with efficient leave-one-out update formulas to retroactively adjust past predictions when new data arrive, thereby aligning the entire set of predictions with the most recent data distribution. Through extensive numerical studies performed on both synthetic and real-world data sets, we show that the proposed approach achieves faster coverage recalibration and improved statistical efficiency compared to existing online conformal prediction methods.",
    "authors": [
      "Jungbin Jun",
      "Ilsang Ohn"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04275v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04275v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.04215v1",
    "title": "Black-Box Guardrail Reverse-engineering Attack",
    "summary": "Large language models (LLMs) increasingly employ guardrails to enforce ethical, legal, and application-specific constraints on their outputs. While effective at mitigating harmful responses, these guardrails introduce a new class of vulnerabilities by exposing observable decision patterns. In this work, we present the first study of black-box LLM guardrail reverse-engineering attacks. We propose Guardrail Reverse-engineering Attack (GRA), a reinforcement learning-based framework that leverages genetic algorithm-driven data augmentation to approximate the decision-making policy of victim guardrails. By iteratively collecting input-output pairs, prioritizing divergence cases, and applying targeted mutations and crossovers, our method incrementally converges toward a high-fidelity surrogate of the victim guardrail. We evaluate GRA on three widely deployed commercial systems, namely ChatGPT, DeepSeek, and Qwen3, and demonstrate that it achieves an rule matching rate exceeding 0.92 while requiring less than $85 in API costs. These findings underscore the practical feasibility of guardrail extraction and highlight significant security risks for current LLM safety mechanisms. Our findings expose critical vulnerabilities in current guardrail designs and highlight the urgent need for more robust defense mechanisms in LLM deployment.",
    "authors": [
      "Hongwei Yao",
      "Yun Xia",
      "Shuo Shao",
      "Haoran Shi",
      "Tong Qiao",
      "Cong Wang"
    ],
    "categories": [
      "cs.CR",
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04215v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04215v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2511.04652v1",
    "title": "Polarization-resolved imaging improves eye tracking",
    "summary": "Polarization-resolved near-infrared imaging adds a useful optical contrast mechanism to eye tracking by measuring the polarization state of light reflected by ocular tissues in addition to its intensity. In this paper we demonstrate how this contrast can be used to enable eye tracking. Specifically, we demonstrate that a polarization-enabled eye tracking (PET) system composed of a polarization--filter--array camera paired with a linearly polarized near-infrared illuminator can reveal trackable features across the sclera and gaze-informative patterns on the cornea, largely absent in intensity-only images. Across a cohort of 346 participants, convolutional neural network based machine learning models trained on data from PET reduced the median 95th-percentile absolute gaze error by 10--16\\% relative to capacity-matched intensity baselines under nominal conditions and in the presence of eyelid occlusions, eye-relief changes, and pupil-size variation. These results link light--tissue polarization effects to practical gains in human--computer interaction and position PET as a simple, robust sensing modality for future wearable devices.",
    "authors": [
      "Mantas Žurauskas",
      "Tom Bu",
      "Sanaz Alali",
      "Beyza Kalkanli",
      "Derek Shi",
      "Fernando Alamos",
      "Gauresh Pandit",
      "Christopher Mei",
      "Ali Behrooz",
      "Ramin Mirjalili",
      "Dave Stronks",
      "Alexander Fix",
      "Dmitri Model"
    ],
    "categories": [
      "cs.CV",
      "physics.optics"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04652v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04652v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.04401v1",
    "title": "Spurious Correlation-Aware Embedding Regularization for Worst-Group   Robustness",
    "summary": "Deep learning models achieve strong performance across various domains but often rely on spurious correlations, making them vulnerable to distribution shifts. This issue is particularly severe in subpopulation shift scenarios, where models struggle in underrepresented groups. While existing methods have made progress in mitigating this issue, their performance gains are still constrained. They lack a rigorous theoretical framework connecting the embedding space representations with worst-group error. To address this limitation, we propose Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness (SCER), a novel approach that directly regularizes feature representations to suppress spurious cues. We show theoretically that worst-group error is influenced by how strongly the classifier relies on spurious versus core directions, identified from differences in group-wise mean embeddings across domains and classes. By imposing theoretical constraints at the embedding level, SCER encourages models to focus on core features while reducing sensitivity to spurious patterns. Through systematic evaluation on multiple vision and language, we show that SCER outperforms prior state-of-the-art studies in worst-group accuracy. Our code is available at \\href{https://github.com/MLAI-Yonsei/SCER}{https://github.com/MLAI-Yonsei/SCER}.",
    "authors": [
      "Subeen Park",
      "Joowang Kim",
      "Hakyung Lee",
      "Sunjae Yoo",
      "Kyungwoo Song"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04401v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04401v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.04114v1",
    "title": "Automated and Explainable Denial of Service Analysis for AI-Driven   Intrusion Detection Systems",
    "summary": "With the increasing frequency and sophistication of Distributed Denial of Service (DDoS) attacks, it has become critical to develop more efficient and interpretable detection methods. Traditional detection systems often struggle with scalability and transparency, hindering real-time response and understanding of attack vectors. This paper presents an automated framework for detecting and interpreting DDoS attacks using machine learning (ML). The proposed method leverages the Tree-based Pipeline Optimization Tool (TPOT) to automate the selection and optimization of ML models and features, reducing the need for manual experimentation. SHapley Additive exPlanations (SHAP) is incorporated to enhance model interpretability, providing detailed insights into the contribution of individual features to the detection process. By combining TPOT's automated pipeline selection with SHAP interpretability, this approach improves the accuracy and transparency of DDoS detection. Experimental results demonstrate that key features such as mean backward packet length and minimum forward packet header length are critical in detecting DDoS attacks, offering a scalable and explainable cybersecurity solution.",
    "authors": [
      "Paul Badu Yakubu",
      "Lesther Santana",
      "Mohamed Rahouti",
      "Yufeng Xin",
      "Abdellah Chehri",
      "Mohammed Aledhari"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04114v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04114v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.04079v1",
    "title": "Improving the Performance of Radiology Report De-identification with   Large-Scale Training and Benchmarking Against Cloud Vendor Methods",
    "summary": "Objective: To enhance automated de-identification of radiology reports by scaling transformer-based models through extensive training datasets and benchmarking performance against commercial cloud vendor systems for protected health information (PHI) detection. Materials and Methods: In this retrospective study, we built upon a state-of-the-art, transformer-based, PHI de-identification pipeline by fine-tuning on two large annotated radiology corpora from Stanford University, encompassing chest X-ray, chest CT, abdomen/pelvis CT, and brain MR reports and introducing an additional PHI category (AGE) into the architecture. Model performance was evaluated on test sets from Stanford and the University of Pennsylvania (Penn) for token-level PHI detection. We further assessed (1) the stability of synthetic PHI generation using a \"hide-in-plain-sight\" method and (2) performance against commercial systems. Precision, recall, and F1 scores were computed across all PHI categories. Results: Our model achieved overall F1 scores of 0.973 on the Penn dataset and 0.996 on the Stanford dataset, outperforming or maintaining the previous state-of-the-art model performance. Synthetic PHI evaluation showed consistent detectability (overall F1: 0.959 [0.958-0.960]) across 50 independently de-identified Penn datasets. Our model outperformed all vendor systems on synthetic Penn reports (overall F1: 0.960 vs. 0.632-0.754). Discussion: Large-scale, multimodal training improved cross-institutional generalization and robustness. Synthetic PHI generation preserved data utility while ensuring privacy. Conclusion: A transformer-based de-identification model trained on diverse radiology datasets outperforms prior academic and commercial systems in PHI detection and establishes a new benchmark for secure clinical text processing.",
    "authors": [
      "Eva Prakash",
      "Maayane Attias",
      "Pierre Chambon",
      "Justin Xu",
      "Steven Truong",
      "Jean-Benoit Delbrouck",
      "Tessa Cook",
      "Curtis Langlotz"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04079v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04079v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.04659v1",
    "title": "Nowcast3D: Reliable precipitation nowcasting via gray-box learning",
    "summary": "Extreme precipitation nowcasting demands high spatiotemporal fidelity and extended lead times, yet existing approaches remain limited. Numerical Weather Prediction (NWP) and its deep-learning emulations are too slow and coarse for rapidly evolving convection, while extrapolation and purely data-driven models suffer from error accumulation and excessive smoothing. Hybrid 2D radar-based methods discard crucial vertical information, preventing accurate reconstruction of height-dependent dynamics. We introduce a gray-box, fully three-dimensional nowcasting framework that directly processes volumetric radar reflectivity and couples physically constrained neural operators with datadriven learning. The model learns vertically varying 3D advection fields under a conservative advection operator, parameterizes spatially varying diffusion, and introduces a Brownian-motion--inspired stochastic term to represent unresolved motions. A residual branch captures small-scale convective initiation and microphysical variability, while a diffusion-based stochastic module estimates uncertainty. The framework achieves more accurate forecasts up to three-hour lead time across precipitation regimes and ranked first in 57\\% of cases in a blind evaluation by 160 meteorologists. By restoring full 3D dynamics with physical consistency, it offers a scalable and robust pathway for skillful and reliable nowcasting of extreme precipitation.",
    "authors": [
      "Huaguan Chen",
      "Wei Han",
      "Haofei Sun",
      "Ning Lin",
      "Xingtao Song",
      "Yunfan Yang",
      "Jie Tian",
      "Yang Liu",
      "Ji-Rong Wen",
      "Xiaoye Zhang",
      "Xueshun Shen",
      "Hao Sun"
    ],
    "categories": [
      "cs.LG",
      "physics.ao-ph"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04659v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04659v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.04555v1",
    "title": "Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic   Alignment",
    "summary": "Vision-Language-Action (VLA) models have emerged as a powerful framework that unifies perception, language, and control, enabling robots to perform diverse tasks through multimodal understanding. However, current VLA models typically contain massive parameters and rely heavily on large-scale robot data pretraining, leading to high computational costs during training, as well as limited deployability for real-time inference. Moreover, most training paradigms often degrade the perceptual representations of the vision-language backbone, resulting in overfitting and poor generalization to downstream tasks. In this work, we present Evo-1, a lightweight VLA model that reduces computation and improves deployment efficiency, while maintaining strong performance without pretraining on robot data. Evo-1 builds on a native multimodal Vision-Language model (VLM), incorporating a novel cross-modulated diffusion transformer along with an optimized integration module, together forming an effective architecture. We further introduce a two-stage training paradigm that progressively aligns action with perception, preserving the representations of the VLM. Notably, with only 0.77 billion parameters, Evo-1 achieves state-of-the-art results on the Meta-World and RoboTwin suite, surpassing the previous best models by 12.4% and 6.9%, respectively, and also attains a competitive result of 94.8% on LIBERO. In real-world evaluations, Evo-1 attains a 78% success rate with high inference frequency and low memory overhead, outperforming all baseline methods. We release code, data, and model weights to facilitate future research on lightweight and efficient VLA models.",
    "authors": [
      "Tao Lin",
      "Yilei Zhong",
      "Yuxin Du",
      "Jingjing Zhang",
      "Jiting Liu",
      "Yinxinyu Chen",
      "Encheng Gu",
      "Ziyan Liu",
      "Hongyi Cai",
      "Yanwen Zou",
      "Lixing Zou",
      "Zhaoye Zhou",
      "Gen Li",
      "Bo Zhao"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04555v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04555v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.04403v1",
    "title": "Online Bayesian Experimental Design for Partially Observed Dynamical   Systems",
    "summary": "Bayesian experimental design (BED) provides a principled framework for optimizing data collection, but existing approaches do not apply to crucial real-world settings such as dynamical systems with partial observability, where only noisy and incomplete observations are available. These systems are naturally modeled as state-space models (SSMs), where latent states mediate the link between parameters and data, making the likelihood -- and thus information-theoretic objectives like the expected information gain (EIG) -- intractable. In addition, the dynamical nature of the system requires online algorithms that update posterior distributions and select designs sequentially in a computationally efficient manner. We address these challenges by deriving new estimators of the EIG and its gradient that explicitly marginalize latent states, enabling scalable stochastic optimization in nonlinear SSMs. Our approach leverages nested particle filters (NPFs) for efficient online inference with convergence guarantees. Applications to realistic models, such as the susceptible-infected-recovered (SIR) and a moving source location task, show that our framework successfully handles both partial observability and online computation.",
    "authors": [
      "Sara Pérez-Vieites",
      "Sahel Iqbal",
      "Simo Särkkä",
      "Dominik Baumann"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.CO"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04403v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04403v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.04237v1",
    "title": "Denoised Recommendation Model with Collaborative Signal Decoupling",
    "summary": "Although the collaborative filtering (CF) algorithm has achieved remarkable performance in recommendation systems, it suffers from suboptimal recommendation performance due to noise in the user-item interaction matrix. Numerous noise-removal studies have improved recommendation models, but most existing approaches conduct denoising on a single graph. This may cause attenuation of collaborative signals: removing edges between two nodes can interrupt paths between other nodes, weakening path-dependent collaborative information. To address these limitations, this study proposes a novel GNN-based CF model called DRCSD for denoising unstable interactions. DRCSD includes two core modules: a collaborative signal decoupling module (decomposes signals into distinct orders by structural characteristics) and an order-wise denoising module (performs targeted denoising on each order). Additionally, the information aggregation mechanism of traditional GNN-based CF models is modified to avoid cross-order signal interference until the final pooling operation. Extensive experiments on three public real-world datasets show that DRCSD has superior robustness against unstable interactions and achieves statistically significant performance improvements in recommendation accuracy metrics compared to state-of-the-art baseline models.",
    "authors": [
      "Zefeng Li",
      "Ning Yang"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04237v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04237v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.04092v1",
    "title": "An Automated Theorem Generator with Theoretical Foundation Based on   Rectangular Standard Contradiction",
    "summary": "Currently, there is a lack of rigorous theoretical system for systematically generating non-trivial and logically valid theorems. Addressing this critical gap, this paper conducts research to propose a novel automated theorem generation theory and tool. Based on the concept of standard contradiction which possesses unique deductive advantages, this paper defines and proves, for the first time, a new logical structure known as rectangular standard contradiction. Centered on this structure, a complete Automated Theorem Generation (ATG) theory is put forward. Theoretical proofs clarify two core properties of rectangular standard contradiction: first, it is a standard contradiction (necessarily unsatisfiable); second, it exhibits non-redundancy (the remaining clause set becomes satisfiable after removing any clause). Leveraging these properties, this paper proves that partitioning a rectangular standard contradiction into a premise subset $A$ and negation of its complement $H$, a valid theorem $A \\vdash \\neg H$ can be formed, and all such theorems are logically equivalent. To implement this theory, an efficient template-based ATG algorithm is designed, and a Rectangular Automated Theorem Generator is developed. This research enables machines to transition from \"verifiers\" to \"discoverers\", opening up new avenues for fundamental research in the fields of logic and artificial intelligence.",
    "authors": [
      "Yang Xu",
      "Peiyao Liu",
      "Shuwei Chen",
      "Jun Liu"
    ],
    "categories": [
      "cs.LO",
      "cs.AI",
      "math.LO"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04092v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04092v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.04063v1",
    "title": "DartQuant: Efficient Rotational Distribution Calibration for LLM   Quantization",
    "summary": "Quantization plays a crucial role in accelerating the inference of large-scale models, and rotational matrices have been shown to effectively improve quantization performance by smoothing outliers. However, end-to-end fine-tuning of rotational optimization algorithms incurs high computational costs and is prone to overfitting. To address this challenge, we propose an efficient distribution-aware rotational calibration method, DartQuant, which reduces the complexity of rotational optimization by constraining the distribution of the activations after rotation. This approach also effectively reduces reliance on task-specific losses, thereby mitigating the risk of overfitting. Additionally, we introduce the QR-Orth optimization scheme, which replaces expensive alternating optimization with a more efficient solution. In a variety of model quantization experiments, DartQuant demonstrates superior performance. Compared to existing methods, it achieves 47$\\times$ acceleration and 10$\\times$ memory savings for rotational optimization on a 70B model. Furthermore, it is the first to successfully complete rotational calibration for a 70B model on a single 3090 GPU, making quantization of large language models feasible in resource-constrained environments. Code is available at https://github.com/CAS-CLab/DartQuant.git.",
    "authors": [
      "Yuantian Shao",
      "Yuanteng Chen",
      "Peisong Wang",
      "Jianlin Yu",
      "Jing Lin",
      "Yiwu Yao",
      "Zhihui Wei",
      "Jian Cheng"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04063v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04063v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.04128v1",
    "title": "DMSORT: An efficient parallel maritime multi-object tracking   architecture for unmanned vessel platforms",
    "summary": "Accurate perception of the marine environment through robust multi-object tracking (MOT) is essential for ensuring safe vessel navigation and effective maritime surveillance. However, the complicated maritime environment often causes camera motion and subsequent visual degradation, posing significant challenges to MOT. To address this challenge, we propose an efficient Dual-branch Maritime SORT (DMSORT) method for maritime MOT. The core of the framework is a parallel tracker with affine compensation, which incorporates an object detection and re-identification (ReID) branch, along with a dedicated branch for dynamic camera motion estimation. Specifically, a Reversible Columnar Detection Network (RCDN) is integrated into the detection module to leverage multi-level visual features for robust object detection. Furthermore, a lightweight Transformer-based appearance extractor (Li-TAE) is designed to capture global contextual information and generate robust appearance features. Another branch decouples platform-induced and target-intrinsic motion by constructing a projective transformation, applying platform-motion compensation within the Kalman filter, and thereby stabilizing true object trajectories. Finally, a clustering-optimized feature fusion module effectively combines motion and appearance cues to ensure identity consistency under noise, occlusion, and drift. Extensive evaluations on the Singapore Maritime Dataset demonstrate that DMSORT achieves state-of-the-art performance. Notably, DMSORT attains the fastest runtime among existing ReID-based MOT frameworks while maintaining high identity consistency and robustness to jitter and occlusion. Code is available at: https://github.com/BiscuitsLzy/DMSORT-An-efficient-parallel-maritime-multi-object-tracking-architecture-.",
    "authors": [
      "Shengyu Tang",
      "Zeyuan Lu",
      "Jiazhi Dong",
      "Changdong Yu",
      "Xiaoyu Wang",
      "Yaohui Lyu",
      "Weihao Xia"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04128v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04128v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.04594v1",
    "title": "Regret Lower Bounds for Decentralized Multi-Agent Stochastic Shortest   Path Problems",
    "summary": "Multi-agent systems (MAS) are central to applications such as swarm robotics and traffic routing, where agents must coordinate in a decentralized manner to achieve a common objective. Stochastic Shortest Path (SSP) problems provide a natural framework for modeling decentralized control in such settings. While the problem of learning in SSP has been extensively studied in single-agent settings, the decentralized multi-agent variant remains largely unexplored. In this work, we take a step towards addressing that gap. We study decentralized multi-agent SSPs (Dec-MASSPs) under linear function approximation, where the transition dynamics and costs are represented using linear models. Applying novel symmetry-based arguments, we identify the structure of optimal policies. Our main contribution is the first regret lower bound for this setting based on the construction of hard-to-learn instances for any number of agents, $n$. Our regret lower bound of $\\Omega(\\sqrt{K})$, over $K$ episodes, highlights the inherent learning difficulty in Dec-MASSPs. These insights clarify the learning complexity of decentralized control and can further guide the design of efficient learning algorithms in multi-agent systems.",
    "authors": [
      "Utkarsh U. Chavan",
      "Prashant Trivedi",
      "Nandyala Hemachandra"
    ],
    "categories": [
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04594v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04594v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.04445v1",
    "title": "ForecastGAN: A Decomposition-Based Adversarial Framework for   Multi-Horizon Time Series Forecasting",
    "summary": "Time series forecasting is essential across domains from finance to supply chain management. This paper introduces ForecastGAN, a novel decomposition based adversarial framework addressing limitations in existing approaches for multi-horizon predictions. Although transformer models excel in long-term forecasting, they often underperform in short-term scenarios and typically ignore categorical features. ForecastGAN operates through three integrated modules: a Decomposition Module that extracts seasonality and trend components; a Model Selection Module that identifies optimal neural network configurations based on forecasting horizon; and an Adversarial Training Module that enhances prediction robustness through Conditional Generative Adversarial Network training. Unlike conventional approaches, ForecastGAN effectively integrates both numerical and categorical features. We validate our framework on eleven benchmark multivariate time series datasets that span various forecasting horizons. The results show that ForecastGAN consistently outperforms state-of-the-art transformer models for short-term forecasting while remaining competitive for long-term horizons. This research establishes a more generalizable approach to time series forecasting that adapts to specific contexts while maintaining strong performance across diverse data characteristics without extensive hyperparameter tuning.",
    "authors": [
      "Syeda Sitara Wishal Fatima",
      "Afshin Rahimi"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04445v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04445v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.04376v1",
    "title": "MusRec: Zero-Shot Text-to-Music Editing via Rectified Flow and Diffusion   Transformers",
    "summary": "Music editing has emerged as an important and practical area of artificial intelligence, with applications ranging from video game and film music production to personalizing existing tracks according to user preferences. However, existing models face significant limitations, such as being restricted to editing synthesized music generated by their own models, requiring highly precise prompts, or necessitating task-specific retraining, thus lacking true zero-shot capability. Leveraging recent advances in rectified flow and diffusion transformers, we introduce MusRec, the first zero-shot text-to-music editing model capable of performing diverse editing tasks on real-world music efficiently and effectively. Experimental results demonstrate that our approach outperforms existing methods in preserving musical content, structural consistency, and editing fidelity, establishing a strong foundation for controllable music editing in real-world scenarios.",
    "authors": [
      "Ali Boudaghi",
      "Hadi Zare"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04376v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04376v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.04334v1",
    "title": "Submanifold Sparse Convolutional Networks for Automated 3D Segmentation   of Kidneys and Kidney Tumours in Computed Tomography",
    "summary": "The accurate delineation of tumours in radiological images like Computed Tomography is a very specialised and time-consuming task, and currently a bottleneck preventing quantitative analyses to be performed routinely in the clinical setting. For this reason, developing methods for the automated segmentation of tumours in medical imaging is of the utmost importance and has driven significant efforts in recent years. However, challenges regarding the impracticality of 3D scans, given the large amount of voxels to be analysed, usually requires the downsampling of such images or using patches thereof when applying traditional convolutional neural networks. To overcome this problem, in this paper we propose a new methodology that uses, divided into two stages, voxel sparsification and submanifold sparse convolutional networks. This method allows segmentations to be performed with high-resolution inputs and a native 3D model architecture, obtaining state-of-the-art accuracies while significantly reducing the computational resources needed in terms of GPU memory and time. We studied the deployment of this methodology in the context of Computed Tomography images of renal cancer patients from the KiTS23 challenge, and our method achieved results competitive with the challenge winners, with Dice similarity coefficients of 95.8% for kidneys + masses, 85.7% for tumours + cysts, and 80.3% for tumours alone. Crucially, our method also offers significant computational improvements, achieving up to a 60% reduction in inference time and up to a 75\\% reduction in VRAM usage compared to an equivalent dense architecture, across both CPU and various GPU cards tested.",
    "authors": [
      "Saúl Alonso-Monsalve",
      "Leigh H. Whitehead",
      "Adam Aurisano",
      "Lorena Escudero Sanchez"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04334v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04334v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.04255v1",
    "title": "MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection",
    "summary": "This paper does not introduce a novel architecture; instead, it revisits a fundamental yet overlooked baseline: adapting human-centric foundation models for anatomical landmark detection in medical imaging. While landmark detection has traditionally relied on domain-specific models, the emergence of large-scale pre-trained vision models presents new opportunities. In this study, we investigate the adaptation of Sapiens, a human-centric foundation model designed for pose estimation, to medical imaging through multi-dataset pretraining, establishing a new state of the art across multiple datasets. Our proposed model, MedSapiens, demonstrates that human-centric foundation models, inherently optimized for spatial pose localization, provide strong priors for anatomical landmark detection, yet this potential has remained largely untapped. We benchmark MedSapiens against existing state-of-the-art models, achieving up to 5.26% improvement over generalist models and up to 21.81% improvement over specialist models in the average success detection rate (SDR). To further assess MedSapiens adaptability to novel downstream tasks with few annotations, we evaluate its performance in limited-data settings, achieving 2.69% improvement over the few-shot state of the art in SDR. Code and model weights are available at https://github.com/xmed-lab/MedSapiens .",
    "authors": [
      "Marawan Elbatel",
      "Anbang Wang",
      "Keyuan Liu",
      "Kaouther Mouheb",
      "Enrique Almar-Munoz",
      "Lizhuo Lin",
      "Yanqi Yang",
      "Karim Lekadir",
      "Xiaomeng Li"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04255v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04255v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.04108v1",
    "title": "Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How   Batch Prompting Suppresses Overthinking in Reasoning Models",
    "summary": "Recent work has explored batch prompting as a strategy to amortize inference cost in large language models (LLMs). In this paper, we show that batching offers an additional, underappreciated benefit: it regularizes model behavior during multi-step reasoning for Large Reasoning Models (LRMs). We conduct a comprehensive study across 13 diverse benchmarks and observe that batching improves accuracy while substantially reducing reasoning token usage, often by 3x-5x. Through detailed behavioral analysis, we find that batching suppresses overthinking, reduces hedging language (e.g., repetitive self-corrections), and encourages more decisive answers. Surprisingly, we also observe emergent collective effects in batched inference: models often generalize patterns from earlier examples to solve harder ones in the same batch. These findings position batching not just as a throughput optimization, but as a powerful inference-time regularizer for more efficient and reliable LLM reasoning.",
    "authors": [
      "Wenmo Qiu",
      "Saurabh Srivastava"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04108v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04108v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.04078v1",
    "title": "Unveiling Deep Semantic Uncertainty Perception for Language-Anchored   Multi-modal Vision-Brain Alignment",
    "summary": "Unveiling visual semantics from neural signals such as EEG, MEG, and fMRI remains a fundamental challenge due to subject variability and the entangled nature of visual features. Existing approaches primarily align neural activity directly with visual embeddings, but visual-only representations often fail to capture latent semantic dimensions, limiting interpretability and deep robustness. To address these limitations, we propose Bratrix, the first end-to-end framework to achieve multimodal Language-Anchored Vision-Brain alignment. Bratrix decouples visual stimuli into hierarchical visual and linguistic semantic components, and projects both visual and brain representations into a shared latent space, enabling the formation of aligned visual-language and brain-language embeddings. To emulate human-like perceptual reliability and handle noisy neural signals, Bratrix incorporates a novel uncertainty perception module that applies uncertainty-aware weighting during alignment. By leveraging learnable language-anchored semantic matrices to enhance cross-modal correlations and employing a two-stage training strategy of single-modality pretraining followed by multimodal fine-tuning, Bratrix-M improves alignment precision. Extensive experiments on EEG, MEG, and fMRI benchmarks demonstrate that Bratrix improves retrieval, reconstruction, and captioning performance compared to state-of-the-art methods, specifically surpassing 14.3% in 200-way EEG retrieval task. Code and model are available.",
    "authors": [
      "Zehui Feng",
      "Chenqi Zhang",
      "Mingru Wang",
      "Minuo Wei",
      "Shiwei Cheng",
      "Cuntai Guan",
      "Ting Han"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04078v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04078v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.04646v1",
    "title": "DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for   Embodied LLM-Based Multi-Agent Collaboration",
    "summary": "Cooperative multi-agent planning requires agents to make joint decisions with partial information and limited communication. Coordination at the trajectory level often fails, as small deviations in timing or movement cascade into conflicts. Symbolic planning mitigates this challenge by raising the level of abstraction and providing a minimal vocabulary of actions that enable synchronization and collective progress. We present DR. WELL, a decentralized neurosymbolic framework for cooperative multi-agent planning. Cooperation unfolds through a two-phase negotiation protocol: agents first propose candidate roles with reasoning and then commit to a joint allocation under consensus and environment constraints. After commitment, each agent independently generates and executes a symbolic plan for its role without revealing detailed trajectories. Plans are grounded in execution outcomes via a shared world model that encodes the current state and is updated as agents act. By reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids brittle step-level alignment and enables higher-level operations that are reusable, synchronizable, and interpretable. Experiments on cooperative block-push tasks show that agents adapt across episodes, with the dynamic world model capturing reusable patterns and improving task completion rates and efficiency. Experiments on cooperative block-push tasks show that our dynamic world model improves task completion and efficiency through negotiation and self-refinement, trading a time overhead for evolving, more efficient collaboration strategies.",
    "authors": [
      "Narjes Nourzad",
      "Hanqing Yang",
      "Shiyu Chen",
      "Carlee Joe-Wong"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04646v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04646v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.04557v1",
    "title": "Integrating Temporal and Structural Context in Graph Transformers for   Relational Deep Learning",
    "summary": "In domains such as healthcare, finance, and e-commerce, the temporal dynamics of relational data emerge from complex interactions-such as those between patients and providers, or users and products across diverse categories. To be broadly useful, models operating on these data must integrate long-range spatial and temporal dependencies across diverse types of entities, while also supporting multiple predictive tasks. However, existing graph models for relational data primarily focus on spatial structure, treating temporal information merely as a filtering constraint to exclude future events rather than a modeling signal, and are typically designed for single-task prediction. To address these gaps, we introduce a temporal subgraph sampler that enhances global context by retrieving nodes beyond the immediate neighborhood to capture temporally relevant relationships. In addition, we propose the Relational Graph Perceiver (RGP), a graph transformer architecture for relational deep learning that leverages a cross-attention-based latent bottleneck to efficiently integrate information from both structural and temporal contexts. This latent bottleneck integrates signals from different node and edge types into a common latent space, enabling the model to build global context across the entire relational system. RGP also incorporates a flexible cross-attention decoder that supports joint learning across tasks with disjoint label spaces within a single model. Experiments on RelBench, SALT, and CTU show that RGP delivers state-of-the-art performance, offering a general and scalable solution for relational deep learning with support for diverse predictive tasks.",
    "authors": [
      "Divyansha Lachi",
      "Mahmoud Mohammadi",
      "Joe Meyer",
      "Vinam Arora",
      "Tom Palczewski",
      "Eva L. Dyer"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04557v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04557v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.04454v1",
    "title": "Fitting Reinforcement Learning Model to Behavioral Data under Bandits",
    "summary": "We consider the problem of fitting a reinforcement learning (RL) model to some given behavioral data under a multi-armed bandit environment. These models have received much attention in recent years for characterizing human and animal decision making behavior. We provide a generic mathematical optimization problem formulation for the fitting problem of a wide range of RL models that appear frequently in scientific research applications, followed by a detailed theoretical analysis of its convexity properties. Based on the theoretical results, we introduce a novel solution method for the fitting problem of RL models based on convex relaxation and optimization. Our method is then evaluated in several simulated bandit environments to compare with some benchmark methods that appear in the literature. Numerical results indicate that our method achieves comparable performance to the state-of-the-art, while significantly reducing computation time. We also provide an open-source Python package for our proposed method to empower researchers to apply it in the analysis of their datasets directly, without prior knowledge of convex optimization.",
    "authors": [
      "Hao Zhu",
      "Jasper Hoffmann",
      "Baohe Zhang",
      "Joschka Boedecker"
    ],
    "categories": [
      "cs.CE",
      "cs.LG",
      "math.OC",
      "q-bio.NC",
      "90C25, 90C59, 90C90"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04454v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04454v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.04451v1",
    "title": "Deep Dictionary-Free Method for Identifying Linear Model of Nonlinear   System with Input Delay",
    "summary": "Nonlinear dynamical systems with input delays pose significant challenges for prediction, estimation, and control due to their inherent complexity and the impact of delays on system behavior. Traditional linear control techniques often fail in these contexts, necessitating innovative approaches. This paper introduces a novel approach to approximate the Koopman operator using an LSTM-enhanced Deep Koopman model, enabling linear representations of nonlinear systems with time delays. By incorporating Long Short-Term Memory (LSTM) layers, the proposed framework captures historical dependencies and efficiently encodes time-delayed system dynamics into a latent space. Unlike traditional extended Dynamic Mode Decomposition (eDMD) approaches that rely on predefined dictionaries, the LSTM-enhanced Deep Koopman model is dictionary-free, which mitigates the problems with the underlying dynamics being known and incorporated into the dictionary. Quantitative comparisons with extended eDMD on a simulated system demonstrate highly significant performance gains in prediction accuracy in cases where the true nonlinear dynamics are unknown and achieve comparable results to eDMD with known dynamics of a system.",
    "authors": [
      "Patrik Valábek",
      "Marek Wadinger",
      "Michal Kvasnica",
      "Martin Klaučo"
    ],
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04451v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04451v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.04426v1",
    "title": "HideAndSeg: an AI-based tool with automated prompting for octopus   segmentation in natural habitats",
    "summary": "Analyzing octopuses in their natural habitats is challenging due to their camouflage capability, rapid changes in skin texture and color, non-rigid body deformations, and frequent occlusions, all of which are compounded by variable underwater lighting and turbidity. Addressing the lack of large-scale annotated datasets, this paper introduces HideAndSeg, a novel, minimally supervised AI-based tool for segmenting videos of octopuses. It establishes a quantitative baseline for this task. HideAndSeg integrates SAM2 with a custom-trained YOLOv11 object detector. First, the user provides point coordinates to generate the initial segmentation masks with SAM2. These masks serve as training data for the YOLO model. After that, our approach fully automates the pipeline by providing a bounding box prompt to SAM2, eliminating the need for further manual intervention. We introduce two unsupervised metrics - temporal consistency $DICE_t$ and new component count $NC_t$ - to quantitatively evaluate segmentation quality and guide mask refinement in the absence of ground-truth data, i.e., real-world information that serves to train, validate, and test AI models. Results show that HideAndSeg achieves satisfactory performance, reducing segmentation noise compared to the manually prompted approach. Our method can re-identify and segment the octopus even after periods of complete occlusion in natural environments, a scenario in which the manually prompted model fails. By reducing the need for manual analysis in real-world scenarios, this work provides a practical tool that paves the way for more efficient behavioral studies of wild cephalopods.",
    "authors": [
      "Alan de Aguiar",
      "Michaella Pereira Andrade",
      "Charles Morphy D. Santos",
      "João Paulo Gois"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04426v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04426v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.04406v1",
    "title": "Dynamic Jointly Batch Selection for Data Efficient Machine Translation   Fine-Tuning",
    "summary": "Data quality and its effective selection are fundamental to improving the performance of machine translation models, serving as cornerstones for achieving robust and reliable translation systems. This paper presents a data selection methodology specifically designed for fine-tuning machine translation systems, which leverages the synergy between a learner model and a pre-trained reference model to enhance overall training effectiveness. By defining a learnability score, our approach systematically evaluates the utility of data points for training, ensuring that only the most relevant and impactful examples contribute to the fine-tuning process. Furthermore, our method employs a batch selection strategy which considers interdependencies among data points, optimizing the efficiency of the training process while maintaining a focus on data relevance. Experiments on English to Persian and several other language pairs using an mBART model fine-tuned on the CCMatrix dataset demonstrate that our method can achieve up to a fivefold improvement in data efficiency compared to an iid baseline. Experimental results indicate that our approach improves computational efficiency by 24 when utilizing cached embeddings, as it requires fewer training data points. Additionally, it enhances generalization, resulting in superior translation performance compared to random selection method.",
    "authors": [
      "Mohammad Amin Ghanizadeh",
      "Mohammad Javad Dousti"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04406v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04406v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.04309v1",
    "title": "DeepPAAC: A New Deep Galerkin Method for Principal-Agent Problems",
    "summary": "We consider numerical resolution of principal-agent (PA) problems in continuous time. We formulate a generic PA model with continuous and lump payments and a multi-dimensional strategy of the agent. To tackle the resulting Hamilton-Jacobi-Bellman equation with an implicit Hamiltonian we develop a novel deep learning method: the Deep Principal-Agent Actor Critic (DeepPAAC) Actor-Critic algorithm. DeepPAAC is able to handle multi-dimensional states and controls, as well as constraints. We investigate the role of the neural network architecture, training designs, loss functions, etc. on the convergence of the solver, presenting five different case studies.",
    "authors": [
      "Michael Ludkovski",
      "Changgen Xie",
      "Zimu Zhu"
    ],
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04309v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04309v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.04192v1",
    "title": "AStF: Motion Style Transfer via Adaptive Statistics Fusor",
    "summary": "Human motion style transfer allows characters to appear less rigidity and more realism with specific style. Traditional arbitrary image style transfer typically process mean and variance which is proved effective. Meanwhile, similar methods have been adapted for motion style transfer. However, due to the fundamental differences between images and motion, relying on mean and variance is insufficient to fully capture the complex dynamic patterns and spatiotemporal coherence properties of motion data. Building upon this, our key insight is to bring two more coefficient, skewness and kurtosis, into the analysis of motion style. Specifically, we propose a novel Adaptive Statistics Fusor (AStF) which consists of Style Disentanglement Module (SDM) and High-Order Multi-Statistics Attention (HOS-Attn). We trained our AStF in conjunction with a Motion Consistency Regularization (MCR) discriminator. Experimental results show that, by providing a more comprehensive model of the spatiotemporal statistical patterns inherent in dynamic styles, our proposed AStF shows proficiency superiority in motion style transfers over state-of-the-arts. Our code and model are available at https://github.com/CHMimilanlan/AStF.",
    "authors": [
      "Hanmo Chen",
      "Chenghao Xu",
      "Jiexi Yan",
      "Cheng Deng"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04192v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04192v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.04158v1",
    "title": "Deep Learning Approach for Clinical Risk Identification Using   Transformer Modeling of Heterogeneous EHR Data",
    "summary": "This study proposes a Transformer-based longitudinal modeling method to address challenges in clinical risk classification with heterogeneous Electronic Health Record (EHR) data, including irregular temporal patterns, large modality differences, and complex semantic structures. The method takes multi-source medical features as input and employs a feature embedding layer to achieve a unified representation of structured and unstructured data. A learnable temporal encoding mechanism is introduced to capture dynamic evolution under uneven sampling intervals. The core model adopts a multi-head self-attention structure to perform global dependency modeling on longitudinal sequences, enabling the aggregation of long-term trends and short-term fluctuations across different temporal scales. To enhance semantic representation, a semantic-weighted pooling module is designed to assign adaptive importance to key medical events, improving the discriminative ability of risk-related features. Finally, a linear mapping layer generates individual-level risk scores. Experimental results show that the proposed model outperforms traditional machine learning and temporal deep learning models in accuracy, recall, precision, and F1-Score, achieving stable and precise risk identification in multi-source heterogeneous EHR environments and providing an efficient and reliable framework for clinical intelligent decision-making.",
    "authors": [
      "Anzhuo Xie",
      "Wei-Chen Chang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04158v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04158v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.04601v1",
    "title": "PixCLIP: Achieving Fine-grained Visual Language Understanding via   Any-granularity Pixel-Text Alignment Learning",
    "summary": "While the Contrastive Language-Image Pretraining(CLIP) model has achieved remarkable success in a variety of downstream vison language understanding tasks, enhancing its capability for fine-grained image-text alignment remains an active research focus. To this end, most existing works adopt the strategy of explicitly increasing the granularity of visual information processing, e.g., incorporating visual prompts to guide the model focus on specific local regions within the image. Meanwhile, researches on Multimodal Large Language Models(MLLMs) have demonstrated that training with long and detailed textual descriptions can effectively improve the model's fine-grained vision-language alignment. However, the inherent token length limitation of CLIP's text encoder fundamentally limits CLIP to process more granular textual information embedded in long text sequences. To synergistically leverage the advantages of enhancing both visual and textual content processing granularity, we propose PixCLIP, a novel framework designed to concurrently accommodate visual prompt inputs and process lengthy textual descriptions. Specifically, we first establish an automated annotation pipeline capable of generating pixel-level localized, long-form textual descriptions for images. Utilizing this pipeline, we construct LongGRIT, a high-quality dataset comprising nearly 1.5 million samples. Secondly, we replace CLIP's original text encoder with the LLM and propose a three-branch pixel-text alignment learning framework, facilitating fine-grained alignment between image regions and corresponding textual descriptions at arbitrary granularity. Experiments demonstrate that PixCLIP showcases breakthroughs in pixel-level interaction and handling long-form texts, achieving state-of-the-art performance.",
    "authors": [
      "Yicheng Xiao",
      "Yu Chen",
      "Haoxuan Ma",
      "Jiale Hong",
      "Caorui Li",
      "Lingxiang Wu",
      "Haiyun Guo",
      "Jinqiao Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04601v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04601v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.04479v1",
    "title": "ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding   in Thai",
    "summary": "We present ThaiOCRBench, the first comprehensive benchmark for evaluating vision-language models (VLMs) on Thai text-rich visual understanding tasks. Despite recent progress in multimodal modeling, existing benchmarks predominantly focus on high-resource languages, leaving Thai underrepresented, especially in tasks requiring document structure understanding. ThaiOCRBench addresses this gap by offering a diverse, human-annotated dataset comprising 2,808 samples across 13 task categories. We evaluate a wide range of state-of-the-art VLMs in a zero-shot setting, spanning both proprietary and open-source systems. Results show a significant performance gap, with proprietary models (e.g., Gemini 2.5 Pro) outperforming open-source counterparts. Notably, fine-grained text recognition and handwritten content extraction exhibit the steepest performance drops among open-source models. Through detailed error analysis, we identify key challenges such as language bias, structural mismatch, and hallucinated content. ThaiOCRBench provides a standardized framework for assessing VLMs in low-resource, script-complex settings, and provides actionable insights for improving Thai-language document understanding.",
    "authors": [
      "Surapon Nonesung",
      "Teetouch Jaknamon",
      "Sirinya Chaiophat",
      "Natapong Nitarach",
      "Chanakan Wittayasakpan",
      "Warit Sirichotedumrong",
      "Adisai Na-Thalang",
      "Kunat Pipatanakul"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04479v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04479v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.04361v1",
    "title": "Causal Regime Detection in Energy Markets With Augmented Time Series   Structural Causal Models",
    "summary": "Energy markets exhibit complex causal relationships between weather patterns, generation technologies, and price formation, with regime changes occurring continuously rather than at discrete break points. Current approaches model electricity prices without explicit causal interpretation or counterfactual reasoning capabilities. We introduce Augmented Time Series Causal Models (ATSCM) for energy markets, extending counterfactual reasoning frameworks to multivariate temporal data with learned causal structure. Our approach models energy systems through interpretable factors (weather, generation mix, demand patterns), rich grid dynamics, and observable market variables. We integrate neural causal discovery to learn time-varying causal graphs without requiring ground truth DAGs. Applied to real-world electricity price data, ATSCM enables novel counterfactual queries such as \"What would prices be under different renewable generation scenarios?\".",
    "authors": [
      "Dennis Thumm"
    ],
    "categories": [
      "q-fin.CP",
      "cs.LG",
      "stat.OT"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04361v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04361v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.04260v1",
    "title": "Proto-LeakNet: Towards Signal-Leak Aware Attribution in Synthetic Human   Face Imagery",
    "summary": "The growing sophistication of synthetic image and deepfake generation models has turned source attribution and authenticity verification into a critical challenge for modern computer vision systems. Recent studies suggest that diffusion pipelines unintentionally imprint persistent statistical traces, known as signal leaks, within their outputs, particularly in latent representations. Building on this observation, we propose Proto-LeakNet, a signal-leak-aware and interpretable attribution framework that integrates closed-set classification with a density-based open-set evaluation on the learned embeddings, enabling analysis of unseen generators without retraining. Operating in the latent domain of diffusion models, our method re-simulates partial forward diffusion to expose residual generator-specific cues. A temporal attention encoder aggregates multi-step latent features, while a feature-weighted prototype head structures the embedding space and enables transparent attribution. Trained solely on closed data and achieving a Macro AUC of 98.13%, Proto-LeakNet learns a latent geometry that remains robust under post-processing, surpassing state-of-the-art methods, and achieves strong separability between known and unseen generators. These results demonstrate that modeling signal-leak bias in latent space enables reliable and interpretable AI-image and deepfake forensics. The code for the whole work will be available upon submission.",
    "authors": [
      "Claudio Giusti",
      "Luca Guarnera",
      "Sebastiano Battiato"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04260v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04260v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.04244v1",
    "title": "Guided by Stars: Interpretable Concept Learning Over Time Series via   Temporal Logic Semantics",
    "summary": "Time series classification is a task of paramount importance, as this kind of data often arises in safety-critical applications. However, it is typically tackled with black-box deep learning methods, making it hard for humans to understand the rationale behind their output. To take on this challenge, we propose a novel approach, STELLE (Signal Temporal logic Embedding for Logically-grounded Learning and Explanation), a neuro-symbolic framework that unifies classification and explanation through direct embedding of trajectories into a space of temporal logic concepts. By introducing a novel STL-inspired kernel that maps raw time series to their alignment with predefined STL formulae, our model jointly optimises accuracy and interpretability, as each prediction is accompanied by the most relevant logical concepts that characterise it. This yields (i) local explanations as human-readable STL conditions justifying individual predictions, and (ii) global explanations as class-characterising formulae. Experiments demonstrate that STELLE achieves competitive accuracy while providing logically faithful explanations, validated on diverse real-world benchmarks.",
    "authors": [
      "Irene Ferfoglia",
      "Simone Silvetti",
      "Gaia Saveri",
      "Laura Nenzi",
      "Luca Bortolussi"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04244v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04244v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.04228v1",
    "title": "REMIND: Input Loss Landscapes Reveal Residual Memorization in   Post-Unlearning LLMs",
    "summary": "Machine unlearning aims to remove the influence of specific training data from a model without requiring full retraining. This capability is crucial for ensuring privacy, safety, and regulatory compliance. Therefore, verifying whether a model has truly forgotten target data is essential for maintaining reliability and trustworthiness. However, existing evaluation methods often assess forgetting at the level of individual inputs. This approach may overlook residual influence present in semantically similar examples. Such influence can compromise privacy and lead to indirect information leakage. We propose REMIND (Residual Memorization In Neighborhood Dynamics), a novel evaluation method aiming to detect the subtle remaining influence of unlearned data and classify whether the data has been effectively forgotten. REMIND analyzes the model's loss over small input variations and reveals patterns unnoticed by single-point evaluations. We show that unlearned data yield flatter, less steep loss landscapes, while retained or unrelated data exhibit sharper, more volatile patterns. REMIND requires only query-based access, outperforms existing methods under similar constraints, and demonstrates robustness across different models, datasets, and paraphrased inputs, making it practical for real-world deployment. By providing a more sensitive and interpretable measure of unlearning effectiveness, REMIND provides a reliable framework to assess unlearning in language models. As a result, REMIND offers a novel perspective on memorization and unlearning.",
    "authors": [
      "Liran Cohen",
      "Yaniv Nemcovesky",
      "Avi Mendelson"
    ],
    "categories": [
      "cs.CL",
      "cs.LG",
      "I.2.7; I.2.6; K.4.1"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04228v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04228v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.04072v1",
    "title": "Plan of Knowledge: Retrieval-Augmented Large Language Models for   Temporal Knowledge Graph Question Answering",
    "summary": "Temporal Knowledge Graph Question Answering (TKGQA) aims to answer time-sensitive questions by leveraging factual information from Temporal Knowledge Graphs (TKGs). While previous studies have employed pre-trained TKG embeddings or graph neural networks to inject temporal knowledge, they fail to fully understand the complex semantic information of time constraints. Recently, Large Language Models (LLMs) have shown remarkable progress, benefiting from their strong semantic understanding and reasoning generalization capabilities. However, their temporal reasoning ability remains limited. LLMs frequently suffer from hallucination and a lack of knowledge. To address these limitations, we propose the Plan of Knowledge framework with a contrastive temporal retriever, which is named PoK. Specifically, the proposed Plan of Knowledge module decomposes a complex temporal question into a sequence of sub-objectives from the pre-defined tools, serving as intermediate guidance for reasoning exploration. In parallel, we construct a Temporal Knowledge Store (TKS) with a contrastive retrieval framework, enabling the model to selectively retrieve semantically and temporally aligned facts from TKGs. By combining structured planning with temporal knowledge retrieval, PoK effectively enhances the interpretability and factual consistency of temporal reasoning. Extensive experiments on four benchmark TKGQA datasets demonstrate that PoK significantly improves the retrieval precision and reasoning accuracy of LLMs, surpassing the performance of the state-of-the-art TKGQA methods by 56.0% at most.",
    "authors": [
      "Xinying Qian",
      "Ying Zhang",
      "Yu Zhao",
      "Baohang Zhou",
      "Xuhui Sui",
      "Xiaojie Yuan"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04072v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04072v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.04671v1",
    "title": "X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human   Demonstrations",
    "summary": "Human videos can be recorded quickly and at scale, making them an appealing source of training data for robot learning. However, humans and robots differ fundamentally in embodiment, resulting in mismatched action execution. Direct kinematic retargeting of human hand motion can therefore produce actions that are physically infeasible for robots. Despite these low-level differences, human demonstrations provide valuable motion cues about how to manipulate and interact with objects. Our key idea is to exploit the forward diffusion process: as noise is added to actions, low-level execution differences fade while high-level task guidance is preserved. We present X-Diffusion, a principled framework for training diffusion policies that maximally leverages human data without learning dynamically infeasible motions. X-Diffusion first trains a classifier to predict whether a noisy action is executed by a human or robot. Then, a human action is incorporated into policy training only after adding sufficient noise such that the classifier cannot discern its embodiment. Actions consistent with robot execution supervise fine-grained denoising at low noise levels, while mismatched human actions provide only coarse guidance at higher noise levels. Our experiments show that naive co-training under execution mismatches degrades policy performance, while X-Diffusion consistently improves it. Across five manipulation tasks, X-Diffusion achieves a 16% higher average success rate than the best baseline. The project website is available at https://portal-cornell.github.io/X-Diffusion/.",
    "authors": [
      "Maximus A. Pace",
      "Prithwish Dan",
      "Chuanruo Ning",
      "Atiksh Bhardwaj",
      "Audrey Du",
      "Edward W. Duan",
      "Wei-Chiu Ma",
      "Kushal Kedia"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04671v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04671v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.04595v1",
    "title": "UniSplat: Unified Spatio-Temporal Fusion via 3D Latent Scaffolds for   Dynamic Driving Scene Reconstruction",
    "summary": "Feed-forward 3D reconstruction for autonomous driving has advanced rapidly, yet existing methods struggle with the joint challenges of sparse, non-overlapping camera views and complex scene dynamics. We present UniSplat, a general feed-forward framework that learns robust dynamic scene reconstruction through unified latent spatio-temporal fusion. UniSplat constructs a 3D latent scaffold, a structured representation that captures geometric and semantic scene context by leveraging pretrained foundation models. To effectively integrate information across spatial views and temporal frames, we introduce an efficient fusion mechanism that operates directly within the 3D scaffold, enabling consistent spatio-temporal alignment. To ensure complete and detailed reconstructions, we design a dual-branch decoder that generates dynamic-aware Gaussians from the fused scaffold by combining point-anchored refinement with voxel-based generation, and maintain a persistent memory of static Gaussians to enable streaming scene completion beyond current camera coverage. Extensive experiments on real-world datasets demonstrate that UniSplat achieves state-of-the-art performance in novel view synthesis, while providing robust and high-quality renderings even for viewpoints outside the original camera coverage.",
    "authors": [
      "Chen Shi",
      "Shaoshuai Shi",
      "Xiaoyang Lyu",
      "Chunyang Liu",
      "Kehua Sheng",
      "Bo Zhang",
      "Li Jiang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04595v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04595v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.04494v1",
    "title": "Distribution-Aware Tensor Decomposition for Compression of Convolutional   Neural Networks",
    "summary": "Neural networks are widely used for image-related tasks but typically demand considerable computing power. Once a network has been trained, however, its memory- and compute-footprint can be reduced by compression. In this work, we focus on compression through tensorization and low-rank representations. Whereas classical approaches search for a low-rank approximation by minimizing an isotropic norm such as the Frobenius norm in weight-space, we use data-informed norms that measure the error in function space. Concretely, we minimize the change in the layer's output distribution, which can be expressed as $\\lVert (W - \\widetilde{W}) \\Sigma^{1/2}\\rVert_F$ where $\\Sigma^{1/2}$ is the square root of the covariance matrix of the layer's input and $W$, $\\widetilde{W}$ are the original and compressed weights. We propose new alternating least square algorithms for the two most common tensor decompositions (Tucker-2 and CPD) that directly optimize the new norm. Unlike conventional compression pipelines, which almost always require post-compression fine-tuning, our data-informed approach often achieves competitive accuracy without any fine-tuning. We further show that the same covariance-based norm can be transferred from one dataset to another with only a minor accuracy drop, enabling compression even when the original training dataset is unavailable. Experiments on several CNN architectures (ResNet-18/50, and GoogLeNet) and datasets (ImageNet, FGVC-Aircraft, Cifar10, and Cifar100) confirm the advantages of the proposed method.",
    "authors": [
      "Alper Kalle",
      "Theo Rudkiewicz",
      "Mohamed-Oumar Ouerfelli",
      "Mohamed Tamaazousti"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04494v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04494v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.04464v1",
    "title": "Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context",
    "summary": "Traditional vehicle routing systems efficiently optimize singular metrics like time or distance, and when considering multiple metrics, they need more processes to optimize . However, they lack the capability to interpret and integrate the complex, semantic, and dynamic contexts of human drivers, such as multi-step tasks, situational constraints, or urgent needs. This paper introduces and evaluates PAVe (Personalized Agentic Vehicular Routing), a hybrid agentic assistant designed to augment classical pathfinding algorithms with contextual reasoning. Our approach employs a Large Language Model (LLM) agent that operates on a candidate set of routes generated by a multi-objective (time, CO2) Dijkstra algorithm. The agent evaluates these options against user-provided tasks, preferences, and avoidance rules by leveraging a pre-processed geospatial cache of urban Points of Interest (POIs). In a benchmark of realistic urban scenarios, PAVe successfully used complex user intent into appropriate route modifications, achieving over 88% accuracy in its initial route selections with a local model. We conclude that combining classical routing algorithms with an LLM-based semantic reasoning layer is a robust and effective approach for creating personalized, adaptive, and scalable solutions for urban mobility optimization.",
    "authors": [
      "Carnot Braun",
      "Rafael O. Jarczewski",
      "Gabriel U. Talasso",
      "Leandro A. Villas",
      "Allan M. de Souza"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04464v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04464v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.04388v1",
    "title": "BoRe-Depth: Self-supervised Monocular Depth Estimation with Boundary   Refinement for Embedded Systems",
    "summary": "Depth estimation is one of the key technologies for realizing 3D perception in unmanned systems. Monocular depth estimation has been widely researched because of its low-cost advantage, but the existing methods face the challenges of poor depth estimation performance and blurred object boundaries on embedded systems. In this paper, we propose a novel monocular depth estimation model, BoRe-Depth, which contains only 8.7M parameters. It can accurately estimate depth maps on embedded systems and significantly improves boundary quality. Firstly, we design an Enhanced Feature Adaptive Fusion Module (EFAF) which adaptively fuses depth features to enhance boundary detail representation. Secondly, we integrate semantic knowledge into the encoder to improve the object recognition and boundary perception capabilities. Finally, BoRe-Depth is deployed on NVIDIA Jetson Orin, and runs efficiently at 50.7 FPS. We demonstrate that the proposed model significantly outperforms previous lightweight models on multiple challenging datasets, and we provide detailed ablation studies for the proposed methods. The code is available at https://github.com/liangxiansheng093/BoRe-Depth.",
    "authors": [
      "Chang Liu",
      "Juan Li",
      "Sheng Zhang",
      "Chang Liu",
      "Jie Li",
      "Xu Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04388v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04388v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.04304v1",
    "title": "Deep learning-based object detection of offshore platforms on Sentinel-1   Imagery and the impact of synthetic training data",
    "summary": "The recent and ongoing expansion of marine infrastructure, including offshore wind farms, oil and gas platforms, artificial islands, and aquaculture facilities, highlights the need for effective monitoring systems. The development of robust models for offshore infrastructure detection relies on comprehensive, balanced datasets, but falls short when samples are scarce, particularly for underrepresented object classes, shapes, and sizes. By training deep learning-based YOLOv10 object detection models with a combination of synthetic and real Sentinel-1 satellite imagery acquired in the fourth quarter of 2023 from four regions (Caspian Sea, South China Sea, Gulf of Guinea, and Coast of Brazil), this study investigates the use of synthetic training data to enhance model performance. We evaluated this approach by applying the model to detect offshore platforms in three unseen regions (Gulf of Mexico, North Sea, Persian Gulf) and thereby assess geographic transferability. This region-holdout evaluation demonstrated that the model generalises beyond the training areas. In total, 3,529 offshore platforms were detected, including 411 in the North Sea, 1,519 in the Gulf of Mexico, and 1,593 in the Persian Gulf. The model achieved an F1 score of 0.85, which improved to 0.90 upon incorporating synthetic data. We analysed how synthetic data enhances the representation of unbalanced classes and overall model performance, taking a first step toward globally transferable detection of offshore infrastructure. This study underscores the importance of balanced datasets and highlights synthetic data generation as an effective strategy to address common challenges in remote sensing, demonstrating the potential of deep learning for scalable, global offshore infrastructure monitoring.",
    "authors": [
      "Robin Spanier",
      "Thorsten Hoeser",
      "Claudia Kuenzer"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04304v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04304v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.04256v1",
    "title": "SSPO: Subsentence-level Policy Optimization",
    "summary": "As a significant part of post-training of the Large Language Models (LLMs), Reinforcement Learning from Verifiable Reward (RLVR) has greatly improved LLMs' reasoning skills. However, some RLVR algorithms, such as GRPO (Group Relative Policy Optimization) and GSPO (Group Sequence Policy Optimization), are observed to suffer from unstable policy updates and low usage of sampling data, respectively. The importance ratio of GRPO is calculated at the token level, which focuses more on optimizing a single token. This will be easily affected by outliers, leading to model training collapse. GSPO proposed the calculation of the response level importance ratio, which solves the problem of high variance and training noise accumulation in the calculation of the GRPO importance ratio. However, since all the response tokens share a common importance ratio, extreme values can easily raise or lower the overall mean, leading to the entire response being mistakenly discarded, resulting in a decrease in the utilization of sampled data. This paper introduces SSPO, which applies sentence-level importance ratio, taking the balance between GRPO and GSPO. SSPO not only avoids training collapse and high variance, but also prevents the whole response tokens from being abandoned by the clipping mechanism. Furthermore, we apply sentence entropy to PPO-CLIP to steadily adjust the clipping bounds, encouraging high-entropy tokens to explore and narrow the clipping range of low-entropy tokens. In particular, SSPO achieves an average score of 46.57 across five datasets, surpassing GRPO (43.01) and GSPO (44.42), and wins state-of-the-art performance on three datasets. These results highlight SSPO's effectiveness in leveraging generated data by taking the essence of GSPO but rejecting its shortcomings.",
    "authors": [
      "Kun Yang",
      "Zikang chen",
      "Yanmeng Wang",
      "Zhigen Li"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04256v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04256v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.04093v1",
    "title": "KGFR: A Foundation Retriever for Generalized Knowledge Graph Question   Answering",
    "summary": "Large language models (LLMs) excel at reasoning but struggle with knowledge-intensive questions due to limited context and parametric knowledge. However, existing methods that rely on finetuned LLMs or GNN retrievers are limited by dataset-specific tuning and scalability on large or unseen graphs. We propose the LLM-KGFR collaborative framework, where an LLM works with a structured retriever, the Knowledge Graph Foundation Retriever (KGFR). KGFR encodes relations using LLM-generated descriptions and initializes entities based on their roles in the question, enabling zero-shot generalization to unseen KGs. To handle large graphs efficiently, it employs Asymmetric Progressive Propagation (APP)- a stepwise expansion that selectively limits high-degree nodes while retaining informative paths. Through node-, edge-, and path-level interfaces, the LLM iteratively requests candidate answers, supporting facts, and reasoning paths, forming a controllable reasoning loop. Experiments demonstrate that LLM-KGFR achieves strong performance while maintaining scalability and generalization, providing a practical solution for KG-augmented reasoning.",
    "authors": [
      "Yuanning Cui",
      "Zequn Sun",
      "Wei Hu",
      "Zhangjie Fu"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04093v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04093v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.04556v1",
    "title": "Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse   Sensing Approach",
    "summary": "Urban surface water flooding, triggered by intense rainfall overwhelming drainage systems, is increasingly frequent and widespread. While flood prediction and monitoring in high spatial-temporal resolution are desired, practical constraints in time, budget, and technology hinder its full implementation. How to monitor urban drainage networks and predict flow conditions under constrained resource is a major challenge. This study presents a data-driven sparse sensing (DSS) framework, integrated with EPA-SWMM, to optimize sensor placement and reconstruct peak flowrates in a stormwater system, using the Woodland Avenue catchment in Duluth, Minnesota, as a case study. We utilized a SWMM model to generate a training dataset of peak flowrate profiles across the stormwater network. Furthermore, we applied DSS - leveraging singular value decomposition for dimensionality reduction and QR factorization for sensor allocation - to identify the optimal monitoring nodes based on the simulated training dataset. We then validated the representativeness of these identified monitoring nodes by comparing the DSS-reconstructed peak flowrate profiles with those obtained from SWMM. Three optimally placed sensors among 77 nodes achieved satisfactory reconstruction performance with Nash-Sutcliffe Efficiency (NSE) values of 0.92-0.95 (25th to 75th percentiles). In addition, the model showed good robustness to uncertainty in measurements. Its robustness to sensor failures is location-dependent and improves with the number of sensors deployed. The framework balances computational efficiency and physical interpretability, enabling high-accuracy flow reconstruction with minimal sensors. This DSS framework can be further integrated with predictive models to realize flood early warning and real-time control under limited sensing and monitoring resource.",
    "authors": [
      "Zihang Ding",
      "Kun Zhang"
    ],
    "categories": [
      "cs.AI",
      "cs.CE"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04556v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04556v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.04500v1",
    "title": "Large language models replicate and predict human cooperation across   experiments in game theory",
    "summary": "Large language models (LLMs) are increasingly used both to make decisions in domains such as health, education and law, and to simulate human behavior. Yet how closely LLMs mirror actual human decision-making remains poorly understood. This gap is critical: misalignment could produce harmful outcomes in practical applications, while failure to replicate human behavior renders LLMs ineffective for social simulations. Here, we address this gap by developing a digital twin of game-theoretic experiments and introducing a systematic prompting and probing framework for machine-behavioral evaluation. Testing three open-source models (Llama, Mistral and Qwen), we find that Llama reproduces human cooperation patterns with high fidelity, capturing human deviations from rational choice theory, while Qwen aligns closely with Nash equilibrium predictions. Notably, we achieved population-level behavioral replication without persona-based prompting, simplifying the simulation process. Extending beyond the original human-tested games, we generate and preregister testable hypotheses for novel game configurations outside the original parameter grid. Our findings demonstrate that appropriately calibrated LLMs can replicate aggregate human behavioral patterns and enable systematic exploration of unexplored experimental spaces, offering a complementary approach to traditional research in the social and behavioral sciences that generates new empirical predictions about human social decision-making.",
    "authors": [
      "Andrea Cera Palatsi",
      "Samuel Martin-Gutierrez",
      "Ana S. Cardenal",
      "Max Pellert"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.GT",
      "cs.MA"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04500v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04500v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.04393v1",
    "title": "Post-Training LLMs as Better Decision-Making Agents: A   Regret-Minimization Approach",
    "summary": "Large language models (LLMs) are increasingly deployed as \"agents\" for decision-making (DM) in interactive and dynamic environments. Yet, since they were not originally designed for DM, recent studies show that LLMs can struggle even in basic online DM problems, failing to achieve low regret or an effective exploration-exploitation tradeoff. To address this, we introduce Iterative Regret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure that repeatedly distills low-regret decision trajectories back into the base model. At each iteration, the model rolls out multiple decision trajectories, selects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior methods that (a) distill action sequences from known DM algorithms or (b) rely on manually crafted chain-of-thought templates, our approach leverages the regret metric to elicit the model's own DM ability and reasoning rationales. This reliance on model-generated reasoning avoids rigid output engineering and provides more flexible, natural-language training signals. Empirical results show that Iterative RMFT improves LLMs' DM performance across diverse models - from Transformers with numerical input/output, to open-weight LLMs, and advanced closed-weight models like GPT-4o mini. Its flexibility in output and reasoning formats enables generalization across tasks with varying horizons, action spaces, reward processes, and natural-language contexts. Finally, we provide theoretical insight showing that a single-layer Transformer under this paradigm can act as a no-regret learner in a simplified setting. Overall, Iterative RMFT offers a principled and general post-training framework for enhancing LLMs' decision-making capabilities.",
    "authors": [
      "Chanwoo Park",
      "Ziyang Chen",
      "Asuman Ozdaglar",
      "Kaiqing Zhang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04393v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04393v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.04341v1",
    "title": "Monitor-Generate-Verify (MGV):Formalising Metacognitive Theory for   Language Model Reasoning",
    "summary": "Test-time reasoning architectures such as those following the Generate-Verify paradigm -- where a model iteratively refines or verifies its own generated outputs -- prioritise generation and verification but exclude the monitoring processes that determine when and how reasoning should begin. This omission may contribute to the prefix dominance trap, in which models commit early to suboptimal reasoning paths and seldom recover, yielding roughly 20% accuracy loss. We address this architectural gap by formalising Flavell's and Nelson and Narens' metacognitive theories into computational specifications, proposing the Monitor-Generate-Verify (MGV) framework. MGV extends the Generate-Verify paradigm by adding explicit monitoring that captures metacognitive experiences (from difficulty assessments to confidence judgements) before generation begins and refines future monitoring through verification feedback. Though we present no empirical validation, this work provides the first systematic computational translation of foundational metacognitive theories, offering a principled vocabulary for understanding reasoning system failures and suggesting specific architectural interventions for future test-time reasoning designs.",
    "authors": [
      "Nick Oh",
      "Fernand Gobet"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04341v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04341v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.04286v1",
    "title": "Efficient Reinforcement Learning from Human Feedback via Bayesian   Preference Inference",
    "summary": "Learning from human preferences is a cornerstone of aligning machine learning models with subjective human judgments. Yet, collecting such preference data is often costly and time-consuming, motivating the need for more efficient learning paradigms. Two established approaches offer complementary advantages: RLHF scales effectively to high-dimensional tasks such as LLM fine-tuning, while PBO achieves greater sample efficiency through active querying. We propose a hybrid framework that unifies RLHF's scalability with PBO's query efficiency by integrating an acquisition-driven module into the RLHF pipeline, thereby enabling active and sample-efficient preference gathering. We validate the proposed approach on two representative domains: (i) high-dimensional preference optimization and (ii) LLM fine-tuning. Experimental results demonstrate consistent improvements in both sample efficiency and overall performance across these tasks.",
    "authors": [
      "Matteo Cercola",
      "Valeria Capretti",
      "Simone Formentin"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04286v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04286v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.04283v1",
    "title": "FastGS: Training 3D Gaussian Splatting in 100 Seconds",
    "summary": "The dominant 3D Gaussian splatting (3DGS) acceleration methods fail to properly regulate the number of Gaussians during training, causing redundant computational time overhead. In this paper, we propose FastGS, a novel, simple, and general acceleration framework that fully considers the importance of each Gaussian based on multi-view consistency, efficiently solving the trade-off between training time and rendering quality. We innovatively design a densification and pruning strategy based on multi-view consistency, dispensing with the budgeting mechanism. Extensive experiments on Mip-NeRF 360, Tanks & Temples, and Deep Blending datasets demonstrate that our method significantly outperforms the state-of-the-art methods in training speed, achieving a 3.32$\\times$ training acceleration and comparable rendering quality compared with DashGaussian on the Mip-NeRF 360 dataset and a 15.45$\\times$ acceleration compared with vanilla 3DGS on the Deep Blending dataset. We demonstrate that FastGS exhibits strong generality, delivering 2-7$\\times$ training acceleration across various tasks, including dynamic scene reconstruction, surface reconstruction, sparse-view reconstruction, large-scale reconstruction, and simultaneous localization and mapping. The project page is available at https://fastgs.github.io/",
    "authors": [
      "Shiwei Ren",
      "Tianci Wen",
      "Yongchun Fang",
      "Biao Lu"
    ],
    "categories": [
      "cs.CV",
      "68T40(Primary)68T45, 68U99 (Secondary)",
      "I.4.8; I.3.7"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04283v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04283v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.04172v1",
    "title": "Transforming Mentorship: An AI Powered Chatbot Approach to University   Guidance",
    "summary": "University students face immense challenges during their undergraduate lives, often being deprived of personalized on-demand guidance that mentors fail to provide at scale. Digital tools exist, but there is a serious lack of customized coaching for newcomers. This paper presents an AI-powered chatbot that will serve as a mentor for the students of BRAC University. The main component is a data ingestion pipeline that efficiently processes and updates information from diverse sources, such as CSV files and university webpages. The chatbot retrieves information through a hybrid approach, combining BM25 lexical ranking with ChromaDB semantic retrieval, and uses a Large Language Model, LLaMA-3.3-70B, to generate conversational responses. The generated text was found to be semantically highly relevant, with a BERTScore of 0.831 and a METEOR score of 0.809. The data pipeline was also very efficient, taking 106.82 seconds for updates, compared to 368.62 seconds for new data. This chatbot will be able to help students by responding to their queries, helping them to get a better understanding of university life, and assisting them to plan better routines for their semester in the open-credit university.",
    "authors": [
      "Mashrur Rahman",
      "Mantaqa abedin",
      "Monowar Zamil Abir",
      "Faizul Islam Ansari",
      "Adib Reza",
      "Farig Yousuf Sadeque",
      "Niloy Farhan"
    ],
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04172v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04172v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.04155v1",
    "title": "Learning to Land Anywhere: Transferable Generative Models for Aircraft   Trajectories",
    "summary": "Access to trajectory data is a key requirement for developing and validating Air Traffic Management (ATM) solutions, yet many secondary and regional airports face severe data scarcity. This limits the applicability of machine learning methods and the ability to perform large-scale simulations or \"what-if\" analyses. In this paper, we investigate whether generative models trained on data-rich airports can be efficiently adapted to data-scarce airports using transfer learning. We adapt state-of-the-art diffusion- and flow-matching-based architectures to the aviation domain and evaluate their transferability between Zurich (source) and Dublin (target) landing trajectory datasets. Models are pretrained on Zurich and fine-tuned on Dublin with varying amounts of local data, ranging from 0% to 100%. Results show that diffusion-based models achieve competitive performance with as little as 5% of the Dublin data and reach baseline-level performance around 20%, consistently outperforming models trained from scratch across metrics and visual inspections. Latent flow matching and latent diffusion models also benefit from pretraining, though with more variable gains, while flow matching models show weaker generalization. Despite challenges in capturing rare trajectory patterns, these findings demonstrate the potential of transfer learning to substantially reduce data requirements for trajectory generation in ATM, enabling realistic synthetic data generation even in environments with limited historical records.",
    "authors": [
      "Olav Finne Praesteng Larsen",
      "Massimiliano Ruocco",
      "Michail Spitieris",
      "Abdulmajid Murad",
      "Martina Ragosta"
    ],
    "categories": [
      "cs.LG",
      "I.2.6; I.5.1"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04155v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04155v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.04086v1",
    "title": "DeNoise: Learning Robust Graph Representations for Unsupervised   Graph-Level Anomaly Detection",
    "summary": "With the rapid growth of graph-structured data in critical domains, unsupervised graph-level anomaly detection (UGAD) has become a pivotal task. UGAD seeks to identify entire graphs that deviate from normal behavioral patterns. However, most Graph Neural Network (GNN) approaches implicitly assume that the training set is clean, containing only normal graphs, which is rarely true in practice. Even modest contamination by anomalous graphs can distort learned representations and sharply degrade performance. To address this challenge, we propose DeNoise, a robust UGAD framework explicitly designed for contaminated training data. It jointly optimizes a graph-level encoder, an attribute decoder, and a structure decoder via an adversarial objective to learn noise-resistant embeddings. Further, DeNoise introduces an encoder anchor-alignment denoising mechanism that fuses high-information node embeddings from normal graphs into all graph embeddings, improving representation quality while suppressing anomaly interference. A contrastive learning component then compacts normal graph embeddings and repels anomalous ones in the latent space. Extensive experiments on eight real-world datasets demonstrate that DeNoise consistently learns reliable graph-level representations under varying noise intensities and significantly outperforms state-of-the-art UGAD baselines.",
    "authors": [
      "Qingfeng Chen",
      "Haojin Zeng",
      "Jingyi Jie",
      "Shichao Zhang",
      "Debo Cheng"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04086v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04086v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.04654v1",
    "title": "Logit-Entropy Adaptive Stopping Heuristic for Efficient Chain-of-Thought   Reasoning",
    "summary": "Chain-of-Thought (CoT) prompting is a key technique for enabling complex reasoning in large language models. However, generating full, fixed-length rationales is computationally wasteful, inflating both token usage and latency. We introduce LEASH: Logit-Entropy Adaptive Stopping Heuristic, a training-free decoding algorithm that adaptively halts rationale generation. LEASH monitors two intrinsic signals: the slope of token-level entropy and the improvement in the top-logit margin. It terminates the generation once both signals plateau, indicating the model has reached a stable reasoning state. Across four instruction-tuned models on the GSM8K and AQuA-RAT benchmarks, LEASH reduces average token generation by 30--35% and latency by 27%, while incurring a 10 p.p. accuracy drop relative to CoT. LEASH is model-agnostic and requires no additional training or supervision, offering a simple and efficient alternative to CoT decoding.",
    "authors": [
      "Mohammad Atif Quamar",
      "Mohammad Areeb"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04654v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04654v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.04560v1",
    "title": "BanglaMedQA and BanglaMMedBench: Evaluating Retrieval-Augmented   Generation Strategies for Bangla Biomedical Question Answering",
    "summary": "Developing accurate biomedical Question Answering (QA) systems in low-resource languages remains a major challenge, limiting equitable access to reliable medical knowledge. This paper introduces BanglaMedQA and BanglaMMedBench, the first large-scale Bangla biomedical Multiple Choice Question (MCQ) datasets designed to evaluate reasoning and retrieval in medical artificial intelligence (AI). The study applies and benchmarks several Retrieval-Augmented Generation (RAG) strategies, including Traditional, Zero-Shot Fallback, Agentic, Iterative Feedback, and Aggregate RAG, combining textbook-based and web retrieval with generative reasoning to improve factual accuracy. A key novelty lies in integrating a Bangla medical textbook corpus through Optical Character Recognition (OCR) and implementing an Agentic RAG pipeline that dynamically selects between retrieval and reasoning strategies. Experimental results show that the Agentic RAG achieved the highest accuracy 89.54% with openai/gpt-oss-120b, outperforming other configurations and demonstrating superior rationale quality. These findings highlight the potential of RAG-based methods to enhance the reliability and accessibility of Bangla medical QA, establishing a foundation for future research in multilingual medical artificial intelligence.",
    "authors": [
      "Sadia Sultana",
      "Saiyma Sittul Muna",
      "Mosammat Zannatul Samarukh",
      "Ajwad Abrar",
      "Tareque Mohmud Chowdhury"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04560v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04560v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.04476v1",
    "title": "Probabilistic Textual Time Series Depression Detection",
    "summary": "Accurate and interpretable predictions of depression severity are essential for clinical decision support, yet existing models often lack uncertainty estimates and temporal modeling. We propose PTTSD, a Probabilistic Textual Time Series Depression Detection framework that predicts PHQ-8 scores from utterance-level clinical interviews while modeling uncertainty over time. PTTSD includes sequence-to-sequence and sequence-to-one variants, both combining bidirectional LSTMs, self-attention, and residual connections with Gaussian or Student-t output heads trained via negative log-likelihood. Evaluated on E-DAIC and DAIC-WOZ, PTTSD achieves state-of-the-art performance among text-only systems (e.g., MAE = 3.85 on E-DAIC, 3.55 on DAIC) and produces well-calibrated prediction intervals. Ablations confirm the value of attention and probabilistic modeling, while comparisons with MentalBERT establish generality. A three-part calibration analysis and qualitative case studies further highlight the interpretability and clinical relevance of uncertainty-aware forecasting.",
    "authors": [
      "Fabian Schmidt",
      "Seyedehmoniba Ravan",
      "Vladimir Vlassov"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04476v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04476v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.04333v1",
    "title": "LUME-DBN: Full Bayesian Learning of DBNs from Incomplete data in   Intensive Care",
    "summary": "Dynamic Bayesian networks (DBNs) are increasingly used in healthcare due to their ability to model complex temporal relationships in patient data while maintaining interpretability, an essential feature for clinical decision-making. However, existing approaches to handling missing data in longitudinal clinical datasets are largely derived from static Bayesian networks literature, failing to properly account for the temporal nature of the data. This gap limits the ability to quantify uncertainty over time, which is particularly critical in settings such as intensive care, where understanding the temporal dynamics is fundamental for model trustworthiness and applicability across diverse patient groups. Despite the potential of DBNs, a full Bayesian framework that integrates missing data handling remains underdeveloped. In this work, we propose a novel Gibbs sampling-based method for learning DBNs from incomplete data. Our method treats each missing value as an unknown parameter following a Gaussian distribution. At each iteration, the unobserved values are sampled from their full conditional distributions, allowing for principled imputation and uncertainty estimation. We evaluate our method on both simulated datasets and real-world intensive care data from critically ill patients. Compared to standard model-agnostic techniques such as MICE, our Bayesian approach demonstrates superior reconstruction accuracy and convergence properties. These results highlight the clinical relevance of incorporating full Bayesian inference in temporal models, providing more reliable imputations and offering deeper insight into model behavior. Our approach supports safer and more informed clinical decision-making, particularly in settings where missing data are frequent and potentially impactful.",
    "authors": [
      "Federico Pirola",
      "Fabio Stella",
      "Marco Grzegorczyk"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04333v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04333v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.04288v1",
    "title": "Vision Foundation Models in Agriculture: Toward Domain-Specific   Adaptation for Weed Herbicide Trials Assessment",
    "summary": "Herbicide field trials require accurate identification of plant species and assessment of herbicide-induced damage across diverse environments. While general-purpose vision foundation models have shown promising results in complex visual domains, their performance can be limited in agriculture, where fine-grained distinctions between species and damage types are critical.   In this work, we adapt a general-purpose vision foundation model to herbicide trial characterization. Trained using a self-supervised learning approach on a large, curated agricultural dataset, the model learns rich and transferable representations optimized for herbicide trials images.   Our domain-specific model significantly outperforms the best general-purpose foundation model in both species identification (F1 score improvement from 0.91 to 0.94) and damage classification (from 0.26 to 0.33). Under unseen conditions (new locations and other time), it achieves even greater gains (species identification from 0.56 to 0.66; damage classification from 0.17 to 0.27). In domain-shift scenarios, such as drone imagery, it maintains strong performance (species classification from 0.49 to 0.60).   Additionally, we show that domain-specific pretraining enhances segmentation accuracy, particularly in low-annotation regimes. An annotation-efficiency analysis reveals that, under unseen conditions, the domain-specific model achieves 5.4% higher F1 score than the general-purpose model, while using 80% fewer labeled samples.   These results demonstrate the generalization capabilities of domain-specific foundation models and their potential to significantly reduce manual annotation efforts, offering a scalable and automated solution for herbicide trial analysis.",
    "authors": [
      "Leire Benito-Del-Valle",
      "Artzai Picón",
      "Daniel Mugica",
      "Manuel Ramos",
      "Eva Portillo",
      "Javier Romero",
      "Carlos Javier Jimenez",
      "Ramón Navarra-Mestre"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04288v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04288v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.04285v1",
    "title": "RLoop: An Self-Improving Framework for Reinforcement Learning with   Iterative Policy Initialization",
    "summary": "While Reinforcement Learning for Verifiable Rewards (RLVR) is powerful for training large reasoning models, its training dynamics harbor a critical challenge: RL overfitting, where models gain training rewards but lose generalization. Our analysis reveals this is driven by policy over-specialization and catastrophic forgetting of diverse solutions generated during training. Standard optimization discards this valuable inter-step policy diversity. To address this, we introduce RLoop, a self-improving framework built on iterative policy initialization. RLoop transforms the standard training process into a virtuous cycle: it first uses RL to explore the solution space from a given policy, then filters the successful trajectories to create an expert dataset. This dataset is used via Rejection-sampling Fine-Tuning (RFT) to refine the initial policy, creating a superior starting point for the next iteration. This loop of exploration and exploitation via iterative re-initialization effectively converts transient policy variations into robust performance gains. Our experiments show RLoop mitigates forgetting and substantially improves generalization, boosting average accuracy by 9% and pass@32 by over 15% compared to vanilla RL.",
    "authors": [
      "Zeng Zhiyuan",
      "Jiashuo Liu",
      "Zhangyue Yin",
      "Ge Zhang",
      "Wenhao Huang",
      "Xipeng Qiu"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04285v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04285v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.04195v1",
    "title": "Computational Turing Test Reveals Systematic Differences Between Human   and AI Language",
    "summary": "Large language models (LLMs) are increasingly used in the social sciences to simulate human behavior, based on the assumption that they can generate realistic, human-like text. Yet this assumption remains largely untested. Existing validation efforts rely heavily on human-judgment-based evaluations -- testing whether humans can distinguish AI from human output -- despite evidence that such judgments are blunt and unreliable. As a result, the field lacks robust tools for assessing the realism of LLM-generated text or for calibrating models to real-world data. This paper makes two contributions. First, we introduce a computational Turing test: a validation framework that integrates aggregate metrics (BERT-based detectability and semantic similarity) with interpretable linguistic features (stylistic markers and topical patterns) to assess how closely LLMs approximate human language within a given dataset. Second, we systematically compare nine open-weight LLMs across five calibration strategies -- including fine-tuning, stylistic prompting, and context retrieval -- benchmarking their ability to reproduce user interactions on X (formerly Twitter), Bluesky, and Reddit. Our findings challenge core assumptions in the literature. Even after calibration, LLM outputs remain clearly distinguishable from human text, particularly in affective tone and emotional expression. Instruction-tuned models underperform their base counterparts, and scaling up model size does not enhance human-likeness. Crucially, we identify a trade-off: optimizing for human-likeness often comes at the cost of semantic fidelity, and vice versa. These results provide a much-needed scalable framework for validation and calibration in LLM simulations -- and offer a cautionary note about their current limitations in capturing human communication.",
    "authors": [
      "Nicolò Pagan",
      "Petter Törnberg",
      "Christopher A. Bail",
      "Anikó Hannák",
      "Christopher Barrie"
    ],
    "categories": [
      "cs.CL",
      "cs.MA",
      "cs.SI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04195v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04195v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.04171v1",
    "title": "Systematic Evaluation of Preprocessing Techniques for Accurate Image   Registration in Digital Pathology",
    "summary": "Image registration refers to the process of spatially aligning two or more images by mapping them into a common coordinate system, so that corresponding anatomical or tissue structures are matched across images. In digital pathology, registration enables direct comparison and integration of information from different stains or imaging modalities, sup-porting applications such as biomarker analysis and tissue reconstruction. Accurate registration of images from different modalities is an essential step in digital pathology. In this study, we investigated how various color transformation techniques affect image registration between hematoxylin and eosin (H&E) stained images and non-linear multimodal images. We used a dataset of 20 tissue sample pairs, with each pair undergoing several preprocessing steps, including different color transformation (CycleGAN, Macenko, Reinhard, Vahadane), inversion, contrast adjustment, intensity normalization, and denoising. All images were registered using the VALIS registration method, which first applies rigid registration and then performs non-rigid registration in two steps on both low and high-resolution images. Registration performance was evaluated using the relative Target Registration Error (rTRE). We reported the median of median rTRE values (MMrTRE) and the average of median rTRE values (AMrTRE) for each method. In addition, we performed a custom point-based evaluation using ten manually selected key points. Registration was done separately for two scenarios, using either the original or inverted multimodal images. In both scenarios, CycleGAN color transformation achieved the lowest registration errors, while the other methods showed higher errors. These findings show that applying color transformation before registration improves alignment between images from different modalities and supports more reliable analysis in digital pathology.",
    "authors": [
      "Fatemehzahra Darzi",
      "Rodrigo Escobar Diaz Guerrero",
      "Thomas Bocklitz"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04171v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04171v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.04090v1",
    "title": "Advancing Equitable AI: Evaluating Cultural Expressiveness in LLMs for   Latin American Contexts",
    "summary": "Artificial intelligence (AI) systems often reflect biases from economically advanced regions, marginalizing contexts in economically developing regions like Latin America due to imbalanced datasets. This paper examines AI representations of diverse Latin American contexts, revealing disparities between data from economically advanced and developing regions. We highlight how the dominance of English over Spanish, Portuguese, and indigenous languages such as Quechua and Nahuatl perpetuates biases, framing Latin American perspectives through a Western lens. To address this, we introduce a culturally aware dataset rooted in Latin American history and socio-political contexts, challenging Eurocentric models. We evaluate six language models on questions testing cultural context awareness, using a novel Cultural Expressiveness metric, statistical tests, and linguistic analyses. Our findings show that some models better capture Latin American perspectives, while others exhibit significant sentiment misalignment (p < 0.001). Fine-tuning Mistral-7B with our dataset improves its cultural expressiveness by 42.9%, advancing equitable AI development. We advocate for equitable AI by prioritizing datasets that reflect Latin American history, indigenous knowledge, and diverse languages, while emphasizing community-centered approaches to amplify marginalized voices.",
    "authors": [
      "Brigitte A. Mora-Reyes",
      "Jennifer A. Drewyor",
      "Abel A. Reyes-Angulo"
    ],
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04090v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04090v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.04668v1",
    "title": "SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding",
    "summary": "Despite impressive high-level video comprehension, multimodal language models struggle with spatial reasoning across time and space. While current spatial training approaches rely on real-world video data, obtaining diverse footage with precise spatial annotations remains a bottleneck. To alleviate this bottleneck, we present SIMS-V -- a systematic data-generation framework that leverages the privileged information of 3D simulators to create spatially-rich video training data for multimodal language models. Using this framework, we investigate which properties of simulated data drive effective real-world transfer through systematic ablations of question types, mixes, and scales. We identify a minimal set of three question categories (metric measurement, perspective-dependent reasoning, and temporal tracking) that prove most effective for developing transferable spatial intelligence, outperforming comprehensive coverage despite using fewer question types. These insights enable highly efficient training: our 7B-parameter video LLM fine-tuned on just 25K simulated examples outperforms the larger 72B baseline and achieves competitive performance with proprietary models on rigorous real-world spatial reasoning benchmarks. Our approach demonstrates robust generalization, maintaining performance on general video understanding while showing substantial improvements on embodied and real-world spatial tasks.",
    "authors": [
      "Ellis Brown",
      "Arijit Ray",
      "Ranjay Krishna",
      "Ross Girshick",
      "Rob Fergus",
      "Saining Xie"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04668v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04668v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.04647v1",
    "title": "Optimal Inference Schedules for Masked Diffusion Models",
    "summary": "A major bottleneck of standard auto-regressive large language models is that their inference process is inherently sequential, resulting in very long and costly inference times. To circumvent this, practitioners proposed a class of language models called diffusion language models, of which the masked diffusion model (MDM) is the most successful. The MDM is able to sample tokens out-of-order and, ostensibly, many tokens at once and in parallel. However, there is very limited rigorous understanding of how much parallel sampling these models can perform without noticeable degradation in their sampling performance. Prior work of Li and Cai obtained some preliminary bounds, but these are not tight for many natural classes of distributions. In this work, we give a new, exact characterization of the expected divergence between the true distribution and the sampled distribution, for any distribution and any unmasking schedule for the sampler, showing an elegant connection to the theory of univariate function approximation.   By leveraging this connection, we then attain a number of novel lower and upper bounds for this problem. While the connection to function approximation in principle gives the optimal unmasking schedule for any distribution, we show that it is in general impossible to compete with it without strong a priori knowledge of the distribution, even in seemingly benign settings. However, we also demonstrate new upper bounds and new sampling schedules in terms of well-studied information-theoretic properties of the base distribution, namely, its total correlation and dual total correlation, which show that in some natural settings, one can sample in $O(log n)$ steps without any visible loss in performance, where $n$ is the total sequence length.",
    "authors": [
      "Sitan Chen",
      "Kevin Cong",
      "Jerry Li"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04647v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04647v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.04534v1",
    "title": "Uncertainty Quantification for Reduced-Order Surrogate Models Applied to   Cloud Microphysics",
    "summary": "Reduced-order models (ROMs) can efficiently simulate high-dimensional physical systems, but lack robust uncertainty quantification methods. Existing approaches are frequently architecture- or training-specific, which limits flexibility and generalization. We introduce a post hoc, model-agnostic framework for predictive uncertainty quantification in latent space ROMs that requires no modification to the underlying architecture or training procedure. Using conformal prediction, our approach estimates statistical prediction intervals for multiple components of the ROM pipeline: latent dynamics, reconstruction, and end-to-end predictions. We demonstrate the method on a latent space dynamical model for cloud microphysics, where it accurately predicts the evolution of droplet-size distributions and quantifies uncertainty across the ROM pipeline.",
    "authors": [
      "Jonas E. Katona",
      "Emily K. de Jong",
      "Nipun Gunawardena"
    ],
    "categories": [
      "cs.LG",
      "physics.ao-ph",
      "physics.comp-ph",
      "I.6.5; I.2.6; G.3; J.2"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04534v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04534v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.04437v1",
    "title": "Deep Koopman Economic Model Predictive Control of a Pasteurisation Unit",
    "summary": "This paper presents a deep Koopman-based Economic Model Predictive Control (EMPC) for efficient operation of a laboratory-scale pasteurization unit (PU). The method uses Koopman operator theory to transform the complex, nonlinear system dynamics into a linear representation, enabling the application of convex optimization while representing the complex PU accurately. The deep Koopman model utilizes neural networks to learn the linear dynamics from experimental data, achieving a 45% improvement in open-loop prediction accuracy over conventional N4SID subspace identification. Both analyzed models were employed in the EMPC formulation that includes interpretable economic costs, such as energy consumption, material losses due to inadequate pasteurization, and actuator wear. The feasibility of EMPC is ensured using slack variables. The deep Koopman EMPC and N4SID EMPC are numerically validated on a nonlinear model of multivariable PU under external disturbance. The disturbances include feed pump fail-to-close scenario and the introduction of a cold batch to be pastuerized. These results demonstrate that the deep Koopmand EMPC achieves a 32% reduction in total economic cost compared to the N4SID baseline. This improvement is mainly due to the reductions in material losses and energy consumption. Furthermore, the steady-state operation via Koopman-based EMPC requires 10.2% less electrical energy. The results highlight the practical advantages of integrating deep Koopman representations with economic optimization to achieve resource-efficient control of thermal-intensive plants.",
    "authors": [
      "Patrik Valábek",
      "Michaela Horváthová",
      "Martin Klaučo"
    ],
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04437v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04437v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.04332v1",
    "title": "Differentially Private In-Context Learning with Nearest Neighbor Search",
    "summary": "Differentially private in-context learning (DP-ICL) has recently become an active research topic due to the inherent privacy risks of in-context learning. However, existing approaches overlook a critical component of modern large language model (LLM) pipelines: the similarity search used to retrieve relevant context data. In this work, we introduce a DP framework for in-context learning that integrates nearest neighbor search of relevant examples in a privacy-aware manner. Our method outperforms existing baselines by a substantial margin across all evaluated benchmarks, achieving more favorable privacy-utility trade-offs. To achieve this, we employ nearest neighbor retrieval from a database of context data, combined with a privacy filter that tracks the cumulative privacy cost of selected samples to ensure adherence to a central differential privacy budget. Experimental results on text classification and document question answering show a clear advantage of the proposed method over existing baselines.",
    "authors": [
      "Antti Koskela",
      "Tejas Kulkarni",
      "Laith Zumot"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04332v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04332v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.04312v1",
    "title": "Probing the Probes: Methods and Metrics for Concept Alignment",
    "summary": "In explainable AI, Concept Activation Vectors (CAVs) are typically obtained by training linear classifier probes to detect human-understandable concepts as directions in the activation space of deep neural networks. It is widely assumed that a high probe accuracy indicates a CAV faithfully representing its target concept. However, we show that the probe's classification accuracy alone is an unreliable measure of concept alignment, i.e., the degree to which a CAV captures the intended concept. In fact, we argue that probes are more likely to capture spurious correlations than they are to represent only the intended concept. As part of our analysis, we demonstrate that deliberately misaligned probes constructed to exploit spurious correlations, achieve an accuracy close to that of standard probes. To address this severe problem, we introduce a novel concept localization method based on spatial linear attribution, and provide a comprehensive comparison of it to existing feature visualization techniques for detecting and mitigating concept misalignment. We further propose three classes of metrics for quantitatively assessing concept alignment: hard accuracy, segmentation scores, and augmentation robustness. Our analysis shows that probes with translation invariance and spatial alignment consistently increase concept alignment. These findings highlight the need for alignment-based evaluation metrics rather than probe accuracy, and the importance of tailoring probes to both the model architecture and the nature of the target concept.",
    "authors": [
      "Jacob Lysnæs-Larsen",
      "Marte Eggen",
      "Inga Strümke"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04312v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04312v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.04137v1",
    "title": "Learning from Online Videos at Inference Time for Computer-Use Agents",
    "summary": "Computer-use agents can operate computers and automate laborious tasks, but despite recent rapid progress, they still lag behind human users, especially when tasks require domain-specific procedural knowledge about particular applications, platforms, and multi-step workflows. Humans can bridge this gap by watching video tutorials: we search, skim, and selectively imitate short segments that match our current subgoal. In this paper, we study how to enable computer-use agents to learn from online videos at inference time effectively. We propose a framework that retrieves and filters tutorial videos, converts them into structured demonstration trajectories, and dynamically selects trajectories as in-context guidance during execution. Particularly, using a VLM, we infer UI actions, segment videos into short subsequences of actions, and assign each subsequence a textual objective. At inference time, a two-stage selection mechanism dynamically chooses a single trajectory to add in context at each step, focusing the agent on the most helpful local guidance for its next decision. Experiments on two widely used benchmarks show that our framework consistently outperforms strong base agents and variants that use only textual tutorials or transcripts. Analyses highlight the importance of trajectory segmentation and selection, action filtering, and visual information, suggesting that abundant online videos can be systematically distilled into actionable guidance that improves computer-use agents at inference time. Our code is available at https://github.com/UCSB-NLP-Chang/video_demo.",
    "authors": [
      "Yujian Liu",
      "Ze Wang",
      "Hao Chen",
      "Ximeng Sun",
      "Xiaodong Yu",
      "Jialian Wu",
      "Jiang Liu",
      "Emad Barsoum",
      "Zicheng Liu",
      "Shiyu Chang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04137v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04137v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.04120v1",
    "title": "RIDE: Difficulty Evolving Perturbation with Item Response Theory for   Mathematical Reasoning",
    "summary": "Large language models (LLMs) achieve high performance on mathematical reasoning, but these results can be inflated by training data leakage or superficial pattern matching rather than genuine reasoning. To this end, an adversarial perturbation-based evaluation is needed to measure true mathematical reasoning ability. Current rule-based perturbation methods often generate ill-posed questions and impede the systematic evaluation of question difficulty and the evolution of benchmarks. To bridge this gap, we propose RIDE, a novel adversarial question-rewriting framework that leverages Item Response Theory (IRT) to rigorously measure question difficulty and to generate intrinsically more challenging, well-posed variations of mathematical problems. We employ 35 LLMs to simulate students and build a difficulty ranker from their responses. This ranker provides a reward signal during reinforcement learning and guides a question-rewriting model to reformulate existing questions across difficulty levels. Applying RIDE to competition-level mathematical benchmarks yields perturbed versions that degrade advanced LLM performance, with experiments showing an average 21.73% drop across 26 models, thereby exposing limited robustness in mathematical reasoning and confirming the validity of our evaluation approach.",
    "authors": [
      "Xinyuan Li",
      "Murong Xu",
      "Wenbiao Tao",
      "Hanlun Zhu",
      "Yike Zhao",
      "Jipeng Zhang",
      "Yunshi Lan"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04120v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04120v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.04071v1",
    "title": "Left Atrial Segmentation with nnU-Net Using MRI",
    "summary": "Accurate segmentation of the left atrium (LA) from cardiac MRI is critical for guiding atrial fibrillation (AF) ablation and constructing biophysical cardiac models. Manual delineation is time-consuming, observer-dependent, and impractical for large-scale or time-sensitive clinical workflows. Deep learning methods, particularly convolutional architectures, have recently demonstrated superior performance in medical image segmentation tasks. In this study, we applied the nnU-Net framework, an automated, self-configuring deep learning segmentation architecture, to the Left Atrial Segmentation Challenge 2013 dataset. The dataset consists of thirty MRI scans with corresponding expert-annotated masks. The nnU-Net model automatically adapted its preprocessing, network configuration, and training pipeline to the characteristics of the MRI data. Model performance was quantitatively evaluated using the Dice similarity coefficient (DSC), and qualitative results were compared against expert segmentations. The proposed nnUNet model achieved a mean Dice score of 93.5, demonstrating high overlap with expert annotations and outperforming several traditional segmentation approaches reported in previous studies. The network exhibited robust generalization across variations in left atrial shape, contrast, and image quality, accurately delineating both the atrial body and proximal pulmonary veins.",
    "authors": [
      "Fatemeh Hosseinabadi",
      "Seyedhassan Sharifi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04071v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04071v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.04678v1",
    "title": "Tracking and Understanding Object Transformations",
    "summary": "Real-world objects frequently undergo state transformations. From an apple being cut into pieces to a butterfly emerging from its cocoon, tracking through these changes is important for understanding real-world objects and dynamics. However, existing methods often lose track of the target object after transformation, due to significant changes in object appearance. To address this limitation, we introduce the task of Track Any State: tracking objects through transformations while detecting and describing state changes, accompanied by a new benchmark dataset, VOST-TAS. To tackle this problem, we present TubeletGraph, a zero-shot system that recovers missing objects after transformation and maps out how object states are evolving over time. TubeletGraph first identifies potentially overlooked tracks, and determines whether they should be integrated based on semantic and proximity priors. Then, it reasons about the added tracks and generates a state graph describing each observed transformation. TubeletGraph achieves state-of-the-art tracking performance under transformations, while demonstrating deeper understanding of object transformations and promising capabilities in temporal grounding and semantic reasoning for complex object transformations. Code, additional results, and the benchmark dataset are available at https://tubelet-graph.github.io.",
    "authors": [
      "Yihong Sun",
      "Xinyu Yang",
      "Jennifer J. Sun",
      "Bharath Hariharan"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04678v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04678v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.04628v1",
    "title": "NovisVQ: A Streaming Convolutional Neural Network for No-Reference   Opinion-Unaware Frame Quality Assessment",
    "summary": "Video quality assessment (VQA) is vital for computer vision tasks, but existing approaches face major limitations: full-reference (FR) metrics require clean reference videos, and most no-reference (NR) models depend on training on costly human opinion labels. Moreover, most opinion-unaware NR methods are image-based, ignoring temporal context critical for video object detection. In this work, we present a scalable, streaming-based VQA model that is both no-reference and opinion-unaware. Our model leverages synthetic degradations of the DAVIS dataset, training a temporal-aware convolutional architecture to predict FR metrics (LPIPS , PSNR, SSIM) directly from degraded video, without references at inference. We show that our streaming approach outperforms our own image-based baseline by generalizing across diverse degradations, underscoring the value of temporal modeling for scalable VQA in real-world vision systems. Additionally, we demonstrate that our model achieves higher correlation with full-reference metrics compared to BRISQUE, a widely-used opinion-aware image quality assessment baseline, validating the effectiveness of our temporal, opinion-unaware approach.",
    "authors": [
      "Kylie Cancilla",
      "Alexander Moore",
      "Amar Saini",
      "Carmen Carrano"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04628v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04628v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.04583v1",
    "title": "Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration   from a Baseline Paper",
    "summary": "Understanding the current capabilities and risks of AI Scientist systems is essential for ensuring trustworthy and sustainable AI-driven scientific progress while preserving the integrity of the academic ecosystem. To this end, we develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system that mimics the core research workflow of a novice student researcher: Given the baseline paper from the human mentor, it analyzes its limitations, formulates novel hypotheses for improvement, validates them through rigorous experimentation, and writes a paper with the results. Unlike previous approaches that assume full automation or operate on small-scale code, Jr. AI Scientist follows a well-defined research workflow and leverages modern coding agents to handle complex, multi-file implementations, leading to scientifically valuable contributions. For evaluation, we conducted automated assessments using AI Reviewers, author-led evaluations, and submissions to Agents4Science, a venue dedicated to AI-driven scientific contributions. The findings demonstrate that Jr. AI Scientist generates papers receiving higher review scores than existing fully automated systems. Nevertheless, we identify important limitations from both the author evaluation and the Agents4Science reviews, indicating the potential risks of directly applying current AI Scientist systems and key challenges for future research. Finally, we comprehensively report various risks identified during development. We hope these insights will deepen understanding of current progress and risks in AI Scientist development.",
    "authors": [
      "Atsuyuki Miyai",
      "Mashiro Toyooka",
      "Takashi Otonari",
      "Zaiying Zhao",
      "Kiyoharu Aizawa"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04583v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04583v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.04510v1",
    "title": "$μ$NeuFMT: Optical-Property-Adaptive Fluorescence Molecular Tomography   via Implicit Neural Representation",
    "summary": "Fluorescence Molecular Tomography (FMT) is a promising technique for non-invasive 3D visualization of fluorescent probes, but its reconstruction remains challenging due to the inherent ill-posedness and reliance on inaccurate or often-unknown tissue optical properties. While deep learning methods have shown promise, their supervised nature limits generalization beyond training data. To address these problems, we propose $\\mu$NeuFMT, a self-supervised FMT reconstruction framework that integrates implicit neural-based scene representation with explicit physical modeling of photon propagation. Its key innovation lies in jointly optimize both the fluorescence distribution and the optical properties ($\\mu$) during reconstruction, eliminating the need for precise prior knowledge of tissue optics or pre-conditioned training data. We demonstrate that $\\mu$NeuFMT robustly recovers accurate fluorophore distributions and optical coefficients even with severely erroneous initial values (0.5$\\times$ to 2$\\times$ of ground truth). Extensive numerical, phantom, and in vivo validations show that $\\mu$NeuFMT outperforms conventional and supervised deep learning approaches across diverse heterogeneous scenarios. Our work establishes a new paradigm for robust and accurate FMT reconstruction, paving the way for more reliable molecular imaging in complex clinically related scenarios, such as fluorescence guided surgery.",
    "authors": [
      "Shihan Zhao",
      "Jianru Zhang",
      "Yanan Wu",
      "Linlin Li",
      "Siyuan Shen",
      "Xingjun Zhu",
      "Guoyan Zheng",
      "Jiahua Jiang",
      "Wuwei Ren"
    ],
    "categories": [
      "eess.IV",
      "cs.CV",
      "physics.optics",
      "68T07, 78A46, 78A70, 92C55",
      "I.2.10; I.4.5"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04510v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04510v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.04506v1",
    "title": "Modeling Clinical Uncertainty in Radiology Reports: from Explicit   Uncertainty Markers to Implicit Reasoning Pathways",
    "summary": "Radiology reports are invaluable for clinical decision-making and hold great potential for automated analysis when structured into machine-readable formats. These reports often contain uncertainty, which we categorize into two distinct types: (i) Explicit uncertainty reflects doubt about the presence or absence of findings, conveyed through hedging phrases. These vary in meaning depending on the context, making rule-based systems insufficient to quantify the level of uncertainty for specific findings; (ii) Implicit uncertainty arises when radiologists omit parts of their reasoning, recording only key findings or diagnoses. Here, it is often unclear whether omitted findings are truly absent or simply unmentioned for brevity. We address these challenges with a two-part framework. We quantify explicit uncertainty by creating an expert-validated, LLM-based reference ranking of common hedging phrases, and mapping each finding to a probability value based on this reference. In addition, we model implicit uncertainty through an expansion framework that systematically adds characteristic sub-findings derived from expert-defined diagnostic pathways for 14 common diagnoses. Using these methods, we release Lunguage++, an expanded, uncertainty-aware version of the Lunguage benchmark of fine-grained structured radiology reports. This enriched resource enables uncertainty-aware image classification, faithful diagnostic reasoning, and new investigations into the clinical impact of diagnostic uncertainty.",
    "authors": [
      "Paloma Rabaey",
      "Jong Hak Moon",
      "Jung-Oh Lee",
      "Min Gwan Kim",
      "Hangyul Yoon",
      "Thomas Demeester",
      "Edward Choi"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04506v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04506v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.04465v1",
    "title": "Fraud-Proof Revenue Division on Subscription Platforms",
    "summary": "We study a model of subscription-based platforms where users pay a fixed fee for unlimited access to content, and creators receive a share of the revenue. Existing approaches to detecting fraud predominantly rely on machine learning methods, engaging in an ongoing arms race with bad actors. We explore revenue division mechanisms that inherently disincentivize manipulation. We formalize three types of manipulation-resistance axioms and examine which existing rules satisfy these. We show that a mechanism widely used by streaming platforms, not only fails to prevent fraud, but also makes detecting manipulation computationally intractable. We also introduce a novel rule, ScaledUserProp, that satisfies all three manipulation-resistance axioms. Finally, experiments with both real-world and synthetic streaming data support ScaledUserProp as a fairer alternative compared to existing rules.",
    "authors": [
      "Abheek Ghosh",
      "Tzeh Yuan Neoh",
      "Nicholas Teh",
      "Giannis Tyrovolas"
    ],
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG",
      "econ.TH"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04465v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04465v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.04384v1",
    "title": "Multi-Task Learning for Visually Grounded Reasoning in Gastrointestinal   VQA",
    "summary": "We present a multi-task framework for the MediaEval Medico 2025 challenge, leveraging a LoRA-tuned Florence-2 model for simultaneous visual question answering (VQA), explanation generation, and visual grounding. The proposed system integrates three curated datasets: (1) Kvasir-VQA-x1 for question-answer learning, (2) a synthetically enriched explanation dataset offering structured medical reasoning, and (3) text-to-region pairs linking visual features with segmentation masks. This multi-task setup enables the model to jointly learn visual grounding, reasoning, and interpretation, producing responses that are both accurate and interpretable. Extensive evaluation demonstrates that our approach substantially improves over single-task baselines in both answer accuracy and visual localization, highlighting the effectiveness of grounded multi-task learning for medical VQA applications.",
    "authors": [
      "Itbaan Safwan",
      "Muhammad Annas Shaikh",
      "Muhammad Haaris",
      "Ramail Khan",
      "Muhammad Atif Tahir"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04384v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04384v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.04139v1",
    "title": "CantoASR: Prosody-Aware ASR-LALM Collaboration for Low-Resource   Cantonese",
    "summary": "Automatic speech recognition (ASR) is critical for language accessibility, yet low-resource Cantonese remains challenging due to limited annotated data, six lexical tones, tone sandhi, and accent variation. Existing ASR models, such as Whisper, often suffer from high word error rates. Large audio-language models (LALMs), in contrast, can leverage broader contextual reasoning but still require explicit tonal and prosodic acoustic cues. We introduce CantoASR, a collaborative ASR-LALM error correction framework that integrates forced alignment for acoustic feature extraction, a LoRA-finetuned Whisper for improved tone discrimination, and an instruction-tuned Qwen-Audio for prosody-aware correction. Evaluations on spontaneous Cantonese data show substantial CER gains over Whisper-Large-V3. These findings suggest that integrating acoustic cues with LALM reasoning provides a scalable strategy for low-resource tonal and dialectal ASR.",
    "authors": [
      "Dazhong Chen",
      "Yi-Cheng Lin",
      "Yuchen Huang",
      "Ziwei Gong",
      "Di Jiang",
      "Zeying Xie",
      "Yi R.",
      " Fung"
    ],
    "categories": [
      "cs.CL",
      "cs.SD"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04139v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04139v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.04112v1",
    "title": "SpatialLock: Precise Spatial Control in Text-to-Image Synthesis",
    "summary": "Text-to-Image (T2I) synthesis has made significant advancements in recent years, driving applications such as generating datasets automatically. However, precise control over object localization in generated images remains a challenge. Existing methods fail to fully utilize positional information, leading to an inadequate understanding of object spatial layouts. To address this issue, we propose SpatialLock, a novel framework that leverages perception signals and grounding information to jointly control the generation of spatial locations. SpatialLock incorporates two components: Position-Engaged Injection (PoI) and Position-Guided Learning (PoG). PoI directly integrates spatial information through an attention layer, encouraging the model to learn the grounding information effectively. PoG employs perception-based supervision to further refine object localization. Together, these components enable the model to generate objects with precise spatial arrangements and improve the visual quality of the generated images. Experiments show that SpatialLock sets a new state-of-the-art for precise object positioning, achieving IOU scores above 0.9 across multiple datasets.",
    "authors": [
      "Biao Liu",
      "Yuanzhi Liang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04112v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04112v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.04040v1",
    "title": "Enhancing Multimodal Protein Function Prediction Through Dual-Branch   Dynamic Selection with Reconstructive Pre-Training",
    "summary": "Multimodal protein features play a crucial role in protein function prediction. However, these features encompass a wide range of information, ranging from structural data and sequence features to protein attributes and interaction networks, making it challenging to decipher their complex interconnections. In this work, we propose a multimodal protein function prediction method (DSRPGO) by utilizing dynamic selection and reconstructive pre-training mechanisms. To acquire complex protein information, we introduce reconstructive pre-training to mine more fine-grained information with low semantic levels. Moreover, we put forward the Bidirectional Interaction Module (BInM) to facilitate interactive learning among multimodal features. Additionally, to address the difficulty of hierarchical multi-label classification in this task, a Dynamic Selection Module (DSM) is designed to select the feature representation that is most conducive to current protein function prediction. Our proposed DSRPGO model improves significantly in BPO, MFO, and CCO on human datasets, thereby outperforming other benchmark models.",
    "authors": [
      "Xiaoling Luo",
      "Peng Chen",
      "Chengliang Liu",
      "Xiaopeng Jin",
      "Jie Wen",
      "Yumeng Liu",
      "Junsong Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.NE",
      "q-bio.BM"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04040v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04040v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.04653v1",
    "title": "TT-Prune: Joint Model Pruning and Resource Allocation for   Communication-efficient Time-triggered Federated Learning",
    "summary": "Federated learning (FL) offers new opportunities in machine learning, particularly in addressing data privacy concerns. In contrast to conventional event-based federated learning, time-triggered federated learning (TT-Fed), as a general form of both asynchronous and synchronous FL, clusters users into different tiers based on fixed time intervals. However, the FL network consists of a growing number of user devices with limited wireless bandwidth, consequently magnifying issues such as stragglers and communication overhead. In this paper, we introduce adaptive model pruning to wireless TT-Fed systems and study the problem of jointly optimizing the pruning ratio and bandwidth allocation to minimize the training loss while ensuring minimal learning latency. To answer this question, we perform convergence analysis on the gradient l_2 norm of the TT-Fed model based on model pruning. Based on the obtained convergence upper bound, a joint optimization problem of pruning ratio and wireless bandwidth is formulated to minimize the model training loss under a given delay threshold. Then, we derive closed-form solutions for wireless bandwidth and pruning ratio using Karush-Kuhn-Tucker(KKT) conditions. The simulation results show that model pruning could reduce the communication cost by 40% while maintaining the model performance at the same level.",
    "authors": [
      "Xinlu Zhang",
      "Yansha Deng",
      "Toktam Mahmoodi"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04653v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04653v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.04638v1",
    "title": "Addressing divergent representations from causal interventions on neural   networks",
    "summary": "A common approach to mechanistic interpretability is to causally manipulate model representations via targeted interventions in order to understand what those representations encode. Here we ask whether such interventions create out-of-distribution (divergent) representations, and whether this raises concerns about how faithful their resulting explanations are to the target model in its natural state. First, we demonstrate empirically that common causal intervention techniques often do shift internal representations away from the natural distribution of the target model. Then, we provide a theoretical analysis of two classes of such divergences: `harmless' divergences that occur in the null-space of the weights and from covariance within behavioral decision boundaries, and `pernicious' divergences that activate hidden network pathways and cause dormant behavioral changes. Finally, in an effort to mitigate the pernicious cases, we modify the Counterfactual Latent (CL) loss from Grant (2025) that regularizes interventions to remain closer to the natural distributions, reducing the likelihood of harmful divergences while preserving the interpretive power of interventions. Together, these results highlight a path towards more reliable interpretability methods.",
    "authors": [
      "Satchel Grant",
      "Simon Jerome Han",
      "Alexa Tartaglini",
      "Christopher Potts"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04638v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04638v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.04520v1",
    "title": "THEval. Evaluation Framework for Talking Head Video Generation",
    "summary": "Video generation has achieved remarkable progress, with generated videos increasingly resembling real ones. However, the rapid advance in generation has outpaced the development of adequate evaluation metrics. Currently, the assessment of talking head generation primarily relies on limited metrics, evaluating general video quality, lip synchronization, and on conducting user studies. Motivated by this, we propose a new evaluation framework comprising 8 metrics related to three dimensions (i) quality, (ii) naturalness, and (iii) synchronization. In selecting the metrics, we place emphasis on efficiency, as well as alignment with human preferences. Based on this considerations, we streamline to analyze fine-grained dynamics of head, mouth, and eyebrows, as well as face quality. Our extensive experiments on 85,000 videos generated by 17 state-of-the-art models suggest that while many algorithms excel in lip synchronization, they face challenges with generating expressiveness and artifact-free details. These videos were generated based on a novel real dataset, that we have curated, in order to mitigate bias of training data. Our proposed benchmark framework is aimed at evaluating the improvement of generative methods. Original code, dataset and leaderboards will be publicly released and regularly updated with new methods, in order to reflect progress in the field.",
    "authors": [
      "Nabyl Quignon",
      "Baptiste Chopin",
      "Yaohui Wang",
      "Antitza Dantcheva"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04520v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04520v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.04456v1",
    "title": "Federated Stochastic Minimax Optimization under Heavy-Tailed Noises",
    "summary": "Heavy-tailed noise has attracted growing attention in nonconvex stochastic optimization, as numerous empirical studies suggest it offers a more realistic assumption than standard bounded variance assumption. In this work, we investigate nonconvex-PL minimax optimization under heavy-tailed gradient noise in federated learning. We propose two novel algorithms: Fed-NSGDA-M, which integrates normalized gradients, and FedMuon-DA, which leverages the Muon optimizer for local updates. Both algorithms are designed to effectively address heavy-tailed noise in federated minimax optimization, under a milder condition. We theoretically establish that both algorithms achieve a convergence rate of $O({1}/{(TNp)^{\\frac{s-1}{2s}}})$. To the best of our knowledge, these are the first federated minimax optimization algorithms with rigorous theoretical guarantees under heavy-tailed noise. Extensive experiments further validate their effectiveness.",
    "authors": [
      "Xinwen Zhang",
      "Hongchang Gao"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04456v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04456v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.04328v1",
    "title": "RxSafeBench: Identifying Medication Safety Issues of Large Language   Models in Simulated Consultation",
    "summary": "Numerous medical systems powered by Large Language Models (LLMs) have achieved remarkable progress in diverse healthcare tasks. However, research on their medication safety remains limited due to the lack of real world datasets, constrained by privacy and accessibility issues. Moreover, evaluation of LLMs in realistic clinical consultation settings, particularly regarding medication safety, is still underexplored. To address these gaps, we propose a framework that simulates and evaluates clinical consultations to systematically assess the medication safety capabilities of LLMs. Within this framework, we generate inquiry diagnosis dialogues with embedded medication risks and construct a dedicated medication safety database, RxRisk DB, containing 6,725 contraindications, 28,781 drug interactions, and 14,906 indication-drug pairs. A two-stage filtering strategy ensures clinical realism and professional quality, resulting in the benchmark RxSafeBench with 2,443 high-quality consultation scenarios. We evaluate leading open-source and proprietary LLMs using structured multiple choice questions that test their ability to recommend safe medications under simulated patient contexts. Results show that current LLMs struggle to integrate contraindication and interaction knowledge, especially when risks are implied rather than explicit. Our findings highlight key challenges in ensuring medication safety in LLM-based systems and provide insights into improving reliability through better prompting and task-specific tuning. RxSafeBench offers the first comprehensive benchmark for evaluating medication safety in LLMs, advancing safer and more trustworthy AI-driven clinical decision support.",
    "authors": [
      "Jiahao Zhao",
      "Luxin Xu",
      "Minghuan Tan",
      "Lichao Zhang",
      "Ahmadreza Argha",
      "Hamid Alinejad-Rokny",
      "Min Yang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04328v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04328v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.04243v1",
    "title": "Twirlator: A Pipeline for Analyzing Subgroup Symmetry Effects in Quantum   Machine Learning Ansatzes",
    "summary": "Leveraging data symmetries has been a key driver of performance gains in geometric deep learning and geometric and equivariant quantum machine learning. While symmetrization appears to be a promising method, its practical overhead, such as additional gates, reduced expressibility, and other factors, is not well understood in quantum machine learning. In this work, we develop an automated pipeline to measure various characteristics of quantum machine learning ansatzes with respect to symmetries that can appear in the learning task. We define the degree of symmetry in the learning problem as the size of the subgroup it admits. Subgroups define partial symmetries, which have not been extensively studied in previous research, which has focused on symmetries defined by whole groups. Symmetrizing the 19 common ansatzes with respect to these varying-sized subgroup representations, we compute three classes of metrics that describe how the common ansatz structures behave under varying amounts of symmetries. The first metric is based on the norm of the difference between the original and symmetrized generators, while the second metric counts depth, size, and other characteristics from the symmetrized circuits. The third class of metrics includes expressibility and entangling capability. The results demonstrate varying gate overhead across the studied ansatzes and confirm that increased symmetry reduces expressibility of the circuits. In most cases, increased symmetry increases entanglement capability. These results help select sufficiently expressible and computationally efficient ansatze patterns for geometric quantum machine learning applications.",
    "authors": [
      "Valter Uotila",
      "Väinö Mehtola",
      "Ilmo Salmenperä",
      "Bo Zhao"
    ],
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04243v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04243v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.04133v1",
    "title": "Testing the Testers: Human-Driven Quality Assessment of Voice AI Testing   Platforms",
    "summary": "Voice AI agents are rapidly transitioning to production deployments, yet systematic methods for ensuring testing reliability remain underdeveloped. Organizations cannot objectively assess whether their testing approaches (internal tools or external platforms) actually work, creating a critical measurement gap as voice AI scales to billions of daily interactions.   We present the first systematic framework for evaluating voice AI testing quality through human-centered benchmarking. Our methodology addresses the fundamental dual challenge of testing platforms: generating realistic test conversations (simulation quality) and accurately evaluating agent responses (evaluation quality). The framework combines established psychometric techniques (pairwise comparisons yielding Elo ratings, bootstrap confidence intervals, and permutation tests) with rigorous statistical validation to provide reproducible metrics applicable to any testing approach.   To validate the framework and demonstrate its utility, we conducted comprehensive empirical evaluation of three leading commercial platforms focused on Voice AI Testing using 21,600 human judgments across 45 simulations and ground truth validation on 60 conversations. Results reveal statistically significant performance differences with the proposed framework, with the top-performing platform, Evalion, achieving 0.92 evaluation quality measured as f1-score versus 0.73 for others, and 0.61 simulation quality using a league based scoring system (including ties) vs 0.43 for other platforms.   This framework enables researchers and organizations to empirically validate the testing capabilities of any platform, providing essential measurement foundations for confident voice AI deployment at scale. Supporting materials are made available to facilitate reproducibility and adoption.",
    "authors": [
      "Miguel E. Andres",
      "Vadim Fedorov",
      "Rida Sadek",
      "Enric Spagnolo-Arrizabalaga",
      "Nadescha Trudel"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04133v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04133v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.04124v1",
    "title": "Decomposable Neuro Symbolic Regression",
    "summary": "Symbolic regression (SR) models complex systems by discovering mathematical expressions that capture underlying relationships in observed data. However, most SR methods prioritize minimizing prediction error over identifying the governing equations, often producing overly complex or inaccurate expressions. To address this, we present a decomposable SR method that generates interpretable multivariate expressions leveraging transformer models, genetic algorithms (GAs), and genetic programming (GP). In particular, our explainable SR method distills a trained ``opaque'' regression model into mathematical expressions that serve as explanations of its computed function. Our method employs a Multi-Set Transformer to generate multiple univariate symbolic skeletons that characterize how each variable influences the opaque model's response. We then evaluate the generated skeletons' performance using a GA-based approach to select a subset of high-quality candidates before incrementally merging them via a GP-based cascade procedure that preserves their original skeleton structure. The final multivariate skeletons undergo coefficient optimization via a GA. We evaluated our method on problems with controlled and varying degrees of noise, demonstrating lower or comparable interpolation and extrapolation errors compared to two GP-based methods, three neural SR methods, and a hybrid approach. Unlike them, our approach consistently learned expressions that matched the original mathematical structure.",
    "authors": [
      "Giorgio Morales",
      "John W. Sheppard"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04124v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04124v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.04084v1",
    "title": "When Swin Transformer Meets KANs: An Improved Transformer Architecture   for Medical Image Segmentation",
    "summary": "Medical image segmentation is critical for accurate diagnostics and treatment planning, but remains challenging due to complex anatomical structures and limited annotated training data. CNN-based segmentation methods excel at local feature extraction, but struggle with modeling long-range dependencies. Transformers, on the other hand, capture global context more effectively, but are inherently data-hungry and computationally expensive. In this work, we introduce UKAST, a U-Net like architecture that integrates rational-function based Kolmogorov-Arnold Networks (KANs) into Swin Transformer encoders. By leveraging rational base functions and Group Rational KANs (GR-KANs) from the Kolmogorov-Arnold Transformer (KAT), our architecture addresses the inefficiencies of vanilla spline-based KANs, yielding a more expressive and data-efficient framework with reduced FLOPs and only a very small increase in parameter count compared to SwinUNETR. UKAST achieves state-of-the-art performance on four diverse 2D and 3D medical image segmentation benchmarks, consistently surpassing both CNN- and Transformer-based baselines. Notably, it attains superior accuracy in data-scarce settings, alleviating the data-hungry limitations of standard Vision Transformers. These results show the potential of KAN-enhanced Transformers to advance data-efficient medical image segmentation. Code is available at: https://github.com/nsapkota417/UKAST",
    "authors": [
      "Nishchal Sapkota",
      "Haoyan Shi",
      "Yejia Zhang",
      "Xianshi Ma",
      "Bofang Zheng",
      "Danny Z. Chen"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04084v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04084v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.04042v1",
    "title": "An LLM-based Framework for Human-Swarm Teaming Cognition in Disaster   Search and Rescue",
    "summary": "Large-scale disaster Search And Rescue (SAR) operations are persistently challenged by complex terrain and disrupted communications. While Unmanned Aerial Vehicle (UAV) swarms offer a promising solution for tasks like wide-area search and supply delivery, yet their effective coordination places a significant cognitive burden on human operators. The core human-machine collaboration bottleneck lies in the ``intention-to-action gap'', which is an error-prone process of translating a high-level rescue objective into a low-level swarm command under high intensity and pressure. To bridge this gap, this study proposes a novel LLM-CRF system that leverages Large Language Models (LLMs) to model and augment human-swarm teaming cognition. The proposed framework initially captures the operator's intention through natural and multi-modal interactions with the device via voice or graphical annotations. It then employs the LLM as a cognitive engine to perform intention comprehension, hierarchical task decomposition, and mission planning for the UAV swarm. This closed-loop framework enables the swarm to act as a proactive partner, providing active feedback in real-time while reducing the need for manual monitoring and control, which considerably advances the efficacy of the SAR task. We evaluate the proposed framework in a simulated SAR scenario. Experimental results demonstrate that, compared to traditional order and command-based interfaces, the proposed LLM-driven approach reduced task completion time by approximately $64.2\\%$ and improved task success rate by $7\\%$. It also leads to a considerable reduction in subjective cognitive workload, with NASA-TLX scores dropping by $42.9\\%$. This work establishes the potential of LLMs to create more intuitive and effective human-swarm collaborations in high-stakes scenarios.",
    "authors": [
      "Kailun Ji",
      "Xiaoyu Hu",
      "Xinyu Zhang",
      "Jun Chen"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04042v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04042v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.04675v1",
    "title": "InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual   Generation",
    "summary": "We introduce InfinityStar, a unified spacetime autoregressive framework for high-resolution image and dynamic video synthesis. Building on the recent success of autoregressive modeling in both vision and language, our purely discrete approach jointly captures spatial and temporal dependencies within a single architecture. This unified design naturally supports a variety of generation tasks such as text-to-image, text-to-video, image-to-video, and long interactive video synthesis via straightforward temporal autoregression. Extensive experiments demonstrate that InfinityStar scores 83.74 on VBench, outperforming all autoregressive models by large margins, even surpassing some diffusion competitors like HunyuanVideo. Without extra optimizations, our model generates a 5s, 720p video approximately 10x faster than leading diffusion-based methods. To our knowledge, InfinityStar is the first discrete autoregressive video generator capable of producing industrial level 720p videos. We release all code and models to foster further research in efficient, high-quality video generation.",
    "authors": [
      "Jinlai Liu",
      "Jian Han",
      "Bin Yan",
      "Hui Wu",
      "Fengda Zhu",
      "Xing Wang",
      "Yi Jiang",
      "Bingyue Peng",
      "Zehuan Yuan"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04675v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04675v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04666v1",
    "title": "Forgetting is Everywhere",
    "summary": "A fundamental challenge in developing general learning algorithms is their tendency to forget past knowledge when adapting to new data. Addressing this problem requires a principled understanding of forgetting; yet, despite decades of study, no unified definition has emerged that provides insights into the underlying dynamics of learning. We propose an algorithm- and task-agnostic theory that characterises forgetting as a lack of self-consistency in a learner's predictive distribution over future experiences, manifesting as a loss of predictive information. Our theory naturally yields a general measure of an algorithm's propensity to forget. To validate the theory, we design a comprehensive set of experiments that span classification, regression, generative modelling, and reinforcement learning. We empirically demonstrate how forgetting is present across all learning settings and plays a significant role in determining learning efficiency. Together, these results establish a principled understanding of forgetting and lay the foundation for analysing and improving the information retention capabilities of general learning algorithms.",
    "authors": [
      "Ben Sanati",
      "Thomas L. Lee",
      "Trevor McInroe",
      "Aidan Scannell",
      "Nikolay Malkin",
      "David Abel",
      "Amos Storkey"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04666v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04666v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04619v1",
    "title": "Dynamic causal discovery in Alzheimer's disease through latent   pseudotime modelling",
    "summary": "The application of causal discovery to diseases like Alzheimer's (AD) is limited by the static graph assumptions of most methods; such models cannot account for an evolving pathophysiology, modulated by a latent disease pseudotime. We propose to apply an existing latent variable model to real-world AD data, inferring a pseudotime that orders patients along a data-driven disease trajectory independent of chronological age, then learning how causal relationships evolve. Pseudotime outperformed age in predicting diagnosis (AUC 0.82 vs 0.59). Incorporating minimal, disease-agnostic background knowledge substantially improved graph accuracy and orientation. Our framework reveals dynamic interactions between novel (NfL, GFAP) and established AD markers, enabling practical causal discovery despite violated assumptions.",
    "authors": [
      "Natalia Glazman",
      "Jyoti Mangal",
      "Pedro Borges",
      "Sebastien Ourselin",
      "M. Jorge Cardoso"
    ],
    "categories": [
      "stat.AP",
      "cs.CE",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04619v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04619v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04573v1",
    "title": "ARETE: an R package for Automated REtrieval from TExt with large   language models",
    "summary": "1. A hard stop for the implementation of rigorous conservation initiatives is our lack of key species data, especially occurrence data. Furthermore, researchers have to contend with an accelerated speed at which new information must be collected and processed due to anthropogenic activity. Publications ranging from scientific papers to gray literature contain this crucial information but their data are often not machine-readable, requiring extensive human work to be retrieved. 2. We present the ARETE R package, an open-source software aiming to automate data extraction of species occurrences powered by large language models, namely using the chatGPT Application Programming Interface. This R package integrates all steps of the data extraction and validation process, from Optical Character Recognition to detection of outliers and output in tabular format. Furthermore, we validate ARETE through systematic comparison between what is modelled and the work of human annotators. 3. We demonstrate the usefulness of the approach by comparing range maps produced using GBIF data and with those automatically extracted for 100 species of spiders. Newly extracted data allowed to expand the known Extent of Occurrence by a mean three orders of magnitude, revealing new areas where the species were found in the past, which mayhave important implications for spatial conservation planning and extinction risk assessments. 4. ARETE allows faster access to hitherto untapped occurrence data, a potential game changer in projects requiring such data. Researchers will be able to better prioritize resources, manually verifying selected species while maintaining automated extraction for the majority. This workflow also allows predicting available bibliographic data during project planning.",
    "authors": [
      "Vasco V. Branco",
      "Jandó Benedek",
      "Lidia Pivovarova",
      "Luís Correia",
      "Pedro Cardoso"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04573v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04573v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04538v1",
    "title": "From Model to Breach: Towards Actionable LLM-Generated Vulnerabilities   Reporting",
    "summary": "As the role of Large Language Models (LLM)-based coding assistants in software development becomes more critical, so does the role of the bugs they generate in the overall cybersecurity landscape. While a number of LLM code security benchmarks have been proposed alongside approaches to improve the security of generated code, it remains unclear to what extent they have impacted widely used coding LLMs. Here, we show that even the latest open-weight models are vulnerable in the earliest reported vulnerability scenarios in a realistic use setting, suggesting that the safety-functionality trade-off has until now prevented effective patching of vulnerabilities. To help address this issue, we introduce a new severity metric that reflects the risk posed by an LLM-generated vulnerability, accounting for vulnerability severity, generation chance, and the formulation of the prompt that induces vulnerable code generation - Prompt Exposure (PE). To encourage the mitigation of the most serious and prevalent vulnerabilities, we use PE to define the Model Exposure (ME) score, which indicates the severity and prevalence of vulnerabilities a model generates.",
    "authors": [
      "Cyril Vallez",
      "Alexander Sternfeld",
      "Andrei Kucharavy",
      "Ljiljana Dolamic"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04538v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04538v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04499v1",
    "title": "Decoding Emergent Big Five Traits in Large Language Models:   Temperature-Dependent Expression and Architectural Clustering",
    "summary": "As Large Language Models (LLMs) become integral to human-centered applications, understanding their personality-like behaviors is increasingly important for responsible development and deployment. This paper systematically evaluates six LLMs, applying the Big Five Inventory-2 (BFI-2) framework, to assess trait expressions under varying sampling temperatures. We find significant differences across four of the five personality dimensions, with Neuroticism and Extraversion susceptible to temperature adjustments. Further, hierarchical clustering reveals distinct model clusters, suggesting that architectural features may predispose certain models toward stable trait profiles. Taken together, these results offer new insights into the emergence of personality-like patterns in LLMs and provide a new perspective on model tuning, selection, and the ethical governance of AI systems. We share the data and code for this analysis here: https://osf.io/bsvzc/?view_only=6672219bede24b4e875097426dc3fac1",
    "authors": [
      "Christos-Nikolaos Zacharopoulos",
      "Revekka Kyriakoglou"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04499v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04499v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04491v1",
    "title": "RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within   Structured Tables",
    "summary": "Existing tabular reasoning benchmarks mostly test models on small, uniform tables, underrepresenting the complexity of real-world data and giving an incomplete view of Large Language Models' (LLMs) reasoning abilities. Real tables are long, heterogeneous, and domain-specific, mixing structured fields with free text and requiring multi-hop reasoning across thousands of tokens. To address this gap, we introduce RUST-BENCH, a benchmark of 7966 questions from 2031 real-world tables spanning two domains: i) RB-Science (NSF grant records) and ii) RB-Sports (NBA statistics). Unlike prior work, RUST-BENCH evaluates LLMs jointly across scale, heterogeneity, domain specificity, and reasoning complexity. Experiments with open-source and proprietary models show that LLMs struggle with heterogeneous schemas and complex multi-hop inference, revealing persistent weaknesses in current architectures and prompting strategies. RUST-BENCH establishes a challenging new testbed for advancing tabular reasoning research.",
    "authors": [
      "Nikhil Abhyankar",
      "Purvi Chaurasia",
      "Sanchit Kabra",
      "Ananya Srivastava",
      "Vivek Gupta",
      "Chandan K. Reddy"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04491v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04491v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04473v1",
    "title": "Ground-Truth Subgraphs for Better Training and Evaluation of Knowledge   Graph Augmented LLMs",
    "summary": "Retrieval of information from graph-structured knowledge bases represents a promising direction for improving the factuality of LLMs. While various solutions have been proposed, a comparison of methods is difficult due to the lack of challenging QA datasets with ground-truth targets for graph retrieval. We present SynthKGQA, a framework for generating high-quality synthetic Knowledge Graph Question Answering datasets from any Knowledge Graph, providing the full set of ground-truth facts in the KG to reason over each question. We show how, in addition to enabling more informative benchmarking of KG retrievers, the data produced with SynthKGQA also allows us to train better models. We apply SynthKGQA to Wikidata to generate GTSQA, a new dataset designed to test zero-shot generalization abilities of KG retrievers with respect to unseen graph structures and relation types, and benchmark popular solutions for KG-augmented LLMs on it.",
    "authors": [
      "Alberto Cattaneo",
      "Carlo Luschi",
      "Daniel Justus"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04473v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04473v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04469v1",
    "title": "Towards Causal Market Simulators",
    "summary": "Market generators using deep generative models have shown promise for synthetic financial data generation, but existing approaches lack causal reasoning capabilities essential for counterfactual analysis and risk assessment. We propose a Time-series Neural Causal Model VAE (TNCM-VAE) that combines variational autoencoders with structural causal models to generate counterfactual financial time series while preserving both temporal dependencies and causal relationships. Our approach enforces causal constraints through directed acyclic graphs in the decoder architecture and employs the causal Wasserstein distance for training. We validate our method on synthetic autoregressive models inspired by the Ornstein-Uhlenbeck process, demonstrating superior performance in counterfactual probability estimation with L1 distances as low as 0.03-0.10 compared to ground truth. The model enables financial stress testing, scenario analysis, and enhanced backtesting by generating plausible counterfactual market trajectories that respect underlying causal mechanisms.",
    "authors": [
      "Dennis Thumm",
      "Luis Ontaneda Mijares"
    ],
    "categories": [
      "cs.LG",
      "q-fin.CP",
      "stat.OT"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04469v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04469v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04461v1",
    "title": "Data-driven uncertainty-aware seakeeping prediction of the Delft 372   catamaran using ensemble Hankel dynamic mode decomposition",
    "summary": "In this study, we present and validate an ensemble-based Hankel Dynamic Mode Decomposition with control (HDMDc) for uncertainty-aware seakeeping predictions of a high-speed catamaran, namely the Delft 372 model. Experimental measurements (time histories) of wave elevation at the longitudinal center of gravity, heave, pitch, notional flight-deck velocity, notional bridge acceleration, and total resistance were collected from irregular wave basin tests on a 1:33.3 scale replica of the Delft 372 model under sea state 5 conditions at Fr = 0.425, and organized into training, validation, and test sets. The HDMDc algorithm constructs an equation-free linear reduced-order model of the seakeeping vessel by augmenting states and inputs with their time-lagged copies to capture nonlinear and memory effects. Two ensembling strategies, namely Bayesian HDMDc (BHDMDc), which samples hyperparameters considered stochastic variables with prior distribution to produce posterior mean forecasts with confidence intervals, and Frequentist HDMDc (FHDMDc), which aggregates multiple model obtained over data subsets, are compared in providing seakeeping prediction and uncertainty quantification. The FHDMDc approach is found to improve the accuracy of the predictions compared to the deterministic counterpart, also providing robust uncertainty estimation; whereas the application of BHDMDc to the present test case is not found beneficial in comparison to the deterministic model. FHDMDc-derived probability density functions for the motions closely match both experimental data and URANS results, demonstrating reliable and computationally efficient seakeeping prediction for design and operational support.",
    "authors": [
      "Giorgio Palma",
      "Andrea Serani",
      "Matteo Diez"
    ],
    "categories": [
      "eess.SY",
      "cs.CE",
      "cs.LG",
      "cs.SY"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04461v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04461v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04321v1",
    "title": "AIM: Software and Hardware Co-design for Architecture-level IR-drop   Mitigation in High-performance PIM",
    "summary": "SRAM Processing-in-Memory (PIM) has emerged as the most promising implementation for high-performance PIM, delivering superior computing density, energy efficiency, and computational precision. However, the pursuit of higher performance necessitates more complex circuit designs and increased operating frequencies, which exacerbate IR-drop issues. Severe IR-drop can significantly degrade chip performance and even threaten reliability. Conventional circuit-level IR-drop mitigation methods, such as back-end optimizations, are resource-intensive and often compromise power, performance, and area (PPA). To address these challenges, we propose AIM, comprehensive software and hardware co-design for architecture-level IR-drop mitigation in high-performance PIM. Initially, leveraging the bit-serial and in-situ dataflow processing properties of PIM, we introduce Rtog and HR, which establish a direct correlation between PIM workloads and IR-drop. Building on this foundation, we propose LHR and WDS, enabling extensive exploration of architecture-level IR-drop mitigation while maintaining computational accuracy through software optimization. Subsequently, we develop IR-Booster, a dynamic adjustment mechanism that integrates software-level HR information with hardware-based IR-drop monitoring to adapt the V-f pairs of the PIM macro, achieving enhanced energy efficiency and performance. Finally, we propose the HR-aware task mapping method, bridging software and hardware designs to achieve optimal improvement. Post-layout simulation results on a 7nm 256-TOPS PIM chip demonstrate that AIM achieves up to 69.2% IR-drop mitigation, resulting in 2.29x energy efficiency improvement and 1.152x speedup.",
    "authors": [
      "Yuanpeng Zhang",
      "Xing Hu",
      "Xi Chen",
      "Zhihang Yuan",
      "Cong Li",
      "Jingchen Zhu",
      "Zhao Wang",
      "Chenguang Zhang",
      "Xin Si",
      "Wei Gao",
      "Qiang Wu",
      "Runsheng Wang",
      "Guangyu Sun"
    ],
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04321v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04321v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04307v1",
    "title": "GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents",
    "summary": "We introduce GUI-360$^\\circ$, a large-scale, comprehensive dataset and benchmark suite designed to advance computer-using agents (CUAs). CUAs present unique challenges and is constrained by three persistent gaps: a scarcity of real-world CUA tasks, the lack of automated collection-and-annotation pipelines for multi-modal trajectories, and the absence of a unified benchmark that jointly evaluates GUI grounding, screen parsing, and action prediction.   GUI-360$^\\circ$ addresses these gaps with an LLM-augmented, largely automated pipeline for query sourcing, environment-template construction, task instantiation, batched execution, and LLM-driven quality filtering. The released corpus contains over 1.2M executed action steps across thousands of trajectories in popular Windows office applications, and includes full-resolution screenshots, accessibility metadata when available, instantiated goals, intermediate reasoning traces, and both successful and failed action trajectories. The dataset supports three canonical tasks, GUI grounding, screen parsing, and action prediction, and a hybrid GUI+API action space that reflects modern agent designs. Benchmarking state-of-the-art vision--language models on GUI-360$^\\circ$ reveals substantial out-of-the-box shortcomings in grounding and action prediction; supervised fine-tuning and reinforcement learning yield significant gains but do not close the gap to human-level reliability. We release GUI-360$^\\circ$ and accompanying code to facilitate reproducible research and accelerate progress on robust desktop CUAs.   The full dataset has been made public on https://huggingface.co/datasets/vyokky/GUI-360.",
    "authors": [
      "Jian Mu",
      "Chaoyun Zhang",
      "Chiming Ni",
      "Lu Wang",
      "Bo Qiao",
      "Kartik Mathur",
      "Qianhui Wu",
      "Yuhang Xie",
      "Xiaojun Ma",
      "Mengyu Zhou",
      "Si Qin",
      "Liqun Li",
      "Yu Kang",
      "Minghua Ma",
      "Qingwei Lin",
      "Saravan Rajmohan",
      "Dongmei Zhang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04307v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04307v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04248v1",
    "title": "Efficient Topic Extraction via Graph-Based Labeling: A Lightweight   Alternative to Deep Models",
    "summary": "Extracting topics from text has become an essential task, especially with the rapid growth of unstructured textual data. Most existing works rely on highly computational methods to address this challenge. In this paper, we argue that probabilistic and statistical approaches, such as topic modeling (TM), can offer effective alternatives that require fewer computational resources. TM is a statistical method that automatically discovers topics in large collections of unlabeled text; however, it produces topics as distributions of representative words, which often lack clear interpretability. Our objective is to perform topic labeling by assigning meaningful labels to these sets of words. To achieve this without relying on computationally expensive models, we propose a graph-based approach that not only enriches topic words with semantically related terms but also explores the relationships among them. By analyzing these connections within the graph, we derive suitable labels that accurately capture each topic's meaning. We present a comparative study between our proposed method and several benchmarks, including ChatGPT-3.5, across two different datasets. Our method achieved consistently better results than traditional benchmarks in terms of BERTScore and cosine similarity and produced results comparable to ChatGPT-3.5, while remaining computationally efficient. Finally, we discuss future directions for topic labeling and highlight potential research avenues for enhancing interpretability and automation.",
    "authors": [
      "Salma Mekaoui",
      "Hiba Sofyan",
      "Imane Amaaz",
      "Imane Benchrif",
      "Arsalane Zarghili",
      "Ilham Chaker",
      "Nikola S. Nikolov"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04248v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04248v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04235v1",
    "title": "Shared Spatial Memory Through Predictive Coding",
    "summary": "Sharing and reconstructing a consistent spatial memory is a critical challenge in multi-agent systems, where partial observability and limited bandwidth often lead to catastrophic failures in coordination. We introduce a multi-agent predictive coding framework that formulate coordination as the minimization of mutual uncertainty among agents. Instantiated as an information bottleneck objective, it prompts agents to learn not only who and what to communicate but also when. At the foundation of this framework lies a grid-cell-like metric as internal spatial coding for self-localization, emerging spontaneously from self-supervised motion prediction. Building upon this internal spatial code, agents gradually develop a bandwidth-efficient communication mechanism and specialized neural populations that encode partners' locations: an artificial analogue of hippocampal social place cells (SPCs). These social representations are further enacted by a hierarchical reinforcement learning policy that actively explores to reduce joint uncertainty. On the Memory-Maze benchmark, our approach shows exceptional resilience to bandwidth constraints: success degrades gracefully from 73.5% to 64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically principled and biologically plausible basis for how complex social representations emerge from a unified predictive drive, leading to social collective intelligence.",
    "authors": [
      "Zhengru Fang",
      "Yu Guo",
      "Jingjing Wang",
      "Yuang Zhang",
      "Haonan An",
      "Yinhai Wang",
      "Yuguang Fang"
    ],
    "categories": [
      "cs.AI",
      "cs.CE"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04235v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04235v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04234v1",
    "title": "Reusing Pre-Training Data at Test Time is a Compute Multiplier",
    "summary": "Large language models learn from their vast pre-training corpora, gaining the ability to solve an ever increasing variety of tasks; yet although researchers work to improve these datasets, there is little effort to understand how efficient the pre-training apparatus is at extracting ideas and knowledge from the data. In this work, we use retrieval augmented generation along with test-time compute as a way to quantify how much dataset value was left behind by the process of pre-training, and how this changes across scale. We demonstrate that pre-training then retrieving from standard and largely open-sourced datasets results in significant accuracy gains in MMLU, Math-500, and SimpleQA, which persist through decontamination. For MMLU we observe that retrieval acts as a ~5x compute multiplier versus pre-training alone. We show that these results can be further improved by leveraging additional compute at test time to parse the retrieved context, demonstrating a 10 percentage point improvement on MMLU for the public LLaMA 3.1 8B model. Overall, our results suggest that today's pre-training methods do not make full use of the information in existing pre-training datasets, leaving significant room for progress.",
    "authors": [
      "Alex Fang",
      "Thomas Voice",
      "Ruoming Pang",
      "Ludwig Schmidt",
      "Tom Gunter"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04234v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04234v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04153v1",
    "title": "BAPPA: Benchmarking Agents, Plans, and Pipelines for Automated   Text-to-SQL Generation",
    "summary": "Text-to-SQL systems provide a natural language interface that can enable even laymen to access information stored in databases. However, existing Large Language Models (LLM) struggle with SQL generation from natural instructions due to large schema sizes and complex reasoning. Prior work often focuses on complex, somewhat impractical pipelines using flagship models, while smaller, efficient models remain overlooked. In this work, we explore three multi-agent LLM pipelines, with systematic performance benchmarking across a range of small to large open-source models: (1) Multi-agent discussion pipeline, where agents iteratively critique and refine SQL queries, and a judge synthesizes the final answer; (2) Planner-Coder pipeline, where a thinking model planner generates stepwise SQL generation plans and a coder synthesizes queries; and (3) Coder-Aggregator pipeline, where multiple coders independently generate SQL queries, and a reasoning agent selects the best query. Experiments on the Bird-Bench Mini-Dev set reveal that Multi-Agent discussion can improve small model performance, with up to 10.6% increase in Execution Accuracy for Qwen2.5-7b-Instruct seen after three rounds of discussion. Among the pipelines, the LLM Reasoner-Coder pipeline yields the best results, with DeepSeek-R1-32B and QwQ-32B planners boosting Gemma 3 27B IT accuracy from 52.4% to the highest score of 56.4%. Codes are available at https://github.com/treeDweller98/bappa-sql.",
    "authors": [
      "Fahim Ahmed",
      "Md Mubtasim Ahasan",
      "Jahir Sadik Monon",
      "Muntasir Wahed",
      "M Ashraful Amin",
      "A K M Mahbubur Rahman",
      "Amin Ahsan Ali"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.MA"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04153v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04153v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.04667v1",
    "title": "Multi-Method Analysis of Mathematics Placement Assessments: Classical,   Machine Learning, and Clustering Approaches",
    "summary": "This study evaluates a 40-item mathematics placement examination administered to 198 students using a multi-method framework combining Classical Test Theory, machine learning, and unsupervised clustering. Classical Test Theory analysis reveals that 55\\% of items achieve excellent discrimination ($D \\geq 0.40$) while 30\\% demonstrate poor discrimination ($D < 0.20$) requiring replacement. Question 6 (Graph Interpretation) emerges as the examination's most powerful discriminator, achieving perfect discrimination ($D = 1.000$), highest ANOVA F-statistic ($F = 4609.1$), and maximum Random Forest feature importance (0.206), accounting for 20.6\\% of predictive power. Machine learning algorithms demonstrate exceptional performance, with Random Forest and Gradient Boosting achieving 97.5\\% and 96.0\\% cross-validation accuracy. K-means clustering identifies a natural binary competency structure with a boundary at 42.5\\%, diverging from the institutional threshold of 55\\% and suggesting potential overclassification into remedial categories. The two-cluster solution exhibits exceptional stability (bootstrap ARI = 0.855) with perfect lower-cluster purity. Convergent evidence across methods supports specific refinements: replace poorly discriminating items, implement a two-stage assessment, and integrate Random Forest predictions with transparency mechanisms. These findings demonstrate that multi-method integration provides a robust empirical foundation for evidence-based mathematics placement optimization.",
    "authors": [
      "Julian D. Allagan",
      "Dasia A. Singleton",
      "Shanae N. Perry",
      "Gabrielle C. Morgan",
      "Essence A. Morgan"
    ],
    "categories": [
      "cs.LG",
      "97C70, 62P25, 62H30, 68T05"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04667v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04667v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.04641v1",
    "title": "Efficient probabilistic surrogate modeling techniques for   partially-observed large-scale dynamical systems",
    "summary": "This paper is concerned with probabilistic techniques for forecasting dynamical systems described by partial differential equations (such as, for example, the Navier-Stokes equations). In particular, it is investigating and comparing various extensions to the flow matching paradigm that reduce the number of sampling steps. In this regard, it compares direct distillation, progressive distillation, adversarial diffusion distillation, Wasserstein GANs and rectified flows. Moreover, experiments are conducted on a set of challenging systems. In particular, we also address the challenge of directly predicting 2D slices of large-scale 3D simulations, paving the way for efficient inflow generation for solvers.",
    "authors": [
      "Hans Harder",
      "Abhijeet Vishwasrao",
      "Luca Guastoni",
      "Ricardo Vinuesa",
      "Sebastian Peitz"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04641v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04641v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.04564v1",
    "title": "Uncertainties in Physics-informed Inverse Problems: The Hidden Risk in   Scientific AI",
    "summary": "Physics-informed machine learning (PIML) integrates partial differential equations (PDEs) into machine learning models to solve inverse problems, such as estimating coefficient functions (e.g., the Hamiltonian function) that characterize physical systems. This framework enables data-driven understanding and prediction of complex physical phenomena. While coefficient functions in PIML are typically estimated on the basis of predictive performance, physics as a discipline does not rely solely on prediction accuracy to evaluate models. For example, Kepler's heliocentric model was favored owing to small discrepancies in planetary motion, despite its similar predictive accuracy to the geocentric model. This highlights the inherent uncertainties in data-driven model inference and the scientific importance of selecting physically meaningful solutions. In this paper, we propose a framework to quantify and analyze such uncertainties in the estimation of coefficient functions in PIML. We apply our framework to reduced model of magnetohydrodynamics and our framework shows that there are uncertainties, and unique identification is possible with geometric constraints. Finally, we confirm that we can estimate the reduced model uniquely by incorporating these constraints.",
    "authors": [
      "Yoh-ichi Mototake",
      "Makoto Sasaki"
    ],
    "categories": [
      "physics.comp-ph",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04564v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04564v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.04502v1",
    "title": "RAGalyst: Automated Human-Aligned Agentic Evaluation for Domain-Specific   RAG",
    "summary": "Retrieval-Augmented Generation (RAG) is a critical technique for grounding Large Language Models (LLMs) in factual evidence, yet evaluating RAG systems in specialized, safety-critical domains remains a significant challenge. Existing evaluation frameworks often rely on heuristic-based metrics that fail to capture domain-specific nuances and other works utilize LLM-as-a-Judge approaches that lack validated alignment with human judgment. This paper introduces RAGalyst, an automated, human-aligned agentic framework designed for the rigorous evaluation of domain-specific RAG systems. RAGalyst features an agentic pipeline that generates high-quality, synthetic question-answering (QA) datasets from source documents, incorporating an agentic filtering step to ensure data fidelity. The framework refines two key LLM-as-a-Judge metrics-Answer Correctness and Answerability-using prompt optimization to achieve a strong correlation with human annotations. Applying this framework to evaluate various RAG components across three distinct domains (military operations, cybersecurity, and bridge engineering), we find that performance is highly context-dependent. No single embedding model, LLM, or hyperparameter configuration proves universally optimal. Additionally, we provide an analysis on the most common low Answer Correctness reasons in RAG. These findings highlight the necessity of a systematic evaluation framework like RAGalyst, which empowers practitioners to uncover domain-specific trade-offs and make informed design choices for building reliable and effective RAG systems. RAGalyst is available on our Github.",
    "authors": [
      "Joshua Gao",
      "Quoc Huy Pham",
      "Subin Varghese",
      "Silwal Saurav",
      "Vedhus Hoskere"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04502v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04502v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.04427v1",
    "title": "Speed at the Cost of Quality? The Impact of LLM Agent Assistance on   Software Development",
    "summary": "Large language models (LLMs) have demonstrated the promise to revolutionize the field of software engineering. Among other things, LLM agents are rapidly gaining momentum in their application to software development, with practitioners claiming a multifold productivity increase after adoption. Yet, empirical evidence is lacking around these claims. In this paper, we estimate the causal effect of adopting a widely popular LLM agent assistant, namely Cursor, on development velocity and software quality. The estimation is enabled by a state-of-the-art difference-in-differences design comparing Cursor-adopting GitHub projects with a matched control group of similar GitHub projects that do not use Cursor. We find that the adoption of Cursor leads to a significant, large, but transient increase in project-level development velocity, along with a significant and persistent increase in static analysis warnings and code complexity. Further panel generalized method of moments estimation reveals that the increase in static analysis warnings and code complexity acts as a major factor causing long-term velocity slowdown. Our study carries implications for software engineering practitioners, LLM agent assistant designers, and researchers.",
    "authors": [
      "Hao He",
      "Courtney Miller",
      "Shyam Agarwal",
      "Christian Kästner",
      "Bogdan Vasilescu"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04427v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04427v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.04418v1",
    "title": "The Illusion of Certainty: Uncertainty quantification for LLMs fails   under ambiguity",
    "summary": "Accurate uncertainty quantification (UQ) in Large Language Models (LLMs) is critical for trustworthy deployment. While real-world language is inherently ambiguous, reflecting aleatoric uncertainty, existing UQ methods are typically benchmarked against tasks with no ambiguity. In this work, we demonstrate that while current uncertainty estimators perform well under the restrictive assumption of no ambiguity, they degrade to close-to-random performance on ambiguous data. To this end, we introduce MAQA* and AmbigQA*, the first ambiguous question-answering (QA) datasets equipped with ground-truth answer distributions estimated from factual co-occurrence. We find this performance deterioration to be consistent across different estimation paradigms: using the predictive distribution itself, internal representations throughout the model, and an ensemble of models. We show that this phenomenon can be theoretically explained, revealing that predictive-distribution and ensemble-based estimators are fundamentally limited under ambiguity. Overall, our study reveals a key shortcoming of current UQ methods for LLMs and motivates a rethinking of current modeling paradigms.",
    "authors": [
      "Tim Tomov",
      "Dominik Fuchsgruber",
      "Tom Wollschläger",
      "Stephan Günnemann"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04418v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04418v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.04316v1",
    "title": "AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research",
    "summary": "The rapid expansion of research on Large Language Model (LLM) safety and robustness has produced a fragmented and oftentimes buggy ecosystem of implementations, datasets, and evaluation methods. This fragmentation makes reproducibility and comparability across studies challenging, hindering meaningful progress. To address these issues, we introduce AdversariaLLM, a toolbox for conducting LLM jailbreak robustness research. Its design centers on reproducibility, correctness, and extensibility. The framework implements twelve adversarial attack algorithms, integrates seven benchmark datasets spanning harmfulness, over-refusal, and utility evaluation, and provides access to a wide range of open-weight LLMs via Hugging Face. The implementation includes advanced features for comparability and reproducibility such as compute-resource tracking, deterministic results, and distributional evaluation techniques. \\name also integrates judging through the companion package JudgeZoo, which can also be used independently. Together, these components aim to establish a robust foundation for transparent, comparable, and reproducible research in LLM safety.",
    "authors": [
      "Tim Beyer",
      "Jonas Dornbusch",
      "Jakob Steimle",
      "Moritz Ladenburger",
      "Leo Schwinn",
      "Stephan Günnemann"
    ],
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04316v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04316v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.04665v1",
    "title": "Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation   of Soft-Body Interactions",
    "summary": "Robotic manipulation policies are advancing rapidly, but their direct evaluation in the real world remains costly, time-consuming, and difficult to reproduce, particularly for tasks involving deformable objects. Simulation provides a scalable and systematic alternative, yet existing simulators often fail to capture the coupled visual and physical complexity of soft-body interactions. We present a real-to-sim policy evaluation framework that constructs soft-body digital twins from real-world videos and renders robots, objects, and environments with photorealistic fidelity using 3D Gaussian Splatting. We validate our approach on representative deformable manipulation tasks, including plush toy packing, rope routing, and T-block pushing, demonstrating that simulated rollouts correlate strongly with real-world execution performance and reveal key behavioral patterns of learned policies. Our results suggest that combining physics-informed reconstruction with high-quality rendering enables reproducible, scalable, and accurate evaluation of robotic manipulation policies. Website: https://real2sim-eval.github.io/",
    "authors": [
      "Kaifeng Zhang",
      "Shuo Sha",
      "Hanxiao Jiang",
      "Matthew Loper",
      "Hyunjong Song",
      "Guangyan Cai",
      "Zhuo Xu",
      "Xiaochen Hu",
      "Changxi Zheng",
      "Yunzhu Li"
    ],
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04665v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04665v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.04662v1",
    "title": "VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical   Consistency Checks",
    "summary": "LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but they cannot reliably verify their own logic. Even when they reach correct answers, the underlying reasoning may be flawed, undermining trust in high-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a neuro-symbolic method that extracts and verifies formal logical arguments from CoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order logic and identifies premises that ground the argument in source context, commonsense knowledge, or prior reasoning steps. The symbolic representation enables automated solvers to verify logical validity while the NL premises allow humans and systems to identify ungrounded or fallacious reasoning steps. Experiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT effectively identifies flawed reasoning, and serves as a strong predictor of final answer correctness. We also leverage VeriCoT's verification signal for (1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on VeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct preference optimization (DPO) using verification-based pairwise rewards, further improving reasoning validity and accuracy.",
    "authors": [
      "Yu Feng",
      "Nathaniel Weir",
      "Kaj Bostrom",
      "Sam Bayless",
      "Darion Cassel",
      "Sapana Chaudhary",
      "Benjamin Kiesl-Reiter",
      "Huzefa Rangwala"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04662v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04662v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.04598v1",
    "title": "Environment Agnostic Goal-Conditioning, A Study of Reward-Free   Autonomous Learning",
    "summary": "In this paper we study how transforming regular reinforcement learning environments into goal-conditioned environments can let agents learn to solve tasks autonomously and reward-free. We show that an agent can learn to solve tasks by selecting its own goals in an environment-agnostic way, at training times comparable to externally guided reinforcement learning. Our method is independent of the underlying off-policy learning algorithm. Since our method is environment-agnostic, the agent does not value any goals higher than others, leading to instability in performance for individual goals. However, in our experiments, we show that the average goal success rate improves and stabilizes. An agent trained with this method can be instructed to seek any observations made in the environment, enabling generic training of agents prior to specific use cases.",
    "authors": [
      "Hampus Åström",
      "Elin Anna Topp",
      "Jacek Malec"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04598v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04598v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.04439v1",
    "title": "The Peril of Preference: Why GRPO fails on Ordinal Rewards",
    "summary": "Group-relative Policy Optimization's (GRPO) simplicity makes it highly desirable for adapting LLMs to become experts at specific tasks. But this simplicity also makes it ill-specified as we seek to enhance RL training with richer, non-binary feedback. When using ordinal rewards to give partial credit, GRPO's simplicity starts to hurt, as its group-average baseline often assigns a positive advantage to failed trajectories and reinforces incorrect behavior.   We introduce Correctness Relative Policy Optimization (CoRPO), a new formulation that solves this flaw. CoRPO uses an adaptive baseline that enforces a minimum quality threshold, ensuring failed solutions are never positively reinforced. Once the policy consistently meets this threshold, the baseline automatically transitions to a relative preference mode, pushing the model to find optimal solutions rather than just \"acceptable\" ones. We empirically validate CoRPO on a code verification task, where it demonstrates more stable convergence and better out-of-domain generalization.   This work represents a critical step in our broader research program to enable LLMs to learn genuinely new capabilities through reinforcement learning. We achieve this by enabling LLMs to learn from rich, multi-dimensional feedback - progressing from binary to ordinal rewards in this work, and onward to denser, per-step supervision.",
    "authors": [
      "Anisha Garg",
      "Ganesh Venkatesh"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04439v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04439v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.04432v1",
    "title": "If I Could Turn Back Time: Temporal Reframing as a Historical Reasoning   Task for LLMs",
    "summary": "In this study, we experiment with the ability of LLMs to do temporal reasoning. Using a Norwegian book from 1940 containing trivia questions, we prompt the LLMs to answer the questions as if it were 1940. We also pose the questions in both English and Norwegian. Correct answers are often presented as sentences, and grading is done by means of LLM-as-judge, with sampled checks by a native speaker. Prompting in English consistently gave better results than in Norwegian, an unexpected result. In contrast, using larger LLMs improved results. We tested the DeepSeek-R1, Gemma3, Qwen3, and Llama3.1 model families, and also the largest available LLM especially crafted for Norwegian.",
    "authors": [
      "Lars Bungum",
      "Charles Yijia Huang",
      "Abeer Kashar"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04432v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04432v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.04422v1",
    "title": "On the Equivalence of Regression and Classification",
    "summary": "A formal link between regression and classification has been tenuous. Even though the margin maximization term $\\|w\\|$ is used in support vector regression, it has at best been justified as a regularizer. We show that a regression problem with $M$ samples lying on a hyperplane has a one-to-one equivalence with a linearly separable classification task with $2M$ samples. We show that margin maximization on the equivalent classification task leads to a different regression formulation than traditionally used. Using the equivalence, we demonstrate a ``regressability'' measure, that can be used to estimate the difficulty of regressing a dataset, without needing to first learn a model for it. We use the equivalence to train neural networks to learn a linearizing map, that transforms input variables into a space where a linear regressor is adequate.",
    "authors": [
      " Jayadeva",
      "Naman Dwivedi",
      "Hari Krishnan",
      "N. M. Anoop Krishnan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "68T05, 68T10, 68Q32",
      "I.2.6; I.5.1; I.5.2"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04422v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04422v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.04179v1",
    "title": "Explaining Software Vulnerabilities with Large Language Models",
    "summary": "The prevalence of security vulnerabilities has prompted companies to adopt static application security testing (SAST) tools for vulnerability detection. Nevertheless, these tools frequently exhibit usability limitations, as their generic warning messages do not sufficiently communicate important information to developers, resulting in misunderstandings or oversight of critical findings. In light of recent developments in Large Language Models (LLMs) and their text generation capabilities, our work investigates a hybrid approach that uses LLMs to tackle the SAST explainability challenges. In this paper, we present SAFE, an Integrated Development Environment (IDE) plugin that leverages GPT-4o to explain the causes, impacts, and mitigation strategies of vulnerabilities detected by SAST tools. Our expert user study findings indicate that the explanations generated by SAFE can significantly assist beginner to intermediate developers in understanding and addressing security vulnerabilities, thereby improving the overall usability of SAST tools.",
    "authors": [
      "Oshando Johnson",
      "Alexandra Fomina",
      "Ranjith Krishnamurthy",
      "Vaibhav Chaudhari",
      "Rohith Kumar Shanmuganathan",
      "Eric Bodden"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04179v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04179v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.04160v1",
    "title": "On Joint Regularization and Calibration in Deep Ensembles",
    "summary": "Deep ensembles are a powerful tool in machine learning, improving both model performance and uncertainty calibration. While ensembles are typically formed by training and tuning models individually, evidence suggests that jointly tuning the ensemble can lead to better performance. This paper investigates the impact of jointly tuning weight decay, temperature scaling, and early stopping on both predictive performance and uncertainty quantification. Additionally, we propose a partially overlapping holdout strategy as a practical compromise between enabling joint evaluation and maximizing the use of data for training. Our results demonstrate that jointly tuning the ensemble generally matches or improves performance, with significant variation in effect size across different tasks and metrics. We highlight the trade-offs between individual and joint optimization in deep ensemble training, with the overlapping holdout strategy offering an attractive practical solution. We believe our findings provide valuable insights and guidance for practitioners looking to optimize deep ensemble models. Code is available at: https://github.com/lauritsf/ensemble-optimality-gap",
    "authors": [
      "Laurits Fredsgaard",
      "Mikkel N. Schmidt"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04160v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04160v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.04147v1",
    "title": "Exchange Policy Optimization Algorithm for Semi-Infinite Safe   Reinforcement Learning",
    "summary": "Safe reinforcement learning (safe RL) aims to respect safety requirements while optimizing long-term performance. In many practical applications, however, the problem involves an infinite number of constraints, known as semi-infinite safe RL (SI-safe RL). Such constraints typically appear when safety conditions must be enforced across an entire continuous parameter space, such as ensuring adequate resource distribution at every spatial location. In this paper, we propose exchange policy optimization (EPO), an algorithmic framework that achieves optimal policy performance and deterministic bounded safety. EPO works by iteratively solving safe RL subproblems with finite constraint sets and adaptively adjusting the active set through constraint expansion and deletion. At each iteration, constraints with violations exceeding the predefined tolerance are added to refine the policy, while those with zero Lagrange multipliers are removed after the policy update. This exchange rule prevents uncontrolled growth of the working set and supports effective policy training. Our theoretical analysis demonstrates that, under mild assumptions, strategies trained via EPO achieve performance comparable to optimal solutions with global constraint violations strictly remaining within a prescribed bound.",
    "authors": [
      "Jiaming Zhang",
      "Yujie Yang",
      "Haoning Wang",
      "Liping Zhang",
      "Shengbo Eben Li"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04147v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04147v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.04132v1",
    "title": "Exploring the Feasibility of End-to-End Large Language Model as a   Compiler",
    "summary": "In recent years, end-to-end Large Language Model (LLM) technology has shown substantial advantages across various domains. As critical system software and infrastructure, compilers are responsible for transforming source code into target code. While LLMs have been leveraged to assist in compiler development and maintenance, their potential as an end-to-end compiler remains largely unexplored. This paper explores the feasibility of LLM as a Compiler (LaaC) and its future directions. We designed the CompilerEval dataset and framework specifically to evaluate the capabilities of mainstream LLMs in source code comprehension and assembly code generation. In the evaluation, we analyzed various errors, explored multiple methods to improve LLM-generated code, and evaluated cross-platform compilation capabilities. Experimental results demonstrate that LLMs exhibit basic capabilities as compilers but currently achieve low compilation success rates. By optimizing prompts, scaling up the model, and incorporating reasoning methods, the quality of assembly code generated by LLMs can be significantly enhanced. Based on these findings, we maintain an optimistic outlook for LaaC and propose practical architectural designs and future research directions. We believe that with targeted training, knowledge-rich prompts, and specialized infrastructure, LaaC has the potential to generate high-quality assembly code and drive a paradigm shift in the field of compilation.",
    "authors": [
      "Hongbin Zhang",
      "Shihao Gao",
      "Yang Liu",
      "Mingjie Xing",
      "Yanjun Wu",
      "Chen Zhao"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04132v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04132v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.04611v1",
    "title": "evomap: A Toolbox for Dynamic Mapping in Python",
    "summary": "This paper presents evomap, a Python package for dynamic mapping. Mapping methods are widely used across disciplines to visualize relationships among objects as spatial representations, or maps. However, most existing statistical software supports only static mapping, which captures objects' relationships at a single point in time and lacks tools to analyze how these relationships evolve. evomap fills this gap by implementing the dynamic mapping framework EvoMap, originally proposed by Matthe, Ringel, and Skiera (2023), which adapts traditional static mapping methods for dynamic analyses. The package supports multiple mapping techniques, including variants of Multidimensional Scaling (MDS), Sammon Mapping, and t-distributed Stochastic Neighbor Embedding (t-SNE). It also includes utilities for data preprocessing, exploration, and result evaluation, offering a comprehensive toolkit for dynamic mapping applications. This paper outlines the foundations of static and dynamic mapping, describes the architecture and functionality of evomap, and illustrates its application through an extensive usage example.",
    "authors": [
      "Maximilian Matthe"
    ],
    "categories": [
      "cs.MS",
      "cs.LG",
      "cs.SE"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04611v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04611v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.04567v1",
    "title": "Machine Learning for Electron-Scale Turbulence Modeling in W7-X",
    "summary": "Constructing reduced models for turbulent transport is essential for accelerating profile predictions and enabling many-query tasks such as uncertainty quantification, parameter scans, and design optimization. This paper presents machine-learning-driven reduced models for Electron Temperature Gradient (ETG) turbulence in the Wendelstein 7-X (W7-X) stellarator. Each model predicts the ETG heat flux as a function of three plasma parameters: the normalized electron temperature radial gradient ($\\omega_{T_e}$), the ratio of normalized electron temperature and density radial gradients ($\\eta_e$), and the electron-to-ion temperature ratio ($\\tau$). We first construct models across seven radial locations using regression and an active machine-learning-based procedure. This process initializes models using low-cardinality sparse-grid training data and then iteratively refines their training sets by selecting the most informative points from a pre-existing simulation database. We evaluate the prediction capabilities of our models using out-of-sample datasets with over $393$ points per location, and $95\\%$ prediction intervals are estimated via bootstrapping to assess prediction uncertainty. We then investigate the construction of generalized reduced models, including a generic, position-independent model, and assess their heat flux prediction capabilities at three additional locations. Our models demonstrate robust performance and predictive accuracy comparable to the original reference simulations, even when applied beyond the training domain.",
    "authors": [
      "Ionut-Gabriel Farcas",
      "Don Lawrence Carl Agapito Fernando",
      "Alejandro Banon Navarro",
      "Gabriele Merlo",
      "Frank Jenko"
    ],
    "categories": [
      "physics.plasm-ph",
      "cs.CE",
      "cs.LG",
      "physics.comp-ph"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04567v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04567v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.04205v1",
    "title": "LLM-as-a-Judge is Bad, Based on AI Attempting the Exam Qualifying for   the Member of the Polish National Board of Appeal",
    "summary": "This study provides an empirical assessment of whether current large language models (LLMs) can pass the official qualifying examination for membership in Poland's National Appeal Chamber (Krajowa Izba Odwo{\\l}awcza). The authors examine two related ideas: using LLM as actual exam candidates and applying the 'LLM-as-a-judge' approach, in which model-generated answers are automatically evaluated by other models. The paper describes the structure of the exam, which includes a multiple-choice knowledge test on public procurement law and a written judgment, and presents the hybrid information recovery and extraction pipeline built to support the models. Several LLMs (including GPT-4.1, Claude 4 Sonnet and Bielik-11B-v2.6) were tested in closed-book and various Retrieval-Augmented Generation settings. The results show that although the models achieved satisfactory scores in the knowledge test, none met the passing threshold in the practical written part, and the evaluations of the 'LLM-as-a-judge' often diverged from the judgments of the official examining committee. The authors highlight key limitations: susceptibility to hallucinations, incorrect citation of legal provisions, weaknesses in logical argumentation, and the need for close collaboration between legal experts and technical teams. The findings indicate that, despite rapid technological progress, current LLMs cannot yet replace human judges or independent examiners in Polish public procurement adjudication.",
    "authors": [
      "Michał Karp",
      "Anna Kubaszewska",
      "Magdalena Król",
      "Robert Król",
      "Aleksander Smywiński-Pohl",
      "Mateusz Szymański",
      "Witold Wydmański"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04205v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04205v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.04460v1",
    "title": "V-Thinker: Interactive Thinking with Images",
    "summary": "Empowering Large Multimodal Models (LMMs) to deeply integrate image interaction with long-horizon reasoning capabilities remains a long-standing challenge in this field. Recent advances in vision-centric reasoning explore a promising \"Thinking with Images\" paradigm for LMMs, marking a shift from image-assisted reasoning to image-interactive thinking. While this milestone enables models to focus on fine-grained image regions, progress remains constrained by limited visual tool spaces and task-specific workflow designs. To bridge this gap, we present V-Thinker, a general-purpose multimodal reasoning assistant that enables interactive, vision-centric thinking through end-to-end reinforcement learning. V-Thinker comprises two key components: (1) a Data Evolution Flywheel that automatically synthesizes, evolves, and verifies interactive reasoning datasets across three dimensions-diversity, quality, and difficulty; and (2) a Visual Progressive Training Curriculum that first aligns perception via point-level supervision, then integrates interactive reasoning through a two-stage reinforcement learning framework. Furthermore, we introduce VTBench, an expert-verified benchmark targeting vision-centric interactive reasoning tasks. Extensive experiments demonstrate that V-Thinker consistently outperforms strong LMM-based baselines in both general and interactive reasoning scenarios, providing valuable insights for advancing image-interactive reasoning applications.",
    "authors": [
      "Runqi Qiao",
      "Qiuna Tan",
      "Minghan Yang",
      "Guanting Dong",
      "Peiqing Yang",
      "Shiqiang Lang",
      "Enhui Wan",
      "Xiaowan Wang",
      "Yida Xu",
      "Lan Yang",
      "Chong Sun",
      "Chen Li",
      "Honggang Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04460v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04460v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.04247v1",
    "title": "On the Brittleness of CLIP Text Encoders",
    "summary": "Multimodal co-embedding models, especially CLIP, have advanced the state of the art in zero-shot classification and multimedia information retrieval in recent years by aligning images and text in a shared representation space. However, such modals trained on a contrastive alignment can lack stability towards small input perturbations. Especially when dealing with manually expressed queries, minor variations in the query can cause large differences in the ranking of the best-matching results. In this paper, we present a systematic analysis of the effect of multiple classes of non-semantic query perturbations in an multimedia information retrieval scenario. We evaluate a diverse set of lexical, syntactic, and semantic perturbations across multiple CLIP variants using the TRECVID Ad-Hoc Video Search queries and the V3C1 video collection. Across models, we find that syntactic and semantic perturbations drive the largest instabilities, while brittleness is concentrated in trivial surface edits such as punctuation and case. Our results highlight robustness as a critical dimension for evaluating vision-language models beyond benchmark accuracy.",
    "authors": [
      "Allie Tran",
      "Luca Rossetto"
    ],
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04247v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04247v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.04217v1",
    "title": "The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms",
    "summary": "The strong lottery ticket hypothesis (SLTH) conjectures that high-performing subnetworks, called strong lottery tickets (SLTs), are hidden in randomly initialized neural networks. Although recent theoretical studies have established the SLTH across various neural architectures, the SLTH for transformer architectures still lacks theoretical understanding. In particular, the current theory of the SLTH does not yet account for the multi-head attention (MHA) mechanism, a core component of transformers. To address this gap, we introduce a theoretical analysis of the existence of SLTs within MHAs. We prove that, if a randomly initialized MHA of $H$ heads and input dimension $d$ has the hidden dimension $O(d\\log(Hd^{3/2}))$ for the key and value, it contains an SLT that approximates an arbitrary MHA with the same input dimension with high probability. Furthermore, by leveraging this theory for MHAs, we extend the SLTH to transformers without normalization layers. We empirically validate our theoretical findings, demonstrating that the approximation error between the SLT within a source model (MHA and transformer) and an approximate target counterpart decreases exponentially by increasing the hidden dimension of the source model.",
    "authors": [
      "Hikari Otsuka",
      "Daiki Chijiwa",
      "Yasuyuki Okoshi",
      "Daichi Fujiki",
      "Susumu Takeuchi",
      "Masato Motomura"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04217v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04217v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.04126v1",
    "title": "Automated Tennis Player and Ball Tracking with Court Keypoints Detection   (Hawk Eye System)",
    "summary": "This study presents a complete pipeline for automated tennis match analysis. Our framework integrates multiple deep learning models to detect and track players and the tennis ball in real time, while also identifying court keypoints for spatial reference. Using YOLOv8 for player detection, a custom-trained YOLOv5 model for ball tracking, and a ResNet50-based architecture for court keypoint detection, our system provides detailed analytics including player movement patterns, ball speed, shot accuracy, and player reaction times. The experimental results demonstrate robust performance in varying court conditions and match scenarios. The model outputs an annotated video along with detailed performance metrics, enabling coaches, broadcasters, and players to gain actionable insights into the dynamics of the game.",
    "authors": [
      "Venkata Manikanta Desu",
      "Syed Fawaz Ali"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04126v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04126v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.04123v1",
    "title": "Text to Sketch Generation with Multi-Styles",
    "summary": "Recent advances in vision-language models have facilitated progress in sketch generation. However, existing specialized methods primarily focus on generic synthesis and lack mechanisms for precise control over sketch styles. In this work, we propose a training-free framework based on diffusion models that enables explicit style guidance via textual prompts and referenced style sketches. Unlike previous style transfer methods that overwrite key and value matrices in self-attention, we incorporate the reference features as auxiliary information with linear smoothing and leverage a style-content guidance mechanism. This design effectively reduces content leakage from reference sketches and enhances synthesis quality, especially in cases with low structural similarity between reference and target sketches. Furthermore, we extend our framework to support controllable multi-style generation by integrating features from multiple reference sketches, coordinated via a joint AdaIN module. Extensive experiments demonstrate that our approach achieves high-quality sketch generation with accurate style alignment and improved flexibility in style control. The official implementation of M3S is available at https://github.com/CMACH508/M3S.",
    "authors": [
      "Tengjie Li",
      "Shikui Tu",
      "Lei Xu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04123v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04123v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.04077v1",
    "title": "The truth is no diaper: Human and AI-generated associations to emotional   words",
    "summary": "Human word associations are a well-known method of gaining insight into the internal mental lexicon, but the responses spontaneously offered by human participants to word cues are not always predictable as they may be influenced by personal experience, emotions or individual cognitive styles. The ability to form associative links between seemingly unrelated concepts can be the driving mechanisms of creativity. We perform a comparison of the associative behaviour of humans compared to large language models. More specifically, we explore associations to emotionally loaded words and try to determine whether large language models generate associations in a similar way to humans. We find that the overlap between humans and LLMs is moderate, but also that the associations of LLMs tend to amplify the underlying emotional load of the stimulus, and that they tend to be more predictable and less creative than human ones.",
    "authors": [
      "Špela Vintar",
      "Jan Jona Javoršek"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04077v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04077v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.04076v1",
    "title": "Agentmandering: A Game-Theoretic Framework for Fair Redistricting via   Large Language Model Agents",
    "summary": "Redistricting plays a central role in shaping how votes are translated into political power. While existing computational methods primarily aim to generate large ensembles of legally valid districting plans, they often neglect the strategic dynamics involved in the selection process. This oversight creates opportunities for partisan actors to cherry-pick maps that, while technically compliant, are politically advantageous. Simply satisfying formal constraints does not ensure fairness when the selection process itself can be manipulated. We propose \\textbf{Agentmandering}, a framework that reimagines redistricting as a turn-based negotiation between two agents representing opposing political interests. Drawing inspiration from game-theoretic ideas, particularly the \\textit{Choose-and-Freeze} protocol, our method embeds strategic interaction into the redistricting process via large language model (LLM) agents. Agents alternate between selecting and freezing districts from a small set of candidate maps, gradually partitioning the state through constrained and interpretable choices. Evaluation on post-2020 U.S. Census data across all states shows that Agentmandering significantly reduces partisan bias and unfairness, while achieving 2 to 3 orders of magnitude lower variance than standard baselines. These results demonstrate both fairness and stability, especially in swing-state scenarios. Our code is available at https://github.com/Lihaogx/AgentMandering.",
    "authors": [
      "Hao Li",
      "Haotian Chen",
      "Ruoyuan Gong",
      "Juanjuan Wang",
      "Hao Jiang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04076v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04076v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.04069v1",
    "title": "Pediatric Appendicitis Detection from Ultrasound Images",
    "summary": "Pediatric appendicitis remains one of the most common causes of acute abdominal pain in children, and its diagnosis continues to challenge clinicians due to overlapping symptoms and variable imaging quality. This study aims to develop and evaluate a deep learning model based on a pretrained ResNet architecture for automated detection of appendicitis from ultrasound images. We used the Regensburg Pediatric Appendicitis Dataset, which includes ultrasound scans, laboratory data, and clinical scores from pediatric patients admitted with abdominal pain to Children Hospital. Hedwig in Regensburg, Germany. Each subject had 1 to 15 ultrasound views covering the right lower quadrant, appendix, lymph nodes, and related structures. For the image based classification task, ResNet was fine tuned to distinguish appendicitis from non-appendicitis cases. Images were preprocessed by normalization, resizing, and augmentation to enhance generalization. The proposed ResNet model achieved an overall accuracy of 93.44, precision of 91.53, and recall of 89.8, demonstrating strong performance in identifying appendicitis across heterogeneous ultrasound views. The model effectively learned discriminative spatial features, overcoming challenges posed by low contrast, speckle noise, and anatomical variability in pediatric imaging.",
    "authors": [
      "Fatemeh Hosseinabadi",
      "Seyedhassan Sharifi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04069v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04069v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.04070v1",
    "title": "T-FIX: Text-Based Explanations with Features Interpretable to eXperts",
    "summary": "As LLMs are deployed in knowledge-intensive settings (e.g., surgery, astronomy, therapy), users expect not just answers, but also meaningful explanations for those answers. In these settings, users are often domain experts (e.g., doctors, astrophysicists, psychologists) who require explanations that reflect expert-level reasoning. However, current evaluation schemes primarily emphasize plausibility or internal faithfulness of the explanation, which fail to capture whether the content of the explanation truly aligns with expert intuition. We formalize expert alignment as a criterion for evaluating explanations with T-FIX, a benchmark spanning seven knowledge-intensive domains. In collaboration with domain experts, we develop novel metrics to measure the alignment of LLM explanations with expert judgment.",
    "authors": [
      "Shreya Havaldar",
      "Helen Jin",
      "Chaehyeon Kim",
      "Anton Xue",
      "Weiqiu You",
      "Marco Gatti",
      "Bhuvnesh Jain",
      "Helen Qu",
      "Daniel A Hashimoto",
      "Amin Madani",
      "Rajat Deo",
      "Sameed Ahmed M. Khatana",
      "Gary E. Weissman",
      "Lyle Ungar",
      "Eric Wong"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04070v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04070v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.04053v1",
    "title": "Interpreting Multi-Attribute Confounding through Numerical Attributes in   Large Language Models",
    "summary": "Although behavioral studies have documented numerical reasoning errors in large language models (LLMs), the underlying representational mechanisms remain unclear. We hypothesize that numerical attributes occupy shared latent subspaces and investigate two questions:(1) How do LLMs internally integrate multiple numerical attributes of a single entity? (2)How does irrelevant numerical context perturb these representations and their downstream outputs? To address these questions, we combine linear probing with partial correlation analysis and prompt-based vulnerability tests across models of varying sizes. Our results show that LLMs encode real-world numerical correlations but tend to systematically amplify them. Moreover, irrelevant context induces consistent shifts in magnitude representations, with downstream effects that vary by model size. These findings reveal a vulnerability in LLM decision-making and lay the groundwork for fairer, representation-aware control under multi-attribute entanglement.",
    "authors": [
      "Hirohane Takagi",
      "Gouki Minegishi",
      "Shota Kizawa",
      "Issey Sukeda",
      "Hitomi Yanaka"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04053v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04053v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.04576v1",
    "title": "Physics-Informed Neural Networks and Neural Operators for Parametric   PDEs: A Human-AI Collaborative Analysis",
    "summary": "PDEs arise ubiquitously in science and engineering, where solutions depend on parameters (physical properties, boundary conditions, geometry). Traditional numerical methods require re-solving the PDE for each parameter, making parameter space exploration prohibitively expensive. Recent machine learning advances, particularly physics-informed neural networks (PINNs) and neural operators, have revolutionized parametric PDE solving by learning solution operators that generalize across parameter spaces. We critically analyze two main paradigms: (1) PINNs, which embed physical laws as soft constraints and excel at inverse problems with sparse data, and (2) neural operators (e.g., DeepONet, Fourier Neural Operator), which learn mappings between infinite-dimensional function spaces and achieve unprecedented generalization. Through comparisons across fluid dynamics, solid mechanics, heat transfer, and electromagnetics, we show neural operators can achieve computational speedups of $10^3$ to $10^5$ times faster than traditional solvers for multi-query scenarios, while maintaining comparable accuracy. We provide practical guidance for method selection, discuss theoretical foundations (universal approximation, convergence), and identify critical open challenges: high-dimensional parameters, complex geometries, and out-of-distribution generalization. This work establishes a unified framework for understanding parametric PDE solvers via operator learning, offering a comprehensive, incrementally updated resource for this rapidly evolving field",
    "authors": [
      "Zhuo Zhang",
      "Xiong Xiong",
      "Sen Zhang",
      "Yuan Zhao",
      "Xi Yang"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "68T01"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04576v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04576v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.04568v1",
    "title": "Riesz Regression As Direct Density Ratio Estimation",
    "summary": "Riesz regression has garnered attention as a tool in debiased machine learning for causal and structural parameter estimation (Chernozhukov et al., 2021). This study shows that Riesz regression is closely related to direct density-ratio estimation (DRE) in important cases, including average treat- ment effect (ATE) estimation. Specifically, the idea and objective in Riesz regression coincide with the one in least-squares importance fitting (LSIF, Kanamori et al., 2009) in direct density-ratio estimation. While Riesz regression is general in the sense that it can be applied to Riesz representer estimation in a wide class of problems, the equivalence with DRE allows us to directly import exist- ing results in specific cases, including convergence-rate analyses, the selection of loss functions via Bregman-divergence minimization, and regularization techniques for flexible models, such as neural networks. Conversely, insights about the Riesz representer in debiased machine learning broaden the applications of direct density-ratio estimation methods. This paper consolidates our prior results in Kato (2025a) and Kato (2025b).",
    "authors": [
      "Masahiro Kato"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "econ.EM",
      "math.ST",
      "stat.ME",
      "stat.TH"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04568v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04568v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.04527v1",
    "title": "Are language models aware of the road not taken? Token-level uncertainty   and hidden state dynamics",
    "summary": "When a language model generates text, the selection of individual tokens might lead it down very different reasoning paths, making uncertainty difficult to quantify. In this work, we consider whether reasoning language models represent the alternate paths that they could take during generation. To test this hypothesis, we use hidden activations to control and predict a language model's uncertainty during chain-of-thought reasoning. In our experiments, we find a clear correlation between how uncertain a model is at different tokens, and how easily the model can be steered by controlling its activations. This suggests that activation interventions are most effective when there are alternate paths available to the model -- in other words, when it has not yet committed to a particular final answer. We also find that hidden activations can predict a model's future outcome distribution, demonstrating that models implicitly represent the space of possible paths.",
    "authors": [
      "Amir Zur",
      "Atticus Geiger",
      "Ekdeep Singh Lubana",
      "Eric Bigelow"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04527v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04527v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.04474v1",
    "title": "Landslide Hazard Mapping with Geospatial Foundation Models: Geographical   Generalizability, Data Scarcity, and Band Adaptability",
    "summary": "Landslides cause severe damage to lives, infrastructure, and the environment, making accurate and timely mapping essential for disaster preparedness and response. However, conventional deep learning models often struggle when applied across different sensors, regions, or under conditions of limited training data. To address these challenges, we present a three-axis analytical framework of sensor, label, and domain for adapting geospatial foundation models (GeoFMs), focusing on Prithvi-EO-2.0 for landslide mapping. Through a series of experiments, we show that it consistently outperforms task-specific CNNs (U-Net, U-Net++), vision transformers (Segformer, SwinV2-B), and other GeoFMs (TerraMind, SatMAE). The model, built on global pretraining, self-supervision, and adaptable fine-tuning, proved resilient to spectral variation, maintained accuracy under label scarcity, and generalized more reliably across diverse datasets and geographic settings. Alongside these strengths, we also highlight remaining challenges such as computational cost and the limited availability of reusable AI-ready training data for landslide research. Overall, our study positions GeoFMs as a step toward more robust and scalable approaches for landslide risk reduction and environmental monitoring.",
    "authors": [
      "Wenwen Li",
      "Sizhe Wang",
      "Hyunho Lee",
      "Chenyan Lu",
      "Sujit Roy",
      "Rahul Ramachandran",
      "Chia-Yu Hsu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04474v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04474v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.04355v1",
    "title": "Where Do LLMs Still Struggle? An In-Depth Analysis of Code Generation   Benchmarks",
    "summary": "Large Language Models (LLMs) have achieved remarkable success in code generation, and the race to improve their performance has become a central focus of AI research. Benchmarks and leaderboards are increasingly popular, offering quantitative rankings of LLMs. However, they provide limited insight into the tasks that LLMs consistently fail to solve - information that is crucial for understanding current limitations and guiding the development of more capable models. To address this gap, we examined code generation tasks across four popular benchmarks, identifying those that major LLMs are most likely to fail. To understand the causes of these failures, we investigated whether the static complexity of solution code contributes to them, followed by a systematic inspection of 114 tasks that LLMs consistently struggled with. Our analysis revealed four recurring patterns of weaknesses in LLMs, as well as common complications within benchmark tasks that most often lead to failure.",
    "authors": [
      "Amir Molzam Sharifloo",
      "Maedeh Heydari",
      "Parsa Kazerooni",
      "Daniel Maninger",
      "Mira Mezini"
    ],
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04355v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04355v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.04184v1",
    "title": "Trustworthy LLM-Mediated Communication: Evaluating Information Fidelity   in LLM as a Communicator (LAAC) Framework in Multiple Application Domains",
    "summary": "The proliferation of AI-generated content has created an absurd communication theater where senders use LLMs to inflate simple ideas into verbose content, recipients use LLMs to compress them back into summaries, and as a consequence neither party engage with authentic content. LAAC (LLM as a Communicator) proposes a paradigm shift - positioning LLMs as intelligent communication intermediaries that capture the sender's intent through structured dialogue and facilitate genuine knowledge exchange with recipients. Rather than perpetuating cycles of AI-generated inflation and compression, LAAC enables authentic communication across diverse contexts including academic papers, proposals, professional emails, and cross-platform content generation. However, deploying LLMs as trusted communication intermediaries raises critical questions about information fidelity, consistency, and reliability. This position paper systematically evaluates the trustworthiness requirements for LAAC's deployment across multiple communication domains. We investigate three fundamental dimensions: (1) Information Capture Fidelity - accuracy of intent extraction during sender interviews across different communication types, (2) Reproducibility - consistency of structured knowledge across multiple interaction instances, and (3) Query Response Integrity - reliability of recipient-facing responses without hallucination, source conflation, or fabrication. Through controlled experiments spanning multiple LAAC use cases, we assess these trust dimensions using LAAC's multi-agent architecture. Preliminary findings reveal measurable trust gaps that must be addressed before LAAC can be reliably deployed in high-stakes communication scenarios.",
    "authors": [
      "Mohammed Musthafa Rafi",
      "Adarsh Krishnamurthy",
      "Aditya Balu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04184v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04184v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.04157v1",
    "title": "Are We Aligned? A Preliminary Investigation of the Alignment of   Responsible AI Values between LLMs and Human Judgment",
    "summary": "Large Language Models (LLMs) are increasingly employed in software engineering tasks such as requirements elicitation, design, and evaluation, raising critical questions regarding their alignment with human judgments on responsible AI values. This study investigates how closely LLMs' value preferences align with those of two human groups: a US-representative sample and AI practitioners. We evaluate 23 LLMs across four tasks: (T1) selecting key responsible AI values, (T2) rating their importance in specific contexts, (T3) resolving trade-offs between competing values, and (T4) prioritizing software requirements that embody those values. The results show that LLMs generally align more closely with AI practitioners than with the US-representative sample, emphasizing fairness, privacy, transparency, safety, and accountability. However, inconsistencies appear between the values that LLMs claim to uphold (Tasks 1-3) and the way they prioritize requirements (Task 4), revealing gaps in faithfulness between stated and applied behavior. These findings highlight the practical risk of relying on LLMs in requirements engineering without human oversight and motivate the need for systematic approaches to benchmark, interpret, and monitor value alignment in AI-assisted software development.",
    "authors": [
      "Asma Yamani",
      "Malak Baslyman",
      "Moataz Ahmed"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04157v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04157v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.04106v1",
    "title": "Sub-exponential Growth in Online Word Usage: A Piecewise Power-Law Model",
    "summary": "The diffusion of ideas and language in society has conventionally been described by S-shaped models, such as the logistic curve. However, the role of sub-exponential growth -a slower than exponential pattern known in epidemiology- has been largely overlooked in broader social phenomena. Here, we present a piecewise power-law model to characterize complex growth curves with a few parameters. We systematically analyzed a large-scale dataset of approximately one billion Japanese blog articles linked to Wikipedia vocabulary, and observed consistent patterns in web search trend data (English, Spanish, and Japanese). Our analysis of the 2,965 selected items reveals that about 55% (1,625 items) were found to have no abrupt jumps and were well captured by one or two segments. For single-segment curves, we found that (i) the mode of the shape parameter alpha was near 0.5, indicating prevalent sub-exponential growth; (ii) the ultimate diffusion scale is primarily determined by the growth rate R, with minor contributions from alpha or the duration T; and (iii) alpha showed a tendency to vary with the nature of the topic, being smaller for niche/local topics and larger for widely shared ones. Furthermore, a micro-behavioral model distinguishing outward contact with strangers from inward interaction within their community suggests that alpha can be interpreted as an index of the preference for outward-oriented communication. These findings suggest that sub-exponential growth is a common pattern of social diffusion, and our model provides a practical framework for consistently describing, comparing, and interpreting complex and diverse growth curves.",
    "authors": [
      "Hayafumi Watanabe"
    ],
    "categories": [
      "physics.soc-ph",
      "cs.CL",
      "cs.CY",
      "stat.AP"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04106v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04106v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.04655v1",
    "title": "Benchmark Designers Should \"Train on the Test Set\" to Expose Exploitable   Non-Visual Shortcuts",
    "summary": "Robust benchmarks are crucial for evaluating Multimodal Large Language Models (MLLMs). Yet we find that models can ace many multimodal benchmarks without strong visual understanding, instead exploiting biases, linguistic priors, and superficial patterns. This is especially problematic for vision-centric benchmarks that are meant to require visual inputs. We adopt a diagnostic principle for benchmark design: if a benchmark can be gamed, it will be. Designers should therefore try to ``game'' their own benchmarks first, using diagnostic and debiasing procedures to systematically identify and mitigate non-visual biases. Effective diagnosis requires directly ``training on the test set'' -- probing the released test set for its intrinsic, exploitable patterns.   We operationalize this standard with two components. First, we diagnose benchmark susceptibility using a ``Test-set Stress-Test'' (TsT) methodology. Our primary diagnostic tool involves fine-tuning a powerful Large Language Model via $k$-fold cross-validation on exclusively the non-visual, textual inputs of the test set to reveal shortcut performance and assign each sample a bias score $s(x)$. We complement this with a lightweight Random Forest-based diagnostic operating on hand-crafted features for fast, interpretable auditing. Second, we debias benchmarks by filtering high-bias samples using an ``Iterative Bias Pruning'' (IBP) procedure. Applying this framework to four benchmarks -- VSI-Bench, CV-Bench, MMMU, and VideoMME -- we uncover pervasive non-visual biases. As a case study, we apply our full framework to create VSI-Bench-Debiased, demonstrating reduced non-visual solvability and a wider vision-blind performance gap than the original.",
    "authors": [
      "Ellis Brown",
      "Jihan Yang",
      "Shusheng Yang",
      "Rob Fergus",
      "Saining Xie"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04655v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04655v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.04622v1",
    "title": "ODE approximation for the Adam algorithm: General and overparametrized   setting",
    "summary": "The Adam optimizer is currently presumably the most popular optimization method in deep learning. In this article we develop an ODE based method to study the Adam optimizer in a fast-slow scaling regime. For fixed momentum parameters and vanishing step-sizes, we show that the Adam algorithm is an asymptotic pseudo-trajectory of the flow of a particular vector field, which is referred to as the Adam vector field. Leveraging properties of asymptotic pseudo-trajectories, we establish convergence results for the Adam algorithm. In particular, in a very general setting we show that if the Adam algorithm converges, then the limit must be a zero of the Adam vector field, rather than a local minimizer or critical point of the objective function.   In contrast, in the overparametrized empirical risk minimization setting, the Adam algorithm is able to locally find the set of minima. Specifically, we show that in a neighborhood of the global minima, the objective function serves as a Lyapunov function for the flow induced by the Adam vector field. As a consequence, if the Adam algorithm enters a neighborhood of the global minima infinitely often, it converges to the set of global minima.",
    "authors": [
      "Steffen Dereich",
      "Arnulf Jentzen",
      "Sebastian Kassing"
    ],
    "categories": [
      "math.OC",
      "cs.LG",
      "math.PR"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04622v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04622v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.04590v1",
    "title": "Complexity as Advantage: A Regret-Based Perspective on Emergent   Structure",
    "summary": "We introduce Complexity as Advantage (CAA), a framework that defines the complexity of a system relative to a family of observers. Instead of measuring complexity as an intrinsic property, we evaluate how much predictive regret a system induces for different observers attempting to model it. A system is complex when it is easy for some observers and hard for others, creating an information advantage. We show that this formulation unifies several notions of emergent behavior, including multiscale entropy, predictive information, and observer-dependent structure. The framework suggests that \"interesting\" systems are those positioned to create differentiated regret across observers, providing a quantitative grounding for why complexity can be functionally valuable. We demonstrate the idea through simple dynamical models and discuss implications for learning, evolution, and artificial agents.",
    "authors": [
      "Oshri Naparstek"
    ],
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04590v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04590v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.04541v1",
    "title": "LLM-as-a-Judge: Toward World Models for Slate Recommendation Systems",
    "summary": "Modeling user preferences across domains remains a key challenge in slate recommendation (i.e. recommending an ordered sequence of items) research. We investigate how Large Language Models (LLM) can effectively act as world models of user preferences through pairwise reasoning over slates. We conduct an empirical study involving several LLMs on three tasks spanning different datasets. Our results reveal relationships between task performance and properties of the preference function captured by LLMs, hinting towards areas for improvement and highlighting the potential of LLMs as world models in recommender systems.",
    "authors": [
      "Baptiste Bonin",
      "Maxime Heuillet",
      "Audrey Durand"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04541v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04541v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.04528v1",
    "title": "IntelliProof: An Argumentation Network-based Conversational Helper for   Organized Reflection",
    "summary": "We present IntelliProof, an interactive system for analyzing argumentative essays through LLMs. IntelliProof structures an essay as an argumentation graph, where claims are represented as nodes, supporting evidence is attached as node properties, and edges encode supporting or attacking relations. Unlike existing automated essay scoring systems, IntelliProof emphasizes the user experience: each relation is initially classified and scored by an LLM, then visualized for enhanced understanding. The system provides justifications for classifications and produces quantitative measures for essay coherence. It enables rapid exploration of argumentative quality while retaining human oversight. In addition, IntelliProof provides a set of tools for a better understanding of an argumentative essay and its corresponding graph in natural language, bridging the gap between the structural semantics of argumentative essays and the user's understanding of a given text. A live demo and the system are available here to try: \\textbf{https://intelliproof.vercel.app}",
    "authors": [
      "Kaveh Eskandari Miandoab",
      "Katharine Kowalyshyn",
      "Kabir Pamnani",
      "Anesu Gavhera",
      "Vasanth Sarathy",
      "Matthias Scheutz"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04528v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04528v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.04505v1",
    "title": "Alternative Fairness and Accuracy Optimization in Criminal Justice",
    "summary": "Algorithmic fairness has grown rapidly as a research area, yet key concepts remain unsettled, especially in criminal justice. We review group, individual, and process fairness and map the conditions under which they conflict. We then develop a simple modification to standard group fairness. Rather than exact parity across protected groups, we minimize a weighted error loss while keeping differences in false negative rates within a small tolerance. This makes solutions easier to find, can raise predictive accuracy, and surfaces the ethical choice of error costs. We situate this proposal within three classes of critique: biased and incomplete data, latent affirmative action, and the explosion of subgroup constraints. Finally, we offer a practical framework for deployment in public decision systems built on three pillars: need-based decisions, Transparency and accountability, and narrowly tailored definitions and solutions. Together, these elements link technical design to legitimacy and provide actionable guidance for agencies that use risk assessment and related tools.",
    "authors": [
      "Shaolong Wu",
      "James Blume",
      "Geshi Yeung"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04505v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04505v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.04394v1",
    "title": "DORAEMON: A Unified Library for Visual Object Modeling and   Representation Learning at Scale",
    "summary": "DORAEMON is an open-source PyTorch library that unifies visual object modeling and representation learning across diverse scales. A single YAML-driven workflow covers classification, retrieval and metric learning; more than 1000 pretrained backbones are exposed through a timm-compatible interface, together with modular losses, augmentations and distributed-training utilities. Reproducible recipes match or exceed reference results on ImageNet-1K, MS-Celeb-1M and Stanford online products, while one-command export to ONNX or HuggingFace bridges research and deployment. By consolidating datasets, models, and training techniques into one platform, DORAEMON offers a scalable foundation for rapid experimentation in visual recognition and representation learning, enabling efficient transfer of research advances to real-world applications. The repository is available at https://github.com/wuji3/DORAEMON.",
    "authors": [
      "Ke Du",
      "Yimin Peng",
      "Chao Gao",
      "Fan Zhou",
      "Siqiao Xue"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04394v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04394v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.04239v1",
    "title": "seqme: a Python library for evaluating biological sequence design",
    "summary": "Recent advances in computational methods for designing biological sequences have sparked the development of metrics to evaluate these methods performance in terms of the fidelity of the designed sequences to a target distribution and their attainment of desired properties. However, a single software library implementing these metrics was lacking. In this work we introduce seqme, a modular and highly extendable open-source Python library, containing model-agnostic metrics for evaluating computational methods for biological sequence design. seqme considers three groups of metrics: sequence-based, embedding-based, and property-based, and is applicable to a wide range of biological sequences: small molecules, DNA, ncRNA, mRNA, peptides and proteins. The library offers a number of embedding and property models for biological sequences, as well as diagnostics and visualization functions to inspect the results. seqme can be used to evaluate both one-shot and iterative computational design methods.",
    "authors": [
      "Rasmus Møller-Larsen",
      "Adam Izdebski",
      "Jan Olszewski",
      "Pankhil Gawade",
      "Michal Kmicikiewicz",
      "Wojciech Zarzecki",
      "Ewa Szczurek"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T01"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04239v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04239v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.04220v1",
    "title": "Opus: A Quantitative Framework for Workflow Evaluation",
    "summary": "This paper introduces the Opus Workflow Evaluation Framework, a probabilistic-normative formulation for quantifying Workflow quality and efficiency. It integrates notions of correctness, reliability, and cost into a coherent mathematical model that enables direct comparison, scoring, and optimization of Workflows. The framework combines the Opus Workflow Reward, a probabilistic function estimating expected performance through success likelihood, resource usage, and output gain, with the Opus Workflow Normative Penalties, a set of measurable functions capturing structural and informational quality across Cohesion, Coupling, Observability, and Information Hygiene. It supports automated Workflow assessment, ranking, and optimization within modern automation systems such as Opus and can be integrated into Reinforcement Learning loops to guide Workflow discovery and refinement. In this paper, we introduce the Opus Workflow Reward model that formalizes Workflow success as a probabilistic expectation over costs and outcomes. We define measurable Opus Workflow Normative Penalties capturing structural, semantic, and signal-related properties of Workflows. Finally, we propose a unified optimization formulation for identifying and ranking optimal Workflows under joint Reward-Penalty trade-offs.",
    "authors": [
      "Alan Seroul",
      "Théo Fagnoni",
      "Inès Adnani",
      "Dana O. Mohamed",
      "Phillip Kingston"
    ],
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04220v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04220v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.04183v1",
    "title": "A Reinforced Evolution-Based Approach to Multi-Resource Load Balancing",
    "summary": "This paper presents a reinforced genetic approach to a defined d-resource system optimization problem. The classical evolution schema was ineffective due to a very strict feasibility function in the studied problem. Hence, the presented strategy has introduced several modifications and adaptations to standard genetic routines, e.g.: a migration operator which is an analogy to the biological random genetic drift.",
    "authors": [
      "Leszek Sliwko"
    ],
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.DC"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04183v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04183v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.04117v1",
    "title": "Tortoise and Hare Guidance: Accelerating Diffusion Model Inference with   Multirate Integration",
    "summary": "In this paper, we propose Tortoise and Hare Guidance (THG), a training-free strategy that accelerates diffusion sampling while maintaining high-fidelity generation. We demonstrate that the noise estimate and the additional guidance term exhibit markedly different sensitivity to numerical error by reformulating the classifier-free guidance (CFG) ODE as a multirate system of ODEs. Our error-bound analysis shows that the additional guidance branch is more robust to approximation, revealing substantial redundancy that conventional solvers fail to exploit. Building on this insight, THG significantly reduces the computation of the additional guidance: the noise estimate is integrated with the tortoise equation on the original, fine-grained timestep grid, while the additional guidance is integrated with the hare equation only on a coarse grid. We also introduce (i) an error-bound-aware timestep sampler that adaptively selects step sizes and (ii) a guidance-scale scheduler that stabilizes large extrapolation spans. THG reduces the number of function evaluations (NFE) by up to 30% with virtually no loss in generation fidelity ($\\Delta$ImageReward $\\leq$ 0.032) and outperforms state-of-the-art CFG-based training-free accelerators under identical computation budgets. Our findings highlight the potential of multirate formulations for diffusion solvers, paving the way for real-time high-quality image synthesis without any model retraining. The source code is available at https://github.com/yhlee-add/THG.",
    "authors": [
      "Yunghee Lee",
      "Byeonghyun Pak",
      "Junwha Hong",
      "Hoseong Kim"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04117v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04117v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.04083v1",
    "title": "Adversarial and Score-Based CT Denoising: CycleGAN vs Noise2Score",
    "summary": "We study CT image denoising in the unpaired and self-supervised regimes by evaluating two strong, training-data-efficient paradigms: a CycleGAN-based residual translator and a Noise2Score (N2S) score-matching denoiser. Under a common evaluation protocol, a configuration sweep identifies a simple standard U-Net backbone within CycleGAN (lambda_cycle = 30, lambda_iden = 2, ngf = ndf = 64) as the most reliable setting; we then train it to convergence with a longer schedule. The selected CycleGAN improves the noisy input from 34.66 dB / 0.9234 SSIM to 38.913 dB / 0.971 SSIM and attains an estimated score of 1.9441 and an unseen-set (Kaggle leaderboard) score of 1.9343. Noise2Score, while slightly behind in absolute PSNR / SSIM, achieves large gains over very noisy inputs, highlighting its utility when clean pairs are unavailable. Overall, CycleGAN offers the strongest final image quality, whereas Noise2Score provides a robust pair-free alternative with competitive performance. Source code is available at https://github.com/hanifsyarubany/CT-Scan-Image-Denoising-using-CycleGAN-and-Noise2Score.",
    "authors": [
      "Abu Hanif Muhammad Syarubany"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04083v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04083v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.04073v1",
    "title": "Learning Filter-Aware Distance Metrics for Nearest Neighbor Search with   Multiple Filters",
    "summary": "Filtered Approximate Nearest Neighbor (ANN) search retrieves the closest vectors for a query vector from a dataset. It enforces that a specified set of discrete labels $S$ for the query must be included in the labels of each retrieved vector. Existing graph-based methods typically incorporate filter awareness by assigning fixed penalties or prioritizing nodes based on filter satisfaction. However, since these methods use fixed, data in- dependent penalties, they often fail to generalize across datasets with diverse label and vector distributions. In this work, we propose a principled alternative that learns the optimal trade-off between vector distance and filter match directly from the data, rather than relying on fixed penalties. We formulate this as a constrained linear optimization problem, deriving weights that better reflect the underlying filter distribution and more effectively address the filtered ANN search problem. These learned weights guide both the search process and index construction, leading to graph structures that more effectively capture the underlying filter distribution and filter semantics. Our experiments demonstrate that adapting the distance function to the data significantly im- proves accuracy by 5-10% over fixed-penalty methods, providing a more flexible and generalizable framework for the filtered ANN search problem.",
    "authors": [
      "Ananya Sutradhar",
      "Suryansh Gupta",
      "Ravishankar Krishnaswamy",
      "Haiyang Xu",
      "Aseem Rastogi",
      "Gopal Srinivasa"
    ],
    "categories": [
      "cs.LG",
      "cs.DB",
      "cs.IR"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04073v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04073v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.04584v1",
    "title": "Are We Asking the Right Questions? On Ambiguity in Natural Language   Queries for Tabular Data Analysis",
    "summary": "Natural language interfaces to tabular data must handle ambiguities inherent to queries. Instead of treating ambiguity as a deficiency, we reframe it as a feature of cooperative interaction, where the responsibility of query specification is shared among the user and the system. We develop a principled framework distinguishing cooperative queries, i.e., queries that yield a resolvable interpretation, from uncooperative queries that cannot be resolved. Applying the framework to evaluations for tabular question answering and analysis, we analyze the queries in 15 popular datasets, and observe an uncontrolled mixing of query types neither adequate for evaluating a system's execution accuracy nor for evaluating interpretation capabilities. Our framework and analysis of queries shifts the perspective from fixing ambiguity to embracing cooperation in resolving queries. This reflection enables more informed design and evaluation for natural language interfaces for tabular data, for which we outline implications and directions for future research.",
    "authors": [
      "Daniel Gomm",
      "Cornelius Wolff",
      "Madelon Hulsebos"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DB",
      "cs.HC"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04584v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04584v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.04552v1",
    "title": "Generative Bayesian Filtering and Parameter Learning",
    "summary": "Generative Bayesian Filtering (GBF) provides a powerful and flexible framework for performing posterior inference in complex nonlinear and non-Gaussian state-space models. Our approach extends Generative Bayesian Computation (GBC) to dynamic settings, enabling recursive posterior inference using simulation-based methods powered by deep neural networks. GBF does not require explicit density evaluations, making it particularly effective when observation or transition distributions are analytically intractable. To address parameter learning, we introduce the Generative-Gibbs sampler, which bypasses explicit density evaluation by iteratively sampling each variable from its implicit full conditional distribution. Such technique is broadly applicable and enables inference in hierarchical Bayesian models with intractable densities, including state-space models. We assess the performance of the proposed methodologies through both simulated and empirical studies, including the estimation of $\\alpha$-stable stochastic volatility models. Our findings indicate that GBF significantly outperforms existing likelihood-free approaches in accuracy and robustness when dealing with intractable state-space models.",
    "authors": [
      "Edoardo Marcelli",
      "Sean O'Hagan",
      "Veronika Rockova"
    ],
    "categories": [
      "stat.ME",
      "stat.CO",
      "stat.ML"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04552v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04552v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.04550v1",
    "title": "Confidential Computing for Cloud Security: Exploring Hardware based   Encryption Using Trusted Execution Environments",
    "summary": "The growth of cloud computing has revolutionized data processing and storage capacities to another levels of scalability and flexibility. But in the process, it has created a huge challenge of security, especially in terms of safeguarding sensitive data. Classical security practices, including encryption at rest and during transit, fail to protect data in use and expose it to various possible breaches. In response to this problem , Confidential Computing has been a tool ,seeking to secure data in processing by usage of hardware-based Trusted Execution Environments (TEEs). TEEs, including Intel's Software Guard Extensions (SGX) and ARM's TrustZone, offers protected contexts within the processor, where data is kept confidential ,intact and secure , even with malicious software or compromised operating systems. In this research, we have explored the architecture and security features of TEEs like Intel SGX and ARM TrustZone, and their effectiveness in improving cloud data security. From a thorough literature survey ,we have analyzed the deployment strategies, performance indicators, and practical uses of these TEEs for the same purpose. In addition, we have discussed the issues regarding deployment, possible weaknesses, scalability issues, and integration issues. Our results focuses on the central position of TEEs in strengthening and advancing cloud security infrastructures, pointing towards their ability to create a secure foundation for Confidential Computing.",
    "authors": [
      "Dhruv Deepak Agarwal",
      "Aswani Kumar Cherukuri"
    ],
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04550v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04550v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.04539v1",
    "title": "Unified Generative Latent Representation for Functional Brain Graphs",
    "summary": "Functional brain graphs are often characterized with separate graph-theoretic or spectral descriptors, overlooking how these properties covary and partially overlap across brains and conditions. We anticipate that dense, weighted functional connectivity graphs occupy a low-dimensional latent geometry along which both topological and spectral structures display graded variations. Here, we estimated this unified graph representation and enabled generation of dense functional brain graphs through a graph transformer autoencoder with latent diffusion, with spectral geometry providing an inductive bias to guide learning. This geometry-aware latent representation, although unsupervised, meaningfully separated working-memory states and decoded visual stimuli, with performance further enhanced by incorporating neural dynamics. From the diffusion modeled distribution, we were able to sample biologically plausible and structurally grounded synthetic dense graphs.",
    "authors": [
      "Subati Abulikemu",
      "Tiago Azevedo",
      "Michail Mamalakis",
      "John Suckling"
    ],
    "categories": [
      "q-bio.NC",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04539v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04539v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.04514v1",
    "title": "Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image   Classifiers",
    "summary": "The phenomenon of linear mode connectivity (LMC) links several aspects of deep learning, including training stability under noisy stochastic gradients, the smoothness and generalization of local minima (basins), the similarity and functional diversity of sampled models, and architectural effects on data processing. In this work, we experimentally study LMC under data shifts and identify conditions that mitigate their impact. We interpret data shifts as an additional source of stochastic gradient noise, which can be reduced through small learning rates and large batch sizes. These parameters influence whether models converge to the same local minimum or to regions of the loss landscape with varying smoothness and generalization. Although models sampled via LMC tend to make similar errors more frequently than those converging to different basins, the benefit of LMC lies in balancing training efficiency against the gains achieved from larger, more diverse ensembles. Code and supplementary materials will be made publicly available at https://github.com/DLR-KI/LMC in due course.",
    "authors": [
      "C. Hepburn",
      "T. Zielke",
      "A. P. Raulf"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04514v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04514v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.04495v1",
    "title": "OUNLP at TSAR 2025 Shared Task: Multi-Round Text Simplifier via Code   Generation",
    "summary": "This paper describes the OUNLP system submitted to the TSAR-2025 Shared Task (Alva-Manchego et al., 2025), designed for readability-controlled text simplification using LLM-prompting-based generation. Based on the analysis of prompt-based text simplification methods, we discovered an interesting finding that text simplification performance is highly related to the gap between the source CEFR (Arase et al., 2022) level and the target CEFR level. Inspired by this finding, we propose two multi-round simplification methods and generate them via GPT-4o: rule-based simplification (MRS-Rule) and jointly rule-based LLM simplification (MRS-Joint). Our submitted systems ranked 7 out of 20 teams. Later improvements with MRS-Joint show that taking the LLM simplified candidates as the starting point could further boost the multi-round simplification performance.",
    "authors": [
      "Cuong Huynh",
      "Jie Cao"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04495v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04495v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.04481v1",
    "title": "Promoting Sustainable Web Agents: Benchmarking and Estimating Energy   Consumption through Empirical and Theoretical Analysis",
    "summary": "Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful agentic systems pushing the boundaries of Large Language Models (LLM). They can autonomously interact with the internet at the user's behest, such as navigating websites, filling search masks, and comparing price lists. Though web agent research is thriving, induced sustainability issues remain largely unexplored. To highlight the urgency of this issue, we provide an initial exploration of the energy and $CO_2$ cost associated with web agents from both a theoretical -via estimation- and an empirical perspective -by benchmarking. Our results show how different philosophies in web agent creation can severely impact the associated expended energy, and that more energy consumed does not necessarily equate to better results. We highlight a lack of transparency regarding disclosing model parameters and processes used for some web agents as a limiting factor when estimating energy consumption. Our work contributes towards a change in thinking of how we evaluate web agents, advocating for dedicated metrics measuring energy consumption in benchmarks.",
    "authors": [
      "Lars Krupp",
      "Daniel Geißler",
      "Vishal Banwari",
      "Paul Lukowicz",
      "Jakob Karolus"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04481v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04481v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.04357v1",
    "title": "GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon   Planning with VLA Policies",
    "summary": "Deploying autonomous robots that can learn new skills from demonstrations is an important challenge of modern robotics. Existing solutions often apply end-to-end imitation learning with Vision-Language Action (VLA) models or symbolic approaches with Action Model Learning (AML). On the one hand, current VLA models are limited by the lack of high-level symbolic planning, which hinders their abilities in long-horizon tasks. On the other hand, symbolic approaches in AML lack generalization and scalability perspectives. In this paper we present a new neuro-symbolic approach, GraSP-VLA, a framework that uses a Continuous Scene Graph representation to generate a symbolic representation of human demonstrations. This representation is used to generate new planning domains during inference and serves as an orchestrator for low-level VLA policies, scaling up the number of actions that can be reproduced in a row. Our results show that GraSP-VLA is effective for modeling symbolic representations on the task of automatic planning domain generation from observations. In addition, results on real-world experiments show the potential of our Continuous Scene Graph representation to orchestrate low-level VLA policies in long-horizon tasks.",
    "authors": [
      "Maëlic Neau",
      "Zoe Falomir",
      "Paulo E. Santos",
      "Anne-Gwenn Bosser",
      "Cédric Buche"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04357v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04357v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.04291v1",
    "title": "Robustness of Minimum-Volume Nonnegative Matrix Factorization under an   Expanded Sufficiently Scattered Condition",
    "summary": "Minimum-volume nonnegative matrix factorization (min-vol NMF) has been used successfully in many applications, such as hyperspectral imaging, chemical kinetics, spectroscopy, topic modeling, and audio source separation. However, its robustness to noise has been a long-standing open problem. In this paper, we prove that min-vol NMF identifies the groundtruth factors in the presence of noise under a condition referred to as the expanded sufficiently scattered condition which requires the data points to be sufficiently well scattered in the latent simplex generated by the basis vectors.",
    "authors": [
      "Giovanni Barbarino",
      "Nicolas Gillis",
      "Subhayan Saha"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "cs.NA",
      "eess.SP",
      "math.NA"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04291v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04291v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.04103v1",
    "title": "A Characterization of List Language Identification in the Limit",
    "summary": "We study the problem of language identification in the limit, where given a sequence of examples from a target language, the goal of the learner is to output a sequence of guesses for the target language such that all the guesses beyond some finite time are correct. Classical results of Gold showed that language identification in the limit is impossible for essentially any interesting collection of languages. Later, Angluin gave a precise characterization of language collections for which this task is possible. Motivated by recent positive results for the related problem of language generation, we revisit the classic language identification problem in the setting where the learner is given the additional power of producing a list of $k$ guesses at each time step. The goal is to ensure that beyond some finite time, one of the guesses is correct at each time step.   We give an exact characterization of collections of languages that can be $k$-list identified in the limit, based on a recursive version of Angluin's characterization (for language identification with a list of size $1$). This further leads to a conceptually appealing characterization: A language collection can be $k$-list identified in the limit if and only if the collection can be decomposed into $k$ collections of languages, each of which can be identified in the limit (with a list of size $1$). We also use our characterization to establish rates for list identification in the statistical setting where the input is drawn as an i.i.d. stream from a distribution supported on some language in the collection. Our results show that if a collection is $k$-list identifiable in the limit, then the collection can be $k$-list identified at an exponential rate, and this is best possible. On the other hand, if a collection is not $k$-list identifiable in the limit, then it cannot be $k$-list identified at any rate that goes to zero.",
    "authors": [
      "Moses Charikar",
      "Chirag Pabbaraju",
      "Ambuj Tewari"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DS",
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04103v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04103v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.04094v1",
    "title": "KoTaP: A Panel Dataset for Corporate Tax Avoidance, Performance, and   Governance in Korea",
    "summary": "This study introduces the Korean Tax Avoidance Panel (KoTaP), a long-term panel dataset of non-financial firms listed on KOSPI and KOSDAQ between 2011 and 2024. After excluding financial firms, firms with non-December fiscal year ends, capital impairment, and negative pre-tax income, the final dataset consists of 12,653 firm-year observations from 1,754 firms. KoTaP is designed to treat corporate tax avoidance as a predictor variable and link it to multiple domains, including earnings management (accrual- and activity-based), profitability (ROA, ROE, CFO, LOSS), stability (LEV, CUR, SIZE, PPE, AGE, INVREC), growth (GRW, MB, TQ), and governance (BIG4, FORN, OWN). Tax avoidance itself is measured using complementary indicators cash effective tax rate (CETR), GAAP effective tax rate (GETR), and book-tax difference measures (TSTA, TSDA) with adjustments to ensure interpretability. A key strength of KoTaP is its balanced panel structure with standardized variables and its consistency with international literature on the distribution and correlation of core indicators. At the same time, it reflects distinctive institutional features of Korean firms, such as concentrated ownership, high foreign shareholding, and elevated liquidity ratios, providing both international comparability and contextual uniqueness. KoTaP enables applications in benchmarking econometric and deep learning models, external validity checks, and explainable AI analyses. It further supports policy evaluation, audit planning, and investment analysis, making it a critical open resource for accounting, finance, and interdisciplinary research.",
    "authors": [
      "Hyungjong Na",
      "Wonho Song",
      "Seungyong Han",
      "Donghyeon Jo",
      "Sejin Myung",
      "Hyungjoon Kim"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04094v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04094v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.04349v1",
    "title": "A MATLAB tutorial on deep feature extraction combined with chemometrics   for analytical applications",
    "summary": "Background In analytical chemistry, spatial information about materials is commonly captured through imaging techniques, such as traditional color cameras or with advanced hyperspectral cameras and microscopes. However, efficiently extracting and analyzing this spatial information for exploratory and predictive purposes remains a challenge, especially when using traditional chemometric methods. Recent advances in deep learning and artificial intelligence have significantly enhanced image processing capabilities, enabling the extraction of multiscale deep features that are otherwise challenging to capture with conventional image processing techniques. Despite the wide availability of open-source deep learning models, adoption in analytical chemistry remains limited because of the absence of structured, step-by-step guidance for implementing these models.   Results This tutorial aims to bridge this gap by providing a step-by-step guide for applying deep learning approaches to extract spatial information from imaging data and integrating it with other data sources, such as spectral information. Importantly, the focus of this work is not on training deep learning models for image processing but on using existing open source models to extract deep features from imaging data.   Significance The tutorial provides MATLAB code tutorial demonstrations, showcasing the processing of imaging data from various imaging modalities commonly encountered in analytical chemistry. Readers must run the tutorial steps on their own datasets using the codes presented in this tutorial.",
    "authors": [
      "Puneet Mishra",
      "Martijntje Vollebregt",
      "Yizhou Ma",
      "Maria Font-i-Furnols"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04349v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04349v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2511.04281v1",
    "title": "DINOv2 Driven Gait Representation Learning for Video-Based   Visible-Infrared Person Re-identification",
    "summary": "Video-based Visible-Infrared person re-identification (VVI-ReID) aims to retrieve the same pedestrian across visible and infrared modalities from video sequences. Existing methods tend to exploit modality-invariant visual features but largely overlook gait features, which are not only modality-invariant but also rich in temporal dynamics, thus limiting their ability to model the spatiotemporal consistency essential for cross-modal video matching. To address these challenges, we propose a DINOv2-Driven Gait Representation Learning (DinoGRL) framework that leverages the rich visual priors of DINOv2 to learn gait features complementary to appearance cues, facilitating robust sequence-level representations for cross-modal retrieval. Specifically, we introduce a Semantic-Aware Silhouette and Gait Learning (SASGL) model, which generates and enhances silhouette representations with general-purpose semantic priors from DINOv2 and jointly optimizes them with the ReID objective to achieve semantically enriched and task-adaptive gait feature learning. Furthermore, we develop a Progressive Bidirectional Multi-Granularity Enhancement (PBMGE) module, which progressively refines feature representations by enabling bidirectional interactions between gait and appearance streams across multiple spatial granularities, fully leveraging their complementarity to enhance global representations with rich local details and produce highly discriminative features. Extensive experiments on HITSZ-VCM and BUPT datasets demonstrate the superiority of our approach, significantly outperforming existing state-of-the-art methods.",
    "authors": [
      "Yujie Yang",
      "Shuang Li",
      "Jun Ye",
      "Neng Dong",
      "Fan Li",
      "Huafeng Li"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04281v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04281v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2511.04144v1",
    "title": "Scaffolding Metacognition in Programming Education: Understanding   Student-AI Interactions and Design Implications",
    "summary": "Generative AI tools such as ChatGPT now provide novice programmers with unprecedented access to instant, personalized support. While this holds clear promise, their influence on students' metacognitive processes remains underexplored. Existing work has largely focused on correctness and usability, with limited attention to whether and how students' use of AI assistants supports or bypasses key metacognitive processes. This study addresses that gap by analyzing student-AI interactions through a metacognitive lens in university-level programming courses. We examined more than 10,000 dialogue logs collected over three years, complemented by surveys of students and educators. Our analysis focused on how prompts and responses aligned with metacognitive phases and strategies. Synthesizing these findings across data sources, we distill design considerations for AI-powered coding assistants that aim to support rather than supplant metacognitive engagement. Our findings provide guidance for developing educational AI tools that strengthen students' learning processes in programming education.",
    "authors": [
      "Boxuan Ma",
      "Huiyong Li",
      "Gen Li",
      "Li Chen",
      "Cheng Tang",
      "Yinjie Xie",
      "Chenghao Gu",
      "Atsushi Shimada",
      "Shin'ichi Konomi"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04144v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04144v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2511.04048v1",
    "title": "Explorability in Pushdown Automata",
    "summary": "We study explorability, a measure of nondeterminism in pushdown automata, which generalises history-determinism. An automaton is k-explorable if, while reading the input, it suffices to follow k concurrent runs, built step-by-step based only on the input seen so far, to construct an accepting one, if it exists. We show that the class of explorable PDAs lies strictly between history-deterministic and fully nondeterministic PDAs in terms of both expressiveness and succinctness. In fact increasing explorability induces an infinite hierarchy: each level k defines a strictly more expressive class than level k-1, yet the entire class remains less expressive than general nondeterministic PDAs. We then introduce a parameterized notion of explorability, where the number of runs may depend on input length, and show that exponential explorability precisely captures the context-free languages. Finally, we prove that explorable PDAs can be doubly exponentially more succinct than history-deterministic ones, and that the succinctness gap between deterministic and 2-explorable PDAs is not recursively enumerable. These results position explorability as a robust and operationally meaningful measure of nondeterminism for pushdown systems.",
    "authors": [
      "Ayaan Bedi",
      "Karoliina Lehtinen"
    ],
    "categories": [
      "cs.FL",
      "cs.CL"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04048v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04048v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2511.04615v1",
    "title": "Building Trust in Virtual Immunohistochemistry: Automated Assessment of   Image Quality",
    "summary": "Deep learning models can generate virtual immunohistochemistry (IHC) stains from hematoxylin and eosin (H&E) images, offering a scalable and low-cost alternative to laboratory IHC. However, reliable evaluation of image quality remains a challenge as current texture- and distribution-based metrics quantify image fidelity rather than the accuracy of IHC staining. Here, we introduce an automated and accuracy grounded framework to determine image quality across sixteen paired or unpaired image translation models. Using color deconvolution, we generate masks of pixels stained brown (i.e., IHC-positive) as predicted by each virtual IHC model. We use the segmented masks of real and virtual IHC to compute stain accuracy metrics (Dice, IoU, Hausdorff distance) that directly quantify correct pixel - level labeling without needing expert manual annotations. Our results demonstrate that conventional image fidelity metrics, including Frechet Inception Distance (FID), peak signal-to-noise ratio (PSNR), and structural similarity (SSIM), correlate poorly with stain accuracy and pathologist assessment. Paired models such as PyramidPix2Pix and AdaptiveNCE achieve the highest stain accuracy, whereas unpaired diffusion- and GAN-based models are less reliable in providing accurate IHC positive pixel labels. Moreover, whole-slide images (WSI) reveal performance declines that are invisible in patch-based evaluations, emphasizing the need for WSI-level benchmarks. Together, this framework defines a reproducible approach for assessing the quality of virtual IHC models, a critical step to accelerate translation towards routine use by pathologists.",
    "authors": [
      "Tushar Kataria",
      "Shikha Dubey",
      "Mary Bronner",
      "Jolanta Jedrzkiewicz",
      "Ben J. Brintz",
      "Shireen Y. Elhabian",
      "Beatrice S. Knudsen"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04615v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04615v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2511.04344v1",
    "title": "Comparative Study of CNN Architectures for Binary Classification of   Horses and Motorcycles in the VOC 2008 Dataset",
    "summary": "This paper presents a comprehensive evaluation of nine convolutional neural network architectures for binary classification of horses and motorcycles in the VOC 2008 dataset. We address the significant class imbalance problem by implementing minority-class augmentation techniques. Our experiments compare modern architectures including ResNet-50, ConvNeXt-Tiny, DenseNet-121, and Vision Transformer across multiple performance metrics. Results demonstrate substantial performance variations, with ConvNeXt-Tiny achieving the highest Average Precision (AP) of 95.53% for horse detection and 89.12% for motorcycle detection. We observe that data augmentation significantly improves minority class detection, particularly benefiting deeper architectures. This study provides insights into architecture selection for imbalanced binary classification tasks and quantifies the impact of data augmentation strategies in mitigating class imbalance issues in object detection.",
    "authors": [
      "Muhammad Annas Shaikh",
      "Hamza Zaman",
      "Arbaz Asif"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04344v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04344v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2511.04177v1",
    "title": "When Empowerment Disempowers",
    "summary": "Empowerment, a measure of an agent's ability to control its environment, has been proposed as a universal goal-agnostic objective for motivating assistive behavior in AI agents. While multi-human settings like homes and hospitals are promising for AI assistance, prior work on empowerment-based assistance assumes that the agent assists one human in isolation. We introduce an open source multi-human gridworld test suite Disempower-Grid. Using Disempower-Grid, we empirically show that assistive RL agents optimizing for one human's empowerment can significantly reduce another human's environmental influence and rewards - a phenomenon we formalize as disempowerment. We characterize when disempowerment occurs in these environments and show that joint empowerment mitigates disempowerment at the cost of the user's reward. Our work reveals a broader challenge for the AI alignment community: goal-agnostic objectives that seem aligned in single-agent settings can become misaligned in multi-agent contexts.",
    "authors": [
      "Claire Yang",
      "Maya Cakmak",
      "Max Kleiman-Weiner"
    ],
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04177v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04177v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2511.04670v1",
    "title": "Cambrian-S: Towards Spatial Supersensing in Video",
    "summary": "We argue that progress in true multimodal intelligence calls for a shift from reactive, task-driven systems and brute-force long context towards a broader paradigm of supersensing. We frame spatial supersensing as four stages beyond linguistic-only understanding: semantic perception (naming what is seen), streaming event cognition (maintaining memory across continuous experiences), implicit 3D spatial cognition (inferring the world behind pixels), and predictive world modeling (creating internal models that filter and organize information). Current benchmarks largely test only the early stages, offering narrow coverage of spatial cognition and rarely challenging models in ways that require true world modeling. To drive progress in spatial supersensing, we present VSI-SUPER, a two-part benchmark: VSR (long-horizon visual spatial recall) and VSC (continual visual spatial counting). These tasks require arbitrarily long video inputs yet are resistant to brute-force context expansion. We then test data scaling limits by curating VSI-590K and training Cambrian-S, achieving +30% absolute improvement on VSI-Bench without sacrificing general capabilities. Yet performance on VSI-SUPER remains limited, indicating that scale alone is insufficient for spatial supersensing. We propose predictive sensing as a path forward, presenting a proof-of-concept in which a self-supervised next-latent-frame predictor leverages surprise (prediction error) to drive memory and event segmentation. On VSI-SUPER, this approach substantially outperforms leading proprietary baselines, showing that spatial supersensing requires models that not only see but also anticipate, select, and organize experience.",
    "authors": [
      "Shusheng Yang",
      "Jihan Yang",
      "Pinzhi Huang",
      "Ellis Brown",
      "Zihao Yang",
      "Yue Yu",
      "Shengbang Tong",
      "Zihan Zheng",
      "Yifan Xu",
      "Muhan Wang",
      "Daohan Lu",
      "Rob Fergus",
      "Yann LeCun",
      "Li Fei-Fei",
      "Saining Xie"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04670v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04670v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.49
  },
  {
    "arxiv_id": "2511.04347v1",
    "title": "Evaluating the Impact of Weather-Induced Sensor Occlusion on BEVFusion   for 3D Object Detection",
    "summary": "Accurate 3D object detection is essential for automated vehicles to navigate safely in complex real-world environments. Bird's Eye View (BEV) representations, which project multi-sensor data into a top-down spatial format, have emerged as a powerful approach for robust perception. Although BEV-based fusion architectures have demonstrated strong performance through multimodal integration, the effects of sensor occlusions, caused by environmental conditions such as fog, haze, or physical obstructions, on 3D detection accuracy remain underexplored. In this work, we investigate the impact of occlusions on both camera and Light Detection and Ranging (LiDAR) outputs using the BEVFusion architecture, evaluated on the nuScenes dataset. Detection performance is measured using mean Average Precision (mAP) and the nuScenes Detection Score (NDS). Our results show that moderate camera occlusions lead to a 41.3% drop in mAP (from 35.6% to 20.9%) when detection is based only on the camera. On the other hand, LiDAR sharply drops in performance only under heavy occlusion, with mAP falling by 47.3% (from 64.7% to 34.1%), with a severe impact on long-range detection. In fused settings, the effect depends on which sensor is occluded: occluding the camera leads to a minor 4.1% drop (from 68.5% to 65.7%), while occluding LiDAR results in a larger 26.8% drop (to 50.1%), revealing the model's stronger reliance on LiDAR for the task of 3D object detection. Our results highlight the need for future research into occlusion-aware evaluation methods and improved sensor fusion techniques that can maintain detection accuracy in the presence of partial sensor failure or degradation due to adverse environmental conditions.",
    "authors": [
      "Sanjay Kumar",
      "Tim Brophy",
      "Eoin Martino Grua",
      "Ganesh Sistu",
      "Valentina Donzella",
      "Ciaran Eising"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04347v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04347v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.49
  },
  {
    "arxiv_id": "2511.04047v1",
    "title": "Why Consciousness Should Explain Physical Phenomena: Toward a Testable   Theory",
    "summary": "The reductionist approach commonly employed in scientific methods presupposes that both macro and micro phenomena can be explained by micro-level laws alone. This assumption implies intra-level causal closure, rendering all macro phenomena epiphenomenal. However, the integrative nature of consciousness suggests that it is a macro phenomenon. To ensure scientific testability and reject epiphenomenalism, the reductionist assumption of intra-level causal closure must be rejected. This implies that even neural-level behavior cannot be explained by observable neural-level laws alone. Therefore, a new methodology is necessary to acknowledge the causal efficacy of macro-level phenomena. We model the brain as operating under dual laws at different levels. This model includes hypothetical macro-level psychological laws that are not determined solely by micro-level neural laws, as well as the causal effects from macro to micro levels. In this study, we propose a constructive approach that explains both mental and physical phenomena through the interaction between these two sets of laws.",
    "authors": [
      "Yoshiyuki Ohmura",
      "Yasuo Kuniyoshi"
    ],
    "categories": [
      "q-bio.NC",
      "cs.NE"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04047v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04047v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.49
  },
  {
    "arxiv_id": "2511.04599v1",
    "title": "Geometric Decomposition of Statistical Inference through Gradient Flow   and Co-Monotonicity Measures",
    "summary": "Understanding feature-outcome associations in high-dimensional data remains   challenging when relationships vary across subpopulations, yet standard   methods assuming global associations miss context-dependent patterns, reducing   statistical power and interpretability. We develop a geometric decomposition   framework offering two strategies for partitioning inference problems into   regional analyses on data-derived Riemannian graphs. Gradient flow   decomposition uses path-monotonicity-validated discrete Morse theory to   partition samples into basins where outcomes exhibit monotonic behavior.   Co-monotonicity decomposition leverages association structure: vertex-level   coefficients measuring directional concordance between outcome and features,   or between feature pairs, define embeddings of samples into association space.   These embeddings induce Riemannian k-NN graphs on which biclustering   identifies co-monotonicity cells (coherent regions) and feature modules. This   extends naturally to multi-modal integration across multiple feature sets.   Both strategies apply independently or jointly, with Bayesian posterior   sampling providing credible intervals.",
    "authors": [
      "Pawel Gajer",
      "Jacques Ravel"
    ],
    "categories": [
      "stat.ME",
      "math.ST",
      "stat.ML",
      "stat.TH",
      "62G08, 62H30, 58E05"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04599v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04599v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.48
  },
  {
    "arxiv_id": "2511.04190v1",
    "title": "Covariance Descriptors Meet General Vision Encoders: Riemannian Deep   Learning for Medical Image Classification",
    "summary": "Covariance descriptors capture second-order statistics of image features. They have shown strong performance in general computer vision tasks, but remain underexplored in medical imaging. We investigate their effectiveness for both conventional and learning-based medical image classification, with a particular focus on SPDNet, a classification network specifically designed for symmetric positive definite (SPD) matrices. We propose constructing covariance descriptors from features extracted by pre-trained general vision encoders (GVEs) and comparing them with handcrafted descriptors. Two GVEs - DINOv2 and MedSAM - are evaluated across eleven binary and multi-class datasets from the MedMNSIT benchmark. Our results show that covariance descriptors derived from GVE features consistently outperform those derived from handcrafted features. Moreover, SPDNet yields superior performance to state-of-the-art methods when combined with DINOv2 features. Our findings highlight the potential of combining covariance descriptors with powerful pretrained vision encoders for medical image analysis.",
    "authors": [
      "Josef Mayr",
      "Anna Reithmeir",
      "Maxime Di Folco",
      "Julia A. Schnabel"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04190v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04190v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.48
  },
  {
    "arxiv_id": "2511.04301v1",
    "title": "Simultaneous Optimization of Geodesics and Fréchet Means",
    "summary": "A central part of geometric statistics is to compute the Fr\\'echet mean. This is a well-known intrinsic mean on a Riemannian manifold that minimizes the sum of squared Riemannian distances from the mean point to all other data points. The Fr\\'echet mean is simple to define and generalizes the Euclidean mean, but for most manifolds even minimizing the Riemannian distance involves solving an optimization problem. Therefore, numerical computations of the Fr\\'echet mean require solving an embedded optimization problem in each iteration. We introduce the GEORCE-FM algorithm to simultaneously compute the Fr\\'echet mean and Riemannian distances in each iteration in a local chart, making it faster than previous methods. We extend the algorithm to Finsler manifolds and introduce an adaptive extension such that GEORCE-FM scales to a large number of data points. Theoretically, we show that GEORCE-FM has global convergence and local quadratic convergence and prove that the adaptive extension converges in expectation to the Fr\\'echet mean. We further empirically demonstrate that GEORCE-FM outperforms existing baseline methods to estimate the Fr\\'echet mean in terms of both accuracy and runtime.",
    "authors": [
      "Frederik Möbius Rygaard",
      "Søren Hauberg",
      "Steen Markvorsen"
    ],
    "categories": [
      "stat.ML",
      "math.DG"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04301v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04301v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2511.04680v1",
    "title": "Carousel: A High-Resolution Dataset for Multi-Target Automatic Image   Cropping",
    "summary": "Automatic image cropping is a method for maximizing the human-perceived quality of cropped regions in photographs. Although several works have proposed techniques for producing singular crops, little work has addressed the problem of producing multiple, distinct crops with aesthetic appeal. In this paper, we motivate the problem with a discussion on modern social media applications, introduce a dataset of 277 relevant images and human labels, and evaluate the efficacy of several single-crop models with an image partitioning algorithm as a pre-processing step. The dataset is available at https://github.com/RafeLoya/carousel.",
    "authors": [
      "Rafe Loya",
      "Andrew Hamara",
      "Benjamin Estell",
      "Benjamin Kilpatrick",
      "Andrew C. Freeman"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04680v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04680v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.46
  },
  {
    "arxiv_id": "2511.04593v1",
    "title": "Neural Computation Without Slots: Steps Towards Biologically Plausible   Memory and Attention in Natural and Artificial Intelligence",
    "summary": "Many models used in artificial intelligence and cognitive science rely on multi-element patterns stored in \"slots\" - dedicated storage locations - in a digital computer. As biological brains likely lack slots, we consider how they might achieve similar functional outcomes without them by building on the neurally-inspired modern Hopfield network (MHN; Krotov & Hopfield, 2021), which stores patterns in the connection weights of an individual neuron. We propose extensions of this approach to increase its biological plausibility as a model of memory and to capture an important advantage of slot-based computation in contemporary language models. For memory, neuroscience research suggests that the weights of overlapping sparse ensembles of neurons, rather than a dedicated individual neuron, are used to store a memory. We introduce the K-winner MHN, extending the approach to ensembles, and find that within a continual learning regime, the ensemble-based MHN exhibits greater retention of older memories, as measured by the graded sensitivity measure d', than a standard (one-neuron) MHN. Next, we consider the powerful use of slot-based memory in contemporary language models. These models use slots to store long sequences of past inputs and their learned encodings, supporting later predictions and allowing error signals to be transported backward in time to adjust weights underlying the learned encodings of these past inputs. Inspired by these models' successes, we show how the MHN can be extended to capture both of these important functional outcomes. Collectively, our modeling approaches constitute steps towards understanding how biologically plausible mechanisms can support computations that have enabled AI systems to capture human-like abilities that no prior models have been able to achieve.",
    "authors": [
      "Shaunak Bhandarkar",
      "James L. McClelland"
    ],
    "categories": [
      "cs.NE",
      "q-bio.NC"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04593v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04593v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.46
  },
  {
    "arxiv_id": "2511.04317v1",
    "title": "RISE-T2V: Rephrasing and Injecting Semantics with LLM for Expansive   Text-to-Video Generation",
    "summary": "Most text-to-video(T2V) diffusion models depend on pre-trained text encoders for semantic alignment, yet they often fail to maintain video quality when provided with concise prompts rather than well-designed ones. The primary issue lies in their limited textual semantics understanding. Moreover, these text encoders cannot rephrase prompts online to better align with user intentions, which limits both the scalability and usability of the models, To address these challenges, we introduce RISE-T2V, which uniquely integrates the processes of prompt rephrasing and semantic feature extraction into a single and seamless step instead of two separate steps. RISE-T2V is universal and can be applied to various pre-trained LLMs and video diffusion models(VDMs), significantly enhancing their capabilities for T2V tasks. We propose an innovative module called the Rephrasing Adapter, enabling diffusion models to utilize text hidden states during the next token prediction of the LLM as a condition for video generation. By employing a Rephrasing Adapter, the video generation model can implicitly rephrase basic prompts into more comprehensive representations that better match the user's intent. Furthermore, we leverage the powerful capabilities of LLMs to enable video generation models to accomplish a broader range of T2V tasks. Extensive experiments demonstrate that RISE-T2V is a versatile framework applicable to different video diffusion model architectures, significantly enhancing the ability of T2V models to generate high-quality videos that align with user intent. Visual results are available on the webpage at https://rise-t2v.github.io.",
    "authors": [
      "Xiangjun Zhang",
      "Litong Gong",
      "Yinglin Zheng",
      "Yansong Liu",
      "Wentao Jiang",
      "Mingyi Xu",
      "Biao Wang",
      "Tiezheng Ge",
      "Ming Zeng"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04317v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04317v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.46
  },
  {
    "arxiv_id": "2511.04679v1",
    "title": "GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human   and Object Interaction",
    "summary": "Humanoid robots are expected to operate in human-centered environments where safe and natural physical interaction is essential. However, most recent reinforcement learning (RL) policies emphasize rigid tracking and suppress external forces. Existing impedance-augmented approaches are typically restricted to base or end-effector control and focus on resisting extreme forces rather than enabling compliance. We introduce GentleHumanoid, a framework that integrates impedance control into a whole-body motion tracking policy to achieve upper-body compliance. At its core is a unified spring-based formulation that models both resistive contacts (restoring forces when pressing against surfaces) and guiding contacts (pushes or pulls sampled from human motion data). This formulation ensures kinematically consistent forces across the shoulder, elbow, and wrist, while exposing the policy to diverse interaction scenarios. Safety is further supported through task-adjustable force thresholds. We evaluate our approach in both simulation and on the Unitree G1 humanoid across tasks requiring different levels of compliance, including gentle hugging, sit-to-stand assistance, and safe object manipulation. Compared to baselines, our policy consistently reduces peak contact forces while maintaining task success, resulting in smoother and more natural interactions. These results highlight a step toward humanoid robots that can safely and effectively collaborate with humans and handle objects in real-world environments.",
    "authors": [
      "Qingzhou Lu",
      "Yao Feng",
      "Baiyu Shi",
      "Michael Piseno",
      "Zhenan Bao",
      "C. Karen Liu"
    ],
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.HC"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04679v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04679v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.44
  },
  {
    "arxiv_id": "2511.04450v1",
    "title": "Solving Convex Partition Visual Jigsaw Puzzles",
    "summary": "Jigsaw puzzle solving requires the rearrangement of unordered pieces into their original pose in order to reconstruct a coherent whole, often an image, and is known to be an intractable problem. While the possible impact of automatic puzzle solvers can be disruptive in various application domains, most of the literature has focused on developing solvers for square jigsaw puzzles, severely limiting their practical use. In this work, we significantly expand the types of puzzles handled computationally, focusing on what is known as Convex Partitions, a major subset of polygonal puzzles whose pieces are convex. We utilize both geometrical and pictorial compatibilities, introduce a greedy solver, and report several performance measures next to the first benchmark dataset of such puzzles.",
    "authors": [
      "Yaniv Ohayon",
      "Ofir Itzhak Shahar",
      "Ohad Ben-Shahar"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-06",
    "url": "https://arxiv.org/abs/2511.04450v1",
    "pdf_url": "https://arxiv.org/pdf/2511.04450v1.pdf",
    "date": "2025-11-07",
    "source": "arxiv",
    "research_score": 0.44
  }
]