[
  {
    "arxiv_id": "2511.03690v1",
    "title": "The OpenHands Software Agent SDK: A Composable and Extensible Foundation   for Production Agents",
    "summary": "Agents are now used widely in the process of software development, but building production-ready software engineering agents is a complex task. Deploying software agents effectively requires flexibility in implementation and experimentation, reliable and secure execution, and interfaces for users to interact with agents. In this paper, we present the OpenHands Software Agent SDK, a toolkit for implementing software development agents that satisfy these desiderata. This toolkit is a complete architectural redesign of the agent components of the popular OpenHands framework for software development agents, which has 64k+ GitHub stars. To achieve flexibility, we design a simple interface for implementing agents that requires only a few lines of code in the default case, but is easily extensible to more complex, full-featured agents with features such as custom tools, memory management, and more. For security and reliability, it delivers seamless local-to-remote execution portability, integrated REST/WebSocket services. For interaction with human users, it can connect directly to a variety of interfaces, such as visual workspaces (VS Code, VNC, browser), command-line interfaces, and APIs. Compared with existing SDKs from OpenAI, Claude, and Google, OpenHands uniquely integrates native sandboxed execution, lifecycle control, model-agnostic multi-LLM routing, and built-in security analysis. Empirical results on SWE-Bench Verified and GAIA benchmarks demonstrate strong performance. Put together, these elements allow the OpenHands Software Agent SDK to provide a practical foundation for prototyping, unlocking new classes of custom applications, and reliably deploying agents at scale.",
    "authors": [
      "Xingyao Wang",
      "Simon Rosenberg",
      "Juan Michelini",
      "Calvin Smith",
      "Hoang Tran",
      "Engel Nyst",
      "Rohit Malhotra",
      "Xuhui Zhou",
      "Valerie Chen",
      "Robert Brennan",
      "Graham Neubig"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03690v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03690v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.81
  },
  {
    "arxiv_id": "2511.03697v1",
    "title": "AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and   Sample-Efficient Analog Circuit Sizing",
    "summary": "Analog/mixed-signal circuits are key for interfacing electronics with the physical world. Their design, however, remains a largely handcrafted process, resulting in long and error-prone design cycles. While the recent rise of AI-based reinforcement learning and generative AI has created new techniques to automate this task, the need for many time-consuming simulations is a critical bottleneck hindering the overall efficiency. Furthermore, the lack of explainability of the resulting design solutions hampers widespread adoption of the tools. To address these issues, a novel agentic AI framework for sample-efficient and explainable analog circuit sizing is presented. It employs a multi-agent workflow where specialized Large Language Model (LLM)-based agents collaborate to interpret the circuit topology, to understand the design goals, and to iteratively refine the circuit's design parameters towards the target goals with human-interpretable reasoning. The adaptive simulation strategy creates an intelligent control that yields a high sample efficiency. The AnaFlow framework is demonstrated for two circuits of varying complexity and is able to complete the sizing task fully automatically, differently from pure Bayesian optimization and reinforcement learning approaches. The system learns from its optimization history to avoid past mistakes and to accelerate convergence. The inherent explainability makes this a powerful tool for analog design space exploration and a new paradigm in analog EDA, where AI agents serve as transparent design assistants.",
    "authors": [
      "Mohsen Ahmadzadeh",
      "Kaichang Chen",
      "Georges Gielen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03697v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03697v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.03595v1",
    "title": "Tensor-Efficient High-Dimensional Q-learning",
    "summary": "High-dimensional reinforcement learning faces challenges with complex calculations and low sample efficiency in large state-action spaces. Q-learning algorithms struggle particularly with the curse of dimensionality, where the number of state-action pairs grows exponentially with problem size. While neural network-based approaches like Deep Q-Networks have shown success, recent tensor-based methods using low-rank decomposition offer more parameter-efficient alternatives. Building upon existing tensor-based methods, we propose Tensor-Efficient Q-Learning (TEQL), which enhances low-rank tensor decomposition via improved block coordinate descent on discretized state-action spaces, incorporating novel exploration and regularization mechanisms. The key innovation is an exploration strategy that combines approximation error with visit count-based upper confidence bound to prioritize actions with high uncertainty, avoiding wasteful random exploration. Additionally, we incorporate a frequency-based penalty term in the objective function to encourage exploration of less-visited state-action pairs and reduce overfitting to frequently visited regions. Empirical results on classic control tasks demonstrate that TEQL outperforms conventional matrix-based methods and deep RL approaches in both sample efficiency and total rewards, making it suitable for resource-constrained applications, such as space and healthcare where sampling costs are high.",
    "authors": [
      "Junyi Wu",
      "Dan Li"
    ],
    "categories": [
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03595v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03595v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.03693v1",
    "title": "Colorectal Cancer Histopathological Grading using Multi-Scale Federated   Learning",
    "summary": "Colorectal cancer (CRC) grading is a critical prognostic factor but remains hampered by inter-observer variability and the privacy constraints of multi-institutional data sharing. While deep learning offers a path to automation, centralized training models conflict with data governance regulations and neglect the diagnostic importance of multi-scale analysis. In this work, we propose a scalable, privacy-preserving federated learning (FL) framework for CRC histopathological grading that integrates multi-scale feature learning within a distributed training paradigm. Our approach employs a dual-stream ResNetRS50 backbone to concurrently capture fine-grained nuclear detail and broader tissue-level context. This architecture is integrated into a robust FL system stabilized using FedProx to mitigate client drift across heterogeneous data distributions from multiple hospitals. Extensive evaluation on the CRC-HGD dataset demonstrates that our framework achieves an overall accuracy of 83.5%, outperforming a comparable centralized model (81.6%). Crucially, the system excels in identifying the most aggressive Grade III tumors with a high recall of 87.5%, a key clinical priority to prevent dangerous false negatives. Performance further improves with higher magnification, reaching 88.0% accuracy at 40x. These results validate that our federated multi-scale approach not only preserves patient privacy but also enhances model performance and generalization. The proposed modular pipeline, with built-in preprocessing, checkpointing, and error handling, establishes a foundational step toward deployable, privacy-aware clinical AI for digital pathology.",
    "authors": [
      "Md Ahasanul Arafath",
      "Abhijit Kumar Ghosh",
      "Md Rony Ahmed",
      "Sabrin Afroz",
      "Minhazul Hosen",
      "Md Hasan Moon",
      "Md Tanzim Reza",
      "Md Ashad Alam"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03693v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03693v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.03559v1",
    "title": "AILA--First Experiments with Localist Language Models",
    "summary": "This paper presents the first empirical demonstration of controllable locality in transformer language models, a novel architectural framework that enables continuous control over the degree of representation localization through a tunable locality dial parameter. Unlike traditional language models that rely exclusively on distributed representations, our approach allows dynamic interpolation between highly interpretable localist encodings and efficient distributed representations without requiring model retraining. We conducted experiments on the WikiText corpus using a two-layer transformer architecture, systematically varying the locality parameter {\\lambda} across the full spectrum from 1.0 (fully localist) to 0.0 (fully distributed). Our results demonstrate that localist configurations achieve dramatically lower attention entropy, with {\\lambda} = 1.0 yielding 5.36 bits compared to 7.18 bits at {\\lambda} = 0.0, while maintaining substantially higher pointer fidelity scores reflecting stronger alignment with rule-specified targets. Prediction experiments reveal that intermediate locality values optimize the tradeoff between interpretability and performance, with {\\lambda} = 0.6 achieving test perplexity of 4.65 and accuracy of 84.7%. These findings establish that localist language models provide a practical framework for applications in regulated domains requiring both transparency and capability, offering precise mathematical control over the interpretability-performance spectrum through explicit penalty thresholds and information-theoretic design principles.",
    "authors": [
      "Joachim Diederich"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03559v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03559v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.03724v1",
    "title": "Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via   Self-Play and Reinforcement Learning",
    "summary": "AI researchers have long focused on poker-like games as a testbed for environments characterized by multi-player dynamics, imperfect information, and reasoning under uncertainty. While recent breakthroughs have matched elite human play at no-limit Texas hold'em, the multi-player dynamics are subdued: most hands converge quickly with only two players engaged through multiple rounds of bidding. In this paper, we present Solly, the first AI agent to achieve elite human play in reduced-format Liar's Poker, a game characterized by extensive multi-player engagement. We trained Solly using self-play with a model-free, actor-critic, deep reinforcement learning algorithm. Solly played at an elite human level as measured by win rate (won over 50% of hands) and equity (money won) in heads-up and multi-player Liar's Poker. Solly also outperformed large language models (LLMs), including those with reasoning abilities, on the same metrics. Solly developed novel bidding strategies, randomized play effectively, and was not easily exploitable by world-class human players.",
    "authors": [
      "Richard Dewey",
      "Janos Botyanszki",
      "Ciamac C. Moallemi",
      "Andrew T. Zheng"
    ],
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03724v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03724v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.03695v1",
    "title": "Behavior-Adaptive Q-Learning: A Unifying Framework for Offline-to-Online   RL",
    "summary": "Offline reinforcement learning (RL) enables training from fixed data without online interaction, but policies learned offline often struggle when deployed in dynamic environments due to distributional shift and unreliable value estimates on unseen state-action pairs. We introduce Behavior-Adaptive Q-Learning (BAQ), a framework designed to enable a smooth and reliable transition from offline to online RL. The key idea is to leverage an implicit behavioral model derived from offline data to provide a behavior-consistency signal during online fine-tuning. BAQ incorporates a dual-objective loss that (i) aligns the online policy toward the offline behavior when uncertainty is high, and (ii) gradually relaxes this constraint as more confident online experience is accumulated. This adaptive mechanism reduces error propagation from out-of-distribution estimates, stabilizes early online updates, and accelerates adaptation to new scenarios. Across standard benchmarks, BAQ consistently outperforms prior offline-to-online RL approaches, achieving faster recovery, improved robustness, and higher overall performance. Our results demonstrate that implicit behavior adaptation is a principled and practical solution for reliable real-world policy deployment.",
    "authors": [
      "Lipeng Zu",
      "Hansong Zhou",
      "Xiaonan Zhang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03695v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03695v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.03576v1",
    "title": "Multi-User Personalisation in Human-Robot Interaction: Using   Quantitative Bipolar Argumentation Frameworks for Preferences Conflict   Resolution",
    "summary": "While personalisation in Human-Robot Interaction (HRI) has advanced significantly, most existing approaches focus on single-user adaptation, overlooking scenarios involving multiple stakeholders with potentially conflicting preferences. To address this, we propose the Multi-User Preferences Quantitative Bipolar Argumentation Framework (MUP-QBAF), a novel multi-user personalisation framework based on Quantitative Bipolar Argumentation Frameworks (QBAFs) that explicitly models and resolves multi-user preference conflicts. Unlike prior work in Argumentation Frameworks, which typically assumes static inputs, our approach is tailored to robotics: it incorporates both users' arguments and the robot's dynamic observations of the environment, allowing the system to adapt over time and respond to changing contexts. Preferences, both positive and negative, are represented as arguments whose strength is recalculated iteratively based on new information. The framework's properties and capabilities are presented and validated through a realistic case study, where an assistive robot mediates between the conflicting preferences of a caregiver and a care recipient during a frailty assessment task. This evaluation further includes a sensitivity analysis of argument base scores, demonstrating how preference outcomes can be shaped by user input and contextual observations. By offering a transparent, structured, and context-sensitive approach to resolving competing user preferences, this work advances the field of multi-user HRI. It provides a principled alternative to data-driven methods, enabling robots to navigate conflicts in real-world environments.",
    "authors": [
      "Aniol Civit",
      "Antonio Andriella",
      "Carles Sierra",
      "Guillem Alenyà"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "68T40",
      "I.2.9; I.2.4"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03576v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03576v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.03635v1",
    "title": "Towards Transparent Stance Detection: A Zero-Shot Approach Using   Implicit and Explicit Interpretability",
    "summary": "Zero-Shot Stance Detection (ZSSD) identifies the attitude of the post toward unseen targets. Existing research using contrastive, meta-learning, or data augmentation suffers from generalizability issues or lack of coherence between text and target. Recent works leveraging large language models (LLMs) for ZSSD focus either on improving unseen target-specific knowledge or generating explanations for stance analysis. However, most of these works are limited by their over-reliance on explicit reasoning, provide coarse explanations that lack nuance, and do not explicitly model the reasoning process, making it difficult to interpret the model's predictions. To address these issues, in our study, we develop a novel interpretable ZSSD framework, IRIS. We provide an interpretable understanding of the attitude of the input towards the target implicitly based on sequences within the text (implicit rationales) and explicitly based on linguistic measures (explicit rationales). IRIS considers stance detection as an information retrieval ranking task, understanding the relevance of implicit rationales for different stances to guide the model towards correct predictions without requiring the ground-truth of rationales, thus providing inherent interpretability. In addition, explicit rationales based on communicative features help decode the emotional and cognitive dimensions of stance, offering an interpretable understanding of the author's attitude towards the given target. Extensive experiments on the benchmark datasets of VAST, EZ-STANCE, P-Stance, and RFD using 50%, 30%, and even 10% training data prove the generalizability of our model, benefiting from the proposed architecture and interpretable design.",
    "authors": [
      "Apoorva Upadhyaya",
      "Wolfgang Nejdl",
      "Marco Fisichella"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03635v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03635v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.03548v1",
    "title": "Flat Minima and Generalization: Insights from Stochastic Convex   Optimization",
    "summary": "Understanding the generalization behavior of learning algorithms is a central goal of learning theory. A recently emerging explanation is that learning algorithms are successful in practice because they converge to flat minima, which have been consistently associated with improved generalization performance. In this work, we study the link between flat minima and generalization in the canonical setting of stochastic convex optimization with a non-negative, $\\beta$-smooth objective. Our first finding is that, even in this fundamental and well-studied setting, flat empirical minima may incur trivial $\\Omega(1)$ population risk while sharp minima generalizes optimally. Then, we show that this poor generalization behavior extends to two natural ''sharpness-aware'' algorithms originally proposed by Foret et al. (2021), designed to bias optimization toward flat solutions: Sharpness-Aware Gradient Descent (SA-GD) and Sharpness-Aware Minimization (SAM). For SA-GD, which performs gradient steps on the maximal loss in a predefined neighborhood, we prove that while it successfully converges to a flat minimum at a fast rate, the population risk of the solution can still be as large as $\\Omega(1)$, indicating that even flat minima found algorithmically using a sharpness-aware gradient method might generalize poorly. For SAM, a computationally efficient approximation of SA-GD based on normalized ascent steps, we show that although it minimizes the empirical loss, it may converge to a sharp minimum and also incur population risk $\\Omega(1)$. Finally, we establish population risk upper bounds for both SA-GD and SAM using algorithmic stability techniques.",
    "authors": [
      "Matan Schliserman",
      "Shira Vansover-Hager",
      "Tomer Koren"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03548v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03548v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.03641v1",
    "title": "Watermarking Large Language Models in Europe: Interpreting the AI Act in   Light of Technology",
    "summary": "To foster trustworthy Artificial Intelligence (AI) within the European Union, the AI Act requires providers to mark and detect the outputs of their general-purpose models. The Article 50 and Recital 133 call for marking methods that are ''sufficiently reliable, interoperable, effective and robust''. Yet, the rapidly evolving and heterogeneous landscape of watermarks for Large Language Models (LLMs) makes it difficult to determine how these four standards can be translated into concrete and measurable evaluations. Our paper addresses this challenge, anchoring the normativity of European requirements in the multiplicity of watermarking techniques. Introducing clear and distinct concepts on LLM watermarking, our contribution is threefold. (1) Watermarking Categorisation: We propose an accessible taxonomy of watermarking methods according to the stage of the LLM lifecycle at which they are applied - before, during, or after training, and during next-token distribution or sampling. (2) Watermarking Evaluation: We interpret the EU AI Act's requirements by mapping each criterion with state-of-the-art evaluations on robustness and detectability of the watermark, and of quality of the LLM. Since interoperability remains largely untheorised in LLM watermarking research, we propose three normative dimensions to frame its assessment. (3) Watermarking Comparison: We compare current watermarking methods for LLMs against the operationalised European criteria and show that no approach yet satisfies all four standards. Encouraged by emerging empirical tests, we recommend further research into watermarking directly embedded within the low-level architecture of LLMs.",
    "authors": [
      "Thomas Souverain"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "68T01, 68727, 68T30, 68T35, 68T37, 68T50"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03641v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03641v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.03616v1",
    "title": "Going Beyond Expert Performance via Deep Implicit Imitation   Reinforcement Learning",
    "summary": "Imitation learning traditionally requires complete state-action demonstrations from optimal or near-optimal experts. These requirements severely limit practical applicability, as many real-world scenarios provide only state observations without corresponding actions and expert performance is often suboptimal. In this paper we introduce a deep implicit imitation reinforcement learning framework that addresses both limitations by combining deep reinforcement learning with implicit imitation learning from observation-only datasets. Our main algorithm, Deep Implicit Imitation Q-Network (DIIQN), employs an action inference mechanism that reconstructs expert actions through online exploration and integrates a dynamic confidence mechanism that adaptively balances expert-guided and self-directed learning. This enables the agent to leverage expert guidance for accelerated training while maintaining capacity to surpass suboptimal expert performance. We further extend our framework with a Heterogeneous Actions DIIQN (HA-DIIQN) algorithm to tackle scenarios where expert and agent possess different action sets, a challenge previously unaddressed in the implicit imitation learning literature. HA-DIIQN introduces an infeasibility detection mechanism and a bridging procedure identifying alternative pathways connecting agent capabilities to expert guidance when direct action replication is impossible. Our experimental results demonstrate that DIIQN achieves up to 130% higher episodic returns compared to standard DQN, while consistently outperforming existing implicit imitation methods that cannot exceed expert performance. In heterogeneous action settings, HA-DIIQN learns up to 64% faster than baselines, leveraging expert datasets unusable by conventional approaches. Extensive parameter sensitivity analysis reveals the framework's robustness across varying dataset sizes and hyperparameter configurations.",
    "authors": [
      "Iason Chrysomallis",
      "Georgios Chalkiadakis"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03616v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03616v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.03570v1",
    "title": "TabGemma: Text-Based Tabular ICL via LLM using Continued Pretraining and   Retrieval",
    "summary": "We study LLMs for tabular prediction with mixed text, numeric, and categorical fields. We introduce TabGemma, a schema-agnostic in-context learner that treats rows as sequences and tackles two practical hurdles when adapting pretrained LLMs for tabular predictions: unstable numeric tokenization and limited context size. We propose to canonicalize numbers via signed scientific notation and continue pretraining of a 12B Gemma 3 model with a target imputation objective using a large-scale real world dataset. For inference, we use a compact n-gram-based retrieval to select informative exemplars that fit within a 128k-token window.   On semantically rich benchmarks, TabGemma establishes a new state of the art on classification across low- and high-data regimes and improves monotonically with more context rows. For regression, it is competitive at small sample sizes but trails conventional approaches as data grows. Our results show that LLMs can be effective tabular in-context learners on highly semantic tasks when paired with dedicated numeric handling and context retrieval, while motivating further advances in numeric modeling and long-context scaling.",
    "authors": [
      "Günther Schindler",
      "Maximilian Schambach",
      "Michael Medek",
      "Sam Thelin"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03570v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03570v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.03708v1",
    "title": "The Adaptivity Barrier in Batched Nonparametric Bandits: Sharp   Characterization of the Price of Unknown Margin",
    "summary": "We study batched nonparametric contextual bandits under a margin condition when the margin parameter $\\alpha$ is unknown. To capture the statistical price of this ignorance, we introduce the regret inflation criterion, defined as the ratio between the regret of an adaptive algorithm and that of an oracle knowing $\\alpha$. We show that the optimal regret inflation grows polynomial with the horizon $T$, with exponent precisely given by the value of a convex optimization problem involving the dimension, smoothness, and batch budget. Moreover, the minimizers of this optimization problem directly prescribe the batch allocation and exploration strategy of a rate-optimal algorithm. Building on this principle, we develop RoBIN (RObust batched algorithm with adaptive BINning), which achieves the optimal regret inflation up to logarithmic factors. These results reveal a new adaptivity barrier: under batching, adaptation to an unknown margin parameter inevitably incurs a polynomial penalty, sharply characterized by a variational problem. Remarkably, this barrier vanishes when the number of batches exceeds $\\log \\log T$; with only a doubly logarithmic number of updates, one can recover the oracle regret rate up to polylogarithmic factors.",
    "authors": [
      "Rong Jiang",
      "Cong Ma"
    ],
    "categories": [
      "math.ST",
      "cs.LG",
      "stat.ML",
      "stat.TH"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03708v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03708v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.03634v1",
    "title": "nanoTabPFN: A Lightweight and Educational Reimplementation of TabPFN",
    "summary": "Tabular foundation models such as TabPFN have revolutionized predictive machine learning for tabular data. At the same time, the driving factors of this revolution are hard to understand. Existing open-source tabular foundation models are implemented in complicated pipelines boasting over 10,000 lines of code, lack architecture documentation or code quality. In short, the implementations are hard to understand, not beginner-friendly, and complicated to adapt for new experiments. We introduce nanoTabPFN, a simplified and lightweight implementation of the TabPFN v2 architecture and a corresponding training loop that uses pre-generated training data. nanoTabPFN makes tabular foundation models more accessible to students and researchers alike. For example, restricted to a small data setting it achieves a performance comparable to traditional machine learning baselines within one minute of pre-training on a single GPU (160,000x faster than TabPFN v2 pretraining). This eliminated requirement of large computational resources makes pre-training tabular foundation models accessible for educational purposes. Our code is available at https://github.com/automl/nanoTabPFN.",
    "authors": [
      "Alexander Pfefferle",
      "Johannes Hog",
      "Lennart Purucker",
      "Frank Hutter"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03634v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03634v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.03601v1",
    "title": "Step-Audio-EditX Technical Report",
    "summary": "We present Step-Audio-EditX, the first open-source LLM-based audio model excelling at expressive and iterative audio editing encompassing emotion, speaking style, and paralinguistics alongside robust zero-shot text-to-speech (TTS) capabilities.Our core innovation lies in leveraging only large-margin synthetic data, which circumvents the need for embedding-based priors or auxiliary modules. This large-margin learning approach enables both iterative control and high expressivity across voices, and represents a fundamental pivot from the conventional focus on representation-level disentanglement. Evaluation results demonstrate that Step-Audio-EditX surpasses both MiniMax-2.6-hd and Doubao-Seed-TTS-2.0 in emotion editing and other fine-grained control tasks.",
    "authors": [
      "Chao Yan",
      "Boyong Wu",
      "Peng Yang",
      "Pengfei Tan",
      "Guoqiang Hu",
      "Yuxin Zhang",
      " Xiangyu",
      " Zhang",
      "Fei Tian",
      "Xuerui Yang",
      "Xiangyu Zhang",
      "Daxin Jiang",
      "Gang Yu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.SD",
      "eess.AS"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03601v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03601v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.03586v1",
    "title": "PerfDojo: Automated ML Library Generation for Heterogeneous   Architectures",
    "summary": "The increasing complexity of machine learning models and the proliferation of diverse hardware architectures (CPUs, GPUs, accelerators) make achieving optimal performance a significant challenge. Heterogeneity in instruction sets, specialized kernel requirements for different data types and model features (e.g., sparsity, quantization), and architecture-specific optimizations complicate performance tuning. Manual optimization is resource-intensive, while existing automatic approaches often rely on complex hardware-specific heuristics and uninterpretable intermediate representations, hindering performance portability. We introduce PerfLLM, a novel automatic optimization methodology leveraging Large Language Models (LLMs) and Reinforcement Learning (RL). Central to this is PerfDojo, an environment framing optimization as an RL game using a human-readable, mathematically-inspired code representation that guarantees semantic validity through transformations. This allows effective optimization without prior hardware knowledge, facilitating both human analysis and RL agent training. We demonstrate PerfLLM's ability to achieve significant performance gains across diverse CPU (x86, Arm, RISC-V) and GPU architectures.",
    "authors": [
      "Andrei Ivanov",
      "Siyuan Shen",
      "Gioele Gottardo",
      "Marcin Chrapek",
      "Afif Boudaoud",
      "Timo Schneider",
      "Luca Benini",
      "Torsten Hoefler"
    ],
    "categories": [
      "cs.PF",
      "cs.AI"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03586v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03586v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.03565v1",
    "title": "Imitation Learning in the Deep Learning Era: A Novel Taxonomy and Recent   Advances",
    "summary": "Imitation learning (IL) enables agents to acquire skills by observing and replicating the behavior of one or multiple experts. In recent years, advances in deep learning have significantly expanded the capabilities and scalability of imitation learning across a range of domains, where expert data can range from full state-action trajectories to partial observations or unlabeled sequences. Alongside this growth, novel approaches have emerged, with new methodologies being developed to address longstanding challenges such as generalization, covariate shift, and demonstration quality. In this survey, we review the latest advances in imitation learning research, highlighting recent trends, methodological innovations, and practical applications. We propose a novel taxonomy that is distinct from existing categorizations to better reflect the current state of the IL research stratum and its trends. Throughout the survey, we critically examine the strengths, limitations, and evaluation practices of representative works, and we outline key challenges and open directions for future research.",
    "authors": [
      "Iason Chrysomallis",
      "Georgios Chalkiadakis"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03565v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03565v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.03563v1",
    "title": "ASVRI-Legal: Fine-Tuning LLMs with Retrieval Augmented Generation for   Enhanced Legal Regulation",
    "summary": "In this study, we explore the fine-tuning of Large Language Models (LLMs) to better support policymakers in their crucial work of understanding, analyzing, and crafting legal regulations. To equip the model with a deep understanding of legal texts, we curated a supervised dataset tailored to the specific needs of the legal domain. Additionally, we integrated the Retrieval-Augmented Generation (RAG) method, enabling the LLM to access and incorporate up-to-date legal knowledge from external sources. This combination of fine-tuning and RAG-based augmentation results in a tool that not only processes legal information but actively assists policymakers in interpreting regulations and drafting new ones that align with current needs. The results demonstrate that this approach can significantly enhance the effectiveness of legal research and regulation development, offering a valuable resource in the ever-evolving field of law.",
    "authors": [
      "One Octadion",
      "Bondan Sapta Prakoso",
      "Nanang Yudi Setiawan",
      "Novanto Yudistira"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03563v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03563v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.03661v1",
    "title": "SHIELD: Securing Healthcare IoT with Efficient Machine Learning   Techniques for Anomaly Detection",
    "summary": "The integration of IoT devices in healthcare introduces significant security and reliability challenges, increasing susceptibility to cyber threats and operational anomalies. This study proposes a machine learning-driven framework for (1) detecting malicious cyberattacks and (2) identifying faulty device anomalies, leveraging a dataset of 200,000 records. Eight machine learning models are evaluated across three learning approaches: supervised learning (XGBoost, K-Nearest Neighbors (K- NN)), semi-supervised learning (Generative Adversarial Networks (GAN), Variational Autoencoders (VAE)), and unsupervised learning (One-Class Support Vector Machine (SVM), Isolation Forest, Graph Neural Networks (GNN), and Long Short-Term Memory (LSTM) Autoencoders). The comprehensive evaluation was conducted across multiple metrics like F1-score, precision, recall, accuracy, ROC-AUC, computational efficiency. XGBoost achieved 99\\% accuracy with minimal computational overhead (0.04s) for anomaly detection, while Isolation Forest balanced precision and recall effectively. LSTM Autoencoders underperformed with lower accuracy and higher latency. For attack detection, KNN achieved near-perfect precision, recall, and F1-score with the lowest computational cost (0.05s), followed by VAE at 97% accuracy. GAN showed the highest computational cost with lowest accuracy and ROC-AUC. These findings enhance IoT-enabled healthcare security through effective anomaly detection strategies. By improving early detection of cyber threats and device failures, this framework has the potential to prevent data breaches, minimize system downtime, and ensure the continuous and safe operation of medical devices, ultimately safeguarding patient health and trust in IoT-driven healthcare solutions.",
    "authors": [
      "Mahek Desai",
      "Apoorva Rumale",
      "Marjan Asadinia"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03661v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03661v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.03571v1",
    "title": "OneOcc: Semantic Occupancy Prediction for Legged Robots with a Single   Panoramic Camera",
    "summary": "Robust 3D semantic occupancy is crucial for legged/humanoid robots, yet most semantic scene completion (SSC) systems target wheeled platforms with forward-facing sensors. We present OneOcc, a vision-only panoramic SSC framework designed for gait-introduced body jitter and 360{\\deg} continuity. OneOcc combines: (i) Dual-Projection fusion (DP-ER) to exploit the annular panorama and its equirectangular unfolding, preserving 360{\\deg} continuity and grid alignment; (ii) Bi-Grid Voxelization (BGV) to reason in Cartesian and cylindrical-polar spaces, reducing discretization bias and sharpening free/occupied boundaries; (iii) a lightweight decoder with Hierarchical AMoE-3D for dynamic multi-scale fusion and better long-range/occlusion reasoning; and (iv) plug-and-play Gait Displacement Compensation (GDC) learning feature-level motion correction without extra sensors. We also release two panoramic occupancy benchmarks: QuadOcc (real quadruped, first-person 360{\\deg}) and Human360Occ (H3O) (CARLA human-ego 360{\\deg} with RGB, Depth, semantic occupancy; standardized within-/cross-city splits). OneOcc sets new state-of-the-art (SOTA): on QuadOcc it beats strong vision baselines and popular LiDAR ones; on H3O it gains +3.83 mIoU (within-city) and +8.08 (cross-city). Modules are lightweight, enabling deployable full-surround perception for legged/humanoid robots. Datasets and code will be publicly available at https://github.com/MasterHow/OneOcc.",
    "authors": [
      "Hao Shi",
      "Ze Wang",
      "Shangwei Guo",
      "Mengfei Duan",
      "Song Wang",
      "Teng Chen",
      "Kailun Yang",
      "Lin Wang",
      "Kaiwei Wang"
    ],
    "categories": [
      "cs.RO",
      "cs.CV",
      "eess.IV"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03571v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03571v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.03685v1",
    "title": "Structured Matrix Scaling for Multi-Class Calibration",
    "summary": "Post-hoc recalibration methods are widely used to ensure that classifiers provide faithful probability estimates. We argue that parametric recalibration functions based on logistic regression can be motivated from a simple theoretical setting for both binary and multiclass classification. This insight motivates the use of more expressive calibration methods beyond standard temperature scaling. For multi-class calibration however, a key challenge lies in the increasing number of parameters introduced by more complex models, often coupled with limited calibration data, which can lead to overfitting. Through extensive experiments, we demonstrate that the resulting bias-variance tradeoff can be effectively managed by structured regularization, robust preprocessing and efficient optimization. The resulting methods lead to substantial gains over existing logistic-based calibration techniques. We provide efficient and easy-to-use open-source implementations of our methods, making them an attractive alternative to common temperature, vector, and matrix scaling implementations.",
    "authors": [
      "Eugène Berta",
      "David Holzmüller",
      "Michael I. Jordan",
      "Francis Bach"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03685v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03685v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.03666v1",
    "title": "Part-Aware Bottom-Up Group Reasoning for Fine-Grained Social Interaction   Detection",
    "summary": "Social interactions often emerge from subtle, fine-grained cues such as facial expressions, gaze, and gestures. However, existing methods for social interaction detection overlook such nuanced cues and primarily rely on holistic representations of individuals. Moreover, they directly detect social groups without explicitly modeling the underlying interactions between individuals. These drawbacks limit their ability to capture localized social signals and introduce ambiguity when group configurations should be inferred from social interactions grounded in nuanced cues. In this work, we propose a part-aware bottom-up group reasoning framework for fine-grained social interaction detection. The proposed method infers social groups and their interactions using body part features and their interpersonal relations. Our model first detects individuals and enhances their features using part-aware cues, and then infers group configuration by associating individuals via similarity-based reasoning, which considers not only spatial relations but also subtle social cues that signal interactions, leading to more accurate group inference. Experiments on the NVI dataset demonstrate that our method outperforms prior methods, achieving the new state of the art.",
    "authors": [
      "Dongkeun Kim",
      "Minsu Cho",
      "Suha Kwak"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03666v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03666v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.03632v1",
    "title": "Neural Beamforming with Doppler-Aware Sparse Attention for High Mobility   Environments",
    "summary": "Beamforming has significance for enhancing spectral efficiency and mitigating interference in multi-antenna wireless systems, facilitating spatial multiplexing and diversity in dense and high mobility scenarios. Traditional beamforming techniques such as zero-forcing beamforming (ZFBF) and minimum mean square error (MMSE) beamforming experience performance deterioration under adverse channel conditions. Deep learning-based beamforming offers an alternative with nonlinear mappings from channel state information (CSI) to beamforming weights by improving robustness against dynamic channel environments. Transformer-based models are particularly effective due to their ability to model long-range dependencies across time and frequency. However, their quadratic attention complexity limits scalability in large OFDM grids. Recent studies address this issue through sparse attention mechanisms that reduce complexity while maintaining expressiveness, yet often employ patterns that disregard channel dynamics, as they are not specifically designed for wireless communication scenarios. In this work, we propose a Doppler-aware Sparse Neural Network Beamforming (Doppler-aware Sparse NNBF) model that incorporates a channel-adaptive sparse attention mechanism in a multi-user single-input multiple-output (MU-SIMO) setting. The proposed sparsity structure is configurable along 2D time-frequency axes based on channel dynamics and is theoretically proven to ensure full connectivity within p hops, where p is the number of attention heads. Simulation results under urban macro (UMa) channel conditions show that Doppler-aware Sparse NNBF significantly outperforms both a fixed-pattern baseline, referred to as Standard Sparse NNBF, and conventional beamforming techniques ZFBF and MMSE beamforming in high mobility scenarios, while maintaining structured sparsity with a controlled number of attended keys per query.",
    "authors": [
      "Cemil Vahapoglu",
      "Timothy J. O'Shea",
      "Wan Liu",
      "Sennur Ulukus"
    ],
    "categories": [
      "cs.IT",
      "cs.LG",
      "eess.SP",
      "math.IT"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03632v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03632v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.03620v1",
    "title": "CLAX: Fast and Flexible Neural Click Models in JAX",
    "summary": "CLAX is a JAX-based library that implements classic click models using modern gradient-based optimization. While neural click models have emerged over the past decade, complex click models based on probabilistic graphical models (PGMs) have not systematically adopted gradient-based optimization, preventing practitioners from leveraging modern deep learning frameworks while preserving the interpretability of classic models. CLAX addresses this gap by replacing EM-based optimization with direct gradient-based optimization in a numerically stable manner. The framework's modular design enables the integration of any component, from embeddings and deep networks to custom modules, into classic click models for end-to-end optimization. We demonstrate CLAX's efficiency by running experiments on the full Baidu-ULTR dataset comprising over a billion user sessions in $\\approx$ 2 hours on a single GPU, orders of magnitude faster than traditional EM approaches. CLAX implements ten classic click models, serving both industry practitioners seeking to understand user behavior and improve ranking performance at scale and researchers developing new click models. CLAX is available at: https://github.com/philipphager/clax",
    "authors": [
      "Philipp Hager",
      "Onno Zoeter",
      "Maarten de Rijke"
    ],
    "categories": [
      "cs.IR",
      "cs.LG",
      "cs.SE"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03620v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03620v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.03549v1",
    "title": "Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code   Understanding",
    "summary": "Understanding the purpose of source code is a critical task in software maintenance, onboarding, and modernization. While large language models (LLMs) have shown promise in generating code explanations, they often lack grounding in the broader software engineering context. We propose a novel approach that leverages natural language artifacts from GitHub -- such as pull request descriptions, issue descriptions and discussions, and commit messages -- to enhance LLM-based code understanding. Our system consists of three components: one that extracts and structures relevant GitHub context, another that uses this context to generate high-level explanations of the code's purpose, and a third that validates the explanation. We implemented this as a standalone tool, as well as a server within the Model Context Protocol (MCP), enabling integration with other AI-assisted development tools. Our main use case is that of enhancing a standard LLM-based code explanation with code insights that our system generates. To evaluate explanations' quality, we conducted a small scale user study, with developers of several open projects, as well as developers of proprietary projects. Our user study indicates that when insights are generated they often are helpful and non trivial, and are free from hallucinations.",
    "authors": [
      "Ziv Nevo",
      "Orna Raz",
      "Karen Yorav"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03549v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03549v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.03628v1",
    "title": "LiveTradeBench: Seeking Real-World Alpha with Large Language Models",
    "summary": "Large language models (LLMs) achieve strong performance across benchmarks--from knowledge quizzes and math reasoning to web-agent tasks--but these tests occur in static settings, lacking real dynamics and uncertainty. Consequently, they evaluate isolated reasoning or problem-solving rather than decision-making under uncertainty. To address this, we introduce LiveTradeBench, a live trading environment for evaluating LLM agents in realistic and evolving markets. LiveTradeBench follows three design principles: (i) Live data streaming of market prices and news, eliminating dependence on offline backtesting and preventing information leakage while capturing real-time uncertainty; (ii) a portfolio-management abstraction that extends control from single-asset actions to multi-asset allocation, integrating risk management and cross-asset reasoning; and (iii) multi-market evaluation across structurally distinct environments--U.S. stocks and Polymarket prediction markets--differing in volatility, liquidity, and information flow. At each step, an agent observes prices, news, and its portfolio, then outputs percentage allocations that balance risk and return. Using LiveTradeBench, we run 50-day live evaluations of 21 LLMs across families. Results show that (1) high LMArena scores do not imply superior trading outcomes; (2) models display distinct portfolio styles reflecting risk appetite and reasoning dynamics; and (3) some LLMs effectively leverage live signals to adapt decisions. These findings expose a gap between static evaluation and real-world competence, motivating benchmarks that test sequential decision making and consistency under live uncertainty.",
    "authors": [
      "Haofei Yu",
      "Fenghai Li",
      "Jiaxuan You"
    ],
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "cs.CE",
      "cs.CL"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03628v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03628v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.03656v1",
    "title": "ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained   Evaluation",
    "summary": "With the rapid advancement of natural language processing (NLP) technologies, the demand for high-quality Chinese document question-answering datasets is steadily growing. To address this issue, we present the Chinese Multi-Document Question Answering Dataset(ChiMDQA), specifically designed for downstream business scenarios across prevalent domains including academic, education, finance, law, medical treatment, and news. ChiMDQA encompasses long-form documents from six distinct fields, consisting of 6,068 rigorously curated, high-quality question-answer (QA) pairs further classified into ten fine-grained categories. Through meticulous document screening and a systematic question-design methodology, the dataset guarantees both diversity and high quality, rendering it applicable to various NLP tasks such as document comprehension, knowledge extraction, and intelligent QA systems. Additionally, this paper offers a comprehensive overview of the dataset's design objectives, construction methodologies, and fine-grained evaluation system, supplying a substantial foundation for future research and practical applications in Chinese QA. The code and data are available at: https://anonymous.4open.science/r/Foxit-CHiMDQA/.",
    "authors": [
      "Jing Gao",
      "Shutiao Luo",
      "Yumeng Liu",
      "Yuanming Li",
      "Hongji Zeng"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03656v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03656v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.03653v1",
    "title": "Efficient Testing Implies Structured Symmetry",
    "summary": "Given a small random sample of $n$-bit strings labeled by an unknown Boolean function, which properties of this function can be tested computationally efficiently? We show an equivalence between properties that are efficiently testable from few samples and properties with structured symmetry, which depend only on the function's average values on parts of a low-complexity partition of the domain. Without the efficiency constraint, a similar characterization in terms of unstructured symmetry was obtained by Blais and Yoshida (2019). Our main technical tool is supersimulation, which builds on methods from the algorithmic fairness literature to approximate arbitrarily complex functions by small-circuit simulators that fool significantly larger distinguishers.   We extend the characterization along other axes as well. We show that allowing parts to overlap exponentially reduces their required number, broadening the scope of the construction from properties testable with $O(\\log n)$ samples to properties testable with $O(n)$ samples. For larger sample sizes, we show that any efficient tester is essentially checking for indistinguishability from a bounded collection of small circuits, in the spirit of a characterization of testable graph properties. Finally, we show that our results for Boolean function testing generalize to high-entropy distribution testing on arbitrary domains.",
    "authors": [
      "Cynthia Dwork",
      "Pranay Tankala"
    ],
    "categories": [
      "cs.CC",
      "cs.DS",
      "cs.LG"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03653v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03653v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.03710v1",
    "title": "Shrinking the Variance: Shrinkage Baselines for Reinforcement Learning   with Verifiable Rewards",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a powerful paradigm for post-training large reasoning models (LRMs) using policy-gradient methods such as GRPO. To stabilize training, these methods typically center trajectory rewards by subtracting the empirical mean for each prompt. Statistically, this centering acts as a control variate (or baseline), reducing the variance of the policy-gradient estimator.   Typically, the mean reward is estimated using per-prompt empirical averages for each prompt in a batch. Drawing inspiration from Stein's paradox, we propose using shrinkage estimators that combine per-prompt and across-prompt means to improve the overall per-prompt mean estimation accuracy -- particularly in the low-generation regime typical of RLVR. Theoretically, we construct a shrinkage-based baseline that provably yields lower-variance policy-gradient estimators across algorithms. Our proposed baseline serves as a drop-in replacement for existing per-prompt mean baselines, requiring no additional hyper-parameters or computation. Empirically, shrinkage baselines consistently outperform standard empirical-mean baselines, leading to lower-variance gradient updates and improved training stability.",
    "authors": [
      "Guanning Zeng",
      "Zhaoyi Zhou",
      "Daman Arora",
      "Andrea Zanette"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03710v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03710v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.03667v1",
    "title": "Addressing prior dependence in hierarchical Bayesian modeling for PTA   data analysis I: Methodology and implementation",
    "summary": "Complex inference tasks, such as those encountered in Pulsar Timing Array (PTA) data analysis, rely on Bayesian frameworks. The high-dimensional parameter space and the strong interdependencies among astrophysical, pulsar noise, and nuisance parameters introduce significant challenges for efficient learning and robust inference. These challenges are emblematic of broader issues in decision science, where model over-parameterization and prior sensitivity can compromise both computational tractability and the reliability of the results. We address these issues in the framework of hierarchical Bayesian modeling by introducing a reparameterization strategy. Our approach employs Normalizing Flows (NFs) to decorrelate the parameters governing hierarchical priors from those of astrophysical interest. The use of NF-based mappings provides both the flexibility to realize the reparametrization and the tractability to preserve proper probability densities. We further adopt i-nessai, a flow-guided nested sampler, to accelerate exploration of complex posteriors. This unified use of NFs improves statistical robustness and computational efficiency, providing a principled methodology for addressing hierarchical Bayesian inference in PTA analysis.",
    "authors": [
      "Luigi D'amico",
      "Eleonora Villa",
      "Fatima Modica Bittordo",
      "Aldo Barca",
      "Francesco Alì",
      "Massimo Meneghetti",
      "Luca Naso"
    ],
    "categories": [
      "astro-ph.IM",
      "astro-ph.CO",
      "astro-ph.HE",
      "stat.ML"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03667v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03667v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.03617v1",
    "title": "Visualization Biases MLLM's Decision Making in Network Data Tasks",
    "summary": "We evaluate how visualizations can influence the judgment of MLLMs about the presence or absence of bridges in a network. We show that the inclusion of visualization improves confidence over a structured text-based input that could theoretically be helpful for answering the question. On the other hand, we observe that standard visualization techniques create a strong bias towards accepting or refuting the presence of a bridge -- independently of whether or not a bridge actually exists in the network. While our results indicate that the inclusion of visualization techniques can effectively influence the MLLM's judgment without compromising its self-reported confidence, they also imply that practitioners must be careful of allowing users to include visualizations in generative AI applications so as to avoid undesired hallucinations.",
    "authors": [
      "Timo Brand",
      "Henry Förster",
      "Stephen G. Kobourov",
      "Jacob Miller"
    ],
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03617v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03617v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.03554v1",
    "title": "The Structure of Cross-Validation Error: Stability, Covariance, and   Minimax Limits",
    "summary": "Despite ongoing theoretical research on cross-validation (CV), many theoretical questions about CV remain widely open. This motivates our investigation into how properties of algorithm-distribution pairs can affect the choice for the number of folds in $k$-fold cross-validation.   Our results consist of a novel decomposition of the mean-squared error of cross-validation for risk estimation, which explicitly captures the correlations of error estimates across overlapping folds and includes a novel algorithmic stability notion, squared loss stability, that is considerably weaker than the typically required hypothesis stability in other comparable works.   Furthermore, we prove:   1. For every learning algorithm that minimizes empirical error, a minimax lower bound on the mean-squared error of $k$-fold CV estimating the population risk $L_\\mathcal{D}$: \\[ \\min_{k \\mid n}\\; \\max_{\\mathcal{D}}\\; \\mathbb{E}\\!\\left[\\big(\\widehat{L}_{\\mathrm{CV}}^{(k)} - L_{\\mathcal{D}}\\big)^{2}\\right] \\;=\\; \\Omega\\!\\big(\\sqrt{k}/n\\big), \\] where $n$ is the sample size and $k$ the number of folds. This shows that even under idealized conditions, for large values of $k$, CV cannot attain the optimum of order $1/n$ achievable by a validation set of size $n$, reflecting an inherent penalty caused by dependence between folds.   2. Complementing this, we exhibit learning rules for which \\[   \\max_{\\mathcal{D}}\\; \\mathbb{E}\\!\\left[\\big(\\widehat{L}_{\\mathrm{CV}}^{(k)} - L_{\\mathcal{D}}\\big)^{2}\\right] \\;=\\; \\Omega(k/n), \\] matching (up to constants) the accuracy of a hold-out estimator of a single fold of size $n/k$.   Together these results delineate the fundamental trade-off in resampling-based risk estimation: CV cannot fully exploit all $n$ samples for unbiased risk evaluation, and its minimax performance is pinned between the $k/n$ and $\\sqrt{k}/n$ regimes.",
    "authors": [
      "Ido Nachum",
      "Rüdiger Urbanke",
      "Thomas Weinberger"
    ],
    "categories": [
      "math.ST",
      "cs.LG",
      "stat.TH"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03554v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03554v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.03610v1",
    "title": "A systematic review of relation extraction task since the emergence of   Transformers",
    "summary": "This article presents a systematic review of relation extraction (RE) research since the advent of Transformer-based models. Using an automated framework to collect and annotate publications, we analyze 34 surveys, 64 datasets, and 104 models published between 2019 and 2024. The review highlights methodological advances, benchmark resources, and the integration of semantic web technologies. By consolidating results across multiple dimensions, the study identifies current trends, limitations, and open challenges, offering researchers and practitioners a comprehensive reference for understanding the evolution and future directions of RE.",
    "authors": [
      "Ringwald Celian",
      " Gandon",
      " Fabien",
      "Faron Catherine",
      "Michel Franck",
      "Abi Akl Hanna"
    ],
    "categories": [
      "cs.CL",
      "A.1; I.2.4; I.2.7"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03610v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03610v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.03718v1",
    "title": "Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist   Annotation Scheme for MapTask",
    "summary": "Collaborative dialogue relies on participants incrementally establishing common ground, yet in asymmetric settings they may believe they agree while referring to different entities. We introduce a perspectivist annotation scheme for the HCRC MapTask corpus (Anderson et al., 1991) that separately captures speaker and addressee grounded interpretations for each reference expression, enabling us to trace how understanding emerges, diverges, and repairs over time. Using a scheme-constrained LLM annotation pipeline, we obtain 13k annotated reference expressions with reliability estimates and analyze the resulting understanding states. The results show that full misunderstandings are rare once lexical variants are unified, but multiplicity discrepancies systematically induce divergences, revealing how apparent grounding can mask referential misalignment. Our framework provides both a resource and an analytic lens for studying grounded misunderstanding and for evaluating (V)LLMs' capacity to model perspective-dependent grounding in collaborative dialogue.",
    "authors": [
      "Nan Li",
      "Albert Gatt",
      "Massimo Poesio"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03718v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03718v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.03578v1",
    "title": "Learning Under Laws: A Constraint-Projected Neural PDE Solver that   Eliminates Hallucinations",
    "summary": "Neural networks can approximate solutions to partial differential equations, but they often break the very laws they are meant to model-creating mass from nowhere, drifting shocks, or violating conservation and entropy. We address this by training within the laws of physics rather than beside them. Our framework, called Constraint-Projected Learning (CPL), keeps every update physically admissible by projecting network outputs onto the intersection of constraint sets defined by conservation, Rankine-Hugoniot balance, entropy, and positivity. The projection is differentiable and adds only about 10% computational overhead, making it fully compatible with back-propagation. We further stabilize training with total-variation damping (TVD) to suppress small oscillations and a rollout curriculum that enforces consistency over long prediction horizons. Together, these mechanisms eliminate both hard and soft violations: conservation holds at machine precision, total-variation growth vanishes, and entropy and error remain bounded. On Burgers and Euler systems, CPL produces stable, physically lawful solutions without loss of accuracy. Instead of hoping neural solvers will respect physics, CPL makes that behavior an intrinsic property of the learning process.",
    "authors": [
      "Mainak Singha"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03578v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03578v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.03553v1",
    "title": "MultiZebraLogic: A Multilingual Logical Reasoning Benchmark",
    "summary": "Measuring the full abilities of large language models (LLMs) requires benchmarks representing multiple tasks. We aim to create large, high-quality datasets for comparison of logical reasoning skills across several languages and of suitable difficulty for LLMs of various reasoning ability. We explore multiple ways of increasing difficulty. We generate zebra puzzles in multiple languages, themes, sizes and including 14 different clue types and 8 red herring types (uninformative clues). We find puzzle sizes 2x3 and 4x5 are sufficiently challenging for GPT-4o mini (a non-reasoning model) and o3-mini (a reasoning model), respectively. Including 5 red herrings decreases o3-mini puzzle-level accuracy on 4x5 puzzles by 15$\\pm$7 %. Scores of o3-mini on 4x5 puzzles are not significantly affected by use of English vs. Danish or the common houses theme vs. the country-specific smoerrebroed theme. We find no correlation between difficulty and the selected clue types. Datasets of 128+1024 puzzles are published as MultiZebraLogic in each of nine Germanic languages for sizes 2x3 and 4x5. We publish code for puzzle generation, designed for adaptablity into more languages and themes.",
    "authors": [
      "Sofie Helene Bruun",
      "Dan Saattrup Smart"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03553v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03553v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.03675v1",
    "title": "Whisper Leak: a side-channel attack on Large Language Models",
    "summary": "Large Language Models (LLMs) are increasingly deployed in sensitive domains including healthcare, legal services, and confidential communications, where privacy is paramount. This paper introduces Whisper Leak, a side-channel attack that infers user prompt topics from encrypted LLM traffic by analyzing packet size and timing patterns in streaming responses. Despite TLS encryption protecting content, these metadata patterns leak sufficient information to enable topic classification. We demonstrate the attack across 28 popular LLMs from major providers, achieving near-perfect classification (often >98% AUPRC) and high precision even at extreme class imbalance (10,000:1 noise-to-target ratio). For many models, we achieve 100% precision in identifying sensitive topics like \"money laundering\" while recovering 5-20% of target conversations. This industry-wide vulnerability poses significant risks for users under network surveillance by ISPs, governments, or local adversaries. We evaluate three mitigation strategies - random padding, token batching, and packet injection - finding that while each reduces attack effectiveness, none provides complete protection. Through responsible disclosure, we have collaborated with providers to implement initial countermeasures. Our findings underscore the need for LLM providers to address metadata leakage as AI systems handle increasingly sensitive information.",
    "authors": [
      "Geoff McDonald",
      "Jonathan Bar Or"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "K.4.1; C.2.0; K.6.5; I.2.7"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03675v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03675v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.03643v1",
    "title": "Explaining Human Choice Probabilities with Simple Vector Representations",
    "summary": "When people pursue rewards in stochastic environments, they often match their choice frequencies to the observed target frequencies, even when this policy is demonstrably sub-optimal. We used a ``hide and seek'' task to evaluate this behavior under conditions where pursuit (seeking) could be toggled to avoidance (hiding), while leaving the probability distribution fixed, or varying complexity by changing the number of possible choices. We developed a model for participant choice built from choice frequency histograms treated as vectors. We posited the existence of a probability antimatching strategy for avoidance (hiding) rounds, and formalized this as a vector reflection of probability matching. We found that only two basis policies: matching/antimatching and maximizing/minimizing were sufficient to account for participant choices across a range of room numbers and opponent probability distributions. This schema requires only that people have the ability to remember the relative frequency of the different outcomes. With this knowledge simple operations can construct the maximizing and minimizing policies as well as matching and antimatching strategies. A mixture of these two policies captures human choice patterns in a stochastic environment.",
    "authors": [
      "Peter DiBerardino",
      "Britt Anderson"
    ],
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03643v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03643v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.03618v1",
    "title": "Towards Formalizing Reinforcement Learning Theory",
    "summary": "In this paper, we formalize the almost sure convergence of $Q$-learning and linear temporal difference (TD) learning with Markovian samples using the Lean 4 theorem prover based on the Mathlib library. $Q$-learning and linear TD are among the earliest and most influential reinforcement learning (RL) algorithms. The investigation of their convergence properties is not only a major research topic during the early development of the RL field but also receives increasing attention nowadays. This paper formally verifies their almost sure convergence in a unified framework based on the Robbins-Siegmund theorem. The framework developed in this work can be easily extended to convergence rates and other modes of convergence. This work thus makes an important step towards fully formalizing convergent RL results. The code is available at https://github.com/ShangtongZhang/rl-theory-in-lean.",
    "authors": [
      "Shangtong Zhang"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03618v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03618v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.03699v1",
    "title": "Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset   in Large Language Models",
    "summary": "In this paper, we investigate whether Large Language Models (LLMs) exhibit conspiratorial tendencies, whether they display sociodemographic biases in this domain, and how easily they can be conditioned into adopting conspiratorial perspectives. Conspiracy beliefs play a central role in the spread of misinformation and in shaping distrust toward institutions, making them a critical testbed for evaluating the social fidelity of LLMs. LLMs are increasingly used as proxies for studying human behavior, yet little is known about whether they reproduce higher-order psychological constructs such as a conspiratorial mindset. To bridge this research gap, we administer validated psychometric surveys measuring conspiracy mindset to multiple models under different prompting and conditioning strategies. Our findings reveal that LLMs show partial agreement with elements of conspiracy belief, and conditioning with socio-demographic attributes produces uneven effects, exposing latent demographic biases. Moreover, targeted prompts can easily shift model responses toward conspiratorial directions, underscoring both the susceptibility of LLMs to manipulation and the potential risks of their deployment in sensitive contexts. These results highlight the importance of critically evaluating the psychological dimensions embedded in LLMs, both to advance computational social science and to inform possible mitigation strategies against harmful uses.",
    "authors": [
      "Francesco Corso",
      "Francesco Pierri",
      "Gianmarco De Francisci Morales"
    ],
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03699v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03699v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.03636v1",
    "title": "Quantifying Weighted Morphological Content of Large-Scale Structures via   Simulation-Based Inference",
    "summary": "In this work, we perform a simulation-based forecasting analysis to compare the constraining power of two higher-order summary statistics of the large-scale structure (LSS), the Minkowski Functionals (MFs) and the Conditional Moments of Derivative (CMD), with a particular focus on their sensitivity to nonlinear and anisotropic features in redshift-space. Our analysis relies on halo catalogs from the Big Sobol Sequence(BSQ) simulations at redshift $z=0.5$, employing a likelihood-free inference framework implemented via neural posterior estimation. At the fiducial cosmology of the Quijote simulations $(\\Omega_{m}=0.3175,\\,\\sigma_{8}=0.834)$, and for the smoothing scale $R=15\\,h^{-1}$Mpc, we find that the CMD yields tighter forecasts for $(\\Omega_{m}},\\,\\sigma_{8})$ than the zeroth- to third-order MFs components, improving the constraint precision by ${\\sim}(44\\%,\\,52\\%)$, ${\\sim}(30\\%,\\,45\\%)$, ${\\sim}(27\\%,\\,17\\%)$, and ${\\sim}(26\\%,\\,17\\%)$, respectively. A joint configuration combining the MFs and CMD further enhances the precision by approximately ${\\sim}27\\%$ compared to the standard MFs alone, highlighting the complementary anisotropy-sensitive information captured by the CMD in contrast to the scalar morphological content encapsulated by the MFs. We further extend the forecasting analysis to a continuous range of cosmological parameter values and multiple smoothing scales. Our results show that, although the absolute forecast uncertainty for each component of summary statistics depends on the underlying parameter values and the adopted smoothing scale, the relative constraining power among the summary statistics remains nearly constant throughout.",
    "authors": [
      "M. H. Jalali Kanafi",
      "S. M. S. Movahed"
    ],
    "categories": [
      "astro-ph.CO",
      "cs.LG",
      "physics.comp-ph"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03636v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03636v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.03631v1",
    "title": "Financial Management System for SMEs: Real-World Deployment of Accounts   Receivable and Cash Flow Prediction",
    "summary": "Small and Medium Enterprises (SMEs), particularly freelancers and early-stage businesses, face unique financial management challenges due to limited resources, small customer bases, and constrained data availability. This paper presents the development and deployment of an integrated financial prediction system that combines accounts receivable prediction and cash flow forecasting specifically designed for SME operational constraints. Our system addresses the gap between enterprise-focused financial tools and the practical needs of freelancers and small businesses. The solution integrates two key components: a binary classification model for predicting invoice payment delays, and a multi-module cash flow forecasting model that handles incomplete and limited historical data. A prototype system has been implemented and deployed as a web application with integration into Cluee's platform, a startup providing financial management tools for freelancers, demonstrating practical feasibility for real-world SME financial management.",
    "authors": [
      "Bartłomiej Małkus",
      "Szymon Bobek",
      "Grzegorz J. Nalepa"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03631v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03631v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.03606v1",
    "title": "Vector-valued self-normalized concentration inequalities beyond   sub-Gaussianity",
    "summary": "The study of self-normalized processes plays a crucial role in a wide range of applications, from sequential decision-making to econometrics. While the behavior of self-normalized concentration has been widely investigated for scalar-valued processes, vector-valued processes remain comparatively underexplored, especially outside of the sub-Gaussian framework. In this contribution, we provide concentration bounds for self-normalized processes with light tails beyond sub-Gaussianity (such as Bennett or Bernstein bounds). We illustrate the relevance of our results in the context of online linear regression, with applications in (kernelized) linear bandits.",
    "authors": [
      "Diego Martinez-Taboada",
      "Tomas Gonzalez",
      "Aaditya Ramdas"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03606v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03606v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.03725v1",
    "title": "Disentangled Concepts Speak Louder Than Words:Explainable Video Action   Recognition",
    "summary": "Effective explanations of video action recognition models should disentangle how movements unfold over time from the surrounding spatial context. However, existing methods based on saliency produce entangled explanations, making it unclear whether predictions rely on motion or spatial context. Language-based approaches offer structure but often fail to explain motions due to their tacit nature -- intuitively understood but difficult to verbalize. To address these challenges, we propose Disentangled Action aNd Context concept-based Explainable (DANCE) video action recognition, a framework that predicts actions through disentangled concept types: motion dynamics, objects, and scenes. We define motion dynamics concepts as human pose sequences. We employ a large language model to automatically extract object and scene concepts. Built on an ante-hoc concept bottleneck design, DANCE enforces prediction through these concepts. Experiments on four datasets -- KTH, Penn Action, HAA500, and UCF-101 -- demonstrate that DANCE significantly improves explanation clarity with competitive performance. We validate the superior interpretability of DANCE through a user study. Experimental results also show that DANCE is beneficial for model debugging, editing, and failure analysis.",
    "authors": [
      "Jongseo Lee",
      "Wooil Lee",
      "Gyeong-Moon Park",
      "Seong Tae Kim",
      "Jinwoo Choi"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03725v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03725v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2511.03651v1",
    "title": "Flying Robotics Art: ROS-based Drone Draws the Record-Breaking Mural",
    "summary": "This paper presents the innovative design and successful deployment of a pioneering autonomous unmanned aerial system developed for executing the world's largest mural painted by a drone. Addressing the dual challenges of maintaining artistic precision and operational reliability under adverse outdoor conditions such as wind and direct sunlight, our work introduces a robust system capable of navigating and painting outdoors with unprecedented accuracy. Key to our approach is a novel navigation system that combines an infrared (IR) motion capture camera and LiDAR technology, enabling precise location tracking tailored specifically for largescale artistic applications. We employ a unique control architecture that uses different regulation in tangential and normal directions relative to the planned path, enabling precise trajectory tracking and stable line rendering. We also present algorithms for trajectory planning and path optimization, allowing for complex curve drawing and area filling. The system includes a custom-designed paint spraying mechanism, specifically engineered to function effectively amidst the turbulent airflow generated by the drone's propellers, which also protects the drone's critical components from paint-related damage, ensuring longevity and consistent performance. Experimental results demonstrate the system's robustness and precision in varied conditions, showcasing its potential for autonomous large-scale art creation and expanding the functional applications of robotics in creative fields.",
    "authors": [
      "Andrei A. Korigodskii",
      "Oleg D. Kalachev",
      "Artem E. Vasiunik",
      "Matvei V. Urvantsev",
      "Georgii E. Bondar"
    ],
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.SY",
      "eess.SY",
      "I.2.9; J.5"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03651v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03651v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2511.03670v1",
    "title": "DQN Performance with Epsilon Greedy Policies and Prioritized Experience   Replay",
    "summary": "We present a detailed study of Deep Q-Networks in finite environments, emphasizing the impact of epsilon-greedy exploration schedules and prioritized experience replay. Through systematic experimentation, we evaluate how variations in epsilon decay schedules affect learning efficiency, convergence behavior, and reward optimization. We investigate how prioritized experience replay leads to faster convergence and higher returns and show empirical results comparing uniform, no replay, and prioritized strategies across multiple simulations. Our findings illuminate the trade-offs and interactions between exploration strategies and memory management in DQN training, offering practical recommendations for robust reinforcement learning in resource-constrained settings.",
    "authors": [
      "Daniel Perkins",
      "Oscar J. Escobar",
      "Luke Green"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T05"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03670v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03670v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2511.03665v1",
    "title": "A Lightweight 3D-CNN for Event-Based Human Action Recognition with   Privacy-Preserving Potential",
    "summary": "This paper presents a lightweight three-dimensional convolutional neural network (3DCNN) for human activity recognition (HAR) using event-based vision data. Privacy preservation is a key challenge in human monitoring systems, as conventional frame-based cameras capture identifiable personal information. In contrast, event cameras record only changes in pixel intensity, providing an inherently privacy-preserving sensing modality. The proposed network effectively models both spatial and temporal dynamics while maintaining a compact design suitable for edge deployment. To address class imbalance and enhance generalization, focal loss with class reweighting and targeted data augmentation strategies are employed. The model is trained and evaluated on a composite dataset derived from the Toyota Smart Home and ETRI datasets. Experimental results demonstrate an F1-score of 0.9415 and an overall accuracy of 94.17%, outperforming benchmark 3D-CNN architectures such as C3D, ResNet3D, and MC3_18 by up to 3%. These results highlight the potential of event-based deep learning for developing accurate, efficient, and privacy-aware human action recognition systems suitable for real-world edge applications.",
    "authors": [
      "Mehdi Sefidgar Dilmaghani",
      "Francis Fowley",
      "Peter Corcoran"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03665v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03665v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.48
  },
  {
    "arxiv_id": "2511.03645v1",
    "title": "Signal Intensity-weighted coordinate channels improve learning stability   and generalisation in 1D and 2D CNNs in localisation tasks on biomedical   signals",
    "summary": "Localisation tasks in biomedical data often require models to learn meaningful spatial or temporal relationships from signals with complex intensity distributions. A common strategy, exemplified by CoordConv layers, is to append coordinate channels to convolutional inputs, enabling networks to learn absolute positions. In this work, we propose a signal intensity-weighted coordinate representation that replaces the pure coordinate channels with channels scaled by local signal intensity. This modification embeds an intensity-position coupling directly in the input representation, introducing a simple and modality-agnostic inductive bias. We evaluate the approach on two distinct localisation problems: (i) predicting the time of morphological transition in 20-second, two-lead ECG signals, and (ii) regressing the coordinates of nuclear centres in cytological images from the SiPaKMeD dataset. In both cases, the proposed representation yields faster convergence and higher generalisation performance relative to conventional coordinate-channel approaches, demonstrating its effectiveness across both one-dimensional and two-dimensional biomedical signals.",
    "authors": [
      "Vittal L. Rao"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03645v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03645v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.44
  },
  {
    "arxiv_id": "2511.03589v1",
    "title": "Human Mesh Modeling for Anny Body",
    "summary": "Parametric body models are central to many human-centric tasks, yet existing models often rely on costly 3D scans and learned shape spaces that are proprietary and demographically narrow. We introduce Anny, a simple, fully differentiable, and scan-free human body model grounded in anthropometric knowledge from the MakeHuman community. Anny defines a continuous, interpretable shape space, where phenotype parameters (e.g. gender, age, height, weight) control blendshapes spanning a wide range of human forms -- across ages (from infants to elders), body types, and proportions. Calibrated using WHO population statistics, it provides realistic and demographically grounded human shape variation within a single unified model. Thanks to its openness and semantic control, Anny serves as a versatile foundation for 3D human modeling -- supporting millimeter-accurate scan fitting, controlled synthetic data generation, and Human Mesh Recovery (HMR). We further introduce Anny-One, a collection of 800k photorealistic humans generated with Anny, showing that despite its simplicity, HMR models trained with Anny can match the performance of those trained with scan-based body models, while remaining interpretable and broadly representative. The Anny body model and its code are released under the Apache 2.0 license, making Anny an accessible foundation for human-centric 3D modeling.",
    "authors": [
      "Romain Brégier",
      "Guénolé Fiche",
      "Laura Bravo-Sánchez",
      "Thomas Lucas",
      "Matthieu Armando",
      "Philippe Weinzaepfel",
      "Grégory Rogez",
      "Fabien Baradel"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-11-05",
    "url": "https://arxiv.org/abs/2511.03589v1",
    "pdf_url": "https://arxiv.org/pdf/2511.03589v1.pdf",
    "date": "2025-11-06",
    "source": "arxiv",
    "research_score": 0.42
  }
]