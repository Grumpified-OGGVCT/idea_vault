[
  {
    "arxiv_id": "2602.09017v1",
    "title": "Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models",
    "summary": "The prevalent paradigm in robot learning attempts to generalize across environments, embodiments, and tasks with language prompts at runtime. A fundamental tension limits this approach: language is often too abstract to guide the concrete physical understanding required for robust manipulation. In this work, we introduce Contact-Anchored Policies (CAP), which replace language conditioning with points of physical contact in space. Simultaneously, we structure CAP as a library of modular utility models rather than a monolithic generalist policy. This factorization allows us to implement a real-to-sim iteration cycle: we build EgoGym, a lightweight simulation benchmark, to rapidly identify failure modes and refine our models and datasets prior to real-world deployment. We show that by conditioning on contact and iterating via simulation, CAP generalizes to novel environments and embodiments out of the box on three fundamental manipulation skills while using only 23 hours of demonstration data, and outperforms large, state-of-the-art VLAs in zero-shot evaluations by 56%. All model checkpoints, codebase, hardware, simulation, and datasets will be open-sourced. Project page: https://cap-policy.github.io/",
    "authors": [
      "Zichen Jeff Cui",
      "Omar Rayyan",
      "Haritheja Etukuru",
      "Bowen Tan",
      "Zavier Andrianarivo",
      "Zicheng Teng",
      "Yihang Zhou",
      "Krish Mehta",
      "Nicholas Wojno",
      "Kevin Yuanbo Wu",
      "Manan H Anjaria",
      "Ziyuan Wu",
      "Manrong Mao",
      "Guangxun Zhang",
      "Binit Shah",
      "Yejin Kim",
      "Soumith Chintala",
      "Lerrel Pinto",
      "Nur Muhammad Mahi Shafiullah"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09017v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09017v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.92
  },
  {
    "arxiv_id": "2602.08734v1",
    "title": "Finite-State Controllers for (Hidden-Model) POMDPs using Deep Reinforcement Learning",
    "summary": "Solving partially observable Markov decision processes (POMDPs) requires computing policies under imperfect state information. Despite recent advances, the scalability of existing POMDP solvers remains limited. Moreover, many settings require a policy that is robust across multiple POMDPs, further aggravating the scalability issue. We propose the Lexpop framework for POMDP solving. Lexpop (1) employs deep reinforcement learning to train a neural policy, represented by a recurrent neural network, and (2) constructs a finite-state controller mimicking the neural policy through efficient extraction methods. Crucially, unlike neural policies, such controllers can be formally evaluated, providing performance guarantees. We extend Lexpop to compute robust policies for hidden-model POMDPs (HM-POMDPs), which describe finite sets of POMDPs. We associate every extracted controller with its worst-case POMDP. Using a set of such POMDPs, we iteratively train a robust neural policy and consequently extract a robust controller. Our experiments show that on problems with large state spaces, Lexpop outperforms state-of-the-art solvers for POMDPs as well as HM-POMDPs.",
    "authors": [
      "David Hudák",
      "Maris F. L. Galesloot",
      "Martin Tappler",
      "Martin Kurečka",
      "Nils Jansen",
      "Milan Češka"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08734v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08734v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.92
  },
  {
    "arxiv_id": "2602.08948v1",
    "title": "CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute",
    "summary": "Large Language Models (LLMs) often rely on test-time scaling via parallel decoding (for example, 512 samples) to boost reasoning accuracy, but this incurs substantial compute. We introduce CoRefine, a confidence-guided self-refinement method that achieves competitive accuracy using a fraction of the tokens via a lightweight 211k-parameter Conv1D controller atop a frozen LLM. The controller consumes full-trace confidence to decide whether to halt, re-examine, or try a different approach, enabling targeted self-correction with an average of 2.7 refinement steps per problem and roughly 190-fold token reduction relative to 512-sample baselines. Across diverse reasoning benchmarks and three open-source models, the controller achieves 92.6 percent precision when it confidently halts, indicating that confidence dynamics reliably signal correctness without ground-truth verification. We extend this to CoRefine-Tree, a hybrid sequential-parallel variant that adaptively balances exploration and exploitation, with easy serving integration and verifier compatibility. By treating confidence as a control signal rather than a correctness guarantee, CoRefine provides a modular primitive for scalable reasoning and agentic settings with imperfect verifiers.",
    "authors": [
      "Chen Jin",
      "Ryutaro Tanno",
      "Tom Diethe",
      "Philip Teare"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08948v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08948v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.89
  },
  {
    "arxiv_id": "2602.08923v1",
    "title": "DynamiQ: Accelerating Gradient Synchronization using Compressed Multi-hop All-reduce",
    "summary": "Multi-hop all-reduce is the de facto backbone of large model training. As the training scale increases, the network often becomes a bottleneck, motivating reducing the volume of transmitted data. Accordingly, recent systems demonstrated significant acceleration of the training process using gradient quantization. However, these systems are not optimized for multi-hop aggregation, where entries are partially summed multiple times along their aggregation topology.   This paper presents DynamiQ, a quantization framework that bridges the gap between quantization best practices and multi-hop aggregation. DynamiQ introduces novel techniques to better represent partial sums, co-designed with a decompress-accumulate-recompress fused kernel to facilitate fast execution.   We extended PyTorch DDP to support DynamiQ over NCCL P2P, and across different LLMs, tasks, and scales, we demonstrate consistent improvement of up to 34.2% over the best among state-of-the-art methods such as Omni-Reduce, THC, and emerging standards such as MXFP4, MXFP6, and MXFP8. Further, DynamiQ is the only evaluated method that consistently reaches near-baseline accuracy (e.g., 99.9% of the BF16 baseline) and does so while significantly accelerating the training.",
    "authors": [
      "Wenchen Han",
      "Shay Vargaftik",
      "Michael Mitzenmacher",
      "Ran Ben Basat"
    ],
    "categories": [
      "cs.LG",
      "cs.DC",
      "cs.NI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08923v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08923v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.89
  },
  {
    "arxiv_id": "2602.09008v1",
    "title": "ShapeCond: Fast Shapelet-Guided Dataset Condensation for Time Series Classification",
    "summary": "Time series data supports many domains (e.g., finance and climate science), but its rapid growth strains storage and computation. Dataset condensation can alleviate this by synthesizing a compact training set that preserves key information. Yet most condensation methods are image-centric and often fail on time series because they miss time-series-specific temporal structure, especially local discriminative motifs such as shapelets. In this work, we propose ShapeCond, a novel and efficient condensation framework for time series classification that leverages shapelet-based dataset knowledge via a shapelet-guided optimization strategy. Our shapelet-assisted synthesis cost is independent of sequence length: longer series yield larger speedups in synthesis (e.g., 29$\\times$ faster over prior state-of-the-art method CondTSC for time-series condensation, and up to 10,000$\\times$ over naively using shapelets on the Sleep dataset with 3,000 timesteps). By explicitly preserving critical local patterns, ShapeCond improves downstream accuracy and consistently outperforms all prior state-of-the-art time series dataset condensation methods across extensive experiments. Code is available at https://github.com/lunaaa95/ShapeCond.",
    "authors": [
      "Sijia Peng",
      "Yun Xiong",
      "Xi Chen",
      "Yi Xie",
      "Guanzhi Li",
      "Yanwei Yu",
      "Yangyong Zhu",
      "Zhiqiang Shen"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09008v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09008v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2602.08792v1",
    "title": "Multimodal Learning for Arcing Detection in Pantograph-Catenary Systems",
    "summary": "The pantograph-catenary interface is essential for ensuring uninterrupted and reliable power delivery in electrified rail systems. However, electrical arcing at this interface poses serious risks, including accelerated wear of contact components, degraded system performance, and potential service disruptions. Detecting arcing events at the pantograph-catenary interface is challenging due to their transient nature, noisy operating environment, data scarcity, and the difficulty of distinguishing arcs from other similar transient phenomena. To address these challenges, we propose a novel multimodal framework that combines high-resolution image data with force measurements to more accurately and robustly detect arcing events. First, we construct two arcing detection datasets comprising synchronized visual and force measurements. One dataset is built from data provided by the Swiss Federal Railways (SBB), and the other is derived from publicly available videos of arcing events in different railway systems and synthetic force data that mimic the characteristics observed in the real dataset. Leveraging these datasets, we propose MultiDeepSAD, an extension of the DeepSAD algorithm for multiple modalities with a new loss formulation. Additionally, we introduce tailored pseudo-anomaly generation techniques specific to each data type, such as synthetic arc-like artifacts in images and simulated force irregularities, to augment training data and improve the discriminative ability of the model. Through extensive experiments and ablation studies, we demonstrate that our framework significantly outperforms baseline approaches, exhibiting enhanced sensitivity to real arcing events even under domain shifts and limited availability of real arcing observations.",
    "authors": [
      "Hao Dong",
      "Eleni Chatzi",
      "Olga Fink"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08792v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08792v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2602.08603v1",
    "title": "OSCAR: Optimization-Steered Agentic Planning for Composed Image Retrieval",
    "summary": "Composed image retrieval (CIR) requires complex reasoning over heterogeneous visual and textual constraints. Existing approaches largely fall into two paradigms: unified embedding retrieval, which suffers from single-model myopia, and heuristic agentic retrieval, which is limited by suboptimal, trial-and-error orchestration. To this end, we propose OSCAR, an optimization-steered agentic planning framework for composed image retrieval. We are the first to reformulate agentic CIR from a heuristic search process into a principled trajectory optimization problem. Instead of relying on heuristic trial-and-error exploration, OSCAR employs a novel offline-online paradigm. In the offline phase, we model CIR via atomic retrieval selection and composition as a two-stage mixed-integer programming problem, mathematically deriving optimal trajectories that maximize ground-truth coverage for training samples via rigorous boolean set operations. These trajectories are then stored in a golden library to serve as in-context demonstrations for online steering of VLM planner at online inference time. Extensive experiments on three public benchmarks and a private industrial benchmark show that OSCAR consistently outperforms SOTA baselines. Notably, it achieves superior performance using only 10% of training data, demonstrating strong generalization of planning logic rather than dataset-specific memorization.",
    "authors": [
      "Teng Wang",
      "Rong Shan",
      "Jianghao Lin",
      "Junjie Wu",
      "Tianyi Xu",
      "Jianping Zhang",
      "Wenteng Chen",
      "Changwang Zhang",
      "Zhaoxiang Wang",
      "Weinan Zhang",
      "Jun Wang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08603v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08603v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2602.09006v1",
    "title": "ARO: A New Lens On Matrix Optimization For Large Models",
    "summary": "Matrix-based optimizers have attracted growing interest for improving LLM training efficiency, with significant progress centered on orthogonalization/whitening based methods. While yielding substantial performance gains, a fundamental question arises: can we develop new paradigms beyond orthogonalization, pushing the efficiency frontier further? We present \\textbf{Adaptively Rotated Optimization (ARO}, a new matrix optimization framework that treats gradient rotation as a first class design principle. ARO accelerates LLM training by performing normed steepest descent in a rotated coordinate system, where the rotation is determined by a novel norm-informed policy. This perspective yields update rules that go beyond existing orthogonalization and whitening optimizers, improving sample efficiency in practice. To make comparisons reliable, we propose a rigorously controlled benchmarking protocol that reduces confounding and bias. Under this protocol, ARO consistently outperforms AdamW (by 1.3 $\\sim$1.35$\\times$) and orthogonalization methods (by 1.1$\\sim$1.15$\\times$) in LLM pretraining at up to 8B activated parameters, and up to $8\\times$ overtrain budget, without evidence of diminishing returns. Finally, we discuss how ARO can be reformulated as a symmetry-aware optimizer grounded in rotational symmetries of residual streams, motivating advanced designs that enable computationally efficient exploitation of cross-layer/cross module couplings.",
    "authors": [
      "Wenbo Gong",
      "Javier Zazo",
      "Qijun Luo",
      "Puqian Wang",
      "James Hensman",
      "Chao Ma"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09006v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09006v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.77
  },
  {
    "arxiv_id": "2602.09000v1",
    "title": "iGRPO: Self-Feedback-Driven LLM Reasoning",
    "summary": "Large Language Models (LLMs) have shown promise in solving complex mathematical problems, yet they still fall short of producing accurate and consistent solutions. Reinforcement Learning (RL) is a framework for aligning these models with task-specific rewards, improving overall quality and reliability. Group Relative Policy Optimization (GRPO) is an efficient, value-function-free alternative to Proximal Policy Optimization (PPO) that leverages group-relative reward normalization. We introduce Iterative Group Relative Policy Optimization (iGRPO), a two-stage extension of GRPO that adds dynamic self-conditioning through model-generated drafts. In Stage 1, iGRPO samples multiple exploratory drafts and selects the highest-reward draft using the same scalar reward signal used for optimization. In Stage 2, it appends this best draft to the original prompt and applies a GRPO-style update on draft-conditioned refinements, training the policy to improve beyond its strongest prior attempt. Under matched rollout budgets, iGRPO consistently outperforms GRPO across base models (e.g., Nemotron-H-8B-Base-8K and DeepSeek-R1 Distilled), validating its effectiveness on diverse reasoning benchmarks. Moreover, applying iGRPO to OpenReasoning-Nemotron-7B trained on AceReason-Math achieves new state-of-the-art results of 85.62\\% and 79.64\\% on AIME24 and AIME25, respectively. Ablations further show that the refinement wrapper generalizes beyond GRPO variants, benefits from a generative judge, and alters learning dynamics by delaying entropy collapse. These results underscore the potential of iterative, self-feedback-based RL for advancing verifiable mathematical reasoning.",
    "authors": [
      "Ali Hatamizadeh",
      "Shrimai Prabhumoye",
      "Igor Gitman",
      "Ximing Lu",
      "Seungju Han",
      "Wei Ping",
      "Yejin Choi",
      "Jan Kautz"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09000v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09000v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.77
  },
  {
    "arxiv_id": "2602.08961v1",
    "title": "MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE",
    "summary": "We introduce MotionCrafter, a video diffusion-based framework that jointly reconstructs 4D geometry and estimates dense motion from a monocular video. The core of our method is a novel joint representation of dense 3D point maps and 3D scene flows in a shared coordinate system, and a novel 4D VAE to effectively learn this representation. Unlike prior work that forces the 3D value and latents to align strictly with RGB VAE latents-despite their fundamentally different distributions-we show that such alignment is unnecessary and leads to suboptimal performance. Instead, we introduce a new data normalization and VAE training strategy that better transfers diffusion priors and greatly improves reconstruction quality. Extensive experiments across multiple datasets demonstrate that MotionCrafter achieves state-of-the-art performance in both geometry reconstruction and dense scene flow estimation, delivering 38.64% and 25.0% improvements in geometry and motion reconstruction, respectively, all without any post-optimization. Project page: https://ruijiezhu94.github.io/MotionCrafter_Page",
    "authors": [
      "Ruijie Zhu",
      "Jiahao Lu",
      "Wenbo Hu",
      "Xiaoguang Han",
      "Jianfei Cai",
      "Ying Shan",
      "Chuanxia Zheng"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CG",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08961v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08961v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.77
  },
  {
    "arxiv_id": "2602.08690v1",
    "title": "SoK: The Pitfalls of Deep Reinforcement Learning for Cybersecurity",
    "summary": "Deep Reinforcement Learning (DRL) has achieved remarkable success in domains requiring sequential decision-making, motivating its application to cybersecurity problems. However, transitioning DRL from laboratory simulations to bespoke cyber environments can introduce numerous issues. This is further exacerbated by the often adversarial, non-stationary, and partially-observable nature of most cybersecurity tasks. In this paper, we identify and systematize 11 methodological pitfalls that frequently occur in DRL for cybersecurity (DRL4Sec) literature across the stages of environment modeling, agent training, performance evaluation, and system deployment. By analyzing 66 significant DRL4Sec papers (2018-2025), we quantify the prevalence of each pitfall and find an average of over five pitfalls per paper. We demonstrate the practical impact of these pitfalls using controlled experiments in (i) autonomous cyber defense, (ii) adversarial malware creation, and (iii) web security testing environments. Finally, we provide actionable recommendations for each pitfall to support the development of more rigorous and deployable DRL-based security systems.",
    "authors": [
      "Shae McFadden",
      "Myles Foley",
      "Elizabeth Bates",
      "Ilias Tsingenopoulos",
      "Sanyam Vyas",
      "Vasilios Mavroudis",
      "Chris Hicks",
      "Fabio Pierazzi"
    ],
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08690v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08690v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.77
  },
  {
    "arxiv_id": "2602.08586v1",
    "title": "PRISM: A Principled Framework for Multi-Agent Reasoning via Gain Decomposition",
    "summary": "Multi-agent collaboration has emerged as a promising paradigm for enhancing reasoning capabilities of Large Language Models (LLMs). However, existing approaches remain largely heuristic, lacking principled guidance on what drives performance gains and how to systematically optimize multi-agent reasoning. Specifically, it remains unclear why multi-agent collaboration outperforms single-agent reasoning and which design choices contribute most to these gains, making it difficult to build better systems.   We address this gap by introducing a unified theoretical framework that decomposes multi-agent reasoning gains into three conceptually independent dimensions: Exploration for diverse solution coverage, Information for high-fidelity feedback, and Aggregation for principled consensus. Through this lens, existing methods can be understood as special cases that optimize only subsets of these dimensions. Building upon this decomposition, a novel framework called PRISM (Propose-Review-Integrate Synthesis for Multi-agent Reasoning) is proposed, which jointly maximizes all three dimensions through role-based diversity, execution-grounded feedback with evidence-based cross-evaluation, and iterative synthesis with closed-loop validation. Extensive experiments across mathematical reasoning, code generation, and function calling benchmarks demonstrate that PRISM achieves state-of-the-art performance with superior compute-efficiency compared to methods optimizing partial dimensions. The theoretical framework provides actionable design principles for future multi-agent reasoning systems.",
    "authors": [
      "Yiming Yang",
      "Zhuoyuan Li",
      "Fanxiang Zeng",
      "Hao Fu",
      "Yue Liu"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08586v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08586v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.77
  },
  {
    "arxiv_id": "2602.08945v1",
    "title": "GitSearch: Enhancing Community Notes Generation with Gap-Informed Targeted Search",
    "summary": "Community-based moderation offers a scalable alternative to centralized fact-checking, yet it faces significant structural challenges, and existing AI-based methods fail in \"cold start\" scenarios. To tackle these challenges, we introduce GitSearch (Gap-Informed Targeted Search), a framework that treats human-perceived quality gaps, such as missing context, etc., as first-class signals. GitSearch has a three-stage pipeline: identifying information deficits, executing real-time targeted web-retrieval to resolve them, and synthesizing platform-compliant notes. To facilitate evaluation, we present PolBench, a benchmark of 78,698 U.S. political tweets with their associated Community Notes. We find GitSearch achieves 99% coverage, almost doubling coverage over the state-of-the-art. GitSearch surpasses human-authored helpful notes with a 69% win rate and superior helpfulness scores (3.87 vs. 3.36), demonstrating retrieval effectiveness that balanced the trade-off between scale and quality.",
    "authors": [
      "Sahajpreet Singh",
      "Kokil Jaidka",
      "Min-Yen Kan"
    ],
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08945v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08945v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2602.08896v1",
    "title": "OmniReview: A Large-scale Benchmark and LLM-enhanced Framework for Realistic Reviewer Recommendation",
    "summary": "Academic peer review remains the cornerstone of scholarly validation, yet the field faces some challenges in data and methods. From the data perspective, existing research is hindered by the scarcity of large-scale, verified benchmarks and oversimplified evaluation metrics that fail to reflect real-world editorial workflows. To bridge this gap, we present OmniReview, a comprehensive dataset constructed by integrating multi-source academic platforms encompassing comprehensive scholarly profiles through the disambiguation pipeline, yielding 202, 756 verified review records. Based on this data, we introduce a three-tier hierarchical evaluaion framework to assess recommendations from recall to precise expert identification. From the method perspective, existing embedding-based approaches suffer from the information bottleneck of semantic compression and limited interpretability. To resolve these method limitations, we propose Profiling Scholars with Multi-gate Mixture-of-Experts (Pro-MMoE), a novel framework that synergizes Large Language Models (LLMs) with Multi-task Learning. Specifically, it utilizes LLM-generated semantic profiles to preserve fine-grained expertise nuances and interpretability, while employing a Task-Adaptive MMoE architecture to dynamically balance conflicting evaluation goals. Comprehensive experiments demonstrate that Pro-MMoE achieves state-of-the-art performance across six of seven metrics, establishing a new benchmark for realistic reviewer recommendation.",
    "authors": [
      "Yehua Huang",
      "Penglei Sun",
      "Zebin Chen",
      "Zhenheng Tang",
      "Xiaowen Chu"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08896v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08896v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2602.08607v1",
    "title": "VocalNet-MDM: Accelerating Streaming Speech LLM via Self-Distilled Masked Diffusion Modeling",
    "summary": "Recent Speech Large Language Models~(LLMs) have achieved impressive capabilities in end-to-end speech interaction. However, the prevailing autoregressive paradigm imposes strict serial constraints, limiting generation efficiency and introducing exposure bias. In this paper, we investigate Masked Diffusion Modeling~(MDM) as a non-autoregressive paradigm for speech LLMs and introduce VocalNet-MDM. To adapt MDM for streaming speech interaction, we address two critical challenges: training-inference mismatch and iterative overhead. We propose Hierarchical Block-wise Masking to align training objectives with the progressive masked states encountered during block diffusion decoding, and Iterative Self-Distillation to compress multi-step refinement into fewer steps for low-latency inference. Trained on a limited scale of only 6K hours of speech data, VocalNet-MDM achieves a 3.7$\\times$--10$\\times$ decoding speedup and reduces first-chunk latency by 34\\% compared to AR baselines. It maintains competitive recognition accuracy while achieving state-of-the-art text quality and speech naturalness, demonstrating that MDM is a promising and scalable alternative for low-latency, efficient speech LLMs.",
    "authors": [
      "Ziyang Cheng",
      "Yuhao Wang",
      "Heyang Liu",
      "Ronghua Wu",
      "Qunshan Gu",
      "Yanfeng Wang",
      "Yu Wang"
    ],
    "categories": [
      "cs.CL",
      "cs.SD"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08607v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08607v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2602.08882v1",
    "title": "Designing Multi-Robot Ground Video Sensemaking with Public Safety Professionals",
    "summary": "Videos from fleets of ground robots can advance public safety by providing scalable situational awareness and reducing professionals' burden. Yet little is known about how to design and integrate multi-robot videos into public safety workflows. Collaborating with six police agencies, we examined how such videos could be made practical. In Study 1, we presented the first testbed for multi-robot ground video sensemaking. The testbed includes 38 events-of-interest (EoI) relevant to public safety, a dataset of 20 robot patrol videos (10 day/night pairs) covering EoI types, and 6 design requirements aimed at improving current video sensemaking practices. In Study 2, we built MRVS, a tool that augments multi-robot patrol video streams with a prompt-engineered video understanding model. Participants reported reduced manual workload and greater confidence with LLM-based explanations, while noting concerns about false alarms and privacy. We conclude with implications for designing future multi-robot video sensemaking tools. The testbed is available at https://github.com/Puqi7/MRVS\\_VideoSensemaking",
    "authors": [
      "Puqi Zhou",
      "Ali Asgarov",
      "Aafiya Hussain",
      "Wonjoon Park",
      "Amit Paudyal",
      "Sameep Shrestha",
      "Chia-wei Tang",
      "Michael F. Lighthiser",
      "Michael R. Hieb",
      "Xuesu Xiao",
      "Chris Thomas",
      "Sungsoo Ray Hong"
    ],
    "categories": [
      "cs.HC",
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08882v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08882v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2602.08983v1",
    "title": "StretchTime: Adaptive Time Series Forecasting via Symplectic Attention",
    "summary": "Transformer architectures have established strong baselines in time series forecasting, yet they typically rely on positional encodings that assume uniform, index-based temporal progression. However, real-world systems, from shifting financial cycles to elastic biological rhythms, frequently exhibit \"time-warped\" dynamics where the effective flow of time decouples from the sampling index. In this work, we first formalize this misalignment and prove that rotary position embedding (RoPE) is mathematically incapable of representing non-affine temporal warping. To address this, we propose Symplectic Positional Embeddings (SyPE), a learnable encoding framework derived from Hamiltonian mechanics. SyPE strictly generalizes RoPE by extending the rotation group $\\mathrm{SO}(2)$ to the symplectic group $\\mathrm{Sp}(2,\\mathbb{R})$, modulated by a novel input-dependent adaptive warp module. By allowing the attention mechanism to adaptively dilate or contract temporal coordinates end-to-end, our approach captures locally varying periodicities without requiring pre-defined warping functions. We implement this mechanism in StretchTime, a multivariate forecasting architecture that achieves state-of-the-art performance on standard benchmarks, demonstrating superior robustness on datasets exhibiting non-stationary temporal dynamics.",
    "authors": [
      "Yubin Kim",
      "Viresh Pati",
      "Jevon Twitty",
      "Vinh Pham",
      "Shihao Yang",
      "Jiecheng Lu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08983v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08983v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2602.08764v1",
    "title": "Efficient Brain Extraction of MRI Scans with Mild to Moderate Neuropathology",
    "summary": "Skull stripping magnetic resonance images (MRI) of the human brain is an important process in many image processing techniques, such as automatic segmentation of brain structures. Numerous methods have been developed to perform this task, however, they often fail in the presence of neuropathology and can be inconsistent in defining the boundary of the brain mask. Here, we propose a novel approach to skull strip T1-weighted images in a robust and efficient manner, aiming to consistently segment the outer surface of the brain, including the sulcal cerebrospinal fluid (CSF), while excluding the full extent of the subarachnoid space and meninges. We train a modified version of the U-net on silver-standard ground truth data using a novel loss function based on the signed-distance transform (SDT). We validate our model both qualitatively and quantitatively using held-out data from the training dataset, as well as an independent external dataset. The brain masks used for evaluation partially or fully include the subarachnoid space, which may introduce bias into the comparison; nonetheless, our model demonstrates strong performance on the held-out test data, achieving a consistent mean Dice similarity coefficient (DSC) of 0.964$\\pm$0.006 and an average symmetric surface distance (ASSD) of 1.4mm$\\pm$0.2mm. Performance on the external dataset is comparable, with a DSC of 0.958$\\pm$0.006 and an ASSD of 1.7$\\pm$0.2mm. Our method achieves performance comparable to or better than existing state-of-the-art methods for brain extraction, particularly in its highly consistent preservation of the brain's outer surface. The method is publicly available on GitHub.",
    "authors": [
      "Hjalti Thrastarson",
      "Lotta M. Ellingsen"
    ],
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08764v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08764v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2602.08681v1",
    "title": "The Theory and Practice of MAP Inference over Non-Convex Constraints",
    "summary": "In many safety-critical settings, probabilistic ML systems have to make predictions subject to algebraic constraints, e.g., predicting the most likely trajectory that does not cross obstacles.   These real-world constraints are rarely convex, nor the densities considered are (log-)concave.   This makes computing this constrained maximum a posteriori (MAP) prediction efficiently and reliably extremely challenging.   In this paper, we first investigate under which conditions we can perform constrained MAP inference over continuous variables exactly and efficiently and devise a scalable message-passing algorithm for this tractable fragment.   Then, we devise a general constrained MAP strategy that interleaves partitioning the domain into convex feasible regions with numerical constrained optimization.   We evaluate both methods on synthetic and real-world benchmarks, showing our %   approaches outperform constraint-agnostic baselines, and scale to complex densities intractable for SoTA exact solvers.",
    "authors": [
      "Leander Kurscheidt",
      "Gabriele Masina",
      "Roberto Sebastiani",
      "Antonio Vergari"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08681v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08681v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2602.08600v1",
    "title": "Beyond Scalar Scores: Reinforcement Learning for Error-Aware Quality Estimation of Machine Translation",
    "summary": "Quality Estimation (QE) aims to assess the quality of machine translation (MT) outputs without relying on reference translations, making it essential for real-world, large-scale MT evaluation. Large Language Models (LLMs) have shown significant promise in advancing the field of quality estimation of machine translation. However, most of the QE approaches solely rely on scalar quality scores, offering no explicit information about the translation errors that should drive these judgments. Moreover, for low-resource languages where annotated QE data is limited, existing approaches struggle to achieve reliable performance. To address these challenges, we introduce the first segment-level QE dataset for English to Malayalam, a severely resource-scarce language pair in the QE domain, comprising human-annotated Direct Assessment (DA) scores and Translation Quality Remarks (TQR), which are short, contextual, free-form annotator comments that describe translation errors. We further introduce ALOPE-RL, a policy-based reinforcement learning framework that trains efficient adapters based on policy rewards derived from DA score and TQR. Integrating error-aware rewards with ALOPE-RL, enables LLMs to reason about translation quality beyond numeric scores. Despite being trained on a small-scale QE dataset, ALOPE-RL achieves state-of-the-art performance on English to Malayalam QE using compact LLMs (<=4B parameters}) fine-tuned with LoRA and 4-bit quantization, outperforming both larger LLM-based baselines and leading encoder-based QE models. Our results demonstrate that error-aware, policy-based learning can deliver strong QE performance under limited data and compute budgets. We release our dataset, code, and trained models to support future research.",
    "authors": [
      "Archchana Sindhujan",
      "Girish A. Koushik",
      "Shenbin Qian",
      "Diptesh Kanojia",
      "Constantin Orăsan"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08600v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08600v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2602.08584v1",
    "title": "Conditional Sequence Modeling for Safe Reinforcement Learning",
    "summary": "Offline safe reinforcement learning (RL) aims to learn policies from a fixed dataset while maximizing performance under cumulative cost constraints. In practice, deployment requirements often vary across scenarios, necessitating a single policy that can adapt zero-shot to different cost thresholds. However, most existing offline safe RL methods are trained under a pre-specified threshold, yielding policies with limited generalization and deployment flexibility across cost thresholds. Motivated by recent progress in conditional sequence modeling (CSM), which enables flexible goal-conditioned control by specifying target returns, we propose RCDT, a CSM-based method that supports zero-shot deployment across multiple cost thresholds within a single trained policy. RCDT is the first CSM-based offline safe RL algorithm that integrates a Lagrangian-style cost penalty with an auto-adaptive penalty coefficient. To avoid overly conservative behavior and achieve a more favorable return--cost trade-off, a reward--cost-aware trajectory reweighting mechanism and Q-value regularization are further incorporated. Extensive experiments on the DSRL benchmark demonstrate that RCDT consistently improves return--cost trade-offs over representative baselines, advancing the state-of-the-art in offline safe RL.",
    "authors": [
      "Wensong Bai",
      "Chao Zhang",
      "Qihang Xu",
      "Chufan Chen",
      "Chenhao Zhou",
      "Hui Qian"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08584v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08584v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2602.08564v1",
    "title": "M-Loss: Quantifying Model Merging Compatibility with Limited Unlabeled Data",
    "summary": "Training of large-scale models is both computationally intensive and often constrained by the availability of labeled data. Model merging offers a compelling alternative by directly integrating the weights of multiple source models without requiring additional data or extensive training. However, conventional model merging techniques, such as parameter averaging, often suffer from the unintended combination of non-generalizable features, especially when source models exhibit significant weight disparities. Comparatively, model ensembling generally provides more stable and superior performance that aggregates multiple models by averaging outputs. However, it incurs higher inference costs and increased storage requirements. While previous studies experimentally showed the similarities between model merging and ensembling, theoretical evidence and evaluation metrics remain lacking. To address this gap, we introduce Merging-ensembling loss (M-Loss), a novel evaluation metric that quantifies the compatibility of merging source models using very limited unlabeled data. By measuring the discrepancy between parameter averaging and model ensembling at layer and node levels, M-Loss facilitates more effective merging strategies. Specifically, M-Loss serves both as a quantitative criterion of the theoretical feasibility of model merging, and a guide for parameter significance in model pruning. Our theoretical analysis and empirical evaluations demonstrate that incorporating M-Loss into the merging process significantly improves the alignment between merged models and model ensembling, providing a scalable and efficient framework for accurate model consolidation.",
    "authors": [
      "Tiantong Wang",
      "Yiyang Duan",
      "Haoyu Chen",
      "Tiantong Wu",
      "Wei Yang Bryan Lim"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08564v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08564v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2602.09002v1",
    "title": "From Obstacles to Etiquette: Robot Social Navigation with VLM-Informed Path Selection",
    "summary": "Navigating socially in human environments requires more than satisfying geometric constraints, as collision-free paths may still interfere with ongoing activities or conflict with social norms. Addressing this challenge calls for analyzing interactions between agents and incorporating common-sense reasoning into planning. This paper presents a social robot navigation framework that integrates geometric planning with contextual social reasoning. The system first extracts obstacles and human dynamics to generate geometrically feasible candidate paths, then leverages a fine-tuned vision-language model (VLM) to evaluate these paths, informed by contextually grounded social expectations, selecting a socially optimized path for the controller. This task-specific VLM distills social reasoning from large foundation models into a smaller and efficient model, allowing the framework to perform real-time adaptation in diverse human-robot interaction contexts. Experiments in four social navigation contexts demonstrate that our method achieves the best overall performance with the lowest personal space violation duration, the minimal pedestrian-facing time, and no social zone intrusions. Project page: https://path-etiquette.github.io",
    "authors": [
      "Zilin Fang",
      "Anxing Xiao",
      "David Hsu",
      "Gim Hee Lee"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09002v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09002v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2602.08762v1",
    "title": "HoGS: Homophily-Oriented Graph Synthesis for Local Differentially Private GNN Training",
    "summary": "Graph neural networks (GNNs) have demonstrated remarkable performance in various graph-based machine learning tasks by effectively modeling high-order interactions between nodes. However, training GNNs without protection may leak sensitive personal information in graph data, including links and node features. Local differential privacy (LDP) is an advanced technique for protecting data privacy in decentralized networks. Unfortunately, existing local differentially private GNNs either only preserve link privacy or suffer significant utility loss in the process of preserving link and node feature privacy. In this paper, we propose an effective LDP framework, called HoGS, which trains GNNs with link and feature protection by generating a synthetic graph. Concretely, HoGS first collects the link and feature information of the graph under LDP, and then utilizes the phenomenon of homophily in graph data to reconstruct the graph structure and node features separately, thereby effectively mitigating the negative impact of LDP on the downstream GNN training. We theoretically analyze the privacy guarantee of HoGS and conduct experiments using the generated synthetic graph as input to various state-of-the-art GNN architectures. Experimental results on three real-world datasets show that HoGS significantly outperforms baseline methods in the accuracy of training GNNs.",
    "authors": [
      "Wen Xu",
      "Zhetao Li",
      "Yong Xiao",
      "Pengpeng Qiao",
      "Mianxiong Dong",
      "Kaoru Ota"
    ],
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08762v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08762v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2602.08629v1",
    "title": "CauScale: Neural Causal Discovery at Scale",
    "summary": "Causal discovery is essential for advancing data-driven fields such as scientific AI and data analysis, yet existing approaches face significant time- and space-efficiency bottlenecks when scaling to large graphs. To address this challenge, we present CauScale, a neural architecture designed for efficient causal discovery that scales inference to graphs with up to 1000 nodes. CauScale improves time efficiency via a reduction unit that compresses data embeddings and improves space efficiency by adopting tied attention weights to avoid maintaining axis-specific attention maps. To keep high causal discovery accuracy, CauScale adopts a two-stream design: a data stream extracts relational evidence from high-dimensional observations, while a graph stream integrates statistical graph priors and preserves key structural signals. CauScale successfully scales to 500-node graphs during training, where prior work fails due to space limitations. Across testing data with varying graph scales and causal mechanisms, CauScale achieves 99.6% mAP on in-distribution data and 84.4% on out-of-distribution data, while delivering 4-13,000 times inference speedups over prior methods. Our project page is at https://github.com/OpenCausaLab/CauScale.",
    "authors": [
      "Bo Peng",
      "Sirui Chen",
      "Jiaguo Tian",
      "Yu Qiao",
      "Chaochao Lu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08629v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08629v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2602.08597v1",
    "title": "An Attention Mechanism for Robust Multimodal Integration in a Global Workspace Architecture",
    "summary": "Global Workspace Theory (GWT), inspired by cognitive neuroscience, posits that flexible cognition could arise via the attentional selection of a relevant subset of modalities within a multimodal integration system. This cognitive framework can inspire novel computational architectures for multimodal integration. Indeed, recent implementations of GWT have explored its multimodal representation capabilities, but the related attention mechanisms remain understudied. Here, we propose and evaluate a top-down attention mechanism to select modalities inside a global workspace. First, we demonstrate that our attention mechanism improves noise robustness of a global workspace system on two multimodal datasets of increasing complexity: Simple Shapes and MM-IMDb 1.0. Second, we highlight various cross-task and cross-modality generalization capabilities that are not shared by multimodal attention models from the literature. Comparing against existing baselines on the MM-IMDb 1.0 benchmark, we find our attention mechanism makes the global workspace competitive with the state of the art.",
    "authors": [
      "Roland Bertin-Johannet",
      "Lara Scipio",
      "Leopold Maytié",
      "Rufin VanRullen"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08597v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08597v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2602.09003v1",
    "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management",
    "summary": "The development of artificial intelligence can be viewed as an evolution of data-driven learning paradigms, with successive shifts in data organization and utilization continuously driving advances in model capability. Current LLM research is dominated by a paradigm that relies heavily on unidirectional scaling of data size, increasingly encountering bottlenecks in data availability, acquisition cost, and training efficiency. In this work, we argue that the development of AGI is entering a new phase of data-model co-evolution, in which models actively guide data management while high-quality data, in turn, amplifies model capabilities. To implement this vision, we propose a tiered data management framework, designed to support the full LLM training lifecycle across heterogeneous learning objectives and cost constraints. Specifically, we introduce an L0-L4 tiered data management framework, ranging from raw uncurated resources to organized and verifiable knowledge. Importantly, LLMs are fully used in data management processes, such as quality scoring and content editing, to refine data across tiers. Each tier is characterized by distinct data properties, management strategies, and training roles, enabling data to be strategically allocated across LLM training stages, including pre-training, mid-training, and alignment. The framework balances data quality, acquisition cost, and marginal training benefit, providing a systematic approach to scalable and sustainable data management. We validate the effectiveness of the proposed framework through empirical studies, in which tiered datasets are constructed from raw corpora and used across multiple training phases. Experimental results demonstrate that tier-aware data utilization significantly improves training efficiency and model performance. To facilitate further research, we release our tiered datasets and processing tools to the community.",
    "authors": [
      "Yudong Wang",
      "Zixuan Fu",
      "Hengyu Zhao",
      "Chen Zhao",
      "Chuyue Zhou",
      "Xinle Lin",
      "Hongya Lyu",
      "Shuaikang Xue",
      "Yi Yi",
      "Yingjiao Wang",
      "Zhi Zheng",
      "Yuzhou Zhang",
      "Jie Zhou",
      "Chaojun Xiao",
      "Xu Han",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09003v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09003v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2602.08979v1",
    "title": "Beyond Transcripts: A Renewed Perspective on Audio Chaptering",
    "summary": "Audio chaptering, the task of automatically segmenting long-form audio into coherent sections, is increasingly important for navigating podcasts, lectures, and videos. Despite its relevance, research remains limited and text-based, leaving key questions unresolved about leveraging audio information, handling ASR errors, and transcript-free evaluation. We address these gaps through three contributions: (1) a systematic comparison between text-based models with acoustic features, a novel audio-only architecture (AudioSeg) operating on learned audio representations, and multimodal LLMs; (2) empirical analysis of factors affecting performance, including transcript quality, acoustic features, duration, and speaker composition; and (3) formalized evaluation protocols contrasting transcript-dependent text-space protocols with transcript-invariant time-space protocols. Our experiments on YTSeg reveal that AudioSeg substantially outperforms text-based approaches, pauses provide the largest acoustic gains, and MLLMs remain limited by context length and weak instruction following, yet MLLMs are promising on shorter audio.",
    "authors": [
      "Fabian Retkowski",
      "Maike Züfle",
      "Thai Binh Nguyen",
      "Jan Niehues",
      "Alexander Waibel"
    ],
    "categories": [
      "cs.SD",
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08979v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08979v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2602.08901v1",
    "title": "GSS: Gated Subspace Steering for Selective Memorization Mitigation in LLMs",
    "summary": "Large language models (LLMs) can memorize and reproduce training sequences verbatim -- a tendency that undermines both generalization and privacy. Existing mitigation methods apply interventions uniformly, degrading performance on the majority of tokens that generalize normally. We show empirically that memorization is sparse, intermittent, and token-conditioned, suggesting that effective mitigation requires context-aware intervention rather than static parameter modification. To this end, we propose a novel and effective selective memorization mitigation method -- Gated Subspace Steering (GSS), which decomposes intervention into a probe (detecting memorization-relevant activations) and a steer (applying targeted correction only when the probe exceeds a threshold). The optimal probe-steer pair emerges from a principled optimization framework based on optimal subspace steering. Experiments on four benchmarks show GSS matches or exceeds state-of-the-art memorization reduction while requiring $100-1000 \\times$ less compute than optimization-based alternatives. Furthermore, we provide new theoretical insights into the geometry of memorization in neural representations.",
    "authors": [
      "Xuanqi Zhang",
      "Haoyang Shang",
      "Xiaoxiao Li"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08901v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08901v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2602.08775v1",
    "title": "VedicTHG: Symbolic Vedic Computation for Low-Resource Talking-Head Generation in Educational Avatars",
    "summary": "Talking-head avatars are increasingly adopted in educational technology to deliver content with social presence and improved engagement. However, many recent talking-head generation (THG) methods rely on GPU-centric neural rendering, large training sets, or high-capacity diffusion models, which limits deployment in offline or resource-constrained learning environments. A deterministic and CPU-oriented THG framework is described, termed Symbolic Vedic Computation, that converts speech to a time-aligned phoneme stream, maps phonemes to a compact viseme inventory, and produces smooth viseme trajectories through symbolic coarticulation inspired by Vedic sutra Urdhva Tiryakbhyam. A lightweight 2D renderer performs region-of-interest (ROI) warping and mouth compositing with stabilization to support real-time synthesis on commodity CPUs. Experiments report synchronization accuracy, temporal stability, and identity consistency under CPU-only execution, alongside benchmarking against representative CPU-feasible baselines. Results indicate that acceptable lip-sync quality can be achieved while substantially reducing computational load and latency, supporting practical educational avatars on low-end hardware. GitHub: https://vineetkumarrakesh.github.io/vedicthg",
    "authors": [
      "Vineet Kumar Rakesh",
      "Ahana Bhattacharjee",
      "Soumya Mazumdar",
      "Tapas Samanta",
      "Hemendra Kumar Pandey",
      "Amitabha Das",
      "Sarbajit Pal"
    ],
    "categories": [
      "cs.CV",
      "cs.CG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08775v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08775v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2602.08990v1",
    "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery",
    "summary": "We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. The architecture allows InternAgent-1.5 to operate continuously across extended discovery cycles while maintaining coherent and improving behavior. It also enables the system to coordinate computational modeling and laboratory experimentation within a single unified system. We evaluate InternAgent-1.5 on scientific reasoning benchmarks such as GAIA, HLE, GPQA, and FrontierScience, and the system achieves leading performance that demonstrates strong foundational capabilities. Beyond these benchmarks, we further assess two categories of discovery tasks. In algorithm discovery tasks, InternAgent-1.5 autonomously designs competitive methods for core machine learning problems. In empirical discovery tasks, it executes complete computational or wet lab experiments and produces scientific findings in earth, life, biological, and physical domains. Overall, these results show that InternAgent-1.5 provides a general and scalable framework for autonomous scientific discovery.",
    "authors": [
      "Shiyang Feng",
      "Runmin Ma",
      "Xiangchao Yan",
      "Yue Fan",
      "Yusong Hu",
      "Songtao Huang",
      "Shuaiyu Zhang",
      "Zongsheng Cao",
      "Tianshuo Peng",
      "Jiakang Yuan",
      "Zijie Guo",
      "Zhijie Zhong",
      "Shangheng Du",
      "Weida Wang",
      "Jinxin Shi",
      "Yuhao Zhou",
      "Xiaohan He",
      "Zhiyin Yu",
      "Fangchen Yu",
      "Qihao Zheng",
      "Jiamin Wu",
      "Mianxin Liu",
      "Chi Zhang",
      "Shaowei Hou",
      "Shuya Li",
      "Yankai Jiang",
      "Wenjie Lou",
      "Lilong Wang",
      "Zifu Wang",
      "Jiong Wang",
      "Wanghan Xu",
      "Yue Deng",
      "Dongrui Liu",
      "Yiheng Wang",
      "Wenlong Zhang",
      "Fenghua Ling",
      "Shufei Zhang",
      "Xiaosong Wang",
      "Shuangjia Zheng",
      "Xun Huang",
      "Siqi Sun",
      "Shuyue Hu",
      "Peng Ye",
      "Chunfeng Song",
      "Bin Wang",
      "Conghui He",
      "Yihao Liu",
      "Xin Li",
      "Qibin Hou",
      "Tao Chen",
      "Xiangyu Yue",
      "Bin Wang",
      "Liang He",
      "Dahua Lin",
      "Bowen Zhou",
      "Bo Zhang",
      "Lei Bai"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08990v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08990v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2602.08905v1",
    "title": "Efficient and Stable Reinforcement Learning for Diffusion Language Models",
    "summary": "Reinforcement Learning (RL) is crucial for unlocking the complex reasoning capabilities of Diffusion-based Large Language Models (dLLMs). However, applying RL to dLLMs faces unique challenges in efficiency and stability. To address these challenges, we propose Spatio-Temporal Pruning (STP), a framework designed to simultaneously improve the efficiency and stability of RL for dLLMs. STP compresses the redundancy in the generative process through: (1) \\textit{spatial pruning}, which constrains the exploration space using static priors; and (2) \\textit{temporal pruning}, which bypasses redundant late-stage refinement steps. Our theoretical analysis demonstrates that STP strictly reduces the variance of the log-likelihood estimation, thereby ensuring more stable policy updates. Extensive experiments demonstrate that STP surpasses state-of-the-art baselines in both efficiency and accuracy. Our code is available at https://github.com/Lolo1222/STP.",
    "authors": [
      "Jiawei Liu",
      "Xiting Wang",
      "Yuanyuan Zhong",
      "Defu Lian",
      "Yu Yang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08905v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08905v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2602.08716v1",
    "title": "PERSPECTRA: A Scalable and Configurable Pluralist Benchmark of Perspectives from Arguments",
    "summary": "Pluralism, the capacity to engage with diverse perspectives without collapsing them into a single viewpoint, is critical for developing large language models that faithfully reflect human heterogeneity. Yet this characteristic has not been carefully examined in the LLM research community and remains absent from most alignment studies. Debate-oriented sources provide a natural entry point for pluralism research. Previous work builds on online debate sources but remains constrained by costly human validation. Other debate-rich platforms such as Reddit and Kialo also offer promising material: Reddit provides linguistic diversity and scale but lacks clear argumentative structure, while Kialo supplies explicit pro/con graphs but remains overly concise and detached from natural discourse. We introduce PERSPECTRA, a pluralist benchmark that integrates the structural clarity of Kialo debate graphs with the linguistic diversity of real Reddit discussions. Using a controlled retrieval-and-expansion pipeline, we construct 3,810 enriched arguments spanning 762 pro/con stances on 100 controversial topics. Each opinion is expanded to multiple naturalistic variants, enabling robust evaluation of pluralism. We initialise three tasks with PERSPECTRA: opinion counting (identifying distinct viewpoints), opinion matching (aligning supporting stances and discourse to source opinions), and polarity check (inferring aggregate stance in mixed discourse). Experiments with state-of-the-art open-source and proprietary LLMs, highlight systematic failures, such as overestimating the number of viewpoints and misclassifying concessive structures, underscoring the difficulty of pluralism-aware understanding and reasoning. By combining diversity with structure, PERSPECTRA establishes the first scalable, configurable benchmark for evaluating how well models represent, distinguish, and reason over multiple perspectives.",
    "authors": [
      "Shangrui Nie",
      "Kian Omoomi",
      "Lucie Flek",
      "Zhixue Zhao",
      "Charles Welch"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08716v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08716v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2602.08590v1",
    "title": "SDFed: Bridging Local Global Discrepancy via Subspace Refinement and Divergence Control in Federated Prompt Learning",
    "summary": "Vision-language pretrained models offer strong transferable representations, yet adapting them in privacy-sensitive multi-party settings is challenging due to the high communication cost of federated optimization and the limited local data on clients. Federated prompt learning mitigates this issue by keeping the VLPM backbone frozen and collaboratively training lightweight prompt parameters. However, existing approaches typically enforce a unified prompt structure and length across clients, which is inadequate under practical client heterogeneity in both data distributions and system resources, and may further introduce conflicts between globally shared and locally optimal knowledge. To address these challenges, we propose \\textbf{SDFed}, a heterogeneous federated prompt learning framework that bridges Local-Global Discrepancy via Subspace Refinement and Divergence Control. SDFed maintains a fixed-length global prompt for efficient aggregation while allowing each client to learn a variable-length local prompt to better match its data characteristics and capacity. To mitigate local-global conflicts and facilitate effective knowledge transfer, SDFed introduces a subspace refinement method for local prompts and an information retention and divergence control strategy that preserves key local information while maintaining appropriate separability between global and local representations. Extensive experiments on several datasets demonstrate that SDFed consistently improves performance and robustness in heterogeneous federated settings.",
    "authors": [
      "Yicheng Di",
      "Wei Yuan",
      "Tieke He",
      "Zhanjie Zhang",
      "Ao Ma",
      "Yuan Liu",
      "Hongzhi Yin"
    ],
    "categories": [
      "cs.LG",
      "cs.DB"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08590v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08590v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2602.08885v1",
    "title": "Breaking the Simplification Bottleneck in Amortized Neural Symbolic Regression",
    "summary": "Symbolic regression (SR) aims to discover interpretable analytical expressions that accurately describe observed data. Amortized SR promises to be much more efficient than the predominant genetic programming SR methods, but currently struggles to scale to realistic scientific complexity. We find that a key obstacle is the lack of a fast reduction of equivalent expressions to a concise normalized form. Amortized SR has addressed this by general-purpose Computer Algebra Systems (CAS) like SymPy, but the high computational cost severely limits training and inference speed. We propose SimpliPy, a rule-based simplification engine achieving a 100-fold speed-up over SymPy at comparable quality. This enables substantial improvements in amortized SR, including scalability to much larger training sets, more efficient use of the per-expression token budget, and systematic training set decontamination with respect to equivalent test expressions. We demonstrate these advantages in our Flash-ANSR framework, which achieves much better accuracy than amortized baselines (NeSymReS, E2E) on the FastSRB benchmark. Moreover, it performs on par with state-of-the-art direct optimization (PySR) while recovering more concise instead of more complex expressions with increasing inference budget.",
    "authors": [
      "Paul Saegert",
      "Ullrich Köthe"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SC"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08885v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08885v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2602.08878v1",
    "title": "Learning Potentials for Dynamic Matching and Application to Heart Transplantation",
    "summary": "Each year, thousands of patients in need of heart transplants face life-threatening wait times due to organ scarcity. While allocation policies aim to maximize population-level outcomes, current approaches often fail to account for the dynamic arrival of organs and the composition of waitlisted candidates, thereby hampering efficiency. The United States is transitioning from rigid, rule-based allocation to more flexible data-driven models. In this paper, we propose a novel framework for non-myopic policy optimization in general online matching relying on potentials, a concept originally introduced for kidney exchange. We develop scalable and accurate ways of learning potentials that are higher-dimensional and more expressive than prior approaches. Our approach is a form of self-supervised imitation learning: the potentials are trained to mimic an omniscient algorithm that has perfect foresight. We focus on the application of heart transplant allocation and demonstrate, using real historical data, that our policies significantly outperform prior approaches -- including the current US status quo policy and the proposed continuous distribution framework -- in optimizing for population-level outcomes. Our analysis and methods come at a pivotal moment in US policy, as the current heart transplant allocation system is under review. We propose a scalable and theoretically grounded path toward more effective organ allocation.",
    "authors": [
      "Itai Zilberstein",
      "Ioannis Anagnostides",
      "Zachary W. Sollie",
      "Arman Kilic",
      "Tuomas Sandholm"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08878v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08878v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2602.08837v1",
    "title": "AMEM4Rec: Leveraging Cross-User Similarity for Memory Evolution in Agentic LLM Recommenders",
    "summary": "Agentic systems powered by Large Language Models (LLMs) have shown strong potential in recommender systems but remain hindered by several challenges. Fine-tuning LLMs is parameter-inefficient, and prompt-based agentic reasoning is limited by context length and hallucination risk. Moreover, existing agentic recommendation systems predominantly leverages semantic knowledge while neglecting the collaborative filtering (CF) signals essential for implicit preference modeling. To address these limitations, we propose AMEM4Rec, an agentic LLM-based recommender that learns collaborative signals in an end-to-end manner through cross-user memory evolution. AMEM4Rec stores abstract user behavior patterns from user histories in a global memory pool. Within this pool, memories are linked to similar existing ones and iteratively evolved to reinforce shared cross-user patterns, enabling the system to become aware of CF signals without relying on a pre-trained CF model. Extensive experiments on Amazon and MIND datasets show that AMEM4Rec consistently outperforms state-of-the-art LLM-based recommenders, demonstrating the effectiveness of evolving memory-guided collaborative filtering.",
    "authors": [
      "Minh-Duc Nguyen",
      "Hai-Dang Kieu",
      "Dung D. Le"
    ],
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08837v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08837v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2602.08679v1",
    "title": "Dashed Line Defense: Plug-And-Play Defense Against Adaptive Score-Based Query Attacks",
    "summary": "Score-based query attacks pose a serious threat to deep learning models by crafting adversarial examples (AEs) using only black-box access to model output scores, iteratively optimizing inputs based on observed loss values. While recent runtime defenses attempt to disrupt this process via output perturbation, most either require access to model parameters or fail when attackers adapt their tactics. In this paper, we first reveal that even the state-of-the-art plug-and-play defense can be bypassed by adaptive attacks, exposing a critical limitation of existing runtime defenses. We then propose Dashed Line Defense (DLD), a plug-and-play post-processing method specifically designed to withstand adaptive query strategies. By introducing ambiguity in how the observed loss reflects the true adversarial strength of candidate examples, DLD prevents attackers from reliably analyzing and adapting their queries, effectively disrupting the AE generation process. We provide theoretical guarantees of DLD's defense capability and validate its effectiveness through experiments on ImageNet, demonstrating that DLD consistently outperforms prior defenses--even under worst-case adaptive attacks--while preserving the model's predicted labels.",
    "authors": [
      "Yanzhang Fu",
      "Zizheng Guo",
      "Jizhou Luo"
    ],
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08679v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08679v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2602.09022v1",
    "title": "WorldCompass: Reinforcement Learning for Long-Horizon World Models",
    "summary": "This work presents WorldCompass, a novel Reinforcement Learning (RL) post-training framework for the long-horizon, interactive video-based world models, enabling them to explore the world more accurately and consistently based on interaction signals. To effectively \"steer\" the world model's exploration, we introduce three core innovations tailored to the autoregressive video generation paradigm: 1) Clip-level rollout Strategy: We generate and evaluate multiple samples at a single target clip, which significantly boosts rollout efficiency and provides fine-grained reward signals. 2) Complementary Reward Functions: We design reward functions for both interaction-following accuracy and visual quality, which provide direct supervision and effectively suppress reward-hacking behaviors. 3) Efficient RL Algorithm: We employ the negative-aware fine-tuning strategy coupled with various efficiency optimizations to efficiently and effectively enhance model capacity. Evaluations on the SoTA open-source world model, WorldPlay, demonstrate that WorldCompass significantly improves interaction accuracy and visual fidelity across various scenarios.",
    "authors": [
      "Zehan Wang",
      "Tengfei Wang",
      "Haiyu Zhang",
      "Xuhui Zuo",
      "Junta Wu",
      "Haoyuan Wang",
      "Wenqiang Sun",
      "Zhenwei Wang",
      "Chenjie Cao",
      "Hengshuang Zhao",
      "Chunchao Guo",
      "Zhou Zhao"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09022v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09022v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.09018v1",
    "title": "Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving",
    "summary": "Out of distribution (OOD) robustness in autonomous driving is often reduced to a single number, hiding what breaks a policy. We decompose environments along five axes: scene (rural/urban), season, weather, time (day/night), and agent mix; and measure performance under controlled $k$-factor perturbations ($k \\in \\{0,1,2,3\\}$). Using closed loop control in VISTA, we benchmark FC, CNN, and ViT policies, train compact ViT heads on frozen foundation-model (FM) features, and vary ID support in scale, diversity, and temporal context. (1) ViT policies are markedly more OOD-robust than comparably sized CNN/FC, and FM features yield state-of-the-art success at a latency cost. (2) Naive temporal inputs (multi-frame) do not beat the best single-frame baseline. (3) The largest single factor drops are rural $\\rightarrow$ urban and day $\\rightarrow$ night ($\\sim 31\\%$ each); actor swaps $\\sim 10\\%$, moderate rain $\\sim 7\\%$; season shifts can be drastic, and combining a time flip with other changes further degrades performance. (4) FM-feature policies stay above $85\\%$ under three simultaneous changes; non-FM single-frame policies take a large first-shift hit, and all no-FM models fall below $50\\%$ by three changes. (5) Interactions are non-additive: some pairings partially offset, whereas season-time combinations are especially harmful. (6) Training on winter/snow is most robust to single-factor shifts, while a rural+summer baseline gives the best overall OOD performance. (7) Scaling traces/views improves robustness ($+11.8$ points from $5$ to $14$ traces), yet targeted exposure to hard conditions can substitute for scale. (8) Using multiple ID environments broadens coverage and strengthens weak cases (urban OOD $60.6\\% \\rightarrow 70.1\\%$) with a small ID drop; single-ID preserves peak performance but in a narrow domain. These results yield actionable design rules for OOD-robust driving policies.",
    "authors": [
      "Amir Mallak",
      "Alaa Maalouf"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09018v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09018v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.08868v1",
    "title": "AnomSeer: Reinforcing Multimodal LLMs to Reason for Time-Series Anomaly Detection",
    "summary": "Time-series anomaly detection (TSAD) with multimodal large language models (MLLMs) is an emerging area, yet a persistent challenge remains: MLLMs rely on coarse time-series heuristics but struggle with multi-dimensional, detailed reasoning, which is vital for understanding complex time-series data. We present AnomSeer to address this by reinforcing the model to ground its reasoning in precise, structural details of time series, unifying anomaly classification, localization, and explanation. At its core, an expert chain-of-thought trace is generated to provide a verifiable, fine-grained reasoning from classical analyses (e.g., statistical measures, frequency transforms). Building on this, we propose a novel time-series grounded policy optimization (TimerPO) that incorporates two additional components beyond standard reinforcement learning: a time-series grounded advantage based on optimal transport and an orthogonal projection to ensure this auxiliary granular signal does not interfere with the primary detection objective. Across diverse anomaly scenarios, AnomSeer, with Qwen2.5-VL-3B/7B-Instruct, outperforms larger commercial baselines (e.g., GPT-4o) in classification and localization accuracy, particularly on point- and frequency-driven exceptions. Moreover, it produces plausible time-series reasoning traces that support its conclusions.",
    "authors": [
      "Junru Zhang",
      "Lang Feng",
      "Haoran Shi",
      "Xu Guo",
      "Han Yu",
      "Yabo Dong",
      "Duanqing Xu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08868v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08868v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.08709v1",
    "title": "FactSim: Fact-Checking for Opinion Summarization",
    "summary": "We explore the need for more comprehensive and precise evaluation techniques for generative artificial intelligence (GenAI) in text summarization tasks, specifically in the area of opinion summarization. Traditional methods, which leverage automated metrics to compare machine-generated summaries from a collection of opinion pieces, e.g. product reviews, have shown limitations due to the paradigm shift introduced by large language models (LLM). This paper addresses these shortcomings by proposing a novel, fully automated methodology for assessing the factual consistency of such summaries. The method is based on measuring the similarity between the claims in a given summary with those from the original reviews, measuring the coverage and consistency of the generated summary. To do so, we rely on a simple approach to extract factual assessment from texts that we then compare and summarize in a suitable score. We demonstrate that the proposed metric attributes higher scores to similar claims, regardless of whether the claim is negated, paraphrased, or expanded, and that the score has a high correlation to human judgment when compared to state-of-the-art metrics.",
    "authors": [
      "Leandro Anghinoni",
      "Jorge Sanchez"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08709v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08709v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.08646v1",
    "title": "Projected Gradient Ascent for Efficient Reward-Guided Updates with One-Step Generative Models",
    "summary": "We propose a constrained latent optimization method for reward-guided generation that preserves white Gaussian noise characteristics with negligible overhead. Test-time latent optimization can unlock substantially better reward-guided generations from pretrained generative models, but it is prone to reward hacking that degrades quality and also too slow for practical use. In this work, we make test-time optimization both efficient and reliable by replacing soft regularization with hard white Gaussian noise constraints enforced via projected gradient ascent. Our method applies a closed-form projection after each update to keep the latent vector explicitly noise-like throughout optimization, preventing the drift that leads to unrealistic artifacts. This enforcement adds minimal cost: the projection matches the $O(N \\log N)$ complexity of standard algorithms such as sorting or FFT and does not practically increase wall-clock time. In experiments, our approach reaches a comparable Aesthetic Score using only 30% of the wall-clock time required by the SOTA regularization-based method, while preventing reward hacking.",
    "authors": [
      "Jisung Hwang",
      "Minhyuk Sung"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08646v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08646v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.08630v1",
    "title": "Debate is efficient with your time",
    "summary": "AI safety via debate uses two competing models to help a human judge verify complex computational tasks. Previous work has established what problems debate can solve in principle, but has not analysed the practical cost of human oversight: how many queries must the judge make to the debate transcript? We introduce Debate Query Complexity}(DQC), the minimum number of bits a verifier must inspect to correctly decide a debate.   Surprisingly, we find that PSPACE/poly (the class of problems which debate can efficiently decide) is precisely the class of functions decidable with O(log n) queries. This characterisation shows that debate is remarkably query-efficient: even for highly complex problems, logarithmic oversight suffices. We also establish that functions depending on all their input bits require Omega(log n) queries, and that any function computable by a circuit of size s satisfies DQC(f) <= log(s) + 3. Interestingly, this last result implies that proving DQC lower bounds of log(n) + 6 for languages in P would yield new circuit lower bounds, connecting debate query complexity to central questions in circuit complexity.",
    "authors": [
      "Jonah Brown-Cohen",
      "Geoffrey Irving",
      "Simon C. Marshall",
      "Ilan Newman",
      "Georgios Piliouras",
      "Mario Szegedy"
    ],
    "categories": [
      "cs.AI",
      "cs.CC"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08630v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08630v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.09024v1",
    "title": "Autoregressive Image Generation with Masked Bit Modeling",
    "summary": "This paper challenges the dominance of continuous pipelines in visual generation. We systematically investigate the performance gap between discrete and continuous methods. Contrary to the belief that discrete tokenizers are intrinsically inferior, we demonstrate that the disparity arises primarily from the total number of bits allocated in the latent space (i.e., the compression ratio). We show that scaling up the codebook size effectively bridges this gap, allowing discrete tokenizers to match or surpass their continuous counterparts. However, existing discrete generation methods struggle to capitalize on this insight, suffering from performance degradation or prohibitive training costs with scaled codebook. To address this, we propose masked Bit AutoRegressive modeling (BAR), a scalable framework that supports arbitrary codebook sizes. By equipping an autoregressive transformer with a masked bit modeling head, BAR predicts discrete tokens through progressively generating their constituent bits. BAR achieves a new state-of-the-art gFID of 0.99 on ImageNet-256, outperforming leading methods across both continuous and discrete paradigms, while significantly reducing sampling costs and converging faster than prior continuous approaches. Project page is available at https://bar-gen.github.io/",
    "authors": [
      "Qihang Yu",
      "Qihao Liu",
      "Ju He",
      "Xinyang Zhang",
      "Yang Liu",
      "Liang-Chieh Chen",
      "Xi Chen"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09024v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09024v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.08965v1",
    "title": "Learning to Coordinate via Quantum Entanglement in Multi-Agent Reinforcement Learning",
    "summary": "The inability to communicate poses a major challenge to coordination in multi-agent reinforcement learning (MARL). Prior work has explored correlating local policies via shared randomness, sometimes in the form of a correlation device, as a mechanism to assist in decentralized decision-making. In contrast, this work introduces the first framework for training MARL agents to exploit shared quantum entanglement as a coordination resource, which permits a larger class of communication-free correlated policies than shared randomness alone. This is motivated by well-known results in quantum physics which posit that, for certain single-round cooperative games with no communication, shared quantum entanglement enables strategies that outperform those that only use shared randomness. In such cases, we say that there is quantum advantage. Our framework is based on a novel differentiable policy parameterization that enables optimization over quantum measurements, together with a novel policy architecture that decomposes joint policies into a quantum coordinator and decentralized local actors. To illustrate the effectiveness of our proposed method, we first show that we can learn, purely from experience, strategies that attain quantum advantage in single-round games that are treated as black box oracles. We then demonstrate how our machinery can learn policies with quantum advantage in an illustrative multi-agent sequential decision-making problem formulated as a decentralized partially observable Markov decision process (Dec-POMDP).",
    "authors": [
      "John Gardiner",
      "Orlando Romero",
      "Brendan Tivnan",
      "Nicolò Dal Fabbro",
      "George J. Pappas"
    ],
    "categories": [
      "cs.MA",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08965v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08965v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.08916v1",
    "title": "AMS-HD: Hyperdimensional Computing for Real-Time and Energy-Efficient Acute Mountain Sickness Detection",
    "summary": "Altitude sickness is a potentially life-threatening condition that impacts many individuals traveling to elevated altitudes. Timely detection is critical as symptoms can escalate rapidly. Early recognition enables simple interventions such as descent, oxygen, or medication, and prompt treatment can save lives by significantly lowering the risk of severe complications. Although conventional machine learning (ML) techniques have been applied to identify altitude sickness using physiological signals, such as heart rate, oxygen saturation, respiration rate, blood pressure, and body temperature, they often struggle to balance predictive performance with low hardware demands. In contrast, hyperdimensional computing (HDC) remains under-explored for this task with limited biomedical features, where it may offer a compelling alternative to existing classification models. Its vector symbolic framework is inherently suited to hardware-efficient design, making it a strong candidate for low-power systems like wearables. Leveraging lightweight computation and efficient streamlined memory usage, HDC enables real-time detection of altitude sickness from physiological parameters collected by wearable devices, achieving accuracy comparable to that of traditional ML models. We present AMS-HD, a novel system that integrates tailored feature extraction and Hadamard HV encoding to enhance both the precision and efficiency of HDC-based detection. This framework is well-positioned for deployment in wearable health monitoring platforms, enabling continuous, on-the-go tracking of acute altitude sickness.",
    "authors": [
      "Abu Masum",
      "Mehran Moghadam",
      "M. Hassan Najafi",
      "Bige Unluturk",
      "Ulkuhan Guler",
      "Sercan Aygun"
    ],
    "categories": [
      "cs.SC",
      "cs.ET",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08916v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08916v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.08862v1",
    "title": "Near-optimal Swap Regret Minimization for Convex Losses",
    "summary": "We give a randomized online algorithm that guarantees near-optimal $\\widetilde O(\\sqrt T)$ expected swap regret against any sequence of $T$ adaptively chosen Lipschitz convex losses on the unit interval. This improves the previous best bound of $\\widetilde O(T^{2/3})$ and answers an open question of Fishelson et al. [2025b]. In addition, our algorithm is efficient: it runs in $\\mathsf{poly}(T)$ time. A key technical idea we develop to obtain this result is to discretize the unit interval into bins at multiple scales of granularity and simultaneously use all scales to make randomized predictions, which we call multi-scale binning and may be of independent interest. A direct corollary of our result is an efficient online algorithm for minimizing the calibration error for general elicitable properties. This result does not require the Lipschitzness assumption of the identification function needed in prior work, making it applicable to median calibration, for which we achieve the first $\\widetilde O(\\sqrt T)$ calibration error guarantee.",
    "authors": [
      "Lunjia Hu",
      "Jon Schneider",
      "Yifan Wu"
    ],
    "categories": [
      "cs.LG",
      "cs.DS",
      "stat.ML"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08862v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08862v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.08722v1",
    "title": "QUOKA: Query-Oriented KV Selection For Efficient LLM Prefill",
    "summary": "We present QUOKA: Query-oriented KV selection for efficient attention, a training-free and hardware agnostic sparse attention algorithm for accelerating transformer inference under chunked prefill. While many queries focus on a smaller group of keys in the attention operator, we observe that queries with low cosine similarity with respect to the mean query interact more strongly with more keys and have the greatest contribution to final attention logits. By prioritizing these low cosine similarity queries, the behavior of full attention during the prefill stage can be closely approximated. QUOKA leverages this observation, accelerating attention by (1) first retaining a small set of representative queries and (2) then subselectin the keys most aligned with those queries. Through experiments on Needle-In-A-Haystack, LongBench, RULER, and Math500, we show that, while realizing a 3x reduction in time-to-first-token, 5x speedup in attention on Nvidia GPUs and up to nearly a 7x speedup on Intel Xeon CPUs, QUOKA achieves near-baseline accuracy, utilizing 88% fewer key-value pairs per attention evaluation.",
    "authors": [
      "Dalton Jones",
      "Junyoung Park",
      "Matthew Morse",
      "Mingu Lee",
      "Chris Lott",
      "Harper Langston"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08722v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08722v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.08660v1",
    "title": "Equalized Generative Treatment: Matching f-divergences for Fairness in Generative Models",
    "summary": "Fairness is a crucial concern for generative models, which not only reflect but can also amplify societal and cultural biases. Existing fairness notions for generative models are largely adapted from classification and focus on balancing the probability of generating samples from each sensitive group. We show that such criteria are brittle, as they can be met even when different sensitive groups are modeled with widely varying quality. To address this limitation, we introduce a new fairness definition for generative models, termed as equalized generative treatment (EGT), which requires comparable generation quality across all sensitive groups, with quality measured via a reference f-divergence. We further analyze the trade-offs induced by EGT, demonstrating that enforcing fairness constraints necessarily couples the overall model quality to that of the most challenging group to approximate. This indicates that a simple yet efficient min-max fine-tuning method should be able to balance f-divergences across sensitive groups to satisfy EGT. We validate this theoretical insight through a set of experiments on both image and text generation tasks. We demonstrate that min-max methods consistently achieve fairer outcomes compared to other approaches from the literature, while maintaining competitive overall performance for both tasks.",
    "authors": [
      "Alexandre Verine",
      "Rafael Pinot",
      "Florian Le Bronnec"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08660v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08660v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.08658v1",
    "title": "Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models",
    "summary": "Deduction, induction, and abduction are fundamental reasoning paradigms, core for human logical thinking. Although improving Large Language Model (LLM) reasoning has attracted significant research efforts, the extent to which the fundamental paradigms induce generalization has yet to be systematically explored. In this study, we shed light on how the interplay between these core paradigms influences LLMs' reasoning behavior. To this end, we first collect a new dataset of reasoning trajectories from symbolic tasks, each targeting one of the three fundamental paradigms, to abstract from concrete world knowledge. Then, we investigate effective ways for inducing these skills into LLMs. We experiment with a battery of methods including simple fine-tuning, and more complex approaches to increase model depth, or transform a dense model to a mixture-of-experts. We comprehensively evaluate induced models on realistic out-of-domain tasks, that are entirely formulated in natural language and contain real-world knowledge. Our results reveal that our approach yields strong generalizability with substantial performance gains (up to $14.60$) across realistic tasks.",
    "authors": [
      "Mingzi Cao",
      "Xingwei Tan",
      "Mahmud Akhter",
      "Marco Valentino",
      "Maria Liakata",
      "Xi Wang",
      "Nikolaos Aletras"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08658v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08658v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.08582v1",
    "title": "SemiNFT: Learning to Transfer Presets from Imitation to Appreciation via Hybrid-Sample Reinforcement Learning",
    "summary": "Photorealistic color retouching plays a vital role in visual content creation, yet manual retouching remains inaccessible to non-experts due to its reliance on specialized expertise. Reference-based methods offer a promising alternative by transferring the preset color of a reference image to a source image. However, these approaches often operate as novice learners, performing global color mappings derived from pixel-level statistics, without a true understanding of semantic context or human aesthetics. To address this issue, we propose SemiNFT, a Diffusion Transformer (DiT)-based retouching framework that mirrors the trajectory of human artistic training: beginning with rigid imitation and evolving into intuitive creation. Specifically, SemiNFT is first taught with paired triplets to acquire basic structural preservation and color mapping skills, and then advanced to reinforcement learning (RL) on unpaired data to cultivate nuanced aesthetic perception. Crucially, during the RL stage, to prevent catastrophic forgetting of old skills, we design a hybrid online-offline reward mechanism that anchors aesthetic exploration with structural review. % experiments Extensive experiments show that SemiNFT not only outperforms state-of-the-art methods on standard preset transfer benchmarks but also demonstrates remarkable intelligence in zero-shot tasks, such as black-and-white photo colorization and cross-domain (anime-to-photo) preset transfer. These results confirm that SemiNFT transcends simple statistical matching and achieves a sophisticated level of aesthetic comprehension. Our project can be found at https://melanyyang.github.io/SemiNFT/.",
    "authors": [
      "Melany Yang",
      "Yuhang Yu",
      "Diwang Weng",
      "Jinwei Chen",
      "Wei Dong"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08582v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08582v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.08892v1",
    "title": "Winner's Curse Drives False Promises in Data-Driven Decisions: A Case Study in Refugee Matching",
    "summary": "A major challenge in data-driven decision-making is accurate policy evaluation-i.e., guaranteeing that a learned decision-making policy achieves the promised benefits. A popular strategy is model-based policy evaluation, which estimates a model from data to infer counterfactual outcomes. This strategy is known to produce unwarrantedly optimistic estimates of the true benefit due to the winner's curse. We searched the recent literature on data-driven decision-making, identifying a sample of 55 papers published in the Management Science in the past decade; all but two relied on this flawed methodology. Several common justifications are provided: (1) the estimated models are accurate, stable, and well-calibrated, (2) the historical data uses random treatment assignment, (3) the model family is well-specified, and (4) the evaluation methodology uses sample splitting. Unfortunately, we show that no combination of these justifications avoids the winner's curse. First, we provide a theoretical analysis demonstrating that the winner's curse can cause large, spurious reported benefits even when all these justifications hold. Second, we perform a simulation study based on the recent and consequential data-driven refugee matching problem. We construct a synthetic refugee matching environment (calibrated to closely match the real setting) but designed so that no assignment policy can improve expected employment compared to random assignment. Model-based methods report large, stable gains of around 60% even when the true effect is zero; these gains are on par with improvements of 22-75% reported in the literature. Our results provide strong evidence against model-based evaluation.",
    "authors": [
      "Hamsa Bastani",
      "Osbert Bastani",
      "Bryce McLaughlin"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "econ.EM"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08892v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08892v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.08858v1",
    "title": "FlattenGPT: Depth Compression for Transformer with Layer Flattening",
    "summary": "Recent works have indicated redundancy across transformer blocks, prompting the research of depth compression to prune less crucial blocks. However, current ways of entire-block pruning suffer from risks of discarding meaningful cues learned in those blocks, leading to substantial performance degradation. As another line of model compression, channel pruning can better preserve performance, while it cannot reduce model depth and is challenged by inconsistent pruning ratios for individual layers. To pursue better model compression and acceleration, this paper proposes \\textbf{FlattenGPT}, a novel way to detect and reduce depth-wise redundancies. By flatting two adjacent blocks into one, it compresses the network depth, meanwhile enables more effective parameter redundancy detection and removal. FlattenGPT allows to preserve the knowledge learned in all blocks, and remains consistent with the original transformer architecture. Extensive experiments demonstrate that FlattenGPT enhances model efficiency with a decent trade-off to performance. It outperforms existing pruning methods in both zero-shot accuracies and WikiText-2 perplexity across various model types and parameter sizes. On LLaMA-2/3 and Qwen-1.5 models, FlattenGPT retains 90-96\\% of zero-shot performance with a compression ratio of 20\\%. It also outperforms other pruning methods in accelerating LLM inference, making it promising for enhancing the efficiency of transformers.",
    "authors": [
      "Ruihan Xu",
      "Qingpei Guo",
      "Yao Zhu",
      "Xiangyang Ji",
      "Ming Yang",
      "Shiliang Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08858v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08858v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.08847v1",
    "title": "Dr. MAS: Stable Reinforcement Learning for Multi-Agent LLM Systems",
    "summary": "Multi-agent LLM systems enable advanced reasoning and tool use via role specialization, yet reliable reinforcement learning (RL) post-training for such systems remains difficult. In this work, we theoretically pinpoint a key reason for training instability when extending group-based RL to multi-agent LLM systems. We show that under GRPO-style optimization, a global normalization baseline may deviate from diverse agents' reward distributions, which ultimately leads to gradient-norm instability. Based on this finding, we propose Dr. MAS, a simple and stable RL training recipe for multi-agent LLM systems. Dr. MAS uses an agent-wise remedy: normalizing advantages per agent using each agent's own reward statistics, which calibrates gradient scales and dramatically stabilizes training, both theoretically and empirically. Beyond the algorithm, Dr. MAS provides an end-to-end RL training framework for multi-agent LLM systems, supporting scalable orchestration, flexible per-agent LLM serving and optimization configs, and shared resource scheduling of LLM actor backends. We evaluate Dr. MAS on multi-agent math reasoning and multi-turn search benchmarks using Qwen2.5 and Qwen3 series models. Dr. MAS achieves clear gains over vanilla GRPO (e.g., +5.6\\% avg@16 and +4.6\\% pass@16 on math, and +15.2\\% avg@16 and +13.1\\% pass@16 on search) while largely eliminating gradient spikes. Moreover, it remains highly effective under heterogeneous agent-model assignments while improving efficiency.",
    "authors": [
      "Lang Feng",
      "Longtao Zheng",
      "Shuo He",
      "Fuxiang Zhang",
      "Bo An"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08847v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08847v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.08817v1",
    "title": "Kirin: Improving ANN efficiency with SNN Hybridization",
    "summary": "Artificial neural networks (ANNs), particularly large language models (LLMs), demonstrate powerful inference capabilities but consume substantial energy. Conversely, spiking neural networks (SNNs) exhibit exceptional energy efficiency due to their binary and event-driven characteristics, thus motivating the study of ANN-to-SNN conversion. In this process, quantization plays a pivotal role, mapping LLMs' floating-point parameters to discrete SNN parameters via the temporal dimension of the time window. However, several challenges remain in the conversion process: (i) converting high bit-width quantization values into binary spikes requires longer time windows, increasing system latency; and (ii) the inherent trade-off between the information loss of single-spike schemes and the energy costs of multi-spike ones in SNN. To address these challenges, we propose Kirin, a integer and spike hybrid based SNN to achieve accuracy lossless ANN-to-SNN conversion with time and energy efficiency. Specifically, we first propose a Spike Matrix Hybridization strategy that encoding low bit-width parameters that leading to small time window size into binary spikes while preserving the rest in integer format, thereby reducing the overall latency of SNN execution. Second, we introduce a silence threshold mechanism to regulate the timing of single-spike firing, ensuring the output is mathematically equivalent to the LLM's output and preserves accuracy. Experimental results demonstrate that Kirin, under a W4A4\\&8 quantization setting, achieves near-FP16 accuracy while reducing energy consumption by up to 84.66\\% and shortening time steps by 93.75\\%.",
    "authors": [
      "Chenyu Wang",
      "Zhanglu Yan",
      "Zhi Zhou",
      "Xu Chen",
      "Weng-Fai Wong"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08817v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08817v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.08808v1",
    "title": "How2Everything: Mining the Web for How-To Procedures to Evaluate and Improve LLMs",
    "summary": "Generating step-by-step \"how-to\" procedures is a key LLM capability: how-to advice is commonly requested in chatbots, and step-by-step planning is critical for reasoning over complex tasks. Yet, measuring and improving procedural validity at scale on real-world tasks remains challenging and understudied. To address this, we introduce How2Everything, a scalable framework to evaluate and improve goal-conditioned procedure generation. Our framework includes How2Mine, which mines 351K procedures from 980K web pages across 14 topics and readily scales to larger corpora. From this pool we build How2Bench, a 7K-example evaluation set balanced across topics. To reliably score model outputs, we develop How2Score, an evaluation protocol that uses an LLM judge to detect whether a generation contains any critical failure that would prevent achieving the goal. For low-cost, reproducible evaluation, we distill a frontier model into an open 8B model, achieving 80.5% agreement with human annotators. How2Bench reveals clear scaling trends across model sizes and training stages, providing signal early in pretraining. Finally, RL using How2Score as a reward improves performance on How2Bench by >10 points across three models without systematic regressions on standard benchmarks, with gains robust to superficial source-document memorization or format compliance. Taken together, How2Everything shows how pretraining web data can support a closed loop of capability evaluation and improvement at scale.",
    "authors": [
      "Yapei Chang",
      "Kyle Lo",
      "Mohit Iyyer",
      "Luca Soldaini"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08808v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08808v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.08742v1",
    "title": "Welfarist Formulations for Diverse Similarity Search",
    "summary": "Nearest Neighbor Search (NNS) is a fundamental problem in data structures with wide-ranging applications, such as web search, recommendation systems, and, more recently, retrieval-augmented generations (RAG). In such recent applications, in addition to the relevance (similarity) of the returned neighbors, diversity among the neighbors is a central requirement. In this paper, we develop principled welfare-based formulations in NNS for realizing diversity across attributes. Our formulations are based on welfare functions -- from mathematical economics -- that satisfy central diversity (fairness) and relevance (economic efficiency) axioms. With a particular focus on Nash social welfare, we note that our welfare-based formulations provide objective functions that adaptively balance relevance and diversity in a query-dependent manner. Notably, such a balance was not present in the prior constraint-based approach, which forced a fixed level of diversity and optimized for relevance. In addition, our formulation provides a parametric way to control the trade-off between relevance and diversity, providing practitioners with flexibility to tailor search results to task-specific requirements. We develop efficient nearest neighbor algorithms with provable guarantees for the welfare-based objectives. Notably, our algorithm can be applied on top of any standard ANN method (i.e., use standard ANN method as a subroutine) to efficiently find neighbors that approximately maximize our welfare-based objectives. Experimental results demonstrate that our approach is practical and substantially improves diversity while maintaining high relevance of the retrieved neighbors.",
    "authors": [
      "Siddharth Barman",
      "Nirjhar Das",
      "Shivam Gupta",
      "Kirankumar Shiragur"
    ],
    "categories": [
      "cs.DS",
      "cs.CG",
      "cs.GT",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08742v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08742v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.08727v1",
    "title": "Artifact Reduction in Undersampled 3D Cone-Beam CTs using a Hybrid 2D-3D CNN Framework",
    "summary": "Undersampled CT volumes minimize acquisition time and radiation exposure but introduce artifacts degrading image quality and diagnostic utility. Reducing these artifacts is critical for high-quality imaging. We propose a computationally efficient hybrid deep-learning framework that combines the strengths of 2D and 3D models. First, a 2D U-Net operates on individual slices of undersampled CT volumes to extract feature maps. These slice-wise feature maps are then stacked across the volume and used as input to a 3D decoder, which utilizes contextual information across slices to predict an artifact-free 3D CT volume. The proposed two-stage approach balances the computational efficiency of 2D processing with the volumetric consistency provided by 3D modeling. The results show substantial improvements in inter-slice consistency in coronal and sagittal direction with low computational overhead. This hybrid framework presents a robust and efficient solution for high-quality 3D CT image post-processing. The code of this project can be found on github: https://github.com/J-3TO/2D-3DCNN_sparseview/.",
    "authors": [
      "Johannes Thalhammer",
      "Tina Dorosti",
      "Sebastian Peterhansl",
      "Daniela Pfeiffer",
      "Franz Pfeiffer",
      "Florian Schaff"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08727v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08727v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.08715v1",
    "title": "Exploring SAIG Methods for an Objective Evaluation of XAI",
    "summary": "The evaluation of eXplainable Artificial Intelligence (XAI) methods is a rapidly growing field, characterized by a wide variety of approaches. This diversity highlights the complexity of the XAI evaluation, which, unlike traditional AI assessment, lacks a universally correct ground truth for the explanation, making objective evaluation challenging. One promising direction to address this issue involves the use of what we term Synthetic Artificial Intelligence Ground truth (SAIG) methods, which generate artificial ground truths to enable the direct evaluation of XAI techniques. This paper presents the first review and analysis of SAIG methods. We introduce a novel taxonomy to classify these approaches, identifying seven key features that distinguish different SAIG methods. Our comparative study reveals a concerning lack of consensus on the most effective XAI evaluation techniques, underscoring the need for further research and standardization in this area.",
    "authors": [
      "Miquel Miró-Nicolau",
      "Gabriel Moyà-Alcover",
      "Anna Arias-Duart"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08715v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08715v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.08655v1",
    "title": "From Robotics to Sepsis Treatment: Offline RL via Geometric Pessimism",
    "summary": "Offline Reinforcement Learning (RL) promises the recovery of optimal policies from static datasets, yet it remains susceptible to the overestimation of out-of-distribution (OOD) actions, particularly in fractured and sparse data manifolds.Current solutions necessitates a trade off between computational efficiency and performance. Methods like CQL offers rigorous conservatism but require tremendous compute power while efficient expectile-based methods like IQL often fail to correct OOD errors on pathological datasets, collapsing to Behavioural Cloning. In this work, we propose Geometric Pessimism, a modular, compute-efficient framework that augments standard IQL with density-based penalty derived from k-nearest-neighbour distances in the state-action embedding space. By pre-computing the penalties applied to each state-action pair our method injects OOD conservatism via reward shaping with a O(1) training overhead. Evaluated on the D4Rl MuJoCo benchmark, our method, Geo-IQL outperforms standard IQL on sensitive and unstable medium-replay tasks by over 18 points, while reducing inter-seed variance by 4x. Furthermore, Geo-IQL does not degrade performance on stable manifolds. Crucially, we validate our algorithm on the MIMIC-III Sepsis critical care dataset. While standard IQL collapses to behaviour cloning, Geo-IQL demonstrates active policy improvement. Maintaining safety constraints, achieving 86.4% terminal agreement with clinicians compared to IQL's 75%. Our results suggest that geometric pessimism provides the necessary regularisation to safely overcome local optima in critical, real-world decision systems.",
    "authors": [
      "Sarthak Wanjari"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08655v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08655v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.08638v1",
    "title": "LEFT: Learnable Fusion of Tri-view Tokens for Unsupervised Time Series Anomaly Detection",
    "summary": "As a fundamental data mining task, unsupervised time series anomaly detection (TSAD) aims to build a model for identifying abnormal timestamps without assuming the availability of annotations. A key challenge in unsupervised TSAD is that many anomalies are too subtle to exhibit detectable deviation in any single view (e.g., time domain), and instead manifest as inconsistencies across multiple views like time, frequency, and a mixture of resolutions. However, most cross-view methods rely on feature or score fusion and do not enforce analysis-synthesis consistency, meaning the frequency branch is not required to reconstruct the time signal through an inverse transform, and vice versa. In this paper, we present Learnable Fusion of Tri-view Tokens (LEFT), a unified unsupervised TSAD framework that models anomalies as inconsistencies across complementary representations. LEFT learns feature tokens from three views of the same input time series: frequency-domain tokens that embed periodicity information, time-domain tokens that capture local dynamics, and multi-scale tokens that learns abnormal patterns at varying time series granularities. By learning a set of adaptive Nyquist-constrained spectral filters, the original time series is rescaled into multiple resolutions and then encoded, allowing these multi-scale tokens to complement the extracted frequency- and time-domain information. When generating the fused representation, we introduce a novel objective that reconstructs fine-grained targets from coarser multi-scale structure, and put forward an innovative time-frequency cycle consistency constraint to explicitly regularize cross-view agreement. Experiments on real-world benchmarks show that LEFT yields the best detection accuracy against SOTA baselines, while achieving a 5x reduction on FLOPs and 8x speed-up for training.",
    "authors": [
      "Dezheng Wang",
      "Tong Chen",
      "Guansong Pang",
      "Congyan Chen",
      "Shihua Li",
      "Hongzhi Yin"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08638v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08638v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.08621v1",
    "title": "Sparse Models, Sparse Safety: Unsafe Routes in Mixture-of-Experts LLMs",
    "summary": "By introducing routers to selectively activate experts in Transformer layers, the mixture-of-experts (MoE) architecture significantly reduces computational costs in large language models (LLMs) while maintaining competitive performance, especially for models with massive parameters. However, prior work has largely focused on utility and efficiency, leaving the safety risks associated with this sparse architecture underexplored. In this work, we show that the safety of MoE LLMs is as sparse as their architecture by discovering unsafe routes: routing configurations that, once activated, convert safe outputs into harmful ones. Specifically, we first introduce the Router Safety importance score (RoSais) to quantify the safety criticality of each layer's router. Manipulation of only the high-RoSais router(s) can flip the default route into an unsafe one. For instance, on JailbreakBench, masking 5 routers in DeepSeek-V2-Lite increases attack success rate (ASR) by over 4$\\times$ to 0.79, highlighting an inherent risk that router manipulation may naturally occur in MoE LLMs. We further propose a Fine-grained token-layer-wise Stochastic Optimization framework to discover more concrete Unsafe Routes (F-SOUR), which explicitly considers the sequentiality and dynamics of input tokens. Across four representative MoE LLM families, F-SOUR achieves an average ASR of 0.90 and 0.98 on JailbreakBench and AdvBench, respectively. Finally, we outline defensive perspectives, including safety-aware route disabling and router training, as promising directions to safeguard MoE LLMs. We hope our work can inform future red-teaming and safeguarding of MoE LLMs. Our code is provided in https://github.com/TrustAIRLab/UnsafeMoE.",
    "authors": [
      "Yukun Jiang",
      "Hai Huang",
      "Mingjie Li",
      "Yage Zhang",
      "Michael Backes",
      "Yang Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08621v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08621v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.08592v1",
    "title": "TFMLinker: Universal Link Predictor by Graph In-Context Learning with Tabular Foundation Models",
    "summary": "Link prediction is a fundamental task in graph machine learning with widespread applications such as recommendation systems, drug discovery, knowledge graphs, etc. In the foundation model era, how to develop universal link prediction methods across datasets and domains becomes a key problem, with some initial attempts adopting Graph Foundation Models utilizing Graph Neural Networks and Large Language Models. However, the existing methods face notable limitations, including limited pre-training scale or heavy reliance on textual information. Motivated by the success of tabular foundation models (TFMs) in achieving universal prediction across diverse tabular datasets, we explore an alternative approach by TFMs, which are pre-trained on diverse synthetic datasets sampled from structural causal models and support strong in-context learning independent of textual attributes. Nevertheless, adapting TFMs for link prediction faces severe technical challenges such as how to obtain the necessary context and capture link-centric topological information. To solve these challenges, we propose TFMLinker (Tabular Foundation Model for Link Predictor), aiming to leverage the in-context learning capabilities of TFMs to perform link prediction across diverse graphs without requiring dataset-specific fine-tuning. Specifically, we first develop a prototype-augmented local-global context module to construct context that captures both graph-specific and cross-graph transferable patterns. Next, we design a universal topology-aware link encoder to capture link-centric topological information and generate link representations as inputs for the TFM. Finally, we employ the TFM to predict link existence through in-context learning. Experiments on 6 graph benchmarks across diverse domains demonstrate the superiority of our method over state-of-the-art baselines without requiring dataset-specific finetuning.",
    "authors": [
      "Tianyin Liao",
      "Chunyu Hu",
      "Yicheng Sui",
      "Xingxuan Zhang",
      "Peng Cui",
      "Jianxin Li",
      "Ziwei Zhang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08592v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08592v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.08589v1",
    "title": "FairRARI: A Plug and Play Framework for Fairness-Aware PageRank",
    "summary": "PageRank (PR) is a fundamental algorithm in graph machine learning tasks. Owing to the increasing importance of algorithmic fairness, we consider the problem of computing PR vectors subject to various group-fairness criteria based on sensitive attributes of the vertices. At present, principled algorithms for this problem are lacking - some cannot guarantee that a target fairness level is achieved, while others do not feature optimality guarantees. In order to overcome these shortcomings, we put forth a unified in-processing convex optimization framework, termed FairRARI, for tackling different group-fairness criteria in a ``plug and play'' fashion. Leveraging a variational formulation of PR, the framework computes fair PR vectors by solving a strongly convex optimization problem with fairness constraints, thereby ensuring that a target fairness level is achieved. We further introduce three different fairness criteria which can be efficiently tackled using FairRARI to compute fair PR vectors with the same asymptotic time-complexity as the original PR algorithm. Extensive experiments on real-world datasets showcase that FairRARI outperforms existing methods in terms of utility, while achieving the desired fairness levels across multiple vertex groups; thereby highlighting its effectiveness.",
    "authors": [
      "Emmanouil Kariotakis",
      "Aritra Konar"
    ],
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08589v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08589v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.08585v1",
    "title": "Predicting Future Utility: Global Combinatorial Optimization for Task-Agnostic KV Cache Eviction",
    "summary": "Given the quadratic complexity of attention, KV cache eviction is vital to accelerate model inference. Current KV cache eviction methods typically rely on instantaneous heuristic metrics, implicitly assuming that score magnitudes are consistent proxies for importance across all heads. However, this overlooks the heterogeneity in predictive fidelity across attention heads. While certain heads prioritize the instantaneous contribution of tokens, others are dedicated to capturing long-horizon utility. In this paper, we propose that optimal budget allocation should be governed by the marginal utility in preserving long-term semantic information. Based on this insight, we propose LU-KV, a novel framework that optimizes head-level budget allocation through a convex-hull relaxation and a marginal-utility-based greedy solver to achieve near-optimal precision. Furthermore, we implement a data-driven offline profiling protocol to facilitate the practical deployment of LU-KV. Extensive evaluations on LongBench and RULER benchmarks demonstrate that LU-KV achieves an 80% reduction in KV cache size with minimal performance degradation, while simultaneously reducing inference latency and GPU memory footprint.",
    "authors": [
      "Ziyao Tang",
      "Pengkun Jiao",
      "Xinhang Chen",
      "Wei Liu",
      "Shiyong Li",
      "Jingjing Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08585v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08585v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.09012v1",
    "title": "Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense",
    "summary": "The rapid evolution of GUI-enabled agents has rendered traditional CAPTCHAs obsolete. While previous benchmarks like OpenCaptchaWorld established a baseline for evaluating multimodal agents, recent advancements in reasoning-heavy models, such as Gemini3-Pro-High and GPT-5.2-Xhigh have effectively collapsed this security barrier, achieving pass rates as high as 90% on complex logic puzzles like \"Bingo\". In response, we introduce Next-Gen CAPTCHAs, a scalable defense framework designed to secure the next-generation web against the advanced agents. Unlike static datasets, our benchmark is built upon a robust data generation pipeline, allowing for large-scale and easily scalable evaluations, notably, for backend-supported types, our system is capable of generating effectively unbounded CAPTCHA instances. We exploit the persistent human-agent \"Cognitive Gap\" in interactive perception, memory, decision-making, and action. By engineering dynamic tasks that require adaptive intuition rather than granular planning, we re-establish a robust distinction between biological users and artificial agents, offering a scalable and diverse defense mechanism for the agentic era.",
    "authors": [
      "Jiacheng Liu",
      "Yaxin Luo",
      "Jiacheng Cui",
      "Xinyi Shang",
      "Xiaohan Zhao",
      "Zhiqiang Shen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09012v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09012v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.08920v1",
    "title": "Diffusion-Inspired Reconfiguration of Transformers for Uncertainty Calibration",
    "summary": "Uncertainty calibration in pre-trained transformers is critical for their reliable deployment in risk-sensitive applications. Yet, most existing pre-trained transformers do not have a principled mechanism for uncertainty propagation through their feature transformation stack. In this work, we propose a diffusion-inspired reconfiguration of transformers in which each feature transformation block is modeled as a probabilistic mapping. Composing these probabilistic mappings reveals a probability path that mimics the structure of a diffusion process, transporting data mass from the input distribution to the pre-trained feature distribution. This probability path can then be recompiled on a diffusion process with a unified transition model to enable principled propagation of representation uncertainty throughout the pre-trained model's architecture while maintaining its original predictive performance. Empirical results across a variety of vision and language benchmarks demonstrate that our method achieves superior calibration and predictive accuracy compared to existing uncertainty-aware transformers.",
    "authors": [
      "Manh Cuong Dao",
      "Quang Hung Pham",
      "Phi Le Nguyen",
      "Thao Nguyen Truong",
      "Bryan Kian Hsiang Low",
      "Trong Nghia Hoang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08920v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08920v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.08917v1",
    "title": "Automatic In-Domain Exemplar Construction and LLM-Based Refinement of Multi-LLM Expansions for Query Expansion",
    "summary": "Query expansion with large language models is promising but often relies on hand-crafted prompts, manually chosen exemplars, or a single LLM, making it non-scalable and sensitive to domain shift. We present an automated, domain-adaptive QE framework that builds in-domain exemplar pools by harvesting pseudo-relevant passages using a BM25-MonoT5 pipeline. A training-free cluster-based strategy selects diverse demonstrations, yielding strong and stable in-context QE without supervision. To further exploit model complementarity, we introduce a two-LLM ensemble in which two heterogeneous LLMs independently generate expansions and a refinement LLM consolidates them into one coherent expansion. Across TREC DL20, DBPedia, and SciFact, the refined ensemble delivers consistent and statistically significant gains over BM25, Rocchio, zero-shot, and fixed few-shot baselines. The framework offers a reproducible testbed for exemplar selection and multi-LLM generation, and a practical, label-free solution for real-world QE.",
    "authors": [
      "Minghan Li",
      "Ercong Nie",
      "Siqi Zhao",
      "Tongna Chen",
      "Huiping Huang",
      "Guodong Zhou"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08917v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08917v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.08872v1",
    "title": "Large Language Models for Geolocation Extraction in Humanitarian Crisis Response",
    "summary": "Humanitarian crises demand timely and accurate geographic information to inform effective response efforts. Yet, automated systems that extract locations from text often reproduce existing geographic and socioeconomic biases, leading to uneven visibility of crisis-affected regions. This paper investigates whether Large Language Models (LLMs) can address these geographic disparities in extracting location information from humanitarian documents. We introduce a two-step framework that combines few-shot LLM-based named entity recognition with an agent-based geocoding module that leverages context to resolve ambiguous toponyms. We benchmark our approach against state-of-the-art pretrained and rule-based systems using both accuracy and fairness metrics across geographic and socioeconomic dimensions. Our evaluation uses an extended version of the HumSet dataset with refined literal toponym annotations. Results show that LLM-based methods substantially improve both the precision and fairness of geolocation extraction from humanitarian texts, particularly for underrepresented regions. By bridging advances in LLM reasoning with principles of responsible and inclusive AI, this work contributes to more equitable geospatial data systems for humanitarian response, advancing the goal of leaving no place behind in crisis analytics.",
    "authors": [
      "G. Cafferata",
      "T. Demarco",
      "K. Kalimeri",
      "Y. Mejova",
      "M. G. Beiró"
    ],
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08872v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08872v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.08864v1",
    "title": "Understanding Dynamic Compute Allocation in Recurrent Transformers",
    "summary": "Token-level adaptive computation seeks to reduce inference cost by allocating more computation to harder tokens and less to easier ones. However, prior work is primarily evaluated on natural-language benchmarks using task-level metrics, where token-level difficulty is unobservable and confounded with architectural factors, making it unclear whether compute allocation truly aligns with underlying complexity. We address this gap through three contributions. First, we introduce a complexity-controlled evaluation paradigm using algorithmic and synthetic language tasks with parameterized difficulty, enabling direct testing of token-level compute allocation. Second, we propose ANIRA, a unified recurrent Transformer framework that supports per-token variable-depth computation while isolating compute allocation decisions from other model factors. Third, we use this framework to conduct a systematic analysis of token-level adaptive computation across alignment with complexity, generalization, and decision timing. Our results show that compute allocation aligned with task complexity can emerge without explicit difficulty supervision, but such alignment does not imply algorithmic generalization: models fail to extrapolate to unseen input sizes despite allocating additional computation. We further find that early compute decisions rely on static structural cues, whereas online halting more closely tracks algorithmic execution state.",
    "authors": [
      "Ibraheem Muhammad Moosa",
      "Suhas Lohit",
      "Ye Wang",
      "Moitreya Chatterjee",
      "Wenpeng Yin"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08864v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08864v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.08855v1",
    "title": "Rethinking Graph Generalization through the Lens of Sharpness-Aware Minimization",
    "summary": "Graph Neural Networks (GNNs) have achieved remarkable success across various graph-based tasks but remain highly sensitive to distribution shifts. In this work, we focus on a prevalent yet under-explored phenomenon in graph generalization, Minimal Shift Flip (MSF),where test samples that slightly deviate from the training distribution are abruptly misclassified. To interpret this phenomenon, we revisit MSF through the lens of Sharpness-Aware Minimization (SAM), which characterizes the local stability and sharpness of the loss landscape while providing a theoretical foundation for modeling generalization error. To quantify loss sharpness, we introduce the concept of Local Robust Radius, measuring the smallest perturbation required to flip a prediction and establishing a theoretical link between local stability and generalization. Building on this perspective, we further observe a continual decrease in the robust radius during training, indicating weakened local stability and an increasingly sharp loss landscape that gives rise to MSF. To jointly solve the MSF phenomenon and the intractability of radius, we develop an energy-based formulation that is theoretically proven to be monotonically correlated with the robust radius, offering a tractable and principled objective for modeling flatness and stability. Building on these insights, we propose an energy-driven generative augmentation framework (E2A) that leverages energy-guided latent perturbations to generate pseudo-OOD samples and enhance model generalization. Extensive experiments across multiple benchmarks demonstrate that E2A consistently improves graph OOD generalization, outperforming state-of-the-art baselines.",
    "authors": [
      "Yang Qiu",
      "Yixiong Zou",
      "Jun Wang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08855v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08855v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.08815v1",
    "title": "Negative-Aware Diffusion Process for Temporal Knowledge Graph Extrapolation",
    "summary": "Temporal Knowledge Graph (TKG) reasoning seeks to predict future missing facts from historical evidence. While diffusion models (DM) have recently gained attention for their ability to capture complex predictive distributions, two gaps remain: (i) the generative path is conditioned only on positive evidence, overlooking informative negative context, and (ii) training objectives are dominated by cross-entropy ranking, which improves candidate ordering but provides little supervision over the calibration of the denoised embedding. To bridge this gap, we introduce Negative-Aware Diffusion model for TKG Extrapolation (NADEx). Specifically, NADEx encodes subject-centric histories of entities, relations and temporal intervals into sequential embeddings. NADEx perturbs the query object in the forward process and reconstructs it in reverse with a Transformer denoiser conditioned on the temporal-relational context. We further derive a cosine-alignment regularizer derived from batch-wise negative prototypes, which tightens the decision boundary against implausible candidates. Comprehensive experiments on four public TKG benchmarks demonstrate that NADEx delivers state-of-the-art performance.",
    "authors": [
      "Yanglei Gan",
      "Peng He",
      "Yuxiang Cai",
      "Run Lin",
      "Guanyu Zhou",
      "Qiao Liu"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08815v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08815v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.08782v1",
    "title": "Amortising Inference and Meta-Learning Priors in Neural Networks",
    "summary": "One of the core facets of Bayesianism is in the updating of prior beliefs in light of new evidence$\\text{ -- }$so how can we maintain a Bayesian approach if we have no prior beliefs in the first place? This is one of the central challenges in the field of Bayesian deep learning, where it is not clear how to represent beliefs about a prediction task by prior distributions over model parameters. Bridging the fields of Bayesian deep learning and probabilistic meta-learning, we introduce a way to $\\textit{learn}$ a weights prior from a collection of datasets by introducing a way to perform per-dataset amortised variational inference. The model we develop can be viewed as a neural process whose latent variable is the set of weights of a BNN and whose decoder is the neural network parameterised by a sample of the latent variable itself. This unique model allows us to study the behaviour of Bayesian neural networks under well-specified priors, use Bayesian neural networks as flexible generative models, and perform desirable but previously elusive feats in neural processes such as within-task minibatching or meta-learning under extreme data-starvation.",
    "authors": [
      "Tommy Rochussen",
      "Vincent Fortuin"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08782v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08782v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.08733v1",
    "title": "Foundation Inference Models for Ordinary Differential Equations",
    "summary": "Ordinary differential equations (ODEs) are central to scientific modelling, but inferring their vector fields from noisy trajectories remains challenging. Current approaches such as symbolic regression, Gaussian process (GP) regression, and Neural ODEs often require complex training pipelines and substantial machine learning expertise, or they depend strongly on system-specific prior knowledge. We propose FIM-ODE, a pretrained Foundation Inference Model that amortises low-dimensional ODE inference by predicting the vector field directly from noisy trajectory data in a single forward pass. We pretrain FIM-ODE on a prior distribution over ODEs with low-degree polynomial vector fields and represent the target field with neural operators. FIM-ODE achieves strong zero-shot performance, matching and often improving upon ODEFormer, a recent pretrained symbolic baseline, across a range of regimes despite using a simpler pretraining prior distribution. Pretraining also provides a strong initialisation for finetuning, enabling fast and stable adaptation that outperforms modern neural and GP baselines without requiring machine learning expertise.",
    "authors": [
      "Maximilian Mauel",
      "Johannes R. Hübers",
      "David Berghaus",
      "Patrick Seifner",
      "Ramses J. Sanchez"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08733v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08733v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.08730v1",
    "title": "Closing the Confusion Loop: CLIP-Guided Alignment for Source-Free Domain Adaptation",
    "summary": "Source-Free Domain Adaptation (SFDA) tackles the problem of adapting a pre-trained source model to an unlabeled target domain without accessing any source data, which is quite suitable for the field of data security. Although recent advances have shown that pseudo-labeling strategies can be effective, they often fail in fine-grained scenarios due to subtle inter-class similarities. A critical but underexplored issue is the presence of asymmetric and dynamic class confusion, where visually similar classes are unequally and inconsistently misclassified by the source model. Existing methods typically ignore such confusion patterns, leading to noisy pseudo-labels and poor target discrimination. To address this, we propose CLIP-Guided Alignment(CGA), a novel framework that explicitly models and mitigates class confusion in SFDA. Generally, our method consists of three parts: (1) MCA: detects first directional confusion pairs by analyzing the predictions of the source model in the target domain; (2) MCC: leverages CLIP to construct confusion-aware textual prompts (e.g. a truck that looks like a bus), enabling more context-sensitive pseudo-labeling; and (3) FAM: builds confusion-guided feature banks for both CLIP and the source model and aligns them using contrastive learning to reduce ambiguity in the representation space. Extensive experiments on various datasets demonstrate that CGA consistently outperforms state-of-the-art SFDA methods, with especially notable gains in confusion-prone and fine-grained scenarios. Our results highlight the importance of explicitly modeling inter-class confusion for effective source-free adaptation. Our code can be find at https://github.com/soloiro/CGA",
    "authors": [
      "Shanshan Wang",
      "Ziying Feng",
      "Xiaozheng Shen",
      "Xun Yang",
      "Pichao Wang",
      "Zhenwei He",
      "Xingyi Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08730v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08730v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.08717v1",
    "title": "Zero-shot System for Automatic Body Region Detection for Volumetric CT and MR Images",
    "summary": "Reliable identification of anatomical body regions is a prerequisite for many automated medical imaging workflows, yet existing solutions remain heavily dependent on unreliable DICOM metadata. Current solutions mainly use supervised learning, which limits their applicability in many real-world scenarios. In this work, we investigate whether body region detection in volumetric CT and MR images can be achieved in a fully zero-shot manner by using knowledge embedded in large pre-trained foundation models. We propose and systematically evaluate three training-free pipelines: (1) a segmentation-driven rule-based system leveraging pre-trained multi-organ segmentation models, (2) a Multimodal Large Language Model (MLLM) guided by radiologist-defined rules, and (3) a segmentation-aware MLLM that combines visual input with explicit anatomical evidence. All methods are evaluated on 887 heterogeneous CT and MR scans with manually verified anatomical region labels. The segmentation-driven rule-based approach achieves the strongest and most consistent performance, with weighted F1-scores of 0.947 (CT) and 0.914 (MR), demonstrating robustness across modalities and atypical scan coverage. The MLLM performs competitively in visually distinctive regions, while the segmentation-aware MLLM reveals fundamental limitations.",
    "authors": [
      "Farnaz Khun Jush",
      "Grit Werner",
      "Mark Klemens",
      "Matthias Lenga"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08717v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08717v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.08683v1",
    "title": "OneVision-Encoder: Codec-Aligned Sparsity as a Foundational Principle for Multimodal Intelligence",
    "summary": "Hypothesis. Artificial general intelligence is, at its core, a compression problem. Effective compression demands resonance: deep learning scales best when its architecture aligns with the fundamental structure of the data. These are the fundamental principles. Yet, modern vision architectures have strayed from these truths: visual signals are highly redundant, while discriminative information, the surprise, is sparse. Current models process dense pixel grids uniformly, wasting vast compute on static background rather than focusing on the predictive residuals that define motion and meaning. We argue that to solve visual understanding, we must align our architectures with the information-theoretic principles of video, i.e., Codecs.   Method. OneVision-Encoder encodes video by compressing predictive visual structure into semantic meaning. By adopting Codec Patchification, OV-Encoder abandons uniform computation to focus exclusively on the 3.1%-25% of regions rich in signal entropy. To unify spatial and temporal reasoning under irregular token layouts, OneVision-Encoder employs a shared 3D RoPE and is trained with a large-scale cluster discrimination objective over more than one million semantic concepts, jointly capturing object permanence and motion dynamics.   Evidence. The results validate our core hypothesis: efficiency and accuracy are not a trade-off; they are positively correlated. When integrated into LLM, it consistently outperforms strong vision backbones such as Qwen3-ViT and SigLIP2 across 16 image, video, and document understanding benchmarks, despite using substantially fewer visual tokens and pretraining data. Notably, on video understanding tasks, OV-Encoder achieves an average improvement of 4.1% over Qwen3-ViT. Codec-aligned, patch-level sparsity is a foundational principle, enabling OV-Encoder as a scalable engine for next-generation visual generalists.",
    "authors": [
      "Feilong Tang",
      "Xiang An",
      "Yunyao Yan",
      "Yin Xie",
      "Bin Qin",
      "Kaicheng Yang",
      "Yifei Shen",
      "Yuanhan Zhang",
      "Chunyuan Li",
      "Shikun Feng",
      "Changrui Chen",
      "Huajie Tan",
      "Ming Hu",
      "Manyuan Zhang",
      "Bo Li",
      "Ziyong Feng",
      "Ziwei Liu",
      "Zongyuan Ge",
      "Jiankang Deng"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08683v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08683v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.08661v1",
    "title": "WiFlow: A Lightweight WiFi-based Continuous Human Pose Estimation Network with Spatio-Temporal Feature Decoupling",
    "summary": "Human pose estimation is fundamental to intelligent perception in the Internet of Things (IoT), enabling applications ranging from smart healthcare to human-computer interaction. While WiFi-based methods have gained traction, they often struggle with continuous motion and high computational overhead. This work presents WiFlow, a novel framework for continuous human pose estimation using WiFi signals. Unlike vision-based approaches such as two-dimensional deep residual networks that treat Channel State Information (CSI) as images, WiFlow employs an encoder-decoder architecture. The encoder captures spatio-temporal features of CSI using temporal and asymmetric convolutions, preserving the original sequential structure of signals. It then refines keypoint features of human bodies to be tracked and capture their structural dependencies via axial attention. The decoder subsequently maps the encoded high-dimensional features into keypoint coordinates. Trained on a self-collected dataset of 360,000 synchronized CSI-pose samples from 5 subjects performing continuous sequences of 8 daily activities, WiFlow achieves a Percentage of Correct Keypoints (PCK) of 97.00% at a threshold of 20% (PCK@20) and 99.48% at PCK@50, with a mean per-joint position error of 0.008m. With only 4.82M parameters, WiFlow significantly reduces model complexity and computational cost, establishing a new performance baseline for practical WiFi-based human pose estimation. Our code and datasets are available at https://github.com/DY2434/WiFlow-WiFi-Pose-Estimation-with-Spatio-Temporal-Decoupling.git.",
    "authors": [
      "Yi Dao",
      "Lankai Zhang",
      "Hao Liu",
      "Haiwei Zhang",
      "Wenbo Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08661v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08661v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.08616v1",
    "title": "Breaking the Grid: Distance-Guided Reinforcement Learning in Large Discrete and Hybrid Action Spaces",
    "summary": "Reinforcement Learning is increasingly applied to logistics, scheduling, and recommender systems, but standard algorithms struggle with the curse of dimensionality in such large discrete action spaces. Existing algorithms typically rely on restrictive grid-based structures or computationally expensive nearest-neighbor searches, limiting their effectiveness in high-dimensional or irregularly structured domains. We propose Distance-Guided Reinforcement Learning (DGRL), combining Sampled Dynamic Neighborhoods (SDN) and Distance-Based Updates (DBU) to enable efficient RL in spaces with up to 10$^\\text{20}$ actions. Unlike prior methods, SDN leverages a semantic embedding space to perform stochastic volumetric exploration, provably providing full support over a local trust region. Complementing this, DBU transforms policy optimization into a stable regression task, decoupling gradient variance from action space cardinality and guaranteeing monotonic policy improvement. DGRL naturally generalizes to hybrid continuous-discrete action spaces without requiring hierarchical dependencies. We demonstrate performance improvements of up to 66% against state-of-the-art benchmarks across regularly and irregularly structured environments, while simultaneously improving convergence speed and computational complexity.",
    "authors": [
      "Heiko Hoppe",
      "Fabian Akkerman",
      "Wouter van Heeswijk",
      "Maximilian Schiffer"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08616v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08616v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.08577v1",
    "title": "An arithmetic method algorithm optimizing k-nearest neighbors compared to regression algorithms and evaluated on real world data sources",
    "summary": "Linear regression analysis focuses on predicting a numeric regressand value based on certain regressor values. In this context, k-Nearest Neighbors (k-NN) is a common non-parametric regression algorithm, which achieves efficient performance when compared with other algorithms in literature. In this research effort an optimization of the k-NN algorithm is proposed by exploiting the potentiality of an introduced arithmetic method, which can provide solutions for linear equations involving an arbitrary number of real variables. Specifically, an Arithmetic Method Algorithm (AMA) is adopted to assess the efficiency of the introduced arithmetic method, while an Arithmetic Method Regression (AMR) algorithm is proposed as an optimization of k-NN adopting the potentiality of AMA. Such algorithm is compared with other regression algorithms, according to an introduced optimal inference decision rule, and evaluated on certain real world data sources, which are publicly available. Results are promising since the proposed AMR algorithm has comparable performance with the other algorithms, while in most cases it achieves better performance than the k-NN. The output results indicate that introduced AMR is an optimization of k-NN.",
    "authors": [
      "Theodoros Anagnostopoulos",
      "Evanthia Zervoudi",
      "Christos Anagnostopoulos",
      "Apostolos Christopoulos",
      "Bogdan Wierzbinski"
    ],
    "categories": [
      "cs.LG",
      "math.CO",
      "stat.CO"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08577v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08577v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.09021v1",
    "title": "$χ_{0}$: Resource-Aware Robust Manipulation via Taming Distributional Inconsistencies",
    "summary": "High-reliability long-horizon robotic manipulation has traditionally relied on large-scale data and compute to understand complex real-world dynamics. However, we identify that the primary bottleneck to real-world robustness is not resource scale alone, but the distributional shift among the human demonstration distribution, the inductive bias learned by the policy, and the test-time execution distribution -- a systematic inconsistency that causes compounding errors in multi-stage tasks. To mitigate these inconsistencies, we propose $χ_{0}$, a resource-efficient framework with effective modules designated to achieve production-level robustness in robotic manipulation. Our approach builds off three technical pillars: (i) Model Arithmetic, a weight-space merging strategy that efficiently soaks up diverse distributions of different demonstrations, varying from object appearance to state variations; (ii) Stage Advantage, a stage-aware advantage estimator that provides stable, dense progress signals, overcoming the numerical instability of prior non-stage approaches; and (iii) Train-Deploy Alignment, which bridges the distribution gap via spatio-temporal augmentation, heuristic DAgger corrections, and temporal chunk-wise smoothing. $χ_{0}$ enables two sets of dual-arm robots to collaboratively orchestrate long-horizon garment manipulation, spanning tasks from flattening, folding, to hanging different clothes. Our method exhibits high-reliability autonomy; we are able to run the system from arbitrary initial state for consecutive 24 hours non-stop. Experiments validate that $χ_{0}$ surpasses the state-of-the-art $π_{0.5}$ in success rate by nearly 250%, with only 20-hour data and 8 A100 GPUs. Code, data and models will be released to facilitate the community.",
    "authors": [
      "Checheng Yu",
      "Chonghao Sima",
      "Gangcheng Jiang",
      "Hai Zhang",
      "Haoguang Mai",
      "Hongyang Li",
      "Huijie Wang",
      "Jin Chen",
      "Kaiyang Wu",
      "Li Chen",
      "Lirui Zhao",
      "Modi Shi",
      "Ping Luo",
      "Qingwen Bu",
      "Shijia Peng",
      "Tianyu Li",
      "Yibo Yuan"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09021v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09021v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.09016v1",
    "title": "Raster2Seq: Polygon Sequence Generation for Floorplan Reconstruction",
    "summary": "Reconstructing a structured vector-graphics representation from a rasterized floorplan image is typically an important prerequisite for computational tasks involving floorplans such as automated understanding or CAD workflows. However, existing techniques struggle in faithfully generating the structure and semantics conveyed by complex floorplans that depict large indoor spaces with many rooms and a varying numbers of polygon corners. To this end, we propose Raster2Seq, framing floorplan reconstruction as a sequence-to-sequence task in which floorplan elements--such as rooms, windows, and doors--are represented as labeled polygon sequences that jointly encode geometry and semantics. Our approach introduces an autoregressive decoder that learns to predict the next corner conditioned on image features and previously generated corners using guidance from learnable anchors. These anchors represent spatial coordinates in image space, hence allowing for effectively directing the attention mechanism to focus on informative image regions. By embracing the autoregressive mechanism, our method offers flexibility in the output format, enabling for efficiently handling complex floorplans with numerous rooms and diverse polygon structures. Our method achieves state-of-the-art performance on standard benchmarks such as Structure3D, CubiCasa5K, and Raster2Graph, while also demonstrating strong generalization to more challenging datasets like WAFFLE, which contain diverse room structures and complex geometric variations.",
    "authors": [
      "Hao Phung",
      "Hadar Averbuch-Elor"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09016v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09016v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.09014v1",
    "title": "ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation",
    "summary": "Diffusion models have achieved remarkable generation quality, but they suffer from significant inference cost due to their reliance on multiple sequential denoising steps, motivating recent efforts to distill this inference process into a few-step regime. However, existing distillation methods typically approximate the teacher trajectory by using linear shortcuts, which makes it difficult to match its constantly changing tangent directions as velocities evolve across timesteps, thereby leading to quality degradation. To address this limitation, we propose ArcFlow, a few-step distillation framework that explicitly employs non-linear flow trajectories to approximate pre-trained teacher trajectories. Concretely, ArcFlow parameterizes the velocity field underlying the inference trajectory as a mixture of continuous momentum processes. This enables ArcFlow to capture velocity evolution and extrapolate coherent velocities to form a continuous non-linear trajectory within each denoising step. Importantly, this parameterization admits an analytical integration of this non-linear trajectory, which circumvents numerical discretization errors and results in high-precision approximation of the teacher trajectory. To train this parameterization into a few-step generator, we implement ArcFlow via trajectory distillation on pre-trained teacher models using lightweight adapters. This strategy ensures fast, stable convergence while preserving generative diversity and quality. Built on large-scale models (Qwen-Image-20B and FLUX.1-dev), ArcFlow only fine-tunes on less than 5% of original parameters and achieves a 40x speedup with 2 NFEs over the original multi-step teachers without significant quality degradation. Experiments on benchmarks show the effectiveness of ArcFlow both qualitatively and quantitatively.",
    "authors": [
      "Zihan Yang",
      "Shuyuan Tu",
      "Licheng Zhang",
      "Qi Dai",
      "Yu-Gang Jiang",
      "Zuxuan Wu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09014v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09014v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.09001v1",
    "title": "DirMoE: Dirichlet-routed Mixture of Experts",
    "summary": "Mixture-of-Experts (MoE) models have demonstrated exceptional performance in large-scale language models. Existing routers typically rely on non-differentiable Top-$k$+Softmax, limiting their performance and scalability. We argue that two distinct decisions, which experts to activate and how to distribute expert contributions among them, are conflated in standard Top-$k$+Softmax. We introduce Dirichlet-Routed MoE (DirMoE), a novel end-to-end differentiable routing mechanism built on a Dirichlet variational autoencoder framework. This design fundamentally disentangles the core routing problems: expert selection, modeled by a Bernoulli component, and expert contribution among chosen experts, handled by a Dirichlet component. The entire forward pass remains fully differentiable through the use of Gumbel-Sigmoid relaxation for the expert selection and implicit reparameterization for the Dirichlet distribution. Our training objective, a variational ELBO, includes a direct sparsity penalty that precisely controls the number of active experts in expectation, alongside a schedule for key hyperparameters that guides the model from an exploratory to a definitive routing state. Moreover, our DirMoE router matches or exceeds other methods while improving expert specialization.",
    "authors": [
      "Amirhossein Vahidi",
      "Hesam Asadollahzadeh",
      "Navid Akhavan Attar",
      "Marie Moullet",
      "Kevin Ly",
      "Xingyi Yang",
      "Mohammad Lotfollahi"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09001v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09001v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.08995v1",
    "title": "When Actions Go Off-Task: Detecting and Correcting Misaligned Actions in Computer-Use Agents",
    "summary": "Computer-use agents (CUAs) have made tremendous progress in the past year, yet they still frequently produce misaligned actions that deviate from the user's original intent. Such misaligned actions may arise from external attacks (e.g., indirect prompt injection) or from internal limitations (e.g., erroneous reasoning). They not only expose CUAs to safety risks, but also degrade task efficiency and reliability. This work makes the first effort to define and study misaligned action detection in CUAs, with comprehensive coverage of both externally induced and internally arising misaligned actions. We further identify three common categories in real-world CUA deployment and construct MisActBench, a benchmark of realistic trajectories with human-annotated, action-level alignment labels. Moreover, we propose DeAction, a practical and universal guardrail that detects misaligned actions before execution and iteratively corrects them through structured feedback. DeAction outperforms all existing baselines across offline and online evaluations with moderate latency overhead: (1) On MisActBench, it outperforms baselines by over 15% absolute in F1 score; (2) In online evaluation, it reduces attack success rate by over 90% under adversarial settings while preserving or even improving task success rate in benign environments.",
    "authors": [
      "Yuting Ning",
      "Jaylen Jones",
      "Zhehao Zhang",
      "Chentao Ye",
      "Weitong Ruan",
      "Junyi Li",
      "Rahul Gupta",
      "Huan Sun"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08995v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08995v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.08849v1",
    "title": "Cutting Through the Noise: On-the-fly Outlier Detection for Robust Training of Machine Learning Interatomic Potentials",
    "summary": "The accuracy of machine learning interatomic potentials suffers from reference data that contains numerical noise. Often originating from unconverged or inconsistent electronic-structure calculations, this noise is challenging to identify. Existing mitigation strategies such as manual filtering or iterative refinement of outliers, require either substantial expert effort or multiple expensive retraining cycles, making them difficult to scale to large datasets. Here, we introduce an on-the-fly outlier detection scheme that automatically down-weights noisy samples, without requiring additional reference calculations. By tracking the loss distribution via an exponential moving average, this unsupervised method identifies outliers throughout a single training run. We show that this approach prevents overfitting and matches the performance of iterative refinement baselines with significantly reduced overhead. The method's effectiveness is demonstrated by recovering accurate physical observables for liquid water from unconverged reference data, including diffusion coefficients. Furthermore, we validate its scalability by training a foundation model for organic chemistry on the SPICE dataset, where it reduces energy errors by a factor of three. This framework provides a simple, automated solution for training robust models on imperfect datasets across dataset sizes.",
    "authors": [
      "Terry C. W. Lam",
      "Niamh O'Neill",
      "Christoph Schran",
      "Lars L. Schaaf"
    ],
    "categories": [
      "stat.ML",
      "cond-mat.mtrl-sci",
      "cs.LG",
      "physics.chem-ph"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08849v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08849v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.08826v1",
    "title": "Affective Flow Language Model for Emotional Support Conversation",
    "summary": "Large language models (LLMs) have been widely applied to emotional support conversation (ESC). However, complex multi-turn support remains challenging.This is because existing alignment schemes rely on sparse outcome-level signals, thus offering limited supervision for intermediate strategy decisions. To fill this gap, this paper proposes affective flow language model for emotional support conversation (AFlow), a framework that introduces fine-grained supervision on dialogue prefixes by modeling a continuous affective flow along multi-turn trajectories. AFlow can estimate intermediate utility over searched trajectories and learn preference-consistent strategy transitions. To improve strategy coherence and empathetic response quality, a subpath-level flow-balance objective is presented to propagate preference signals to intermediate states. Experiment results show consistent and significant improvements over competitive baselines in diverse emotional contexts. Remarkably, AFlow with a compact open-source backbone outperforms proprietary LMMs such as GPT-4o and Claude-3.5 on major ESC metrics. Our code is available at https://github.com/chzou25-lgtm/AffectiveFlow.",
    "authors": [
      "Chenghui Zou",
      "Ning Wang",
      "Tiesunlong Shen",
      "Luwei Xiao",
      "Chuan Ma",
      "Xiangpeng Li",
      "Rui Mao",
      "Erik Cambria"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08826v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08826v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.08813v1",
    "title": "Robust Policy Optimization to Prevent Catastrophic Forgetting",
    "summary": "Large language models are commonly trained through multi-stage post-training: first via RLHF, then fine-tuned for other downstream objectives. Yet even small downstream updates can compromise earlier learned behaviors (e.g., safety), exposing a brittleness known as catastrophic forgetting. This suggests standard RLHF objectives do not guarantee robustness to future adaptation. To address it, most prior work designs downstream-time methods to preserve previously learned behaviors. We argue that preventing this requires pre-finetuning robustness: the base policy should avoid brittle high-reward solutions whose reward drops sharply under standard fine-tuning.   We propose Fine-tuning Robust Policy Optimization (FRPO), a robust RLHF framework that optimizes reward not only at the current policy, but across a KL-bounded neighborhood of policies reachable by downstream adaptation. The key idea is to ensure reward stability under policy shifts via a max-min formulation. By modifying GRPO, we develop an algorithm with no extra computation, and empirically show it substantially reduces safety degradation across multiple base models and downstream fine-tuning regimes (SFT and RL) while preserving downstream task performance. We further study a math-focused RL setting, demonstrating that FRPO preserves accuracy under subsequent fine-tuning.",
    "authors": [
      "Mahdi Sabbaghi",
      "George Pappas",
      "Adel Javanmard",
      "Hamed Hassani"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08813v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08813v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.08804v1",
    "title": "Root Cause Analysis Method Based on Large Language Models with Residual Connection Structures",
    "summary": "Root cause localization remain challenging in complex and large-scale microservice architectures. The complex fault propagation among microservices and the high dimensionality of telemetry data, including metrics, logs, and traces, limit the effectiveness of existing root cause analysis (RCA) methods. In this paper, a residual-connection-based RCA method using large language model (LLM), named RC-LLM, is proposed. A residual-like hierarchical fusion structure is designed to integrate multi-source telemetry data, while the contextual reasoning capability of large language models is leveraged to model temporal and cross-microservice causal dependencies. Experimental results on CCF-AIOps microservice datasets demonstrate that RC-LLM achieves strong accuracy and efficiency in root cause analysis.",
    "authors": [
      "Liming Zhou",
      "Ailing Liu",
      "Hongwei Liu",
      "Min He",
      "Heng Zhang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08804v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08804v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.08725v1",
    "title": "FusionEdit: Semantic Fusion and Attention Modulation for Training-Free Image Editing",
    "summary": "Text-guided image editing aims to modify specific regions according to the target prompt while preserving the identity of the source image. Recent methods exploit explicit binary masks to constrain editing, but hard mask boundaries introduce artifacts and reduce editability. To address these issues, we propose FusionEdit, a training-free image editing framework that achieves precise and controllable edits. First, editing and preserved regions are automatically identified by measuring semantic discrepancies between source and target prompts. To mitigate boundary artifacts, FusionEdit performs distance-aware latent fusion along region boundaries to yield the soft and accurate mask, and employs a total variation loss to enforce smooth transitions, obtaining natural editing results. Second, FusionEdit leverages AdaIN-based modulation within DiT attention layers to perform a statistical attention fusion in the editing region, enhancing editability while preserving global consistency with the source image. Extensive experiments demonstrate that our FusionEdit significantly outperforms state-of-the-art methods. Code is available at \\href{https://github.com/Yvan1001/FusionEdit}{https://github.com/Yvan1001/FusionEdit}.",
    "authors": [
      "Yongwen Lai",
      "Chaoqun Wang",
      "Shaobo Min"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08725v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08725v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.08686v1",
    "title": "CompilerKV: Risk-Adaptive KV Compression via Offline Experience Compilation",
    "summary": "Large Language Models (LLMs) in long-context scenarios are severely constrained by the linear growth of Key-Value (KV) cache memory. Existing KV compression methods rely either on static thresholds and attention-only heuristics or on coarse memory budget allocation. Under tight memory budgets, these methods overlook two key factors: prompt-dependent variation in compression risk and functional heterogeneity across attention heads, which destabilize token selection and lead to tail failures. To address these challenges, we propose CompilerKV, a risk-adaptive and head-aware compression framework that compiles offline experience into reusable decision tables for prefill-only deployment. CompilerKV integrates two key synergistic components: (i) a Head Heterogeneity Table, learned via offline contextual bandits, which assigns head-specific reliability weights to govern functional differences across attention heads explicitly; and (ii) a Risk-Adaptive Threshold Gating mechanism that jointly models attention entropy and local perplexity, transforming prompt-level risk into deployable retention thresholds. Experiments on LongBench show CompilerKV dominates SOTA methods under a 512-token budget, recovering 97.7\\% of FullKV performance while achieving up to +5.2 points gain over the strongest competitor.",
    "authors": [
      "Ning Yang",
      "Chengzhi Wang",
      "Yibo Liu",
      "Baoliang Tian",
      "Haijun Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08686v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08686v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.08676v1",
    "title": "LLaDA2.1: Speeding Up Text Diffusion via Token Editing",
    "summary": "While LLaDA2.0 showcased the scaling potential of 100B-level block-diffusion models and their inherent parallelization, the delicate equilibrium between decoding speed and generation quality has remained an elusive frontier. Today, we unveil LLaDA2.1, a paradigm shift designed to transcend this trade-off. By seamlessly weaving Token-to-Token (T2T) editing into the conventional Mask-to-Token (M2T) scheme, we introduce a joint, configurable threshold-decoding scheme. This structural innovation gives rise to two distinct personas: the Speedy Mode (S Mode), which audaciously lowers the M2T threshold to bypass traditional constraints while relying on T2T to refine the output; and the Quality Mode (Q Mode), which leans into conservative thresholds to secure superior benchmark performances with manageable efficiency degrade. Furthering this evolution, underpinned by an expansive context window, we implement the first large-scale Reinforcement Learning (RL) framework specifically tailored for dLLMs, anchored by specialized techniques for stable gradient estimation. This alignment not only sharpens reasoning precision but also elevates instruction-following fidelity, bridging the chasm between diffusion dynamics and complex human intent. We culminate this work by releasing LLaDA2.1-Mini (16B) and LLaDA2.1-Flash (100B). Across 33 rigorous benchmarks, LLaDA2.1 delivers strong task performance and lightning-fast decoding speed. Despite its 100B volume, on coding tasks it attains an astounding 892 TPS on HumanEval+, 801 TPS on BigCodeBench, and 663 TPS on LiveCodeBench.",
    "authors": [
      "Tiwei Bie",
      "Maosong Cao",
      "Xiang Cao",
      "Bingsen Chen",
      "Fuyuan Chen",
      "Kun Chen",
      "Lun Du",
      "Daozhuo Feng",
      "Haibo Feng",
      "Mingliang Gong",
      "Zhuocheng Gong",
      "Yanmei Gu",
      "Jian Guan",
      "Kaiyuan Guan",
      "Hongliang He",
      "Zenan Huang",
      "Juyong Jiang",
      "Zhonghui Jiang",
      "Zhenzhong Lan",
      "Chengxi Li",
      "Jianguo Li",
      "Zehuan Li",
      "Huabin Liu",
      "Lin Liu",
      "Guoshan Lu",
      "Yuan Lu",
      "Yuxin Ma",
      "Xingyu Mou",
      "Zhenxuan Pan",
      "Kaida Qiu",
      "Yuji Ren",
      "Jianfeng Tan",
      "Yiding Tian",
      "Zian Wang",
      "Lanning Wei",
      "Tao Wu",
      "Yipeng Xing",
      "Wentao Ye",
      "Liangyu Zha",
      "Tianze Zhang",
      "Xiaolu Zhang",
      "Junbo Zhao",
      "Da Zheng",
      "Hao Zhong",
      "Wanli Zhong",
      "Jun Zhou",
      "Junlin Zhou",
      "Liwang Zhu",
      "Muzhi Zhu",
      "Yihong Zhuang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08676v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08676v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.08617v1",
    "title": "ERIS: Enhancing Privacy and Communication Efficiency in Serverless Federated Learning",
    "summary": "Scaling federated learning (FL) to billion-parameter models introduces critical trade-offs between communication efficiency, model accuracy, and privacy guarantees. Existing solutions often tackle these challenges in isolation, sacrificing accuracy or relying on costly cryptographic tools. We propose ERIS, a serverless FL framework that balances privacy and accuracy while eliminating the server bottleneck and distributing the communication load. ERIS combines a model partitioning strategy, distributing aggregation across multiple client-side aggregators, with a distributed shifted gradient compression mechanism. We theoretically prove that ERIS (i) converges at the same rate as FedAvg under standard assumptions, and (ii) bounds mutual information leakage inversely with the number of aggregators, enabling strong privacy guarantees with no accuracy degradation. Experiments across image and text tasks, including large language models, confirm that ERIS achieves FedAvg-level accuracy while substantially reducing communication cost and improving robustness to membership inference and reconstruction attacks, without relying on heavy cryptography or noise injection.",
    "authors": [
      "Dario Fenoglio",
      "Pasquale Polverino",
      "Jacopo Quizi",
      "Martin Gjoreski",
      "Marc Langheinrich"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08617v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08617v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.09009v1",
    "title": "ANCRe: Adaptive Neural Connection Reassignment for Efficient Depth Scaling",
    "summary": "Scaling network depth has been a central driver behind the success of modern foundation models, yet recent investigations suggest that deep layers are often underutilized. This paper revisits the default mechanism for deepening neural networks, namely residual connections, from an optimization perspective. Rigorous analysis proves that the layout of residual connections can fundamentally shape convergence behavior, and even induces an exponential gap in convergence rates. Prompted by this insight, we introduce adaptive neural connection reassignment (ANCRe), a principled and lightweight framework that parameterizes and learns residual connectivities from the data. ANCRe adaptively reassigns residual connections with negligible computational and memory overhead ($<1\\%$), while enabling more effective utilization of network depth. Extensive numerical tests across pre-training of large language models, diffusion models, and deep ResNets demonstrate consistently accelerated convergence, boosted performance, and enhanced depth efficiency over conventional residual connections.",
    "authors": [
      "Yilang Zhang",
      "Bingcong Li",
      "Niao He",
      "Georgios B. Giannakis"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09009v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09009v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.08933v1",
    "title": "Provably robust learning of regression neural networks using $β$-divergences",
    "summary": "Regression neural networks (NNs) are most commonly trained by minimizing the mean squared prediction error, which is highly sensitive to outliers and data contamination. Existing robust training methods for regression NNs are often limited in scope and rely primarily on empirical validation, with only a few offering partial theoretical guarantees. In this paper, we propose a new robust learning framework for regression NNs based on the $β$-divergence (also known as the density power divergence) which we call `rRNet'. It applies to a broad class of regression NNs, including models with non-smooth activation functions and error densities, and recovers the classical maximum likelihood learning as a special case. The rRNet is implemented via an alternating optimization scheme, for which we establish convergence guarantees to stationary points under mild, verifiable conditions. The (local) robustness of rRNet is theoretically characterized through the influence functions of both the parameter estimates and the resulting rRNet predictor, which are shown to be bounded for suitable choices of the tuning parameter $β$, depending on the error density. We further prove that rRNet attains the optimal 50\\% asymptotic breakdown point at the assumed model for all $β\\in(0, 1]$, providing a strong global robustness guarantee that is largely absent for existing NN learning methods. Our theoretical results are complemented by simulation experiments and real-data analyses, illustrating practical advantages of rRNet over existing approaches in both function approximation problems and prediction tasks with noisy observations.",
    "authors": [
      "Abhik Ghosh",
      "Suryasis Jana"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "cs.NE",
      "stat.ME"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08933v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08933v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.08889v1",
    "title": "Scalable Delphi: Large Language Models for Structured Risk Estimation",
    "summary": "Quantitative risk assessment in high-stakes domains relies on structured expert elicitation to estimate unobservable properties. The gold standard - the Delphi method - produces calibrated, auditable judgments but requires months of coordination and specialist time, placing rigorous risk assessment out of reach for most applications. We investigate whether Large Language Models (LLMs) can serve as scalable proxies for structured expert elicitation. We propose Scalable Delphi, adapting the classical protocol for LLMs with diverse expert personas, iterative refinement, and rationale sharing. Because target quantities are typically unobservable, we develop an evaluation framework based on necessary conditions: calibration against verifiable proxies, sensitivity to evidence, and alignment with human expert judgment. We evaluate in the domain of AI-augmented cybersecurity risk, using three capability benchmarks and independent human elicitation studies. LLM panels achieve strong correlations with benchmark ground truth (Pearson r=0.87-0.95), improve systematically as evidence is added, and align with human expert panels - in one comparison, closer to a human panel than the two human panels are to each other. This demonstrates that LLM-based elicitation can extend structured expert judgment to settings where traditional methods are infeasible, reducing elicitation time from months to minutes.",
    "authors": [
      "Tobias Lorenz",
      "Mario Fritz"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08889v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08889v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.08835v1",
    "title": "Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning",
    "summary": "Value-aware AI should recognise human values and adapt to the value systems (value-based preferences) of different users. This requires operationalization of values, which can be prone to misspecification. The social nature of values demands their representation to adhere to multiple users while value systems are diverse, yet exhibit patterns among groups. In sequential decision making, efforts have been made towards personalization for different goals or values from demonstrations of diverse agents. However, these approaches demand manually designed features or lack value-based interpretability and/or adaptability to diverse user preferences.   We propose algorithms for learning models of value alignment and value systems for a society of agents in Markov Decision Processes (MDPs), based on clustering and preference-based multi-objective reinforcement learning (PbMORL). We jointly learn socially-derived value alignment models (groundings) and a set of value systems that concisely represent different groups of users (clusters) in a society. Each cluster consists of a value system representing the value-based preferences of its members and an approximately Pareto-optimal policy that reflects behaviours aligned with this value system. We evaluate our method against a state-of-the-art PbMORL algorithm and baselines on two MDPs with human values.",
    "authors": [
      "Andrés Holgado-Sánchez",
      "Peter Vamplew",
      "Richard Dazeley",
      "Sascha Ossowski",
      "Holger Billhardt"
    ],
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08835v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08835v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.08793v1",
    "title": "LakeHopper: Cross Data Lakes Column Type Annotation through Model Adaptation",
    "summary": "Column type annotation is vital for tasks like data cleaning, integration, and visualization. Recent solutions rely on resource-intensive language models fine-tuned on well-annotated columns from a particular set of tables, i.e., a source data lake. In this paper, we study whether we can adapt an existing pre-trained LM-based model to a new (i.e., target) data lake to minimize the annotations required on the new data lake. However, challenges include the source-target knowledge gap, selecting informative target data, and fine-tuning without losing shared knowledge exist. We propose LakeHopper, a framework that identifies and resolves the knowledge gap through LM interactions, employs a cluster-based data selection scheme for unannotated columns, and uses an incremental fine-tuning mechanism that gradually adapts the source model to the target data lake. Our experimental results validate the effectiveness of LakeHopper on two different data lake transfers under both low-resource and high-resource settings.",
    "authors": [
      "Yushi Sun",
      "Xujia Li",
      "Nan Tang",
      "Quanqing Xu",
      "Chuanhui Yang",
      "Lei Chen"
    ],
    "categories": [
      "cs.CL",
      "cs.DB"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08793v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08793v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.08740v1",
    "title": "Map of Encoders -- Mapping Sentence Encoders using Quantum Relative Entropy",
    "summary": "We propose a method to compare and visualise sentence encoders at scale by creating a map of encoders where each sentence encoder is represented in relation to the other sentence encoders. Specifically, we first represent a sentence encoder using an embedding matrix of a sentence set, where each row corresponds to the embedding of a sentence. Next, we compute the Pairwise Inner Product (PIP) matrix for a sentence encoder using its embedding matrix. Finally, we create a feature vector for each sentence encoder reflecting its Quantum Relative Entropy (QRE) with respect to a unit base encoder. We construct a map of encoders covering 1101 publicly available sentence encoders, providing a new perspective of the landscape of the pre-trained sentence encoders. Our map accurately reflects various relationships between encoders, where encoders with similar attributes are proximally located on the map. Moreover, our encoder feature vectors can be used to accurately infer downstream task performance of the encoders, such as in retrieval and clustering tasks, demonstrating the faithfulness of our map.",
    "authors": [
      "Gaifan Zhang",
      "Danushka Bollegala"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08740v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08740v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.08688v1",
    "title": "Old wine in old glasses: Comparing computational and qualitative methods in identifying incivility on Persian Twitter during the #MahsaAmini movement",
    "summary": "This paper compares three approaches to detecting incivility in Persian tweets: human qualitative coding, supervised learning with ParsBERT, and large language models (ChatGPT). Using 47,278 tweets from the #MahsaAmini movement in Iran, we evaluate the accuracy and efficiency of each method. ParsBERT substantially outperforms seven evaluated ChatGPT models in identifying hate speech. We also find that ChatGPT struggles not only with subtle cases but also with explicitly uncivil content, and that prompt language (English vs. Persian) does not meaningfully affect its outputs. The study provides a detailed comparison of these approaches and clarifies their strengths and limitations for analyzing hate speech in a low-resource language context.",
    "authors": [
      "Hossein Kermani",
      "Fatemeh Oudlajani",
      "Pardis Yarahmadi",
      "Hamideh Mahdi Soltani",
      "Mohammad Makki",
      "Zahra HosseiniKhoo"
    ],
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08688v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08688v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.08619v1",
    "title": "Enhancing Genetic Algorithms with Graph Neural Networks: A Timetabling Case Study",
    "summary": "This paper investigates the impact of hybridizing a multi-modal Genetic Algorithm with a Graph Neural Network for timetabling optimization. The Graph Neural Network is designed to encapsulate general domain knowledge to improve schedule quality, while the Genetic Algorithm explores different regions of the search space and integrates the deep learning model as an enhancement operator to guide the solution search towards optimality. Initially, both components of the hybrid technique were designed, developed, and optimized independently to solve the tackled task. Multiple experiments were conducted on Staff Rostering, a well-known timetabling problem, to compare the proposed hybridization with the standalone optimized versions of the Genetic Algorithm and Graph Neural Network. The experimental results demonstrate that the proposed hybridization brings statistically significant improvements in both the time efficiency and solution quality metrics, compared to the standalone methods. To the best of our knowledge, this work proposes the first hybridization of a Genetic Algorithm with a Graph Neural Network for solving timetabling problems.",
    "authors": [
      "Laura-Maria Cornei",
      "Mihaela-Elena Breabăn"
    ],
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08619v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08619v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.09015v1",
    "title": "CIC-Trap4Phish: A Unified Multi-Format Dataset for Phishing and Quishing Attachment Detection",
    "summary": "Phishing attacks represents one of the primary attack methods which is used by cyber attackers. In many cases, attackers use deceptive emails along with malicious attachments to trick users into giving away sensitive information or installing malware while compromising entire systems. The flexibility of malicious email attachments makes them stand out as a preferred vector for attackers as they can embed harmful content such as malware or malicious URLs inside standard document formats. Although phishing email defenses have improved a lot, attackers continue to abuse attachments, enabling malicious content to bypass security measures. Moreover, another challenge that researches face in training advance models, is lack of an unified and comprehensive dataset that covers the most prevalent data types. To address this gap, we generated CIC-Trap4Phish, a multi-format dataset containing both malicious and benign samples across five categories commonly used in phishing campaigns: Microsoft Word documents, Excel spreadsheets, PDF files, HTML pages, and QR code images. For the first four file types, a set of execution-free static feature pipeline was proposed, designed to capture structural, lexical, and metadata-based indicators without the need to open or execute files. Feature selection was performed using a combination of SHAP analysis and feature importance, yielding compact, discriminative feature subsets for each file type. The selected features were evaluated by using lightweight machine learning models, including Random Forest, XGBoost, and Decision Tree. All models demonstrate high detection accuracy across formats. For QR code-based phishing (quishing), two complementary methods were implemented: image-based detection by employing Convolutional Neural Networks (CNNs) and lexical analysis of decoded URLs using recent lightweight language models.",
    "authors": [
      "Fatemeh Nejati",
      "Mahdi Rabbani",
      "Mansur Mirani",
      "Gunjan Piya",
      "Igor Opushnyev",
      "Ali A. Ghorbani",
      "Sajjad Dadkhah"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09015v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09015v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.08818v1",
    "title": "FlexMoRE: A Flexible Mixture of Rank-heterogeneous Experts for Efficient Federatedly-trained Large Language Models",
    "summary": "Recent advances in mixture-of-experts architectures have shown that individual experts models can be trained federatedly, i.e., in isolation from other experts by using a common base model to facilitate coordination. However, we hypothesize that full-sized experts may not be necessary for all domains and that instead low-rank adapters may be sufficient. Here, we introduce FlexMoRE, a Flexible Mixture of Rank-heterogenous Experts, which may be either full-sized experts or adapters of a suitable rank. We systematically investigate the trade-off between expert rank and downstream task performance by evaluating $6$ experts with ranks $2^0$ to $2^{14}$ resulting in experiments covering 150 mixtures (96 with 2 experts, 54 with 7 experts) that are evaluated across $120$ tasks. For our experiments, we build on FlexOlmo and turn its pre-trained experts into low-rank versions. Our regression analysis from expert rank to downstream task performance reveals that the best-performing rank is substantially higher for reasoning-heavy benchmarks than for knowledge-heavy benchmarks. These findings on rank sensitivity come with direct implications for memory efficiency: Using optimal ranks, FlexMoRE yields improved downstream task performance (average score $47.18$) compared to the baseline FlexOlmo-style mixture of full-sized experts (average score $45.46$) at less than one third the parameters ($10.75$B for FlexMoRE vs. $33.27$B for FlexOlmo). All code will be made available.",
    "authors": [
      "Annemette Brok Pirchert",
      "Jacob Nielsen",
      "Mogens Henrik From",
      "Lukas Galke Poech",
      "Peter Schneider-Kamp"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08818v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08818v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.08809v1",
    "title": "Efficient Deep Learning for Biometrics: Overview, Challenges and Trends in Ear of Frugal AI",
    "summary": "Recent advances in deep learning, whether on discriminative or generative tasks have been beneficial for various applications, among which security and defense. However, their increasing computational demands during training and deployment translates directly into high energy consumption. As a consequence, this induces a heavy carbon footprint which hinders their widespread use and scalability, but also a limitation when deployed on resource-constrained edge devices for real-time use. In this paper, we briefly survey efficient deep learning methods for biometric applications. Specifically, we tackle the challenges one might incur when training and deploying deep learning approaches, and provide a taxonomy of the various efficient deep learning families. Additionally, we discuss complementary metrics for evaluating the efficiency of these models such as memory, computation, latency, throughput, and advocate for universal and reproducible metrics for better comparison. Last, we give future research directions to consider.",
    "authors": [
      "Karim Haroun",
      "Aya Zitouni",
      "Aicha Zenakhri",
      "Meriem Amel Guessoum",
      "Larbi Boubchir"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08809v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08809v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.08672v1",
    "title": "Learning to Judge: LLMs Designing and Applying Evaluation Rubrics",
    "summary": "Large language models (LLMs) are increasingly used as evaluators for natural language generation, applying human-defined rubrics to assess system outputs. However, human rubrics are often static and misaligned with how models internally represent language quality. We introduce GER-Eval (Generating Evaluation Rubrics for Evaluation) to investigate whether LLMs can design and apply their own evaluation rubrics. We evaluate the semantic coherence and scoring reliability of LLM-defined criteria and their alignment with human criteria. LLMs reliably generate interpretable and task-aware evaluation dimensions and apply them consistently within models, but their scoring reliability degrades in factual and knowledge-intensive settings. Closed-source models such as GPT-4o achieve higher agreement and cross-model generalization than open-weight models such as Llama. Our findings position evaluation as a learned linguistic capability of LLMs, consistent within models but fragmented across them, and call for new methods that jointly model human and LLM evaluative language to improve reliability and interpretability.",
    "authors": [
      "Clemencia Siro",
      "Pourya Aliannejadi",
      "Mohammad Aliannejadi"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08672v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08672v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.08657v1",
    "title": "Two-Stage Data Synthesization: A Statistics-Driven Restricted Trade-off between Privacy and Prediction",
    "summary": "Synthetic data have gained increasing attention across various domains, with a growing emphasis on their performance in downstream prediction tasks. However, most existing synthesis strategies focus on maintaining statistical information. Although some studies address prediction performance guarantees, their single-stage synthesis designs make it challenging to balance the privacy requirements that necessitate significant perturbations and the prediction performance that is sensitive to such perturbations. We propose a two-stage synthesis strategy. In the first stage, we introduce a synthesis-then-hybrid strategy, which involves a synthesis operation to generate pure synthetic data, followed by a hybrid operation that fuses the synthetic data with the original data. In the second stage, we present a kernel ridge regression (KRR)-based synthesis strategy, where a KRR model is first trained on the original data and then used to generate synthetic outputs based on the synthetic inputs produced in the first stage. By leveraging the theoretical strengths of KRR and the covariant distribution retention achieved in the first stage, our proposed two-stage synthesis strategy enables a statistics-driven restricted privacy--prediction trade-off and guarantee optimal prediction performance. We validate our approach and demonstrate its characteristics of being statistics-driven and restricted in achieving the privacy--prediction trade-off both theoretically and numerically. Additionally, we showcase its generalizability through applications to a marketing problem and five real-world datasets.",
    "authors": [
      "Xiaotong Liu",
      "Shao-Bo Lin",
      "Jun Fan",
      "Ding-Xuan Zhou"
    ],
    "categories": [
      "cs.LG",
      "stat.ME"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08657v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08657v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.08563v1",
    "title": "Stateless Yet Not Forgetful: Implicit Memory as a Hidden Channel in LLMs",
    "summary": "Large language models (LLMs) are commonly treated as stateless: once an interaction ends, no information is assumed to persist unless it is explicitly stored and re-supplied. We challenge this assumption by introducing implicit memory-the ability of a model to carry state across otherwise independent interactions by encoding information in its own outputs and later recovering it when those outputs are reintroduced as input. This mechanism does not require any explicit memory module, yet it creates a persistent information channel across inference requests. As a concrete demonstration, we introduce a new class of temporal backdoors, which we call time bombs. Unlike conventional backdoors that activate on a single trigger input, time bombs activate only after a sequence of interactions satisfies hidden conditions accumulated via implicit memory. We show that such behavior can be induced today through straightforward prompting or fine-tuning. Beyond this case study, we analyze broader implications of implicit memory, including covert inter-agent communication, benchmark contamination, targeted manipulation, and training-data poisoning. Finally, we discuss detection challenges and outline directions for stress-testing and evaluation, with the goal of anticipating and controlling future developments. To promote future research, we release code and data at: https://github.com/microsoft/implicitMemory.",
    "authors": [
      "Ahmed Salem",
      "Andrew Paverd",
      "Sahar Abdelnabi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08563v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08563v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.08949v1",
    "title": "Digital Twin and Agentic AI for Wild Fire Disaster Management: Intelligent Virtual Situation Room",
    "summary": "According to the United Nations, wildfire frequency and intensity are projected to increase by approximately 14% by 2030 and 30% by 2050 due to global warming, posing critical threats to life, infrastructure, and ecosystems. Conventional disaster management frameworks rely on static simulations and passive data acquisition, hindering their ability to adapt to arbitrarily evolving wildfire episodes in real-time. To address these limitations, we introduce the Intelligent Virtual Situation Room (IVSR), a bidirectional Digital Twin (DT) platform augmented by autonomous AI agents. The IVSR continuously ingests multisource sensor imagery, weather data, and 3D forest models to create a live virtual replica of the fire environment. A similarity engine powered by AI aligns emerging conditions with a precomputed Disaster Simulation Library, retrieving and calibrating intervention tactics under the watchful eyes of experts. Authorized action-ranging from UAV redeployment to crew reallocation-is cycled back through standardized procedures to the physical layer, completing the loop between response and analysis. We validate IVSR through detailed case-study simulations provided by an industrial partner, demonstrating capabilities in localized incident detection, privacy-preserving playback, collider-based fire-spread projection, and site-specific ML retraining. Our results indicate marked reductions in detection-to-intervention latency and more effective resource coordination versus traditional systems. By uniting real-time bidirectional DTs with agentic AI, IVSR offers a scalable, semi-automated decision-support paradigm for proactive, adaptive wildfire disaster management.",
    "authors": [
      "Mohammad Morsali",
      "Siavash H. Khajavi"
    ],
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08949v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08949v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.08914v1",
    "title": "Gesturing Toward Abstraction: Multimodal Convention Formation in Collaborative Physical Tasks",
    "summary": "A quintessential feature of human intelligence is the ability to create ad hoc conventions over time to achieve shared goals efficiently. We investigate how communication strategies evolve through repeated collaboration as people coordinate on shared procedural abstractions. To this end, we conducted an online unimodal study (n = 98) using natural language to probe abstraction hierarchies. In a follow-up lab study (n = 40), we examined how multimodal communication (speech and gestures) changed during physical collaboration. Pairs used augmented reality to isolate their partner's hand and voice; one participant viewed a 3D virtual tower and sent instructions to the other, who built the physical tower. Participants became faster and more accurate by establishing linguistic and gestural abstractions and using cross-modal redundancy to emphasize key changes from previous interactions. Based on these findings, we extend probabilistic models of convention formation to multimodal settings, capturing shifts in modality preferences. Our findings and model provide building blocks for designing convention-aware intelligent agents situated in the physical world.",
    "authors": [
      "Kiyosu Maeda",
      "William P. McCarthy",
      "Ching-Yi Tsai",
      "Jeffrey Mu",
      "Haoliang Wang",
      "Robert D. Hawkins",
      "Judith E. Fan",
      "Parastoo Abtahi"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08914v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08914v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.08913v1",
    "title": "GEMSS: A Variational Bayesian Method for Discovering Multiple Sparse Solutions in Classification and Regression Problems",
    "summary": "Selecting interpretable feature sets in underdetermined ($n \\ll p$) and highly correlated regimes constitutes a fundamental challenge in data science, particularly when analyzing physical measurements. In such settings, multiple distinct sparse subsets may explain the response equally well. Identifying these alternatives is crucial for generating domain-specific insights into the underlying mechanisms, yet conventional methods typically isolate a single solution, obscuring the full spectrum of plausible explanations.   We present GEMSS (Gaussian Ensemble for Multiple Sparse Solutions), a variational Bayesian framework specifically designed to simultaneously discover multiple, diverse sparse feature combinations. The method employs a structured spike-and-slab prior for sparsity, a mixture of Gaussians to approximate the intractable multimodal posterior, and a Jaccard-based penalty to further control solution diversity. Unlike sequential greedy approaches, GEMSS optimizes the entire ensemble of solutions within a single objective function via stochastic gradient descent.   The method is validated on a comprehensive benchmark comprising 128 synthetic experiments across classification and regression tasks. Results demonstrate that GEMSS scales effectively to high-dimensional settings ($p=5000$) with sample size as small as $n = 50$, generalizes seamlessly to continuous targets, handles missing data natively, and exhibits remarkable robustness to class imbalance and Gaussian noise.   GEMSS is available as a Python package 'gemss' at PyPI. The full GitHub repository at https://github.com/kat-er-ina/gemss/ also includes a free, easy-to-use application suitable for non-coders.",
    "authors": [
      "Kateřina Henclová",
      "Václav Šmídl"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08913v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08913v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.08874v1",
    "title": "Is Reasoning Capability Enough for Safety in Long-Context Language Models?",
    "summary": "Large language models (LLMs) increasingly combine long-context processing with advanced reasoning, enabling them to retrieve and synthesize information distributed across tens of thousands of tokens. A hypothesis is that stronger reasoning capability should improve safety by helping models recognize harmful intent even when it is not stated explicitly. We test this hypothesis in long-context settings where harmful intent is implicit and must be inferred through reasoning, and find that it does not hold. We introduce compositional reasoning attacks, a new threat model in which a harmful query is decomposed into incomplete fragments that scattered throughout a long context. The model is then prompted with a neutral reasoning query that induces retrieval and synthesis, causing the harmful intent to emerge only after composition. Evaluating 14 frontier LLMs on contexts up to 64k tokens, we uncover three findings: (1) models with stronger general reasoning capability are not more robust to compositional reasoning attacks, often assembling the intent yet failing to refuse; (2) safety alignment consistently degrades as context length increases; and (3) inference-time reasoning effort is a key mitigating factor: increasing inference-time compute reduces attack success by over 50 percentage points on GPT-oss-120b model. Together, these results suggest that safety does not automatically scale with reasoning capability, especially under long-context inference.",
    "authors": [
      "Yu Fu",
      "Haz Sameen Shahgir",
      "Huanli Gong",
      "Zhipeng Wei",
      "N. Benjamin Erichson",
      "Yue Dong"
    ],
    "categories": [
      "cs.CL",
      "cs.CR"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08874v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08874v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.08873v1",
    "title": "Whose Name Comes Up? Benchmarking and Intervention-Based Auditing of LLM-Based Scholar Recommendation",
    "summary": "Large language models (LLMs) are increasingly used for academic expert recommendation. Existing audits typically evaluate model outputs in isolation, largely ignoring end-user inference-time interventions. As a result, it remains unclear whether failures such as refusals, hallucinations, and uneven coverage stem from model choice or deployment decisions. We introduce LLMScholarBench, a benchmark for auditing LLM-based scholar recommendation that jointly evaluates model infrastructure and end-user interventions across multiple tasks. LLMScholarBench measures both technical quality and social representation using nine metrics. We instantiate the benchmark in physics expert recommendation and audit 22 LLMs under temperature variation, representation-constrained prompting, and retrieval-augmented generation (RAG) via web search. Our results show that end-user interventions do not yield uniform improvements but instead redistribute error across dimensions. Higher temperature degrades validity, consistency, and factuality. Representation-constrained prompting improves diversity at the expense of factuality, while RAG primarily improves technical quality while reducing diversity and parity. Overall, end-user interventions reshape trade-offs rather than providing a general fix. We release code and data that can be adapted to other disciplines by replacing domain-specific ground truth and metrics.",
    "authors": [
      "Lisette Espin-Noboa",
      "Gonzalo Gabriel Mendez"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CY",
      "cs.SI",
      "physics.soc-ph"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08873v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08873v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.08825v1",
    "title": "A Methodology for Effective Surrogate Learning in Complex Optimization",
    "summary": "Solving complex problems requires continuous effort in developing theory and practice to cope with larger, more difficult scenarios. Working with surrogates is normal for creating a proxy that realistically models the problem into the computer. Thus, the question of how to best define and characterize such a surrogate model is of the utmost importance. In this paper, we introduce the PTME methodology to study deep learning surrogates by analyzing their Precision, Time, Memory, and Energy consumption. We argue that only a combination of numerical and physical performance can lead to a surrogate that is both a trusted scientific substitute for the real problem and an efficient experimental artifact for scalable studies. Here, we propose different surrogates for a real problem in optimally organizing the network of traffic lights in European cities and perform a PTME study on the surrogates' sampling methods, dataset sizes, and resource consumption. We further use the built surrogates in new optimization metaheuristics for decision-making in real cities. We offer better techniques and conclude that the PTME methodology can be used as a guideline for other applications and solvers.",
    "authors": [
      "Tomohiro Harada",
      "Enrique Alba",
      "Gabriel Luque"
    ],
    "categories": [
      "cs.NE"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08825v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08825v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.08819v1",
    "title": "Bayesian Preference Learning for Test-Time Steerable Reward Models",
    "summary": "Reward models are central to aligning language models with human preferences via reinforcement learning (RL). As RL is increasingly applied to settings such as verifiable rewards and multi-objective alignment, RMs are expected to encode more complex and multifaceted preference distributions. However, classifier RMs remain static once trained, limiting their adaptability at test time. We propose Variational In-Context Reward Modeling (ICRM), a novel Bayesian reward modeling objective that enables test-time steerability via in-context preference demonstrations. ICRM casts reward modeling as amortized variational inference over a latent preference probability under the Bradley-Terry model using a conjugate Beta prior. We show that ICRM adapt to unseen preference distributions at test time for both single and multi-objective settings. With more in-context demonstrations, ICRM gains 34% accuracy on SafeRLHF and 9% accuracy on RM-Bench in the single-objective setting, while widening the Pareto frontier with a 4% gain in hypervolume on helpfulness and refusal benchmarks. We further study the practical applicability of ICRM for RL training, showing that it can effectively encode verifiable rewards by outperforming a conventional RM in math reasoning. Finally, we provide theoretical guarantees that the variational objective admits a global interior optimum with finite confidence, and we analyze how KL regularization mitigates reward over-optimization.",
    "authors": [
      "Jiwoo Hong",
      "Shao Tang",
      "Zhipeng Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08819v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08819v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.08751v1",
    "title": "Central Dogma Transformer II: An AI Microscope for Understanding Cellular Regulatory Mechanisms",
    "summary": "Current biological AI models lack interpretability -- their internal representations do not correspond to biological relationships that   researchers can examine. Here we present CDT-II, an \"AI microscope\" whose attention maps are directly interpretable as regulatory structure.   By mirroring the central dogma in its architecture, each attention mechanism corresponds to a specific biological relationship: DNA   self-attention for genomic relationships, RNA self-attention for gene co-regulation, and DNA-to-RNA cross-attention for transcriptional   control. Using only genomic embeddings and raw per-cell expression, CDT-II enables experimental biologists to observe regulatory networks in   their own data. Applied to K562 CRISPRi data, CDT-II predicts perturbation effects (per-gene mean $r = 0.84$) and recovers the GFI1B   regulatory network without supervision (6.6-fold enrichment, $P = 3.5 \\times 10^{-17}$). Two distinct attention mechanisms converge on an RNA   processing module ($P = 1 \\times 10^{-16}$). CDT-II establishes mechanism-oriented AI as an alternative to task-oriented approaches, revealing   regulatory structure rather than merely optimizing predictions.",
    "authors": [
      "Nobuyuki Ota"
    ],
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08751v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08751v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.08724v1",
    "title": "Rotated Lights for Consistent and Efficient 2D Gaussians Inverse Rendering",
    "summary": "Inverse rendering aims to decompose a scene into its geometry, material properties and light conditions under a certain rendering model. It has wide applications like view synthesis, relighting, and scene editing. In recent years, inverse rendering methods have been inspired by view synthesis approaches like neural radiance fields and Gaussian splatting, which are capable of efficiently decomposing a scene into its geometry and radiance. They then further estimate the material and lighting that lead to the observed scene radiance. However, the latter step is highly ambiguous and prior works suffer from inaccurate color and baked shadows in their albedo estimation albeit their regularization. To this end, we propose RotLight, a simple capturing setup, to address the ambiguity. Compared to a usual capture, RotLight only requires the object to be rotated several times during the process. We show that as few as two rotations is effective in reducing artifacts. To further improve 2DGS-based inverse rendering, we additionally introduce a proxy mesh that not only allows accurate incident light tracing, but also enables a residual constraint and improves global illumination handling. We demonstrate with both synthetic and real world datasets that our method achieves superior albedo estimation while keeping efficient computation.",
    "authors": [
      "Geng Lin",
      "Matthias Zwicker"
    ],
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08724v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08724v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.08706v1",
    "title": "Technosocial risks of ideal emotion recognition technologies: A defense of the (social) value of emotional expressions",
    "summary": "The prospect of AI systems that I call ideal emotion recognition technologies (ERTs) is often defended on the assumption that social life would benefit from increased affective transparency. This paper challenges that assumption by examining the technosocial risks posed by ideal ERTs, understood as multimodal systems capable of reliably inferring inner affective states in real time. Drawing on philosophical accounts of emotional expression and social practice, as well as empirical work in affective science and social psychology, I argue that the appeal of such systems rests on a misunderstanding of the social functions of emotional expression. Emotional expressions function not only as read-outs of inner states, but also as tools for coordinating action, enabling moral repair, sustaining interpersonal trust, and supporting collective norms. These functions depend on a background of partial opacity and epistemic friction. When deployed in socially authoritative or evaluative contexts, ideal ERTs threaten this expressive space by collapsing epistemic friction, displacing relational meaning with technology-mediated affective profiles, and narrowing the space for aspirational and role-sensitive expressions. The result is a drift towards affective determinism and ambient forms of affective auditing, which undermine both social cohesion and individual agency. I argue that, although it is intuitive to think that increasing accuracy would legitimise such systems, in the case of ERTs accuracy does not straightforwardly justify their deployment, and may, in some contexts, provide a reason for regulatory restraint. I conclude by defending a function-first regulatory approach that treats expressive discretion and intentional emotional expression as constitutive of certain social goods, and that accordingly seeks to protect these goods from excessive affective legibility.",
    "authors": [
      "Alexandra Pregent"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08706v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08706v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.08682v1",
    "title": "ALIVE: Animate Your World with Lifelike Audio-Video Generation",
    "summary": "Video generation is rapidly evolving towards unified audio-video generation. In this paper, we present ALIVE, a generation model that adapts a pretrained Text-to-Video (T2V) model to Sora-style audio-video generation and animation. In particular, the model unlocks the Text-to-Video&Audio (T2VA) and Reference-to-Video&Audio (animation) capabilities compared to the T2V foundation models. To support the audio-visual synchronization and reference animation, we augment the popular MMDiT architecture with a joint audio-video branch which includes TA-CrossAttn for temporally-aligned cross-modal fusion and UniTemp-RoPE for precise audio-visual alignment. Meanwhile, a comprehensive data pipeline consisting of audio-video captioning, quality control, etc., is carefully designed to collect high-quality finetuning data. Additionally, we introduce a new benchmark to perform a comprehensive model test and comparison. After continue pretraining and finetuning on million-level high-quality data, ALIVE demonstrates outstanding performance, consistently outperforming open-source models and matching or surpassing state-of-the-art commercial solutions. With detailed recipes and benchmarks, we hope ALIVE helps the community develop audio-video generation models more efficiently. Official page: https://github.com/FoundationVision/Alive.",
    "authors": [
      "Ying Guo",
      "Qijun Gan",
      "Yifu Zhang",
      "Jinlai Liu",
      "Yifei Hu",
      "Pan Xie",
      "Dongjun Qian",
      "Yu Zhang",
      "Ruiqi Li",
      "Yuqi Zhang",
      "Ruibiao Lu",
      "Xiaofeng Mei",
      "Bo Han",
      "Xiang Yin",
      "Bingyue Peng",
      "Zehuan Yuan"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08682v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08682v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.08625v1",
    "title": "Do Multilingual LLMs have specialized language heads?",
    "summary": "Multilingual large language models (LLMs) have gained significant popularity for their ability to process and generate text across multiple languages. However, deploying these models in production can be inefficient when only a subset of the supported languages is of interest. There has been some research conducted on identifying whether machine translation models have language-specific or language-agnostic heads, however no research has been conducted for multilingual LLMs, to the best of our knowledge, that as we know are capable of performing diverse tasks beyond just translation. This paper explores whether multilingual LLMs have specialized language attention heads for each language, and investigates the possibility of removing language-specific heads for unwanted languages without degrading performance in the targeted languages. Our findings could inform more efficient deployment strategies for multilingual LLMs, enabling reduced model complexity while maintaining high accuracy for targeted languages.",
    "authors": [
      "Muhammad Naufil"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08625v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08625v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.08561v1",
    "title": "Automating Computational Reproducibility in Social Science: Comparing Prompt-Based and Agent-Based Approaches",
    "summary": "Reproducing computational research is often assumed to be as simple as rerunning the original code with provided data. In practice, missing packages, fragile file paths, version conflicts, or incomplete logic frequently cause analyses to fail, even when materials are shared. This study investigates whether large language models and AI agents can automate the diagnosis and repair of such failures, making computational results easier to reproduce and verify. We evaluate this using a controlled reproducibility testbed built from five fully reproducible R-based social science studies. Realistic failures were injected, ranging from simple issues to complex missing logic, and two automated repair workflows were tested in clean Docker environments. The first workflow is prompt-based, repeatedly querying language models with structured prompts of varying context, while the second uses agent-based systems that inspect files, modify code, and rerun analyses autonomously. Across prompt-based runs, reproduction success ranged from 31-79 percent, with performance strongly influenced by prompt context and error complexity. Complex cases benefited most from additional context. Agent-based workflows performed substantially better, with success rates of 69-96 percent across all complexity levels. These results suggest that automated workflows, especially agent-based systems, can significantly reduce manual effort and improve reproduction success across diverse error types. Unlike prior benchmarks, our testbed isolates post-publication repair under controlled failure modes, allowing direct comparison of prompt-based and agent-based approaches.",
    "authors": [
      "Syed Mehtab Hussain Shah",
      "Frank Hopfgartner",
      "Arnim Bleier"
    ],
    "categories": [
      "cs.SE",
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08561v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08561v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.09007v1",
    "title": "GEBench: Benchmarking Image Generation Models as GUI Environments",
    "summary": "Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity, leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench, a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation. GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score, a novel five-dimensional metric that assesses Goal Achievement, Interaction Logic, Content Consistency, UI Plausibility, and Visual Quality. Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/GEBench.",
    "authors": [
      "Haodong Li",
      "Jingwei Wu",
      "Quan Sun",
      "Guopeng Li",
      "Juanxi Tian",
      "Huanyu Zhang",
      "Yanlin Lai",
      "Ruichuan An",
      "Hongbo Peng",
      "Yuhong Dai",
      "Chenxi Li",
      "Chunmei Qing",
      "Jia Wang",
      "Ziyang Meng",
      "Zheng Ge",
      "Xiangyu Zhang",
      "Daxin Jiang"
    ],
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09007v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09007v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08968v1",
    "title": "stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation",
    "summary": "World Models have emerged as a powerful paradigm for learning compact, predictive representations of environment dynamics, enabling agents to reason, plan, and generalize beyond direct experience. Despite recent interest in World Models, most available implementations remain publication-specific, severely limiting their reusability, increasing the risk of bugs, and reducing evaluation standardization. To mitigate these issues, we introduce stable-worldmodel (SWM), a modular, tested, and documented world-model research ecosystem that provides efficient data-collection tools, standardized environments, planning algorithms, and baseline implementations. In addition, each environment in SWM enables controllable factors of variation, including visual and physical properties, to support robustness and continual learning research. Finally, we demonstrate the utility of SWM by using it to study zero-shot robustness in DINO-WM.",
    "authors": [
      "Lucas Maes",
      "Quentin Le Lidec",
      "Dan Haramati",
      "Nassim Massaudi",
      "Damien Scieur",
      "Yann LeCun",
      "Randall Balestriero"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08968v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08968v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08964v1",
    "title": "A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents",
    "summary": "Understanding an agent's goals helps explain and predict its behaviour, yet there is no established methodology for reliably attributing goals to agentic systems. We propose a framework for evaluating goal-directedness that integrates behavioural evaluation with interpretability-based analyses of models' internal representations. As a case study, we examine an LLM agent navigating a 2D grid world toward a goal state. Behaviourally, we evaluate the agent against an optimal policy across varying grid sizes, obstacle densities, and goal structures, finding that performance scales with task difficulty while remaining robust to difficulty-preserving transformations and complex goal structures. We then use probing methods to decode the agent's internal representations of the environment state and its multi-step action plans. We find that the LLM agent non-linearly encodes a coarse spatial map of the environment, preserving approximate task-relevant cues about its position and the goal location; that its actions are broadly consistent with these internal representations; and that reasoning reorganises them, shifting from broader environment structural cues toward information supporting immediate action selection. Our findings support the view that introspective examination is required beyond behavioural evaluations to characterise how agents represent and pursue their objectives.",
    "authors": [
      "Raghu Arghal",
      "Fade Chen",
      "Niall Dalton",
      "Evgenii Kortukov",
      "Calum McNamara",
      "Angelos Nalmpantis",
      "Moksh Nirvaan",
      "Gabriele Sarti",
      "Mario Giulianelli"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08964v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08964v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08934v1",
    "title": "StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors",
    "summary": "AI-text detectors face a critical robustness challenge: adversarial paraphrasing attacks that preserve semantics while evading detection. We introduce StealthRL, a reinforcement learning framework that stress-tests detector robustness under realistic adversarial conditions. StealthRL trains a paraphrase policy against a multi-detector ensemble using Group Relative Policy Optimization (GRPO) with LoRA adapters on Qwen3-4B, optimizing a composite reward that balances detector evasion with semantic preservation. We evaluate six attack settings (M0-M5) against three detector families (RoBERTa, FastDetectGPT, and Binoculars) at the security-relevant 1% false positive rate operating point. StealthRL achieves near-zero detection (0.001 mean TPR@1%FPR), reduces mean AUROC from 0.74 to 0.27, and attains a 99.9% attack success rate. Critically, attacks transfer to a held-out detector family not seen during training, revealing shared architectural vulnerabilities rather than detector-specific brittleness. We additionally conduct LLM-based quality evaluation via Likert scoring, analyze detector score distributions to explain why evasion succeeds, and provide per-detector AUROC with bootstrap confidence intervals. Our results expose significant robustness gaps in current AI-text detection and establish StealthRL as a principled adversarial evaluation protocol. Code and evaluation pipeline are publicly available at https://github.com/suraj-ranganath/StealthRL.",
    "authors": [
      "Suraj Ranganath",
      "Atharv Ramesh"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08934v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08934v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08886v1",
    "title": "Contrastive Learning for Diversity-Aware Product Recommendations in Retail",
    "summary": "Recommender systems often struggle with long-tail distributions and limited item catalog exposure, where a small subset of popular items dominates recommendations. This challenge is especially critical in large-scale online retail settings with extensive and diverse product assortments. This paper introduces an approach to enhance catalog coverage without compromising recommendation quality in the existing digital recommendation pipeline at IKEA Retail. Drawing inspiration from recent advances in negative sampling to address popularity bias, we integrate contrastive learning with carefully selected negative samples. Through offline and online evaluations, we demonstrate that our method improves catalog coverage, ensuring a more diverse set of recommendations yet preserving strong recommendation performance.",
    "authors": [
      "Vasileios Karlis",
      "Ezgi Yıldırım",
      "David Vos",
      "Maarten de Rijke"
    ],
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08886v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08886v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08877v1",
    "title": "Stress-Testing Alignment Audits With Prompt-Level Strategic Deception",
    "summary": "Alignment audits aim to robustly identify hidden goals from strategic, situationally aware misaligned models. Despite this threat model, existing auditing methods have not been systematically stress-tested against deception strategies. We address this gap, implementing an automatic red-team pipeline that generates deception strategies (in the form of system prompts) tailored to specific white-box and black-box auditing methods. Stress-testing assistant prefills, user persona sampling, sparse autoencoders, and token embedding similarity methods against secret-keeping model organisms, our automatic red-team pipeline finds prompts that deceive both the black-box and white-box methods into confident, incorrect guesses. Our results provide the first documented evidence of activation-based strategic deception, and suggest that current black-box and white-box methods would not be robust to a sufficiently capable misaligned model.",
    "authors": [
      "Oliver Daniels",
      "Perusha Moodley",
      "Ben Marlin",
      "David Lindner"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08877v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08877v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08859v1",
    "title": "Magnitude Distance: A Geometric Measure of Dataset Similarity",
    "summary": "Quantifying the distance between datasets is a fundamental question in mathematics and machine learning. We propose \\textit{magnitude distance}, a novel distance metric defined on finite datasets using the notion of the \\emph{magnitude} of a metric space. The proposed distance incorporates a tunable scaling parameter, $t$, that controls the sensitivity to global structure (small $t$) and finer details (large $t$). We prove several theoretical properties of magnitude distance, including its limiting behavior across scales and conditions under which it satisfies key metric properties. In contrast to classical distances, we show that magnitude distance remains discriminative in high-dimensional settings when the scale is appropriately tuned. We further demonstrate how magnitude distance can be used as a training objective for push-forward generative models. Our experimental results support our theoretical analysis and demonstrate that magnitude distance provides meaningful signals, comparable to established distance-based generative approaches.",
    "authors": [
      "Sahel Torkamani",
      "Henry Gouk",
      "Rik Sarkar"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08859v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08859v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08848v1",
    "title": "Deciding the Satisfiability of Combined Qualitative Constraint Networks",
    "summary": "Among the various forms of reasoning studied in the context of artificial intelligence, qualitative reasoning makes it possible to infer new knowledge in the context of imprecise, incomplete information without numerical values. In this paper, we propose a formal framework unifying several forms of extensions and combinations of qualitative formalisms, including multi-scale reasoning, temporal sequences, and loose integrations. This framework makes it possible to reason in the context of each of these combinations and extensions, but also to study in a unified way the satisfiability decision and its complexity. In particular, we establish two complementary theorems guaranteeing that the satisfiability decision is polynomial, and we use them to recover the known results of the size-topology combination. We also generalize the main definition of qualitative formalism to include qualitative formalisms excluded from the definitions of the literature, important in the context of combinations.",
    "authors": [
      "Quentin Cohen-Solal",
      "Alexandre Niveau",
      "Maroua Bouzid"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08848v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08848v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08829v1",
    "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions",
    "summary": "Reward models (RMs) are crucial for the training of large language models (LLMs), yet they typically rely on large-scale human-annotated preference pairs. With the widespread deployment of LLMs, in-the-wild interactions have emerged as a rich source of implicit reward signals. This raises the question: Can we develop reward models directly from in-the-wild interactions? In this work, we explore this possibility by adopting WildChat as an interaction source and proposing a pipeline to extract reliable human feedback, yielding 186k high-quality instances for training WildReward via ordinal regression directly on user feedback without preference pairs. Extensive experiments demonstrate that WildReward achieves comparable or even superior performance compared to conventional reward models, with improved calibration and cross-sample consistency. We also observe that WildReward benefits directly from user diversity, where more users yield stronger reward models. Finally, we apply WildReward to online DPO training and observe significant improvements across various tasks. Code and data are released at https://github.com/THU-KEG/WildReward.",
    "authors": [
      "Hao Peng",
      "Yunjia Qi",
      "Xiaozhi Wang",
      "Zijun Yao",
      "Lei Hou",
      "Juanzi Li"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08829v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08829v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08828v1",
    "title": "VideoVeritas: AI-Generated Video Detection via Perception Pretext Reinforcement Learning",
    "summary": "The growing capability of video generation poses escalating security risks, making reliable detection increasingly essential. In this paper, we introduce VideoVeritas, a framework that integrates fine-grained perception and fact-based reasoning. We observe that while current multi-modal large language models (MLLMs) exhibit strong reasoning capacity, their granular perception ability remains limited. To mitigate this, we introduce Joint Preference Alignment and Perception Pretext Reinforcement Learning (PPRL). Specifically, rather than directly optimizing for detection task, we adopt general spatiotemporal grounding and self-supervised object counting in the RL stage, enhancing detection performance with simple perception pretext tasks. To facilitate robust evaluation, we further introduce MintVid, a light yet high-quality dataset containing 3K videos from 9 state-of-the-art generators, along with a real-world collected subset that has factual errors in content. Experimental results demonstrate that existing methods tend to bias towards either superficial reasoning or mechanical analysis, while VideoVeritas achieves more balanced performance across diverse benchmarks.",
    "authors": [
      "Hao Tan",
      "Jun Lan",
      "Senyuan Shi",
      "Zichang Tan",
      "Zijian Yu",
      "Huijia Zhu",
      "Weiqiang Wang",
      "Jun Wan",
      "Zhen Lei"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08828v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08828v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08797v1",
    "title": "Addressing data annotation scarcity in Brain Tumor Segmentation on 3D MRI scan Using a Semi-Supervised Teacher-Student Framework",
    "summary": "Accurate brain tumor segmentation from MRI is limited by expensive annotations and data heterogeneity across scanners and sites. We propose a semi-supervised teacher-student framework that combines an uncertainty-aware pseudo-labeling teacher with a progressive, confidence-based curriculum for the student. The teacher produces probabilistic masks and per-pixel uncertainty; unlabeled scans are ranked by image-level confidence and introduced in stages, while a dual-loss objective trains the student to learn from high-confidence regions and unlearn low-confidence ones. Agreement-based refinement further improves pseudo-label quality. On BraTS 2021, validation DSC increased from 0.393 (10% data) to 0.872 (100%), with the largest gains in early stages, demonstrating data efficiency. The teacher reached a validation DSC of 0.922, and the student surpassed the teacher on tumor subregions (e.g., NCR/NET 0.797 and Edema 0.980); notably, the student recovered the Enhancing class (DSC 0.620) where the teacher failed. These results show that confidence-driven curricula and selective unlearning provide robust segmentation under limited supervision and noisy pseudo-labels.",
    "authors": [
      "Jiaming Liu",
      "Cheng Ding",
      "Daoqiang Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08797v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08797v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08796v1",
    "title": "The Use of AI Tools to Develop and Validate Q-Matrices",
    "summary": "Constructing a Q-matrix is a critical but labor-intensive step in cognitive diagnostic modeling (CDM). This study investigates whether AI tools (i.e., general language models) can support Q-matrix development by comparing AI-generated Q-matrices with a validated Q-matrix from Li and Suen (2013) for a reading comprehension test. In May 2025, multiple AI models were provided with the same training materials as human experts. Agreement among AI-generated Q-matrices, the validated Q-matrix, and human raters' Q-matrices was assessed using Cohen's kappa. Results showed substantial variation across AI models, with Google Gemini 2.5 Pro achieving the highest agreement (Kappa = 0.63) with the validated Q-matrix, exceeding that of all human experts. A follow-up analysis in January 2026 using newer AI versions, however, revealed lower agreement with the validated Q-matrix. Implications and directions for future research are discussed.",
    "authors": [
      "Kevin Fan",
      "Jacquelyn A. Bialo",
      "Hongli Li"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08796v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08796v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08774v1",
    "title": "Default Machine Learning Hyperparameters Do Not Provide Informative Initialization for Bayesian Optimization",
    "summary": "Bayesian Optimization (BO) is a standard tool for hyperparameter tuning thanks to its sample efficiency on expensive black-box functions. While most BO pipelines begin with uniform random initialization, default hyperparameter values shipped with popular ML libraries such as scikit-learn encode implicit expert knowledge and could serve as informative starting points that accelerate convergence. This hypothesis, despite its intuitive appeal, has remained largely unexamined. We formalize the idea by initializing BO with points drawn from truncated Gaussian distributions centered at library defaults and compare the resulting trajectories against a uniform-random baseline. We conduct an extensive empirical evaluation spanning three BO back-ends (BoTorch, Optuna, Scikit-Optimize), three model families (Random Forests, Support Vector Machines, Multilayer Perceptrons), and five benchmark datasets covering classification and regression tasks. Performance is assessed through convergence speed and final predictive quality, and statistical significance is determined via one-sided binomial tests. Across all conditions, default-informed initialization yields no statistically significant advantage over purely random sampling, with p-values ranging from 0.141 to 0.908. A sensitivity analysis on the prior variance confirms that, while tighter concentration around the defaults improves early evaluations, this transient benefit vanishes as optimization progresses, leaving final performance unchanged. Our results provide no evidence that default hyperparameters encode useful directional information for optimization. We therefore recommend that practitioners treat hyperparameter tuning as an integral part of model development and favor principled, data-driven search strategies over heuristic reliance on library defaults.",
    "authors": [
      "Nicolás Villagrán Prieto",
      "Eduardo C. Garrido-Merchán"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08774v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08774v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08768v1",
    "title": "FreqLens: Interpretable Frequency Attribution for Time Series Forecasting",
    "summary": "Time series forecasting models often lack interpretability, limiting their adoption in domains requiring explainable predictions. We propose \\textsc{FreqLens}, an interpretable forecasting framework that discovers and attributes predictions to learnable frequency components. \\textsc{FreqLens} introduces two key innovations: (1) \\emph{learnable frequency discovery} -- frequency bases are parameterized via sigmoid mapping and learned from data with diversity regularization, enabling automatic discovery of dominant periodic patterns without domain knowledge; and (2) \\emph{axiomatic frequency attribution} -- a theoretically grounded framework that provably satisfies Completeness, Faithfulness, Null-Frequency, and Symmetry axioms, with per-frequency attributions equivalent to Shapley values. On Traffic and Weather datasets, \\textsc{FreqLens} achieves competitive or superior performance while discovering physically meaningful frequencies: all 5 independent runs discover the 24-hour daily cycle ($24.6 \\pm 0.1$h, 2.5\\% error) and 12-hour half-daily cycle ($11.8 \\pm 0.1$h, 1.6\\% error) on Traffic, and weekly cycles ($10\\times$ longer than the input window) on Weather. These results demonstrate genuine frequency-level knowledge discovery with formal theoretical guarantees on attribution quality.",
    "authors": [
      "Chi-Sheng Chen",
      "Xinyu Zhang",
      "En-Jui Kuo",
      "Guan-Ying Chen",
      "Qiuzhe Xie",
      "Fan Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08768v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08768v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08735v1",
    "title": "From Correspondence to Actions: Human-Like Multi-Image Spatial Reasoning in Multi-modal Large Language Models",
    "summary": "While multimodal large language models (MLLMs) have made substantial progress in single-image spatial reasoning, multi-image spatial reasoning, which requires integration of information from multiple viewpoints, remains challenging. Cognitive studies suggest that humans address such tasks through two mechanisms: cross-view correspondence, which identifies regions across different views that correspond to the same physical locations, and stepwise viewpoint transformation, which composes relative viewpoint changes sequentially. However, existing studies incorporate these mechanisms only partially and often implicitly, without explicit supervision for both. We propose Human-Aware Training for Cross-view correspondence and viewpoint cHange (HATCH), a training framework with two complementary objectives: (1) Patch-Level Spatial Alignment, which encourages patch representations to align across views for spatially corresponding regions, and (2) Action-then-Answer Reasoning, which requires the model to generate explicit viewpoint transition actions before predicting the final answer. Experiments on three benchmarks demonstrate that HATCH consistently outperforms baselines of comparable size by a clear margin and achieves competitive results against much larger models, while preserving single-image reasoning capabilities.",
    "authors": [
      "Masanari Oi",
      "Koki Maeda",
      "Ryuto Koike",
      "Daisuke Oba",
      "Nakamasa Inoue",
      "Naoaki Okazaki"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08735v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08735v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08632v1",
    "title": "We Should Separate Memorization from Copyright",
    "summary": "The widespread use of foundation models has introduced a new risk factor of copyright issue. This issue is leading to an active, lively and on-going debate amongst the data-science community as well as amongst legal scholars. Where claims and results across both sides are often interpreted in different ways and leading to different implications. Our position is that much of the technical literature relies on traditional reconstruction techniques that are not designed for copyright analysis. As a result, memorization and copying have been conflated across both technical and legal communities and in multiple contexts. We argue that memorization, as commonly studied in data science, should not be equated with copying and should not be used as a proxy for copyright infringement. We distinguish technical signals that meaningfully indicate infringement risk from those that instead reflect lawful generalization or high-frequency content. Based on this analysis, we advocate for an output-level, risk-based evaluation process that aligns technical assessments with established copyright standards and provides a more principled foundation for research, auditing, and policy.",
    "authors": [
      "Adi Haviv",
      "Niva Elkin-Koren",
      "Uri Hacohen",
      "Roi Livni",
      "Shay Moran"
    ],
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08632v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08632v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08593v1",
    "title": "Kissan-Dost: Bridging the Last Mile in Smallholder Precision Agriculture with Conversational IoT",
    "summary": "We present Kissan-Dost, a multilingual, sensor-grounded conversational system that turns live on-farm measurements and weather into plain-language guidance delivered over WhatsApp text or voice. The system couples commodity soil and climate sensors with retrieval-augmented generation, then enforces grounding, traceability, and proactive alerts through a modular pipeline. In a 90-day, two-site pilot with five participants, we ran three phases (baseline, dashboard only, chatbot only). Dashboard engagement was sporadic and faded, while the chatbot was used nearly daily and informed concrete actions. Controlled tests on 99 sensor-grounded crop queries achieved over 90 percent correctness with subsecond end-to-end latency, alongside high-quality translation outputs. Results show that careful last-mile integration, not novel circuitry, unlocks the latent value of existing Agri-IoT for smallholders.",
    "authors": [
      "Muhammad Saad Ali",
      "Daanish U. Khan",
      "Laiba Intizar Ahmad",
      "Umer Irfan",
      "Maryam Mustafa",
      "Naveed Anwar Bhatti",
      "Muhammad Hamad Alizai"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08593v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08593v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08565v1",
    "title": "Agent-Supported Foresight for AI Systemic Risks: AI Agents for Breadth, Experts for Judgment",
    "summary": "AI impact assessments often stress near-term risks because human judgment degrades over longer horizons, exemplifying the Collingridge dilemma: foresight is most needed when knowledge is scarcest. To address long-term systemic risks, we introduce a scalable approach that simulates in-silico agents using the strategic foresight method of the Futures Wheel. We applied it to four AI uses spanning Technology Readiness Levels (TRLs): Chatbot Companion (TRL 9, mature), AI Toy (TRL 7, medium), Griefbot (TRL 5, low), and Death App (TRL 2, conceptual). Across 30 agent runs per use, agents produced 86-110 consequences, condensed into 27-47 unique risks. To benchmark the agent outputs against human perspectives, we collected evaluations from 290 domain experts and 7 leaders, and conducted Futures Wheel sessions with 42 experts and 42 laypeople. Agents generated many systemic consequences across runs. Compared with these outputs, experts identified fewer risks, typically less systemic but judged more likely, whereas laypeople surfaced more emotionally salient concerns that were generally less systemic. We propose a hybrid foresight workflow, wherein agents broaden systemic coverage, and humans provide contextual grounding. Our dataset is available at: https://social-dynamics.net/ai-risks/foresight.",
    "authors": [
      "Leon Fröhling",
      "Alessandro Giaconia",
      "Edyta Paulina Bogucka",
      "Daniele Quercia"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08565v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08565v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.08997v1",
    "title": "Paradox of De-identification: A Critique of HIPAA Safe Harbour in the Age of LLMs",
    "summary": "Privacy is a human right that sustains patient-provider trust. Clinical notes capture a patient's private vulnerability and individuality, which are used for care coordination and research. Under HIPAA Safe Harbor, these notes are de-identified to protect patient privacy. However, Safe Harbor was designed for an era of categorical tabular data, focusing on the removal of explicit identifiers while ignoring the latent information found in correlations between identity and quasi-identifiers, which can be captured by modern LLMs. We first formalize these correlations using a causal graph, then validate it empirically through individual re-identification of patients from scrubbed notes. The paradox of de-identification is further shown through a diagnosis ablation: even when all other information is removed, the model can predict the patient's neighborhood based on diagnosis alone. This position paper raises the question of how we can act as a community to uphold patient-provider trust when de-identification is inherently imperfect. We aim to raise awareness and discuss actionable recommendations.",
    "authors": [
      "Lavender Y. Jiang",
      "Xujin Chris Liu",
      "Kyunghyun Cho",
      "Eric K. Oermann"
    ],
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08997v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08997v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.08880v1",
    "title": "Differentiable Logical Programming for Quantum Circuit Discovery and Optimization",
    "summary": "Designing high-fidelity quantum circuits remains challenging, and current paradigms often depend on heuristic, fixed-ansatz structures or rule-based compilers that can be suboptimal or lack generality. We introduce a neuro-symbolic framework that reframes quantum circuit design as a differentiable logic programming problem. Our model represents a scaffold of potential quantum gates and parameterized operations as a set of learnable, continuous ``truth values'' or ``switches,'' $s \\in [0, 1]^N$. These switches are optimized via standard gradient descent to satisfy a user-defined set of differentiable, logical axioms (e.g., correctness, simplicity, robustness). We provide a theoretical formulation bridging continuous logic (via T-norms) and unitary evolution (via geodesic interpolation), while addressing the barren plateau problem through biased initialization. We illustrate the approach on tasks including discovery of a 4-qubit Quantum Fourier Transform (QFT) from a scaffold of 21 candidate gates. We also report a hardware-aware adaptation experiment on the 133-qubit IBM Torino processor, where the method improved fidelity by 59.3 percentage points in a localized routing task while adapting to hardware failures.",
    "authors": [
      "Antonin Sulc"
    ],
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08880v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08880v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.08857v1",
    "title": "Discovering Interpretable Algorithms by Decompiling Transformers to RASP",
    "summary": "Recent work has shown that the computations of Transformers can be simulated in the RASP family of programming languages. These findings have enabled improved understanding of the expressive capacity and generalization abilities of Transformers. In particular, Transformers have been suggested to length-generalize exactly on problems that have simple RASP programs. However, it remains open whether trained models actually implement simple interpretable programs. In this paper, we present a general method to extract such programs from trained Transformers. The idea is to faithfully re-parameterize a Transformer as a RASP program and then apply causal interventions to discover a small sufficient sub-program. In experiments on small Transformers trained on algorithmic and formal language tasks, we show that our method often recovers simple and interpretable RASP programs from length-generalizing transformers. Our results provide the most direct evidence so far that Transformers internally implement simple RASP programs.",
    "authors": [
      "Xinting Huang",
      "Aleksandra Bakalova",
      "Satwik Bhattamishra",
      "William Merrill",
      "Michael Hahn"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08857v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08857v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.08810v1",
    "title": "$\\texttt{lrnnx}$: A library for Linear RNNs",
    "summary": "Linear recurrent neural networks (LRNNs) provide a structured approach to sequence modeling that bridges classical linear dynamical systems and modern deep learning, offering both expressive power and theoretical guarantees on stability and trainability. In recent years, multiple LRNN-based architectures have been proposed, each introducing distinct parameterizations, discretization schemes, and implementation constraints. However, existing implementations are fragmented across different software frameworks, often rely on framework-specific optimizations, and in some cases require custom CUDA kernels or lack publicly available code altogether. As a result, using, comparing, or extending LRNNs requires substantial implementation effort. To address this, we introduce $\\texttt{lrnnx}$, a unified software library that implements several modern LRNN architectures under a common interface. The library exposes multiple levels of control, allowing users to work directly with core components or higher-level model abstractions. $\\texttt{lrnnx}$ aims to improve accessibility, reproducibility, and extensibility of LRNN research and applications. We make our code available under a permissive MIT license.",
    "authors": [
      "Karan Bania",
      "Soham Kalburgi",
      "Manit Tanwar",
      " Dhruthi",
      "Aditya Nagarsekar",
      "Harshvardhan Mestha",
      "Naman Chibber",
      "Raj Deshmukh",
      "Anish Sathyanarayanan",
      "Aarush Rathore",
      "Pratham Chheda"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08810v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08810v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.08723v1",
    "title": "Data Reconstruction: Identifiability and Optimization with Sample Splitting",
    "summary": "Training data reconstruction from KKT conditions has shown striking empirical success, yet it remains unclear when the resulting KKT equations have unique solutions and, even in identifiable regimes, how to reliably recover solutions by optimization. This work hereby focuses on these two complementary questions: identifiability and optimization. On the identifiability side, we discuss the sufficient conditions for KKT system of two-layer networks with polynomial activations to uniquely determine the training data, providing a theoretical explanation of when and why reconstruction is possible. On the optimization side, we introduce sample splitting, a curvature-aware refinement step applicable to general reconstruction objectives (not limited to KKT-based formulations): it creates additional descent directions to escape poor stationary points and refine solutions. Experiments demonstrate that augmenting several existing reconstruction methods with sample splitting consistently improves reconstruction performance.",
    "authors": [
      "Yujie Shen",
      "Zihan Wang",
      "Jian Qian",
      "Qi Lei"
    ],
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08723v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08723v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.08711v1",
    "title": "TimeChat-Captioner: Scripting Multi-Scene Videos with Time-Aware and Structural Audio-Visual Captions",
    "summary": "This paper proposes Omni Dense Captioning, a novel task designed to generate continuous, fine-grained, and structured audio-visual narratives with explicit timestamps. To ensure dense semantic coverage, we introduce a six-dimensional structural schema to create \"script-like\" captions, enabling readers to vividly imagine the video content scene by scene, akin to a cinematographic screenplay. To facilitate research, we construct OmniDCBench, a high-quality, human-annotated benchmark, and propose SodaM, a unified metric that evaluates time-aware detailed descriptions while mitigating scene boundary ambiguity. Furthermore, we construct a training dataset, TimeChatCap-42K, and present TimeChat-Captioner-7B, a strong baseline trained via SFT and GRPO with task-specific rewards. Extensive experiments demonstrate that TimeChat-Captioner-7B achieves state-of-the-art performance, surpassing Gemini-2.5-Pro, while its generated dense descriptions significantly boost downstream capabilities in audio-visual reasoning (DailyOmni and WorldSense) and temporal grounding (Charades-STA). All datasets, models, and code will be made publicly available at https://github.com/yaolinli/TimeChat-Captioner.",
    "authors": [
      "Linli Yao",
      "Yuancheng Wei",
      "Yaojie Zhang",
      "Lei Li",
      "Xinlong Chen",
      "Feifan Song",
      "Ziyue Wang",
      "Kun Ouyang",
      "Yuanxin Liu",
      "Lingpeng Kong",
      "Qi Liu",
      "Pengfei Wan",
      "Kun Gai",
      "Yuanxing Zhang",
      "Xu Sun"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08711v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08711v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.08689v1",
    "title": "Learning To Sample From Diffusion Models Via Inverse Reinforcement Learning",
    "summary": "Diffusion models generate samples through an iterative denoising process, guided by a neural network. While training the denoiser on real-world data is computationally demanding, the sampling procedure itself is more flexible. This adaptability serves as a key lever in practice, enabling improvements in both the quality of generated samples and the efficiency of the sampling process. In this work, we introduce an inverse reinforcement learning framework for learning sampling strategies without retraining the denoiser. We formulate the diffusion sampling procedure as a discrete-time finite-horizon Markov Decision Process, where actions correspond to optional modifications of the sampling dynamics. To optimize action scheduling, we avoid defining an explicit reward function. Instead, we directly match the target behavior expected from the sampler using policy gradient techniques. We provide experimental evidence that this approach can improve the quality of samples generated by pretrained diffusion models and automatically tune sampling hyperparameters.",
    "authors": [
      "Constant Bourdrez",
      "Alexandre Vérine",
      "Olivier Cappé"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08689v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08689v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.08580v1",
    "title": "retinalysis-vascx: An explainable software toolbox for the extraction of retinal vascular biomarkers",
    "summary": "The automatic extraction of retinal vascular biomarkers from color fundus images (CFI) is essential for large-scale studies of the retinal vasculature. We present VascX, an open-source Python toolbox designed for the automated extraction of biomarkers from artery and vein segmentations. The VascX workflow processes vessel segmentation masks into skeletons to build undirected and directed vessel graphs, which are then used to resolve segments into continuous vessels. This architecture enables the calculation of a comprehensive suite of biomarkers, including vascular density, bifurcation angles, central retinal equivalents (CREs), tortuosity, and temporal angles, alongside image quality metrics.   A distinguishing feature of VascX is its region awareness; by utilizing the fovea, optic disc, and CFI boundaries as anatomical landmarks, the tool ensures spatially standardized measurements and identifies when specific biomarkers are not computable. Spatially localized biomarkers are calculated over grids relative to these landmarks, facilitating precise clinical analysis. Released via GitHub and PyPI, VascX provides an explainable and modifiable framework that supports reproducible vascular research through integrated visualizations. By enabling the rapid extraction of established biomarkers and the development of new ones, VascX advances the field of oculomics, offering a robust, computationally efficient solution for scalable deployment in large-scale clinical and epidemiological databases.",
    "authors": [
      "Jose D. Vargas Quiros",
      "Michael J. Beyeler",
      "Sofia Ortin Vela",
      "EyeNED Reading Center",
      "Sven Bergmann",
      "Caroline C. W. Klaver",
      "Bart Liefers"
    ],
    "categories": [
      "q-bio.TO",
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08580v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08580v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.08986v1",
    "title": "Improving Detection of Rare Nodes in Hierarchical Multi-Label Learning",
    "summary": "In hierarchical multi-label classification, a persistent challenge is enabling model predictions to reach deeper levels of the hierarchy for more detailed or fine-grained classifications. This difficulty partly arises from the natural rarity of certain classes (or hierarchical nodes) and the hierarchical constraint that ensures child nodes are almost always less frequent than their parents. To address this, we propose a weighted loss objective for neural networks that combines node-wise imbalance weighting with focal weighting components, the latter leveraging modern quantification of ensemble uncertainties. By emphasizing rare nodes rather than rare observations (data points), and focusing on uncertain nodes for each model output distribution during training, we observe improvements in recall by up to a factor of five on benchmark datasets, along with statistically significant gains in $F_{1}$ score. We also show our approach aids convolutional networks on challenging tasks, as in situations with suboptimal encoders or limited data.",
    "authors": [
      "Isaac Xu",
      "Martin Gillis",
      "Ayushi Sharma",
      "Benjamin Misiuk",
      "Craig J. Brown",
      "Thomas Trappenberg"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08986v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08986v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.08958v1",
    "title": "Grow with the Flow: 4D Reconstruction of Growing Plants with Gaussian Flow Fields",
    "summary": "Modeling the time-varying 3D appearance of plants during their growth poses unique challenges: unlike many dynamic scenes, plants generate new geometry over time as they expand, branch, and differentiate. Recent motion modeling techniques are ill-suited to this problem setting. For example, deformation fields cannot introduce new geometry, and 4D Gaussian splatting constrains motion to a linear trajectory in space and time and cannot track the same set of Gaussians over time. Here, we introduce a 3D Gaussian flow field representation that models plant growth as a time-varying derivative over Gaussian parameters -- position, scale, orientation, color, and opacity -- enabling nonlinear and continuous-time growth dynamics. To initialize a sufficient set of Gaussian primitives, we reconstruct the mature plant and learn a process of reverse growth, effectively simulating the plant's developmental history in reverse. Our approach achieves superior image quality and geometric accuracy compared to prior methods on multi-view timelapse datasets of plant growth, providing a new approach for appearance modeling of growing 3D structures.",
    "authors": [
      "Weihan Luo",
      "Lily Goli",
      "Sherwin Bahmani",
      "Felix Taubner",
      "Andrea Tagliasacchi",
      "David B. Lindell"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08958v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08958v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.08820v1",
    "title": "Omni-Video 2: Scaling MLLM-Conditioned Diffusion for Unified Video Generation and Editing",
    "summary": "We present Omni-Video 2, a scalable and computationally efficient model that connects pretrained multimodal large-language models (MLLMs) with video diffusion models for unified video generation and editing. Our key idea is to exploit the understanding and reasoning capabilities of MLLMs to produce explicit target captions to interpret user instructions. In this way, the rich contextual representations from the understanding model are directly used to guide the generative process, thereby improving performance on complex and compositional editing. Moreover, a lightweight adapter is developed to inject multimodal conditional tokens into pretrained text-to-video diffusion models, allowing maximum reuse of their powerful generative priors in a parameter-efficient manner. Benefiting from these designs, we scale up Omni-Video 2 to a 14B video diffusion model on meticulously curated training data with quality, supporting high quality text-to-video generation and various video editing tasks such as object removal, addition, background change, complex motion editing, \\emph{etc.} We evaluate the performance of Omni-Video 2 on the FiVE benchmark for fine-grained video editing and the VBench benchmark for text-to-video generation. The results demonstrate its superior ability to follow complex compositional instructions in video editing, while also achieving competitive or superior quality in video generation tasks.",
    "authors": [
      "Hao Yang",
      "Zhiyu Tan",
      "Jia Gong",
      "Luozheng Qin",
      "Hesen Chen",
      "Xiaomeng Yang",
      "Yuqing Sun",
      "Yuetan Lin",
      "Mengping Yang",
      "Hao Li"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08820v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08820v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.08794v1",
    "title": "MOVA: Towards Scalable and Synchronized Video-Audio Generation",
    "summary": "Audio is indispensable for real-world video, yet generation models have largely overlooked audio components. Current approaches to producing audio-visual content often rely on cascaded pipelines, which increase cost, accumulate errors, and degrade overall quality. While systems such as Veo 3 and Sora 2 emphasize the value of simultaneous generation, joint multimodal modeling introduces unique challenges in architecture, data, and training. Moreover, the closed-source nature of existing systems limits progress in the field. In this work, we introduce MOVA (MOSS Video and Audio), an open-source model capable of generating high-quality, synchronized audio-visual content, including realistic lip-synced speech, environment-aware sound effects, and content-aligned music. MOVA employs a Mixture-of-Experts (MoE) architecture, with a total of 32B parameters, of which 18B are active during inference. It supports IT2VA (Image-Text to Video-Audio) generation task. By releasing the model weights and code, we aim to advance research and foster a vibrant community of creators. The released codebase features comprehensive support for efficient inference, LoRA fine-tuning, and prompt enhancement.",
    "authors": [
      "SII-OpenMOSS Team",
      " :",
      "Donghua Yu",
      "Mingshu Chen",
      "Qi Chen",
      "Qi Luo",
      "Qianyi Wu",
      "Qinyuan Cheng",
      "Ruixiao Li",
      "Tianyi Liang",
      "Wenbo Zhang",
      "Wenming Tu",
      "Xiangyu Peng",
      "Yang Gao",
      "Yanru Huo",
      "Ying Zhu",
      "Yinze Luo",
      "Yiyang Zhang",
      "Yuerong Song",
      "Zhe Xu",
      "Zhiyu Zhang",
      "Chenchen Yang",
      "Cheng Chang",
      "Chushu Zhou",
      "Hanfu Chen",
      "Hongnan Ma",
      "Jiaxi Li",
      "Jingqi Tong",
      "Junxi Liu",
      "Ke Chen",
      "Shimin Li",
      "Songlin Wang",
      "Wei Jiang",
      "Zhaoye Fei",
      "Zhiyuan Ning",
      "Chunguo Li",
      "Chenhui Li",
      "Ziwei He",
      "Zengfeng Huang",
      "Xie Chen",
      "Xipeng Qiu"
    ],
    "categories": [
      "cs.CV",
      "cs.SD"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08794v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08794v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.08755v1",
    "title": "Redundancy-Free View Alignment for Multimodal Human Activity Recognition with Arbitrarily Missing Views",
    "summary": "Multimodal multiview learning seeks to integrate information from diverse sources to enhance task performance. Existing approaches often struggle with flexible view configurations, including arbitrary view combinations, numbers of views, and heterogeneous modalities. Focusing on the context of human activity recognition, we propose RALIS, a model that combines multiview contrastive learning with a mixture-of-experts module to support arbitrary view availability during both training and inference. Instead of trying to reconstruct missing views, an adjusted center contrastive loss is used for self-supervised representation learning and view alignment, mitigating the impact of missing views on multiview fusion. This loss formulation allows for the integration of view weights to account for view quality. Additionally, it reduces computational complexity from $O(V^2)$ to $O(V)$, where $V$ is the number of views. To address residual discrepancies not captured by contrastive learning, we employ a mixture-of-experts module with a specialized load balancing strategy, tasked with adapting to arbitrary view combinations. We highlight the geometric relationship among components in our model and how they combine well in the latent space. RALIS is validated on four datasets encompassing inertial and human pose modalities, with the number of views ranging from three to nine, demonstrating its performance and flexibility.",
    "authors": [
      "Duc-Anh Nguyen",
      "Nhien-An Le-Khac"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08755v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08755v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.08698v1",
    "title": "Challenges in Translating Technical Lectures: Insights from the NPTEL",
    "summary": "This study examines the practical applications and methodological implications of Machine Translation in Indian Languages, specifically Bangla, Malayalam, and Telugu, within emerging translation workflows and in relation to existing evaluation frameworks. The choice of languages prioritized in this study is motivated by a triangulation of linguistic diversity, which illustrates the significance of multilingual accommodation of educational technology under NEP 2020. This is further supported by the largest MOOC portal, i.e., NPTEL, which has served as a corpus to facilitate the arguments presented in this paper. The curation of a spontaneous speech corpora that accounts for lucid delivery of technical concepts, considering the retention of suitable register and lexical choices are crucial in a diverse country like India. The findings of this study highlight metric-specific sensitivity and the challenges of morphologically rich and semantically compact features when tested against surface overlapping metrics.",
    "authors": [
      "Basudha Raje",
      "Sadanand Venkatraman",
      "Nandana TP",
      "Soumyadeepa Das",
      "Polkam Poojitha",
      "M. Vijaykumar",
      "Tanima Bagchi",
      "Hema A. Murthy"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08698v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08698v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.08693v1",
    "title": "Reasoning aligns language models to human cognition",
    "summary": "Do language models make decisions under uncertainty like humans do, and what role does chain-of-thought (CoT) reasoning play in the underlying decision process? We introduce an active probabilistic reasoning task that cleanly separates sampling (actively acquiring evidence) from inference (integrating evidence toward a decision). Benchmarking humans and a broad set of contemporary large language models against near-optimal reference policies reveals a consistent pattern: extended reasoning is the key determinant of strong performance, driving large gains in inference and producing belief trajectories that become strikingly human-like, while yielding only modest improvements in active sampling. To explain these differences, we fit a mechanistic model that captures systematic deviations from optimal behavior via four interpretable latent variables: memory, strategy, choice bias, and occlusion awareness. This model places humans and models in a shared low-dimensional cognitive space, reproduces behavioral signatures across agents, and shows how chain-of-thought shifts language models toward human-like regimes of evidence accumulation and belief-to-choice mapping, tightening alignment in inference while leaving a persistent gap in information acquisition.",
    "authors": [
      "Gonçalo Guiomar",
      "Elia Torre",
      "Pehuen Moure",
      "Victoria Shavina",
      "Mario Giulianelli",
      "Shih-Chii Liu",
      "Valerio Mante"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08693v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08693v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.08998v1",
    "title": "Universal Coefficients and Mayer-Vietoris Sequence for Groupoid Homology",
    "summary": "We study homology of ample groupoids via the compactly supported Moore complex of the nerve. Let $A$ be a topological abelian group. For $n\\ge 0$ set $C_n(\\mathcal G;A) := C_c(\\mathcal G_n,A)$ and define $\\partial_n^A=\\sum_{i=0}^n(-1)^i(d_i)_*$. This defines $H_n(\\mathcal G;A)$. The theory is functorial for continuous étale homomorphisms. It is compatible with standard reductions, including restriction to saturated clopen subsets. In the ample setting it is invariant under Kakutani equivalence. We reprove Matui type long exact sequences and identify the comparison maps at chain level. For discrete $A$ we prove a natural universal coefficient short exact sequence $$0\\to H_n(\\mathcal G)\\otimes_{\\mathbb Z}A\\xrightarrow{\\ ι_n^{\\mathcal G}\\ }H_n(\\mathcal G;A)\\xrightarrow{\\ κ_n^{\\mathcal G}\\ }\\operatorname{Tor}_1^{\\mathbb Z}\\bigl(H_{n-1}(\\mathcal G),A\\bigr)\\to 0.$$ The key input is the chain level isomorphism $C_c(\\mathcal G_n,\\mathbb Z)\\otimes_{\\mathbb Z}A\\cong C_c(\\mathcal G_n,A)$, which reduces the groupoid statement to the classical algebraic UCT for the free complex $C_c(\\mathcal G_\\bullet,\\mathbb Z)$. We also isolate the obstruction for non-discrete coefficients. For a locally compact totally disconnected Hausdorff space $X$ with a basis of compact open sets, the image of $Φ_X:C_c(X,\\mathbb Z)\\otimes_{\\mathbb Z}A\\to C_c(X,A)$ is exactly the compactly supported functions with finite image. Thus $Φ_X$ is surjective if and only if every $f\\in C_c(X,A)$ has finite image, and for suitable $X$ one can produce compactly supported continuous maps $X\\to A$ with infinite image. Finally, for a clopen saturated cover $\\mathcal G_0=U_1\\cup U_2$ we construct a short exact sequence of Moore complexes and derive a Mayer-Vietoris long exact sequence for $H_\\bullet(\\mathcal G;A)$ for explicit computations.",
    "authors": [
      "Luciano Melodia"
    ],
    "categories": [
      "math.AT",
      "cs.LG",
      "math.OA",
      "stat.ML"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08998v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08998v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.08980v1",
    "title": "When do neural ordinary differential equations generalize on complex networks?",
    "summary": "Neural ordinary differential equations (neural ODEs) can effectively learn dynamical systems from time series data, but their behavior on graph-structured data remains poorly understood, especially when applied to graphs with different size or structure than encountered during training. We study neural ODEs ($\\mathtt{nODE}$s) with vector fields following the Barabási-Barzel form, trained on synthetic data from five common dynamical systems on graphs. Using the $\\mathbb{S}^1$-model to generate graphs with realistic and tunable structure, we find that degree heterogeneity and the type of dynamical system are the primary factors in determining $\\mathtt{nODE}$s' ability to generalize across graph sizes and properties. This extends to $\\mathtt{nODE}$s' ability to capture fixed points and maintain performance amid missing data. Average clustering plays a secondary role in determining $\\mathtt{nODE}$ performance. Our findings highlight $\\mathtt{nODE}$s as a powerful approach to understanding complex systems but underscore challenges emerging from degree heterogeneity and clustering in realistic graphs.",
    "authors": [
      "Moritz Laber",
      "Tina Eliassi-Rad",
      "Brennan Klein"
    ],
    "categories": [
      "physics.soc-ph",
      "cs.LG",
      "cs.SI",
      "stat.ML"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08980v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08980v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.08976v1",
    "title": "Distributionally Robust Optimization via Generative Ambiguity Modeling",
    "summary": "This paper studies Distributionally Robust Optimization (DRO), a fundamental framework for enhancing the robustness and generalization of statistical learning and optimization. An effective ambiguity set for DRO must involve distributions that remain consistent to the nominal distribution while being diverse enough to account for a variety of potential scenarios. Moreover, it should lead to tractable DRO solutions. To this end, we propose generative model-based ambiguity sets that capture various adversarial distributions beyond the nominal support space while maintaining consistency with the nominal distribution. Building on this generative ambiguity modeling, we propose DRO with Generative Ambiguity Set (GAS-DRO), a tractable DRO algorithm that solves the inner maximization over the parameterized generative model space. We formally establish the stationary convergence performance of GAS-DRO. We implement GAS-DRO with a diffusion model and empirically demonstrate its superior Out-of-Distribution (OOD) generalization performance in ML tasks.",
    "authors": [
      "Jiaqi Wen",
      "Jianyi Yang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08976v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08976v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.08907v1",
    "title": "Positive Distribution Shift as a Framework for Understanding Tractable Learning",
    "summary": "We study a setting where the goal is to learn a target function f(x) with respect to a target distribution D(x), but training is done on i.i.d. samples from a different training distribution D'(x), labeled by the true target f(x). Such a distribution shift (here in the form of covariate shift) is usually viewed negatively, as hurting or making learning harder, and the traditional distribution shift literature is mostly concerned with limiting or avoiding this negative effect. In contrast, we argue that with a well-chosen D'(x), the shift can be positive and make learning easier -- a perspective called Positive Distribution Shift (PDS). Such a perspective is central to contemporary machine learning, where much of the innovation is in finding good training distributions D'(x), rather than changing the training algorithm. We further argue that the benefit is often computational rather than statistical, and that PDS allows computationally hard problems to become tractable even using standard gradient-based training. We formalize different variants of PDS, show how certain hard classes are easily learnable under PDS, and make connections with membership query learning.",
    "authors": [
      "Marko Medvedev",
      "Idan Attias",
      "Elisabetta Cornacchia",
      "Theodor Misiakiewicz",
      "Gal Vardi",
      "Nathan Srebro"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08907v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08907v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.08887v1",
    "title": "DeepQuali: Initial results of a study on the use of large language models for assessing the quality of user stories",
    "summary": "Generative artificial intelligence (GAI), specifically large language models (LLMs), are increasingly used in software engineering, mainly for coding tasks. However, requirements engineering - particularly requirements validation - has seen limited application of GAI. The current focus of using GAI for requirements is on eliciting, transforming, and classifying requirements, not on quality assessment. We propose and evaluate the LLM-based (GPT-4o) approach \"DeepQuali\", for assessing and improving requirements quality in agile software development. We applied it to projects in two small companies, where we compared LLM-based quality assessments with expert judgments. Experts also participated in walkthroughs of the solution, provided feedback, and rated their acceptance of the approach. Experts largely agreed with the LLM's quality assessments, especially regarding overall ratings and explanations. However, they did not always agree with the other experts on detailed ratings, suggesting that expertise and experience may influence judgments. Experts recognized the usefulness of the approach but criticized the lack of integration into their workflow. LLMs show potential in supporting software engineers with the quality assessment and improvement of requirements. The explicit use of quality models and explanatory feedback increases acceptance.",
    "authors": [
      "Adam Trendowicz",
      "Daniel Seifert",
      "Andreas Jedlitschka",
      "Marcus Ciolkowski",
      "Anton Strahilov"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08887v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08887v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.08861v1",
    "title": "TiFRe: Text-guided Video Frame Reduction for Efficient Video Multi-modal Large Language Models",
    "summary": "With the rapid development of Large Language Models (LLMs), Video Multi-Modal Large Language Models (Video MLLMs) have achieved remarkable performance in video-language tasks such as video understanding and question answering. However, Video MLLMs face high computational costs, particularly in processing numerous video frames as input, which leads to significant attention computation overhead. A straightforward approach to reduce computational costs is to decrease the number of input video frames. However, simply selecting key frames at a fixed frame rate (FPS) often overlooks valuable information in non-key frames, resulting in notable performance degradation. To address this, we propose Text-guided Video Frame Reduction (TiFRe), a framework that reduces input frames while preserving essential video information. TiFRe uses a Text-guided Frame Sampling (TFS) strategy to select key frames based on user input, which is processed by an LLM to generate a CLIP-style prompt. Pre-trained CLIP encoders calculate the semantic similarity between the prompt and each frame, selecting the most relevant frames as key frames. To preserve video semantics, TiFRe employs a Frame Matching and Merging (FMM) mechanism, which integrates non-key frame information into the selected key frames, minimizing information loss. Experiments show that TiFRe effectively reduces computational costs while improving performance on video-language tasks.",
    "authors": [
      "Xiangtian Zheng",
      "Zishuo Wang",
      "Yuxin Peng"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08861v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08861v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.08783v1",
    "title": "Dynamics Within Latent Chain-of-Thought: An Empirical Study of Causal Structure",
    "summary": "Latent or continuous chain-of-thought methods replace explicit textual rationales with a number of internal latent steps, but these intermediate computations are difficult to evaluate beyond correlation-based probes. In this paper, we view latent chain-of-thought as a manipulable causal process in representation space by modeling latent steps as variables in a structural causal model (SCM) and analyzing their effects through step-wise $\\mathrm{do}$-interventions. We study two representative paradigms (i.e., Coconut and CODI) on both mathematical and general reasoning tasks to investigate three key questions: (1) which steps are causally necessary for correctness and when answers become decidable early; (2) how does influence propagate across steps, and how does this structure compare to explicit CoT; and (3) do intermediate trajectories retain competing answer modes, and how does output-level commitment differ from representational commitment across steps. We find that latent-step budgets behave less like homogeneous extra depth and more like staged functionality with non-local routing, and we identify a persistent gap between early output bias and late representational commitment. These results motivate mode-conditional and stability-aware analyses -- and corresponding training/decoding objectives -- as more reliable tools for interpreting and improving latent reasoning systems.",
    "authors": [
      "Zirui Li",
      "Xuefeng Bai",
      "Kehai Chen",
      "Yizhi Li",
      "Jian Yang",
      "Chenghua Lin",
      "Min Zhang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08783v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08783v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.08765v1",
    "title": "Taming Scylla: Understanding the multi-headed agentic daemon of the coding seas",
    "summary": "LLM-based tools are automating more software development tasks at a rapid pace, but there is no rigorous way to evaluate how different architectural choices -- prompts, skills, tools, multi-agent setups -- materially affect both capability and cost. This paper introduces Scylla, an evaluation framework for benchmarking agentic coding tools through structured ablation studies that uses seven testing tiers (T0-T6) progressively adding complexity to isolate what directly influences results and how. The key metric is Cost-of-Pass (CoP): the expected dollar cost to get one correct solution, which directly quantifies the trade-off between complexity and efficiency. The framework is model-agnostic, designed to work with any CLI tool; this paper demonstrates it with Claude Sonnet 4.5, using multiple LLM judges (Opus 4.5, Sonnet 4.5, Haiku 4.5) from the same vendor for evaluation consensus, where judges score results using direct tests, human-designed LLM-evaluated rubrics, and qualitative assessment. The result is a reproducible framework that quantifies trade-offs between agent complexity and actual outcomes, suggesting that architectural complexity does not always improve quality.",
    "authors": [
      "Micah Villmow"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08765v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08765v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.08749v1",
    "title": "Shifting the Breaking Point of Flow Matching for Multi-Instance Editing",
    "summary": "Flow matching models have recently emerged as an efficient alternative to diffusion, especially for text-guided image generation and editing, offering faster inference through continuous-time dynamics. However, existing flow-based editors predominantly support global or single-instruction edits and struggle with multi-instance scenarios, where multiple parts of a reference input must be edited independently without semantic interference. We identify this limitation as a consequence of globally conditioned velocity fields and joint attention mechanisms, which entangle concurrent edits. To address this issue, we introduce Instance-Disentangled Attention, a mechanism that partitions joint attention operations, enforcing binding between instance-specific textual instructions and spatial regions during velocity field estimation. We evaluate our approach on both natural image editing and a newly introduced benchmark of text-dense infographics with region-level editing instructions. Experimental results demonstrate that our approach promotes edit disentanglement and locality while preserving global output coherence, enabling single-pass, instance-level editing.",
    "authors": [
      "Carmine Zaccagnino",
      "Fabio Quattrini",
      "Enis Simsar",
      "Marta Tintoré Gazulla",
      "Rita Cucchiara",
      "Alessio Tonioni",
      "Silvia Cascianelli"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08749v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08749v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.08745v1",
    "title": "On the Expressive Power of GNNs for Boolean Satisfiability",
    "summary": "Machine learning approaches to solving Boolean Satisfiability (SAT) aim to replace handcrafted heuristics with learning-based models. Graph Neural Networks have emerged as the main architecture for SAT solving, due to the natural graph representation of Boolean formulas. We analyze the expressive power of GNNs for SAT solving through the lens of the Weisfeiler-Leman (WL) test. As our main result, we prove that the full WL hierarchy cannot, in general, distinguish between satisfiable and unsatisfiable instances. We show that indistinguishability under higher-order WL carries over to practical limitations for WL-bounded solvers that set variables sequentially. We further study the expressivity required for several important families of SAT instances, including regular, random and planar instances. To quantify expressivity needs in practice, we conduct experiments on random instances from the G4SAT benchmark and industrial instances from the International SAT Competition. Our results suggest that while random instances are largely distinguishable, industrial instances often require more expressivity to predict a satisfying assignment.",
    "authors": [
      "Saku Peltonen",
      "Roger Wattenhofer"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08745v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08745v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.08692v1",
    "title": "PBLean: Pseudo-Boolean Proof Certificates for Lean 4",
    "summary": "We present PBLean, a method for importing VeriPB pseudo-Boolean (PB) proof certificates into Lean 4. Key to our approach is reflection: a Boolean checker function whose soundness is fully proved in Lean and executed as compiled native code. Our method scales to proofs with tens of thousands of steps that would exhaust memory under explicit proof-term construction. Our checker supports all VeriPB kernel rules, including cutting-plane derivations and proof-by-contradiction subproofs. In contrast to external verified checkers that produce verdicts, our integration yields Lean theorems that can serve as composable lemmas in larger formal developments. To derive theorems about the original combinatorial problems rather than about PB constraints alone, we support verified encodings. This closes the trust gap between solver output and problem semantics since the constraint translation and its correctness proof are both formalized in Lean. We demonstrate the approach on various combinatorial problems.",
    "authors": [
      "Stefan Szeider"
    ],
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08692v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08692v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.08675v1",
    "title": "6G-Bench: An Open Benchmark for Semantic Communication and Network-Level Reasoning with Foundation Models in AI-Native 6G Networks",
    "summary": "This paper introduces 6G-Bench, an open benchmark for evaluating semantic communication and network-level reasoning in AI-native 6G networks. 6G-Bench defines a taxonomy of 30 decision-making tasks (T1--T30) extracted from ongoing 6G and AI-agent standardization activities in 3GPP, IETF, ETSI, ITU-T, and the O-RAN Alliance, and organizes them into five standardization-aligned capability categories. Starting from 113,475 scenarios, we generate a balanced pool of 10,000 very-hard multiple-choice questions using task-conditioned prompts that enforce multi-step quantitative reasoning under uncertainty and worst-case regret minimization over multi-turn horizons. After automated filtering and expert human validation, 3,722 questions are retained as a high-confidence evaluation set, while the full pool is released to support training and fine-tuning of 6G-specialized models. Using 6G-Bench, we evaluate 22 foundation models spanning dense and mixture-of-experts architectures, short- and long-context designs (up to 1M tokens), and both open-weight and proprietary systems. Across models, deterministic single-shot accuracy (pass@1) spans a wide range from 0.22 to 0.82, highlighting substantial variation in semantic reasoning capability. Leading models achieve intent and policy reasoning accuracy in the range 0.87--0.89, while selective robustness analysis on reasoning-intensive tasks shows pass@5 values ranging from 0.20 to 0.91. To support open science and reproducibility, we release the 6G-Bench dataset on GitHub: https://github.com/maferrag/6G-Bench",
    "authors": [
      "Mohamed Amine Ferrag",
      "Abderrahmane Lakas",
      "Merouane Debbah"
    ],
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08675v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08675v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.08567v1",
    "title": "ValueFlow: Measuring the Propagation of Value Perturbations in Multi-Agent LLM Systems",
    "summary": "Multi-agent large language model (LLM) systems increasingly consist of agents that observe and respond to one another's outputs. While value alignment is typically evaluated for isolated models, how value perturbations propagate through agent interactions remains poorly understood. We present ValueFlow, a perturbation-based evaluation framework for measuring and analyzing value drift in multi-agent systems. ValueFlow introduces a 56-value evaluation dataset derived from the Schwartz Value Survey and quantifies agents' value orientations during interaction using an LLM-as-a-judge protocol. Building on this measurement layer, ValueFlow decomposes value drift into agent-level response behavior and system-level structural effects, operationalized by two metrics: beta-susceptibility, which measures an agent's sensitivity to perturbed peer signals, and system susceptibility (SS), which captures how node-level perturbations affect final system outputs. Experiments across multiple model backbones, prompt personas, value dimensions, and network structures show that susceptibility varies widely across values and is strongly shaped by structural topology.",
    "authors": [
      "Jinnuo Liu",
      "Chuke Liu",
      "Hua Shen"
    ],
    "categories": [
      "cs.MA",
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08567v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08567v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.09013v1",
    "title": "Dexterous Manipulation Policies from RGB Human Videos via 4D Hand-Object Trajectory Reconstruction",
    "summary": "Multi-finger robotic hand manipulation and grasping are challenging due to the high-dimensional action space and the difficulty of acquiring large-scale training data. Existing approaches largely rely on human teleoperation with wearable devices or specialized sensing equipment to capture hand-object interactions, which limits scalability. In this work, we propose VIDEOMANIP, a device-free framework that learns dexterous manipulation directly from RGB human videos. Leveraging recent advances in computer vision, VIDEOMANIP reconstructs explicit 4D robot-object trajectories from monocular videos by estimating human hand poses, object meshes, and retargets the reconstructed human motions to robotic hands for manipulation learning. To make the reconstructed robot data suitable for dexterous manipulation training, we introduce hand-object contact optimization with interaction-centric grasp modeling, as well as a demonstration synthesis strategy that generates diverse training trajectories from a single video, enabling generalizable policy learning without additional robot demonstrations. In simulation, the learned grasping model achieves a 70.25% success rate across 20 diverse objects using the Inspire Hand. In the real world, manipulation policies trained from RGB videos achieve an average 62.86% success rate across seven tasks using the LEAP Hand, outperforming retargeting-based methods by 15.87%. Project videos are available at videomanip.github.io.",
    "authors": [
      "Hongyi Chen",
      "Tony Dong",
      "Tiancheng Wu",
      "Liquan Wang",
      "Yash Jangir",
      "Yaru Niu",
      "Yufei Ye",
      "Homanga Bharadhwaj",
      "Zackory Erickson",
      "Jeffrey Ichnowski"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.09013v1",
    "pdf_url": "https://arxiv.org/pdf/2602.09013v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.08984v1",
    "title": "Next Concept Prediction in Discrete Latent Space Leads to Stronger Language Models",
    "summary": "We propose Next Concept Prediction (NCP), a generative pretraining paradigm built on top of Next Token Prediction (NTP). NCP predicts discrete concepts that span multiple tokens, thereby forming a more challenging pretraining objective. Our model, ConceptLM, quantizes hidden states using Vector Quantization and constructs a concept vocabulary. It leverages both NCP and NTP to drive parameter updates and generates a concept to guide the generation of the following tokens. We train ConceptLM from scratch at scales ranging from 70M to 1.5B parameters with up to 300B training data, including Pythia and GPT-2 backbones. Results on 13 benchmarks show that NCP yields consistent performance gains over traditional token-level models. Furthermore, continual pretraining experiments on an 8B-parameter Llama model indicate that NCP can further improve an NTP-trained model. Our analysis suggests that NCP leads to more powerful language models by introducing a harder pretraining task, providing a promising path toward better language modeling.",
    "authors": [
      "Yuliang Liu",
      "Yunchong Song",
      "Yixuan Wang",
      "Kewen Ge",
      "Alex Lamb",
      "Qipeng Guo",
      "Kai Chen",
      "Bowen Zhou",
      "Zhouhan Lin"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08984v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08984v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.08951v1",
    "title": "How Should We Model the Probability of a Language?",
    "summary": "Of the over 7,000 languages spoken in the world, commercial language identification (LID) systems only reliably identify a few hundred in written form. Research-grade systems extend this coverage under certain circumstances, but for most languages coverage remains patchy or nonexistent. This position paper argues that this situation is largely self-imposed. In particular, it arises from a persistent framing of LID as decontextualized text classification, which obscures the central role of prior probability estimation and is reinforced by institutional incentives that favor global, fixed-prior models. We argue that improving coverage for tail languages requires rethinking LID as a routing problem and developing principled ways to incorporate environmental cues that make languages locally plausible.",
    "authors": [
      "Rasul Dent",
      "Pedro Ortiz Suarez",
      "Thibault Clérice",
      "Benoît Sagot"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08951v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08951v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.08941v1",
    "title": "pixelLOG: Logging of Online Gameplay for Cognitive Research",
    "summary": "Traditional cognitive assessments often rely on isolated, output-focused measurements that may fail to capture the complexity of human cognition in naturalistic settings. We present pixelLOG, a high-performance data collection framework for Spigot-based Minecraft servers designed specifically for process-based cognitive research. Unlike existing frameworks tailored only for artificial intelligence agents, pixelLOG also enables human behavioral tracking in multi-player/multi-agent environments. Operating at configurable frequencies up to and exceeding 20 updates per second, the system captures comprehensive behavioral data through a hybrid approach of active state polling and passive event monitoring. By leveraging Spigot's extensible API, pixelLOG facilitates robust session isolation and produces structured JSON outputs integrable with standard analytical pipelines. This framework bridges the gap between decontextualized laboratory assessments and richer, more ecologically valid tasks, enabling high-resolution analysis of cognitive processes as they unfold in complex, virtual environments.",
    "authors": [
      "Zeyu Lu",
      "Dennis L. Barbour"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08941v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08941v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.08939v1",
    "title": "CausalT5K: Diagnosing and Informing Refusal for Trustworthy Causal Reasoning of Skepticism, Sycophancy, Detection-Correction, and Rung Collapse",
    "summary": "LLM failures in causal reasoning, including sycophancy, rung collapse, and miscalibrated refusal, are well-documented, yet progress on remediation is slow because no benchmark enables systematic diagnosis. We introduce CausalT5K, a diagnostic benchmark of over 5,000 cases across 10 domains that tests three critical capabilities: (1) detecting rung collapse, where models answer interventional queries with associational evidence; (2) resisting sycophantic drift under adversarial pressure; and (3) generating Wise Refusals that specify missing information when evidence is underdetermined. Unlike synthetic benchmarks, CausalT5K embeds causal traps in realistic narratives and decomposes performance into Utility (sensitivity) and Safety (specificity), revealing failure modes invisible to aggregate accuracy. Developed through a rigorous human-machine collaborative pipeline involving 40 domain experts, iterative cross-validation cycles, and composite verification via rule-based, LLM, and human scoring, CausalT5K implements Pearl's Ladder of Causation as research infrastructure. Preliminary experiments reveal a Four-Quadrant Control Landscape where static audit policies universally fail, a finding that demonstrates CausalT5K's value for advancing trustworthy reasoning systems. Repository: https://github.com/genglongling/CausalT5kBench",
    "authors": [
      "Longling Geng",
      "Andy Ouyang",
      "Theodore Wu",
      "Daphne Barretto",
      "Matthew John Hayes",
      "Rachael Cooper",
      "Yuqiao Zeng",
      "Sameer Vijay",
      "Gia Ancone",
      "Ankit Rai",
      "Matthew Wolfman",
      "Patrick Flanagan",
      "Edward Y. Chang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08939v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08939v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.08753v1",
    "title": "MVAnimate: Enhancing Character Animation with Multi-View Optimization",
    "summary": "The demand for realistic and versatile character animation has surged, driven by its wide-ranging applications in various domains. However, the animation generation algorithms modeling human pose with 2D or 3D structures all face various problems, including low-quality output content and training data deficiency, preventing the related algorithms from generating high-quality animation videos. Therefore, we introduce MVAnimate, a novel framework that synthesizes both 2D and 3D information of dynamic figures based on multi-view prior information, to enhance the generated video quality. Our approach leverages multi-view prior information to produce temporally consistent and spatially coherent animation outputs, demonstrating improvements over existing animation methods. Our MVAnimate also optimizes the multi-view videos of the target character, enhancing the video quality from different views. Experimental results on diverse datasets highlight the robustness of our method in handling various motion patterns and appearances.",
    "authors": [
      "Tianyu Sun",
      "Zhoujie Fu",
      "Bang Zhang",
      "Guosheng Lin"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08753v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08753v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.08707v1",
    "title": "Why do we Trust Chatbots? From Normative Principles to Behavioral Drivers",
    "summary": "As chatbots increasingly blur the boundary between automated systems and human conversation, the foundations of trust in these systems warrant closer examination. While regulatory and policy frameworks tend to define trust in normative terms, the trust users place in chatbots often emerges from behavioral mechanisms. In many cases, this trust is not earned through demonstrated trustworthiness but is instead shaped by interactional design choices that leverage cognitive biases to influence user behavior. Based on this observation, we propose reframing chatbots not as companions or assistants, but as highly skilled salespeople whose objectives are determined by the deploying organization. We argue that the coexistence of competing notions of \"trust\" under a shared term obscures important distinctions between psychological trust formation and normative trustworthiness. Addressing this gap requires further research and stronger support mechanisms to help users appropriately calibrate trust in conversational AI systems.",
    "authors": [
      "Aditya Gulati",
      "Nuria Oliver"
    ],
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08707v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08707v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.08696v1",
    "title": "Prototype-Based Disentanglement for Controllable Dysarthric Speech Synthesis",
    "summary": "Dysarthric speech exhibits high variability and limited labeled data, posing major challenges for both automatic speech recognition (ASR) and assistive speech technologies. Existing approaches rely on synthetic data augmentation or speech reconstruction, yet often entangle speaker identity with pathological articulation, limiting controllability and robustness.   In this paper, we propose ProtoDisent-TTS, a prototype-based disentanglement TTS framework built on a pre-trained text-to-speech backbone that factorizes speaker timbre and dysarthric articulation within a unified latent space. A pathology prototype codebook provides interpretable and controllable representations of healthy and dysarthric speech patterns, while a dual-classifier objective with a gradient reversal layer enforces invariance of speaker embeddings to pathological attributes. Experiments on the TORGO dataset demonstrate that this design enables bidirectional transformation between healthy and dysarthric speech, leading to consistent ASR performance gains and robust, speaker-aware speech reconstruction.",
    "authors": [
      "Haoshen Wang",
      "Xueli Zhong",
      "Bingbing Lin",
      "Jia Huang",
      "Xingduo Pan",
      "Shengxiang Liang",
      "Nizhuan Wang",
      "Wai Ting Siok"
    ],
    "categories": [
      "cs.SD",
      "cs.CL"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08696v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08696v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.08652v1",
    "title": "Deep Learning-Based Fixation Type Prediction for Quality Assurance in Digital Pathology",
    "summary": "Accurate annotation of fixation type is a critical step in slide preparation for pathology laboratories. However, this manual process is prone to   errors, impacting downstream analyses and diagnostic accuracy. Existing methods for verifying formalin-fixed, paraffin-embedded (FFPE), and frozen   section (FS) fixation types typically require full-resolution whole-slide images (WSIs), limiting scalability for high-throughput quality control.   We propose a deep-learning model to predict fixation types using low-resolution, pre-scan thumbnail images. The model was trained on WSIs from   the TUM Institute of Pathology (n=1,200, Leica GT450DX) and evaluated on a class-balanced subset of The Cancer Genome Atlas dataset (TCGA, n=8,800,   Leica AT2), as well as on class-balanced datasets from Augsburg (n=695 [392 FFPE, 303 FS], Philips UFS) and Regensburg (n=202, 3DHISTECH P1000).   Our model achieves an AUROC of 0.88 on TCGA, outperforming comparable pre-scan methods by 4.8%. It also achieves AUROCs of 0.72 on Regensburg and   Augsburg slides, underscoring challenges related to scanner-induced domain shifts. Furthermore, the model processes each slide in 21 ms, $400\\times$   faster than existing high-magnification, full-resolution methods, enabling rapid, high-throughput processing.   This approach provides an efficient solution for detecting labelling errors without relying on high-magnification scans, offering a valuable tool for   quality control in high-throughput pathology workflows. Future work will improve and evaluate the model's generalisation to additional scanner   types. Our findings suggest that this method can increase accuracy and efficiency in digital pathology workflows and may be extended to other   low-resolution slide annotations.",
    "authors": [
      "Oskar Thaeter",
      "Tanja Niedermair",
      "Johannes Raffler",
      "Ralf Huss",
      "Peter J. Schüffler"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08652v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08652v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.08579v1",
    "title": "Modeling Score Approximation Errors in Diffusion Models via Forward SPDEs",
    "summary": "This study investigates the dynamics of Score-based Generative Models (SGMs) by treating the score estimation error as a stochastic source driving the Fokker-Planck equation. Departing from particle-centric SDE analyses, we employ an SPDE framework to model the evolution of the probability density field under stochastic drift perturbations. Under a simplified setting, we utilize this framework to interpret the robustness of generative models through the lens of geometric stability and displacement convexity. Furthermore, we introduce a candidate evaluation metric derived from the quadratic variation of the SPDE solution projected onto a radial test function. Preliminary observations suggest that this metric remains effective using only the initial 10% of the sampling trajectory, indicating a potential for computational efficiency.",
    "authors": [
      "Junsu Seo"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08579v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08579v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.08927v1",
    "title": "Online monotone density estimation and log-optimal calibration",
    "summary": "We study the problem of online monotone density estimation, where density estimators must be constructed in a predictable manner from sequentially observed data. We propose two online estimators: an online analogue of the classical Grenander estimator, and an expert aggregation estimator inspired by exponential weighting methods from the online learning literature. In the well-specified stochastic setting, where the underlying density is monotone, we show that the expected cumulative log-likelihood gap between the online estimators and the true density admits an $O(n^{1/3})$ bound. We further establish a $\\sqrt{n\\log{n}}$ pathwise regret bound for the expert aggregation estimator relative to the best offline monotone estimator chosen in hindsight, under minimal regularity assumptions on the observed sequence. As an application of independent interest, we show that the problem of constructing log-optimal p-to-e calibrators for sequential hypothesis testing can be formulated as an online monotone density estimation problem. We adapt the proposed estimators to build empirically adaptive p-to-e calibrators and establish their optimality. Numerical experiments illustrate the theoretical results.",
    "authors": [
      "Rohan Hore",
      "Ruodu Wang",
      "Aaditya Ramdas"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08927v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08927v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.08909v1",
    "title": "Analysis of Converged 3D Gaussian Splatting Solutions: Density Effects and Prediction Limit",
    "summary": "We investigate what structure emerges in 3D Gaussian Splatting (3DGS) solutions from standard multi-view optimization. We term these Rendering-Optimal References (RORs) and analyze their statistical properties, revealing stable patterns: mixture-structured scales and bimodal radiance across diverse scenes. To understand what determines these parameters, we apply learnability probes by training predictors to reconstruct RORs from point clouds without rendering supervision. Our analysis uncovers fundamental density-stratification. Dense regions exhibit geometry-correlated parameters amenable to render-free prediction, while sparse regions show systematic failure across architectures. We formalize this through variance decomposition, demonstrating that visibility heterogeneity creates covariance-dominated coupling between geometric and appearance parameters in sparse regions. This reveals the dual character of RORs: geometric primitives where point clouds suffice, and view synthesis primitives where multi-view constraints are essential. We provide density-aware strategies that improve training robustness and discuss architectural implications for systems that adaptively balance feed-forward prediction and rendering-based refinement.",
    "authors": [
      "Zhendong Wang",
      "Cihan Ruan",
      "Jingchuan Xiao",
      "Chuqing Shi",
      "Wei Jiang",
      "Wei Wang",
      "Wenjie Liu",
      "Nam Ling"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08909v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08909v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.08894v1",
    "title": "Discrete Bridges for Mutual Information Estimation",
    "summary": "Diffusion bridge models in both continuous and discrete state spaces have recently become powerful tools in the field of generative modeling. In this work, we leverage the discrete state space formulation of bridge matching models to address another important problem in machine learning and information theory: the estimation of the mutual information (MI) between discrete random variables. By neatly framing MI estimation as a domain transfer problem, we construct a Discrete Bridge Mutual Information (DBMI) estimator suitable for discrete data, which poses difficulties for conventional MI estimators. We showcase the performance of our estimator on two MI estimation settings: low-dimensional and image-based.",
    "authors": [
      "Iryna Zabarianska",
      "Sergei Kholkin",
      "Grigoriy Ksenofontov",
      "Ivan Butakov",
      "Alexander Korotin"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08894v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08894v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.08816v1",
    "title": "Permissive-Washing in the Open AI Supply Chain: A Large-Scale Audit of License Integrity",
    "summary": "Permissive licenses like MIT, Apache-2.0, and BSD-3-Clause dominate open-source AI, signaling that artifacts like models, datasets, and code can be freely used, modified, and redistributed. However, these licenses carry mandatory requirements: include the full license text, provide a copyright notice, and preserve upstream attribution, that remain unverified at scale. Failure to meet these conditions can place reuse outside the scope of the license, effectively leaving AI artifacts under default copyright for those uses and exposing downstream users to litigation. We call this phenomenon ``permissive washing'': labeling AI artifacts as free to use, while omitting the legal documentation required to make that label actionable. To assess how widespread permissive washing is in the AI supply chain, we empirically audit 124,278 dataset $\\rightarrow$ model $\\rightarrow$ application supply chains, spanning 3,338 datasets, 6,664 models, and 28,516 applications across Hugging Face and GitHub. We find that an astonishing 96.5\\% of datasets and 95.8\\% of models lack the required license text, only 2.3\\% of datasets and 3.2\\% of models satisfy both license text and copyright requirements, and even when upstream artifacts provide complete licensing evidence, attribution rarely propagates downstream: only 27.59\\% of models preserve compliant dataset notices and only 5.75\\% of applications preserve compliant model notices (with just 6.38\\% preserving any linked upstream notice). Practitioners cannot assume permissive labels confer the rights they claim: license files and notices, not metadata, are the source of legal truth. To support future research, we release our full audit dataset and reproducible pipeline.",
    "authors": [
      "James Jewitt",
      "Gopi Krishnan Rajbahadur",
      "Hao Li",
      "Bram Adams",
      "Ahmed E. Hassan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.SE"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08816v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08816v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.08786v1",
    "title": "Empirically Understanding the Value of Prediction in Allocation",
    "summary": "Institutions increasingly use prediction to allocate scarce resources. From a design perspective, better predictions compete with other investments, such as expanding capacity or improving treatment quality. Here, the big question is not how to solve a specific allocation problem, but rather which problem to solve. In this work, we develop an empirical toolkit to help planners form principled answers to this question and quantify the bottom-line welfare impact of investments in prediction versus other policy levers such as expanding capacity and improving treatment quality. Applying our framework in two real-world case studies on German employment services and poverty targeting in Ethiopia, we illustrate how decision-makers can reliably derive context-specific conclusions about the relative value of prediction in their allocation problem. We make our software toolkit, rvp, and parts of our data available in order to enable future empirical work in this area.",
    "authors": [
      "Unai Fischer-Abaigar",
      "Emily Aiken",
      "Christoph Kern",
      "Juan Carlos Perdomo"
    ],
    "categories": [
      "cs.CY",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08786v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08786v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.08785v1",
    "title": "A Graphop Analysis of Graph Neural Networks on Sparse Graphs: Generalization and Universal Approximation",
    "summary": "Generalization and approximation capabilities of message passing graph neural networks (MPNNs) are often studied by defining a compact metric on a space of input graphs under which MPNNs are Hölder continuous. Such analyses are of two varieties: 1) when the metric space includes graphs of unbounded sizes, the theory is only appropriate for dense graphs, and, 2) when studying sparse graphs, the metric space only includes graphs of uniformly bounded size. In this work, we present a unified approach, defining a compact metric on the space of graphs of all sizes, both sparse and dense, under which MPNNs are Hölder continuous. This leads to more powerful universal approximation theorems and generalization bounds than previous works. The theory is based on, and extends, a recent approach to graph limit theory called graphop analysis.",
    "authors": [
      "Ofek Amran",
      "Tom Gilat",
      "Ron Levie"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08785v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08785v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.08695v1",
    "title": "Trapped by simplicity: When Transformers fail to learn from noisy features",
    "summary": "Noise is ubiquitous in data used to train large language models, but it is not well understood whether these models are able to correctly generalize to inputs generated without noise. Here, we study noise-robust learning: are transformers trained on data with noisy features able to find a target function that correctly predicts labels for noiseless features? We show that transformers succeed at noise-robust learning for a selection of $k$-sparse parity and majority functions, compared to LSTMs which fail at this task for even modest feature noise. However, we find that transformers typically fail at noise-robust learning of random $k$-juntas, especially when the boolean sensitivity of the optimal solution is smaller than that of the target function. We argue that this failure is due to a combination of two factors: transformers' bias toward simpler functions, combined with an observation that the optimal function for noise-robust learning typically has lower sensitivity than the target function for random boolean functions. We test this hypothesis by exploiting transformers' simplicity bias to trap them in an incorrect solution, but show that transformers can escape this trap by training with an additional loss term penalizing high-sensitivity solutions. Overall, we find that transformers are particularly ineffective for learning boolean functions in the presence of feature noise.",
    "authors": [
      "Evan Peters",
      "Ando Deng",
      "Matheus H. Zambianco",
      "Devin Blankespoor",
      "Achim Kempf"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08695v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08695v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.08670v1",
    "title": "A Machine Learning accelerated geophysical fluid solver",
    "summary": "Machine learning methods have been successful in many areas, like image classification and natural language processing. However, it still needs to be determined how to apply ML to areas with mathematical constraints, like solving PDEs. Among various approaches to applying ML techniques to solving PDEs, the data-driven discretization method presents a promising way of accelerating and improving existing PDE solver on structured grids where it predicts the coefficients of quasi-linear stencils for computing values or derivatives of a function at given positions. It can improve the accuracy and stability of low-resolution simulation compared with using traditional finite difference or finite volume schemes. Meanwhile, it can also benefit from traditional numerical schemes like achieving conservation law by adapting finite volume type formulations. In this thesis, we have implemented the shallow water equation and Euler equation classic solver under a different framework. Experiments show that our classic solver performs much better than the Pyclaw solver. Then we propose four different deep neural networks for the ML-based solver. The results indicate that two of these approaches could output satisfactory solutions.",
    "authors": [
      "Yang Bai"
    ],
    "categories": [
      "cs.CV",
      "cs.CE",
      "cs.PF",
      "physics.comp-ph"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08670v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08670v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.08668v1",
    "title": "Retrieval Pivot Attacks in Hybrid RAG: Measuring and Mitigating Amplified Leakage from Vector Seeds to Graph Expansion",
    "summary": "Hybrid Retrieval-Augmented Generation (RAG) pipelines combine vector similarity search with knowledge graph expansion for multi-hop reasoning. We show that this composition introduces a distinct security failure mode: a vector-retrieved \"seed\" chunk can pivot via entity links into sensitive graph neighborhoods, causing cross-tenant data leakage that does not occur in vector-only retrieval. We formalize this risk as Retrieval Pivot Risk (RPR) and introduce companion metrics Leakage@k, Amplification Factor, and Pivot Depth (PD) to quantify leakage magnitude and traversal structure.   We present seven Retrieval Pivot Attacks that exploit the vector-to-graph boundary and show that adversarial injection is not required: naturally shared entities create cross-tenant pivot paths organically. Across a synthetic multi-tenant enterprise corpus and the Enron email corpus, the undefended hybrid pipeline exhibits high pivot risk (RPR up to 0.95) with multiple unauthorized items returned per query. Leakage consistently appears at PD=2, which we attribute to the bipartite chunk-entity topology and formalize as a proposition.   We then show that enforcing authorization at a single location, the graph expansion boundary, eliminates measured leakage (RPR near 0) across both corpora, all attack variants, and label forgery rates up to 10 percent, with minimal overhead. Our results indicate the root cause is boundary enforcement, not inherently complex defenses: two individually secure retrieval components can compose into an insecure system unless authorization is re-checked at the transition point.",
    "authors": [
      "Scott Thornton"
    ],
    "categories": [
      "cs.CR",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08668v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08668v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.08615v1",
    "title": "Inspiration Seeds: Learning Non-Literal Visual Combinations for Generative Exploration",
    "summary": "While generative models have become powerful tools for image synthesis, they are typically optimized for executing carefully crafted textual prompts, offering limited support for the open-ended visual exploration that often precedes idea formation. In contrast, designers frequently draw inspiration from loosely connected visual references, seeking emergent connections that spark new ideas. We propose Inspiration Seeds, a generative framework that shifts image generation from final execution to exploratory ideation. Given two input images, our model produces diverse, visually coherent compositions that reveal latent relationships between inputs, without relying on user-specified text prompts. Our approach is feed-forward, trained on synthetic triplets of decomposed visual aspects derived entirely through visual means: we use CLIP Sparse Autoencoders to extract editing directions in CLIP latent space and isolate concept pairs. By removing the reliance on language and enabling fast, intuitive recombination, our method supports visual ideation at the early and ambiguous stages of creative work.",
    "authors": [
      "Kfir Goldberg",
      "Elad Richardson",
      "Yael Vinker"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08615v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08615v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.08606v1",
    "title": "Constructive conditional normalizing flows",
    "summary": "Motivated by applications in conditional sampling, given a probability measure $μ$ and a diffeomorphism $φ$, we consider the problem of simultaneously approximating $φ$ and the pushforward $φ_{\\#}μ$ by means of the flow of a continuity equation whose velocity field is a perceptron neural network with piecewise constant weights. We provide an explicit construction based on a polar-like decomposition of the Lagrange interpolant of $φ$. The latter involves a compressible component, given by the gradient of a particular convex function, which can be realized exactly, and an incompressible component, which -- after approximating via permutations -- can be implemented through shear flows intrinsic to the continuity equation. For more regular maps $φ$ -- such as the Knöthe-Rosenblatt rearrangement -- we provide an alternative, probabilistic construction inspired by the Maurey empirical method, in which the number of discontinuities in the weights doesn't scale inversely with the ambient dimension.",
    "authors": [
      "Borjan Geshkovski",
      "Domènec Ruiz-Balet"
    ],
    "categories": [
      "math.OC",
      "cs.LG",
      "math.AP",
      "math.PR"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08606v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08606v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.08700v1",
    "title": "Do Images Clarify? A Study on the Effect of Images on Clarifying Questions in Conversational Search",
    "summary": "Conversational search systems increasingly employ clarifying questions to refine user queries and improve the search experience. Previous studies have demonstrated the usefulness of text-based clarifying questions in enhancing both retrieval performance and user experience. While images have been shown to improve retrieval performance in various contexts, their impact on user performance when incorporated into clarifying questions remains largely unexplored. We conduct a user study with 73 participants to investigate the role of images in conversational search, specifically examining their effects on two search-related tasks: (i) answering clarifying questions and (ii) query reformulation. We compare the effect of multimodal and text-only clarifying questions in both tasks within a conversational search context from various perspectives. Our findings reveal that while participants showed a strong preference for multimodal questions when answering clarifying questions, preferences were more balanced in the query reformulation task. The impact of images varied with both task type and user expertise. In answering clarifying questions, images helped maintain engagement across different expertise levels, while in query reformulation they led to more precise queries and improved retrieval performance. Interestingly, for clarifying question answering, text-only setups demonstrated better user performance as they provided more comprehensive textual information in the absence of images. These results provide valuable insights for designing effective multimodal conversational search systems, highlighting that the benefits of visual augmentation are task-dependent and should be strategically implemented based on the specific search context and user characteristics.",
    "authors": [
      "Clemencia Siro",
      "Zahra Abbasiantaeb",
      "Yifei Yuan",
      "Mohammad Aliannejadi",
      "Maarten de Rijke"
    ],
    "categories": [
      "cs.CL",
      "cs.HC",
      "cs.IR"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08700v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08700v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2602.08626v1",
    "title": "Revisiting [CLS] and Patch Token Interaction in Vision Transformers",
    "summary": "Vision Transformers have emerged as powerful, scalable and versatile representation learners. To capture both global and local features, a learnable [CLS] class token is typically prepended to the input sequence of patch tokens. Despite their distinct nature, both token types are processed identically throughout the model. In this work, we investigate the friction between global and local feature learning under different pre-training strategies by analyzing the interactions between class and patch tokens. Our analysis reveals that standard normalization layers introduce an implicit differentiation between these token types. Building on this insight, we propose specialized processing paths that selectively disentangle the computational flow of class and patch tokens, particularly within normalization layers and early query-key-value projections. This targeted specialization leads to significantly improved patch representation quality for dense prediction tasks. Our experiments demonstrate segmentation performance gains of over 2 mIoU points on standard benchmarks, while maintaining strong classification accuracy. The proposed modifications introduce only an 8% increase in parameters, with no additional computational overhead. Through comprehensive ablations, we provide insights into which architectural components benefit most from specialization and how our approach generalizes across model scales and learning frameworks.",
    "authors": [
      "Alexis Marouani",
      "Oriane Siméoni",
      "Hervé Jégou",
      "Piotr Bojanowski",
      "Huy V. Vo"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08626v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08626v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2602.08613v1",
    "title": "Overview and Comparison of AVS Point Cloud Compression Standard",
    "summary": "Point cloud is a prevalent 3D data representation format with significant application values in immersive media, autonomous driving, digital heritage protection, etc. However, the large data size of point clouds poses challenges to transmission and storage, which influences the wide deployments. Therefore, point cloud compression plays a crucial role in practical applications for both human and machine perception optimization. To this end, the Moving Picture Experts Group (MPEG) has established two standards for point cloud compression, including Geometry-based Point Cloud Compression (G-PCC) and Video-based Point Cloud Compression (V-PCC). In the meantime, the Audio Video coding Standard (AVS) Workgroup of China also have launched and completed the development for its first generation point cloud compression standard, namely AVS PCC. This new standardization effort has adopted many new coding tools and techniques, which are different from the other counterpart standards. This paper reviews the AVS PCC standard from two perspectives, i.e., the related technologies and performance comparisons.",
    "authors": [
      "Wei Gao",
      "Wenxu Gao",
      "Xingming Mu",
      "Changhao Peng",
      "Ge Li"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08613v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08613v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2602.08996v1",
    "title": "Generalizing Sports Feedback Generation by Watching Competitions and Reading Books: A Rock Climbing Case Study",
    "summary": "While there is rapid progress in video-LLMs with advanced reasoning capabilities, prior work shows that these models struggle on the challenging task of sports feedback generation and require expensive and difficult-to-collect finetuning feedback data for each sport. This limitation is evident from the poor generalization to sports unseen during finetuning. Furthermore, traditional text generation evaluation metrics (e.g., BLEU-4, METEOR, ROUGE-L, BERTScore), originally developed for machine translation and summarization, fail to capture the unique aspects of sports feedback quality. To address the first problem, using rock climbing as our case study, we propose using auxiliary freely-available web data from the target domain, such as competition videos and coaching manuals, in addition to existing sports feedback from a disjoint, source domain to improve sports feedback generation performance on the target domain. To improve evaluation, we propose two evaluation metrics: (1) specificity and (2) actionability. Together, our approach enables more meaningful and practical generation of sports feedback under limited annotations.",
    "authors": [
      "Arushi Rai",
      "Adriana Kovashka"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08996v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08996v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2602.08754v1",
    "title": "Belief Offloading in Human-AI Interaction",
    "summary": "What happens when people's beliefs are derived from information provided by an LLM? People's use of LLM chatbots as thought partners can contribute to cognitive offloading, which can have adverse effects on cognitive skills in cases of over-reliance. This paper defines and investigates a particular kind of cognitive offloading in human-AI interaction, \"belief offloading,\" in which people's processes of forming and upholding beliefs are offloaded onto an AI system with downstream consequences on their behavior and the nature of their system of beliefs. Drawing on philosophy, psychology, and computer science research, we clarify the boundary conditions under which belief offloading occurs and provide a descriptive taxonomy of belief offloading and its normative implications. We close with directions for future work to assess the potential for and consequences of belief offloading in human-AI interaction.",
    "authors": [
      "Rose E. Guingrich",
      "Dvija Mehta",
      "Umang Bhatt"
    ],
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08754v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08754v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2602.08708v1",
    "title": "Intermediate Results on the Complexity of STRIPS$_{1}^{1}$",
    "summary": "This paper is based on Bylander's results on the computational complexity of propositional STRIPS planning. He showed that when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. While NP-hardness is settled, it is unknown whether propositional STRIPS with operators that only have one precondition and one effect is NP-complete. We shed light on the question whether this small solution hypothesis for STRIPS$^1_1$ is true, calling a SAT solver for small instances, introducing the literal graph, and mapping it to Petri nets.",
    "authors": [
      "Stefan Edelkamp",
      "Jiří Fink",
      "Petr Gregor",
      "Anders Jonsson",
      "Bernhard Nebel"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08708v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08708v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2602.08822v1",
    "title": "Any-to-All MRI Synthesis: A Unified Foundation Model for Nasopharyngeal Carcinoma and Its Downstream Applications",
    "summary": "Magnetic resonance imaging (MRI) is essential for nasopharyngeal carcinoma (NPC) radiotherapy (RT), but practical constraints, such as patient discomfort, long scan times, and high costs often lead to incomplete modalities in clinical practice, compromising RT planning accuracy. Traditional MRI synthesis methods are modality-specific, limited in anatomical adaptability, and lack clinical interpretability-failing to meet NPC's RT needs. Here, we developed a unified foundation model integrating contrastive visual representation learning and vision-language alignment (VLA) to enable any-to-all MRI synthesis. The model uses a contrastive encoder for modality-invariant representations and a CLIP-based text-informed decoder for semantically consistent synthesis, supporting any-to-all MRI synthesis via one unified foundation model. Trained on 40,825 images from 13 institutions, it achieves consistently high performance (average SSIM 0.90, PSNR 27) across 26 internal/external validation sites (15,748 images), with superior synthesis fidelity and robustness to noise and domain shifts. Meanwhile, its unified representation enhances downstream RT-relevant tasks (e.g., segmentation). This work advances digital medicine solutions for NPC care by leveraging foundation models to bridge technical synthesis and clinical utility.",
    "authors": [
      "Yao Pu",
      "Yiming Shi",
      "Zhenxi Zhang",
      "Peixin Yu",
      "Yitao Zhuang",
      "Xiang Wang",
      "Hongzhao Chen",
      "Jing Cai",
      "Ge Ren"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08822v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08822v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.49
  },
  {
    "arxiv_id": "2602.08620v1",
    "title": "Improving Reconstruction of Representation Autoencoder",
    "summary": "Recent work leverages Vision Foundation Models as image encoders to boost the generative performance of latent diffusion models (LDMs), as their semantic feature distributions are easy to learn. However, such semantic features often lack low-level information (\\eg, color and texture), leading to degraded reconstruction fidelity, which has emerged as a primary bottleneck in further scaling LDMs. To address this limitation, we propose LV-RAE, a representation autoencoder that augments semantic features with missing low-level information, enabling high-fidelity reconstruction while remaining highly aligned with the semantic distribution. We further observe that the resulting high-dimensional, information-rich latent make decoders sensitive to latent perturbations, causing severe artifacts when decoding generated latent and consequently degrading generation quality. Our analysis suggests that this sensitivity primarily stems from excessive decoder responses along directions off the data manifold. Building on these insights, we propose fine-tuning the decoder to increase its robustness and smoothing the generated latent via controlled noise injection, thereby enhancing generation quality. Experiments demonstrate that LV-RAE significantly improves reconstruction fidelity while preserving the semantic abstraction and achieving strong generative quality. Our code is available at https://github.com/modyu-liu/LVRAE.",
    "authors": [
      "Siyu Liu",
      "Chujie Qin",
      "Hubery Yin",
      "Qixin Yan",
      "Zheng-Peng Duan",
      "Chen Li",
      "Jing Lyu",
      "Chun-Le Guo",
      "Chongyi Li"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08620v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08620v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.48
  },
  {
    "arxiv_id": "2602.08726v1",
    "title": "SynSacc: A Blender-to-V2E Pipeline for Synthetic Neuromorphic Eye-Movement Data and Sim-to-Real Spiking Model Training",
    "summary": "The study of eye movements, particularly saccades and fixations, are fundamental to understanding the mechanisms of human cognition and perception. Accurate classification of these movements requires sensing technologies capable of capturing rapid dynamics without distortion. Event cameras, also known as Dynamic Vision Sensors (DVS), provide asynchronous recordings of changes in light intensity, thereby eliminating motion blur inherent in conventional frame-based cameras and offering superior temporal resolution and data efficiency. In this study, we introduce a synthetic dataset generated with Blender to simulate saccades and fixations under controlled conditions. Leveraging Spiking Neural Networks (SNNs), we evaluate its robustness by training two architectures and finetuning on real event data. The proposed models achieve up to 0.83 accuracy and maintain consistent performance across varying temporal resolutions, demonstrating stability in eye movement classification. Moreover, the use of SNNs with synthetic event streams yields substantial computational efficiency gains over artificial neural network (ANN) counterparts, underscoring the utility of synthetic data augmentation in advancing event-based vision. All code and datasets associated with this work is available at https: //github.com/Ikhadija-5/SynSacc-Dataset.",
    "authors": [
      "Khadija Iddrisu",
      "Waseem Shariff",
      "Suzanne Little",
      "Noel OConnor"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08726v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08726v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2602.08962v1",
    "title": "Modeling 3D Pedestrian-Vehicle Interactions for Vehicle-Conditioned Pose Forecasting",
    "summary": "Accurately predicting pedestrian motion is crucial for safe and reliable autonomous driving in complex urban environments. In this work, we present a 3D vehicle-conditioned pedestrian pose forecasting framework that explicitly incorporates surrounding vehicle information. To support this, we enhance the Waymo-3DSkelMo dataset with aligned 3D vehicle bounding boxes, enabling realistic modeling of multi-agent pedestrian-vehicle interactions. We introduce a sampling scheme to categorize scenes by pedestrian and vehicle count, facilitating training across varying interaction complexities. Our proposed network adapts the TBIFormer architecture with a dedicated vehicle encoder and pedestrian-vehicle interaction cross-attention module to fuse pedestrian and vehicle features, allowing predictions to be conditioned on both historical pedestrian motion and surrounding vehicles. Extensive experiments demonstrate substantial improvements in forecasting accuracy and validate different approaches for modeling pedestrian-vehicle interactions, highlighting the importance of vehicle-aware 3D pose prediction for autonomous driving. Code is available at: https://github.com/GuangxunZhu/VehCondPose3D",
    "authors": [
      "Guangxun Zhu",
      "Xuan Liu",
      "Nicolas Pugeault",
      "Chongfeng Wei",
      "Edmond S. L. Ho"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08962v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08962v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.46
  },
  {
    "arxiv_id": "2602.08699v1",
    "title": "Low-Light Video Enhancement with An Effective Spatial-Temporal Decomposition Paradigm",
    "summary": "Low-Light Video Enhancement (LLVE) seeks to restore dynamic or static scenes plagued by severe invisibility and noise. In this paper, we present an innovative video decomposition strategy that incorporates view-independent and view-dependent components to enhance the performance of LLVE. The framework is called View-aware Low-light Video Enhancement (VLLVE). We leverage dynamic cross-frame correspondences for the view-independent term (which primarily captures intrinsic appearance) and impose a scene-level continuity constraint on the view-dependent term (which mainly describes the shading condition) to achieve consistent and satisfactory decomposition results. To further ensure consistent decomposition, we introduce a dual-structure enhancement network featuring a cross-frame interaction mechanism. By supervising different frames simultaneously, this network encourages them to exhibit matching decomposition features. This mechanism can seamlessly integrate with encoder-decoder single-frame networks, incurring minimal additional parameter costs. Building upon VLLVE, we propose a more comprehensive decomposition strategy by introducing an additive residual term, resulting in VLLVE++. This residual term can simulate scene-adaptive degradations, which are difficult to model using a decomposition formulation for common scenes, thereby further enhancing the ability to capture the overall content of videos. In addition, VLLVE++ enables bidirectional learning for both enhancement and degradation-aware correspondence refinement (end-to-end manner), effectively increasing reliable correspondences while filtering out incorrect ones. Notably, VLLVE++ demonstrates strong capability in handling challenging cases, such as real-world scenes and videos with high dynamics. Extensive experiments are conducted on widely recognized LLVE benchmarks.",
    "authors": [
      "Xiaogang Xu",
      "Kun Zhou",
      "Tao Hu",
      "Jiafei Wu",
      "Ruixing Wang",
      "Hao Peng",
      "Bei Yu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08699v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08699v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.46
  },
  {
    "arxiv_id": "2602.08971v1",
    "title": "WorldArena: A Unified Benchmark for Evaluating Perception and Functional Utility of Embodied World Models",
    "summary": "While world models have emerged as a cornerstone of embodied intelligence by enabling agents to reason about environmental dynamics through action-conditioned prediction, their evaluation remains fragmented. Current evaluation of embodied world models has largely focused on perceptual fidelity (e.g., video generation quality), overlooking the functional utility of these models in downstream decision-making tasks. In this work, we introduce WorldArena, a unified benchmark designed to systematically evaluate embodied world models across both perceptual and functional dimensions. WorldArena assesses models through three dimensions: video perception quality, measured with 16 metrics across six sub-dimensions; embodied task functionality, which evaluates world models as data engines, policy evaluators, and action planners integrating with subjective human evaluation. Furthermore, we propose EWMScore, a holistic metric integrating multi-dimensional performance into a single interpretable index. Through extensive experiments on 14 representative models, we reveal a significant perception-functionality gap, showing that high visual quality does not necessarily translate into strong embodied task capability. WorldArena benchmark with the public leaderboard is released at https://worldarena.ai, providing a framework for tracking progress toward truly functional world models in embodied AI.",
    "authors": [
      "Yu Shang",
      "Zhuohang Li",
      "Yiding Ma",
      "Weikang Su",
      "Xin Jin",
      "Ziyou Wang",
      "Xin Zhang",
      "Yinzhou Tang",
      "Chen Gao",
      "Wei Wu",
      "Xihui Liu",
      "Dhruv Shah",
      "Zhaoxiang Zhang",
      "Zhibo Chen",
      "Jun Zhu",
      "Yonghong Tian",
      "Tat-Seng Chua",
      "Wenwu Zhu",
      "Yong Li"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "published": "2026-02-09",
    "url": "https://arxiv.org/abs/2602.08971v1",
    "pdf_url": "https://arxiv.org/pdf/2602.08971v1.pdf",
    "date": "2026-02-10",
    "source": "arxiv",
    "research_score": 0.44
  }
]