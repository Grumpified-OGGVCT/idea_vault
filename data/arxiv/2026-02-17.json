[
  {
    "arxiv_id": "2602.14158v1",
    "title": "A Multi-Agent Framework for Medical AI: Leveraging Fine-Tuned GPT, LLaMA, and DeepSeek R1 for Evidence-Based and Bias-Aware Clinical Query Processing",
    "summary": "Large language models (LLMs) show promise for healthcare question answering, but clinical use is limited by weak verification, insufficient evidence grounding, and unreliable confidence signalling. We propose a multi-agent medical QA framework that combines complementary LLMs with evidence retrieval, uncertainty estimation, and bias checks to improve answer reliability. Our approach has two phases. First, we fine-tune three representative LLM families (GPT, LLaMA, and DeepSeek R1) on MedQuAD-derived medical QA data (20k+ question-answer pairs across multiple NIH domains) and benchmark generation quality. DeepSeek R1 achieves the strongest scores (ROUGE-1 0.536 +- 0.04; ROUGE-2 0.226 +-0.03; BLEU 0.098 -+ 0.018) and substantially outperforms the specialised biomedical baseline BioGPT in zero-shot evaluation. Second, we implement a modular multi-agent pipeline in which a Clinical Reasoning agent (fine-tuned LLaMA) produces structured explanations, an Evidence Retrieval agent queries PubMed to ground responses in recent literature, and a Refinement agent (DeepSeek R1) improves clarity and factual consistency; an optional human validation path is triggered for high-risk or high-uncertainty cases. Safety mechanisms include Monte Carlo dropout and perplexity-based uncertainty scoring, plus lexical and sentiment-based bias detection supported by LIME/SHAP-based analyses. In evaluation, the full system achieves 87% accuracy with relevance around 0.80, and evidence augmentation reduces uncertainty (perplexity 4.13) compared to base responses, with mean end-to-end latency of 36.5 seconds under the reported configuration. Overall, the results indicate that agent specialisation and verification layers can mitigate key single-model limitations and provide a practical, extensible design for evidence-based and bias-aware medical AI.",
    "authors": [
      "Naeimeh Nourmohammadi",
      "Md Meem Hossain",
      "The Anh Han",
      "Safina Showkat Ara",
      "Zia Ush Shamszaman"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14158v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14158v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2602.14041v1",
    "title": "BitDance: Scaling Autoregressive Generative Models with Binary Tokens",
    "summary": "We present BitDance, a scalable autoregressive (AR) image generator that predicts binary visual tokens instead of codebook indices. With high-entropy binary latents, BitDance lets each token represent up to $2^{256}$ states, yielding a compact yet highly expressive discrete representation. Sampling from such a huge token space is difficult with standard classification. To resolve this, BitDance uses a binary diffusion head: instead of predicting an index with softmax, it employs continuous-space diffusion to generate the binary tokens. Furthermore, we propose next-patch diffusion, a new decoding method that predicts multiple tokens in parallel with high accuracy, greatly speeding up inference. On ImageNet 256x256, BitDance achieves an FID of 1.24, the best among AR models. With next-patch diffusion, BitDance beats state-of-the-art parallel AR models that use 1.4B parameters, while using 5.4x fewer parameters (260M) and achieving 8.7x speedup. For text-to-image generation, BitDance trains on large-scale multimodal tokens and generates high-resolution, photorealistic images efficiently, showing strong performance and favorable scaling. When generating 1024x1024 images, BitDance achieves a speedup of over 30x compared to prior AR models. We release code and models to facilitate further research on AR foundation models. Code and models are available at: https://github.com/shallowdream204/BitDance.",
    "authors": [
      "Yuang Ai",
      "Jiaming Han",
      "Shaobin Zhuang",
      "Weijia Mao",
      "Xuefeng Hu",
      "Ziyan Yang",
      "Zhenheng Yang",
      "Huaibo Huang",
      "Xiangyu Yue",
      "Hao Chen"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14041v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14041v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2602.14012v1",
    "title": "From SFT to RL: Demystifying the Post-Training Pipeline for LLM-based Vulnerability Detection",
    "summary": "The integration of LLMs into vulnerability detection (VD) has shifted the field toward interpretable and context-aware analysis. While post-training methods have shown promise in general coding tasks, their systematic application to VD remains underexplored. In this paper, we present the first comprehensive investigation into the post-training pipeline for LLM-based VD, spanning from cold-start SFT to off-policy preference optimization and on-policy RL, uncovering how data curation, stage interactions, reward mechanisms, and evaluation protocols collectively dictate the efficacy of model training and assessment. Our study identifies practical guidelines and insights: (1) SFT based on rejection sampling greatly outperforms rationalization-based supervision, which can introduce hallucinations due to ground-truth leakage. (2) While increased SFT epochs constantly benefit preference optimization, excessive SFT inhibits self-exploration during RL, ultimately limiting performance gains. (3) Coarse-grained reward signals often mislead RL, whereas fine-grained root-cause judgments ensure reliable credit assignment. Specification-based rewards offer further benefits but incur significant effort in specification generation. (4) Although filtering extremely hard-to-detect vulnerability samples improves RL training efficiency, the cost of performance loss should be considered in practical applications. (5) Models trained under GRPO significantly outperform those using SFT and preference optimization (i.e., DPO and ORPO), as well as a series of zero-shot SOTA LLMs, underscoring the significant potential of on-policy RL for LLM-based VD. (6) In contrast to binary matching that tends to overestimate performance, LLM-as-a-Judge based on root-cause analysis provides a more robust evaluation protocol, although its accuracy varies across judge models with different levels of security expertise.",
    "authors": [
      "Youpeng Li",
      "Fuxun Yu",
      "Xinda Wang"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14012v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14012v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2602.13937v1",
    "title": "A Multi-Agent Framework for Code-Guided, Modular, and Verifiable Automated Machine Learning",
    "summary": "Automated Machine Learning (AutoML) has revolutionized the development of data-driven solutions; however, traditional frameworks often function as \"black boxes\", lacking the flexibility and transparency required for complex, real-world engineering tasks. Recent Large Language Model (LLM)-based agents have shifted toward code-driven approaches. However, they frequently suffer from hallucinated logic and logic entanglement, where monolithic code generation leads to unrecoverable runtime failures. In this paper, we present iML, a novel multi-agent framework designed to shift AutoML from black-box prompting to a code-guided, modular, and verifiable architectural paradigm. iML introduces three main ideas: (1) Code-Guided Planning, which synthesizes a strategic blueprint grounded in autonomous empirical profiling to eliminate hallucination; (2) Code-Modular Implementation, which decouples preprocessing and modeling into specialized components governed by strict interface contracts; and (3) Code-Verifiable Integration, which enforces physical feasibility through dynamic contract verification and iterative self-correction. We evaluate iML across MLE-BENCH and the newly introduced iML-BENCH, comprising a diverse range of real-world Kaggle competitions. The experimental results show iML's superiority over state-of-the-art agents, achieving a valid submission rate of 85% and a competitive medal rate of 45% on MLE-BENCH, with an average standardized performance score (APS) of 0.77. On iML-BENCH, iML significantly outperforms the other approaches by 38%-163% in APS. Furthermore, iML maintains a robust 70% success rate even under stripped task descriptions, effectively filling information gaps through empirical profiling. These results highlight iML's potential to bridge the gap between stochastic generation and reliable engineering, marking a meaningful step toward truly AutoML.",
    "authors": [
      "Dat Le",
      "Duc-Cuong Le",
      "Anh-Son Nguyen",
      "Tuan-Dung Bui",
      "Thu-Trang Nguyen",
      "Son Nguyen",
      "Hieu Dinh Vo"
    ],
    "categories": [
      "cs.LG",
      "cs.SE"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13937v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13937v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2602.14065v1",
    "title": "REAL: Resolving Knowledge Conflicts in Knowledge-Intensive Visual Question Answering via Reasoning-Pivot Alignment",
    "summary": "Knowledge-intensive Visual Question Answering (KI-VQA) frequently suffers from severe knowledge conflicts caused by the inherent limitations of open-domain retrieval. However, existing paradigms face critical limitations due to the lack of generalizable conflict detection and intra-model constraint mechanisms to handle conflicting evidence. To address these challenges, we propose the REAL (Reasoning-Pivot Alignment) framework centered on the novel concept of the Reasoning-Pivot. Distinct from reasoning steps that prioritize internal self-derivation, a reasoning-pivot serves as an atomic unit (node or edge) in the reasoning chain that emphasizes knowledge linkage, and it typically relies on external evidence to complete the reasoning. Supported by our constructed REAL-VQA dataset, our approach integrates Reasoning-Pivot Aware SFT (RPA-SFT) to train a generalizable discriminator by aligning conflicts with pivot extraction, and employs Reasoning-Pivot Guided Decoding (RPGD), an intra-model decoding strategy that leverages these pivots for targeted conflict mitigation. Extensive experiments across diverse benchmarks demonstrate that REAL significantly enhances discrimination accuracy and achieves state-of-the-art performance, validating the effectiveness of our pivot-driven resolution paradigm.",
    "authors": [
      "Kai Ye",
      "Xianwei Mao",
      "Sheng Zhou",
      "Zirui Shao",
      "Ye Mo",
      "Liangliang Liu",
      "Haikuan Huang",
      "Bin Li",
      "Jiajun Bu"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14065v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14065v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2602.14060v1",
    "title": "LM-Lexicon: Improving Definition Modeling via Harmonizing Semantic Experts",
    "summary": "We introduce LM-Lexicon, an innovative definition modeling approach that incorporates data clustering, semantic expert learning, and model merging using a sparse mixture-of-experts architecture. By decomposing the definition modeling task into specialized semantic domains, where small language models are trained as domain experts, LM-Lexicon achieves substantial improvements (+7% BLEU score compared with the prior state-of-the-art model) over existing methods on five widely used benchmarks. Empirically, we demonstrate that 1) the clustering strategy enables fine-grained expert specialization with nearly 10% improvement in definition quality; 2) the semantic-aware domain-level routing mechanism achieves higher expert efficacy (+1%) than conventional token-level routing; and 3) further performance gains can be obtained through test-time compute and semantic expert scaling. Our work advances definition modeling while providing insights into the development of efficient language models for semantic-intensive applications.",
    "authors": [
      "Yang Liu",
      "Jiaye Yang",
      "Weikang Li",
      "Jiahui Liang",
      "Yang Li",
      "Lingyong Yan"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14060v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14060v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2602.14010v1",
    "title": "A Deployment-Friendly Foundational Framework for Efficient Computational Pathology",
    "summary": "Pathology foundation models (PFMs) have enabled robust generalization in computational pathology through large-scale datasets and expansive architectures, but their substantial computational cost, particularly for gigapixel whole slide images, limits clinical accessibility and scalability. Here, we present LitePath, a deployment-friendly foundational framework designed to mitigate model over-parameterization and patch level redundancy. LitePath integrates LiteFM, a compact model distilled from three large PFMs (Virchow2, H-Optimus-1 and UNI2) using 190 million patches, and the Adaptive Patch Selector (APS), a lightweight component for task-specific patch selection. The framework reduces model parameters by 28x and lowers FLOPs by 403.5x relative to Virchow2, enabling deployment on low-power edge hardware such as the NVIDIA Jetson Orin Nano Super. On this device, LitePath processes 208 slides per hour, 104.5x faster than Virchow2, and consumes 0.36 kWh per 3,000 slides, 171x lower than Virchow2 on an RTX3090 GPU. We validated accuracy using 37 cohorts across four organs and 26 tasks (26 internal, 9 external, and 2 prospective), comprising 15,672 slides from 9,808 patients disjoint from the pretraining data. LitePath ranks second among 19 evaluated models and outperforms larger models including H-Optimus-1, mSTAR, UNI2 and GPFM, while retaining 99.71% of the AUC of Virchow2 on average. To quantify the balance between accuracy and efficiency, we propose the Deployability Score (D-Score), defined as the weighted geometric mean of normalized AUC and normalized FLOP, where LitePath achieves the highest value, surpassing Virchow2 by 10.64%. These results demonstrate that LitePath enables rapid, cost-effective and energy-efficient pathology image analysis on accessible hardware while maintaining accuracy comparable to state-of-the-art PFMs and reducing the carbon footprint of AI deployment.",
    "authors": [
      "Yu Cai",
      "Cheng Jin",
      "Jiabo Ma",
      "Fengtao Zhou",
      "Yingxue Xu",
      "Zhengrui Guo",
      "Yihui Wang",
      "Zhengyu Zhang",
      "Ling Liang",
      "Yonghao Tan",
      "Pingcheng Dong",
      "Du Cai",
      "On Ki Tang",
      "Chenglong Zhao",
      "Xi Wang",
      "Can Yang",
      "Yali Xu",
      "Jing Cui",
      "Zhenhui Li",
      "Ronald Cheong Kin Chan",
      "Yueping Liu",
      "Feng Gao",
      "Xiuming Zhang",
      "Li Liang",
      "Hao Chen",
      "Kwang-Ting Cheng"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14010v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14010v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2602.14089v1",
    "title": "TabTracer: Monte Carlo Tree Search for Complex Table Reasoning with Large Language Models",
    "summary": "Large language models (LLMs) have emerged as powerful tools for natural language table reasoning, where there are two main categories of methods. Prompt-based approaches rely on language-only inference or one-pass program generation without step-level verification. Agent-based approaches use tools in a closed loop, but verification is often local and backtracking is limited, allowing errors to propagate and increasing cost. Moreover, they rely on chain- or beam-style trajectories that are typically combinatorially redundant, leading to high token costs. In this paper, we propose TabTracer, an agentic framework that coordinates multi-step tool calls over intermediate table states, with explicit state tracking for verification and rollback. First, it enforces step-level verification with typed operations and lightweight numeric and format checks to provide reliable rewards and suppress hallucinations. Second, execution-feedback Monte Carlo Tree Search maintains a search tree of candidate table states and uses backpropagated reflection scores to guide UCB1 selection and rollback via versioned snapshots. Third, it reduces redundancy with budget-aware pruning, deduplication, and state hashing with a monotonicity gate to cut token cost. Comprehensive evaluation on TabFact, WikiTQ, and CRT datasets shows that TabTracer outperforms state-of-the-art baselines by up to 6.7% in accuracy while reducing token consumption by 59--84%.",
    "authors": [
      "Zhizhao Luo",
      "Zhaojing Luo",
      "Meihui Zhang",
      "Rui Mao"
    ],
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14089v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14089v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2602.13933v1",
    "title": "HyMem: Hybrid Memory Architecture with Dynamic Retrieval Scheduling",
    "summary": "Large language model (LLM) agents demonstrate strong performance in short-text contexts but often underperform in extended dialogues due to inefficient memory management. Existing approaches face a fundamental trade-off between efficiency and effectiveness: memory compression risks losing critical details required for complex reasoning, while retaining raw text introduces unnecessary computational overhead for simple queries. The crux lies in the limitations of monolithic memory representations and static retrieval mechanisms, which fail to emulate the flexible and proactive memory scheduling capabilities observed in humans, thus struggling to adapt to diverse problem scenarios. Inspired by the principle of cognitive economy, we propose HyMem, a hybrid memory architecture that enables dynamic on-demand scheduling through multi-granular memory representations. HyMem adopts a dual-granular storage scheme paired with a dynamic two-tier retrieval system: a lightweight module constructs summary-level context for efficient response generation, while an LLM-based deep module is selectively activated only for complex queries, augmented by a reflection mechanism for iterative reasoning refinement. Experiments show that HyMem achieves strong performance on both the LOCOMO and LongMemEval benchmarks, outperforming full-context while reducing computational cost by 92.6\\%, establishing a state-of-the-art balance between efficiency and performance in long-term memory management.",
    "authors": [
      "Xiaochen Zhao",
      "Kaikai Wang",
      "Xiaowen Zhang",
      "Chen Yao",
      "Aili Wang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13933v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13933v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2602.14083v1",
    "title": "Plan-MCTS: Plan Exploration for Action Exploitation in Web Navigation",
    "summary": "Large Language Models (LLMs) have empowered autonomous agents to handle complex web navigation tasks. While recent studies integrate tree search to enhance long-horizon reasoning, applying these algorithms in web navigation faces two critical challenges: sparse valid paths that lead to inefficient exploration, and a noisy context that dilutes accurate state perception. To address this, we introduce Plan-MCTS, a framework that reformulates web navigation by shifting exploration to a semantic Plan Space. By decoupling strategic planning from execution grounding, it transforms sparse action space into a Dense Plan Tree for efficient exploration, and distills noisy contexts into an Abstracted Semantic History for precise state awareness. To ensure efficiency and robustness, Plan-MCTS incorporates a Dual-Gating Reward to strictly validate both physical executability and strategic alignment and Structural Refinement for on-policy repair of failed subplans. Extensive experiments on WebArena demonstrate that Plan-MCTS achieves state-of-the-art performance, surpassing current approaches with higher task effectiveness and search efficiency.",
    "authors": [
      "Weiming Zhang",
      "Jihong Wang",
      "Jiamu Zhou",
      "Qingyao Li",
      "Xinbei Ma",
      "Congmin Zheng",
      "Xingyu Lou",
      "Weiwen Liu",
      "Zhuosheng Zhang",
      "Jun Wang",
      "Yong Yu",
      "Weinan Zhang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14083v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14083v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2602.14177v1",
    "title": "Towards Spatial Transcriptomics-driven Pathology Foundation Models",
    "summary": "Spatial transcriptomics (ST) provides spatially resolved measurements of gene expression, enabling characterization of the molecular landscape of human tissue beyond histological assessment as well as localized readouts that can be aligned with morphology. Concurrently, the success of multimodal foundation models that integrate vision with complementary modalities suggests that morphomolecular coupling between local expression and morphology can be systematically used to improve histological representations themselves. We introduce Spatial Expression-Aligned Learning (SEAL), a vision-omics self-supervised learning framework that infuses localized molecular information into pathology vision encoders. Rather than training new encoders from scratch, SEAL is designed as a parameter-efficient vision-omics finetuning method that can be flexibly applied to widely used pathology foundation models. We instantiate SEAL by training on over 700,000 paired gene expression spot-tissue region examples spanning tumor and normal samples from 14 organs. Tested across 38 slide-level and 15 patch-level downstream tasks, SEAL provides a drop-in replacement for pathology foundation models that consistently improves performance over widely used vision-only and ST prediction baselines on slide-level molecular status, pathway activity, and treatment response prediction, as well as patch-level gene expression prediction tasks. Additionally, SEAL encoders exhibit robust domain generalization on out-of-distribution evaluations and enable new cross-modal capabilities such as gene-to-image retrieval. Our work proposes a general framework for ST-guided finetuning of pathology foundation models, showing that augmenting existing models with localized molecular supervision is an effective and practical step for improving visual representations and expanding their cross-modal utility.",
    "authors": [
      "Konstantin Hemker",
      "Andrew H. Song",
      "Cristina Almagro-PÃ©rez",
      "Guillaume Jaume",
      "Sophia J. Wagner",
      "Anurag Vaidya",
      "Nikola Simidjievski",
      "Mateja Jamnik",
      "Faisal Mahmood"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14177v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14177v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2602.14054v1",
    "title": "LogitsCoder: Towards Efficient Chain-of-Thought Path Search via Logits Preference Decoding for Code Generation",
    "summary": "Code generation remains a challenging task that requires precise and structured reasoning. Existing Test Time Scaling (TTS) methods, including structured tree search, have made progress in exploring reasoning paths but still face two major challenges: (1) underthinking, where reasoning chains tend to be shallow and fail to capture the full complexity of problems; and (2) overthinking, where overly verbose reasoning leads to inefficiency and increased computational costs. To address these issues, we propose LogitsCoder, a novel framework that enhances chain-of-thought reasoning through lightweight, logit-level control mechanisms for code generation. LogitsCoder iteratively generates and refines reasoning steps by first steering token selection toward statistically preferred patterns via Logits Preference Decoding, then selecting and aggregating diverse reasoning paths using Logits Rank Based Path Selection and Thoughts Aggregation. This results in coherent and effective reasoning chains that balance depth and efficiency. Extensive experiments demonstrate that LogitsCoder produces more efficient and higher-quality reasoning chains, leading to superior code generation performance compared to baseline methods.",
    "authors": [
      "Jizheng Chen",
      "Weiming Zhang",
      "Xinyi Dai",
      "Weiwen Liu",
      "Kounianhua Du",
      "Yasheng Wang",
      "Ruiming Tang",
      "Yong Yu",
      "Weinan Zhang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14054v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14054v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2602.14043v1",
    "title": "Beyond Static Snapshots: Dynamic Modeling and Forecasting of Group-Level Value Evolution with Large Language Models",
    "summary": "Social simulation is critical for mining complex social dynamics and supporting data-driven decision making. LLM-based methods have emerged as powerful tools for this task by leveraging human-like social questionnaire responses to model group behaviors. Existing LLM-based approaches predominantly focus on group-level values at discrete time points, treating them as static snapshots rather than dynamic processes. However, group-level values are not fixed but shaped by long-term social changes. Modeling their dynamics is thus crucial for accurate social evolution prediction--a key challenge in both data mining and social science. This problem remains underexplored due to limited longitudinal data, group heterogeneity, and intricate historical event impacts.   To bridge this gap, we propose a novel framework for group-level dynamic social simulation by integrating historical value trajectories into LLM-based human response modeling. We select China and the U.S. as representative contexts, conducting stratified simulations across four core sociodemographic dimensions (gender, age, education, income). Using the World Values Survey, we construct a multi-wave, group-level longitudinal dataset to capture historical value evolution, and then propose the first event-based prediction method for this task, unifying social events, current value states, and group attributes into a single framework. Evaluations across five LLM families show substantial gains: a maximum 30.88\\% improvement on seen questions and 33.97\\% on unseen questions over the Vanilla baseline. We further find notable cross-group heterogeneity: U.S. groups are more volatile than Chinese groups, and younger groups in both countries are more sensitive to external changes. These findings advance LLM-based social simulation and provide new insights for social scientists to understand and predict social value changes.",
    "authors": [
      "Qiankun Pi",
      "Guixin Su",
      "Jinliang Li",
      "Mayi Xu",
      "Xin Miao",
      "Jiawei Jiang",
      "Ming Zhong",
      "Tieyun Qian"
    ],
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14043v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14043v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2602.14003v1",
    "title": "Prompt-Driven Low-Altitude Edge Intelligence: Modular Agents and Generative Reasoning",
    "summary": "The large artificial intelligence models (LAMs) show strong capabilities in perception, reasoning, and multi-modal understanding, and can enable advanced capabilities in low-altitude edge intelligence. However, the deployment of LAMs at the edge remains constrained by some fundamental limitations. First, tasks are rigidly tied to specific models, limiting the flexibility. Besides, the computational and memory demands of full-scale LAMs exceed the capacity of most edge devices. Moreover, the current inference pipelines are typically static, making it difficult to respond to real-time changes of tasks. To address these challenges, we propose a prompt-to-agent edge cognition framework (P2AECF), enabling the flexible, efficient, and adaptive edge intelligence. Specifically, P2AECF transforms high-level semantic prompts into executable reasoning workflows through three key mechanisms. First, the prompt-defined cognition parses task intent into abstract and model-agnostic representations. Second, the agent-based modular execution instantiates these tasks using lightweight and reusable cognitive agents dynamically selected based on current resource conditions. Third, the diffusion-controlled inference planning adaptively constructs and refines execution strategies by incorporating runtime feedback and system context. In addition, we illustrate the framework through a representative low-altitude intelligent network use case, showing its ability to deliver adaptive, modular, and scalable edge intelligence for real-time low-altitude aerial collaborations.",
    "authors": [
      "Jiahao You",
      "Ziye Jia",
      "Chao Dong",
      "Qihui Wu"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14003v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14003v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2602.14160v1",
    "title": "Process-Supervised Multi-Agent Reinforcement Learning for Reliable Clinical Reasoning",
    "summary": "Clinical decision-making requires nuanced reasoning over heterogeneous evidence and traceable justifications. While recent LLM multi-agent systems (MAS) show promise, they largely optimise for outcome accuracy while overlooking process-grounded reasoning aligned with clinical standards. One critical real-world case of this is gene-disease validity curation, where experts must determine whether a gene is causally implicated in a disease by synthesising diverse biomedical evidence. We introduce an agent-as-tool reinforcement learning framework for this task with two objectives: (i) process-level supervision to ensure reasoning follows valid clinical pathways, and (ii) efficient coordination via a hierarchical multi-agent system. Our evaluation on the ClinGen dataset shows that with outcome-only rewards, MAS with a GRPO-trained Qwen3-4B supervisor agent substantially improves final outcome accuracy from 0.195 with a base model supervisor to 0.732, but results in poor process alignment (0.392 F1). Conversely, with process + outcome rewards, MAS with GRPO-trained supervisor achieves higher outcome accuracy (0.750) while significantly improving process fidelity to 0.520 F1. Our code is available at https://github.com/chaeeunlee-io/GeneDiseaseCurationAgents.",
    "authors": [
      "Chaeeun Lee",
      "T. Michael Yates",
      "Pasquale Minervini",
      "T. Ian Simpson"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14160v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14160v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2602.14130v1",
    "title": "Algebraic Quantum Intelligence: A New Framework for Reproducible Machine Creativity",
    "summary": "Large language models (LLMs) have achieved remarkable success in generating fluent and contextually appropriate text; however, their capacity to produce genuinely creative outputs remains limited. This paper posits that this limitation arises from a structural property of contemporary LLMs: when provided with rich context, the space of future generations becomes strongly constrained, and the generation process is effectively governed by near-deterministic dynamics. Recent approaches such as test-time scaling and context adaptation improve performance but do not fundamentally alter this constraint. To address this issue, we propose Algebraic Quantum Intelligence (AQI) as a computational framework that enables systematic expansion of semantic space. AQI is formulated as a noncommutative algebraic structure inspired by quantum theory, allowing properties such as order dependence, interference, and uncertainty to be implemented in a controlled and designable manner. Semantic states are represented as vectors in a Hilbert space, and their evolution is governed by C-values computed from noncommutative operators, thereby ensuring the coexistence and expansion of multiple future semantic possibilities. In this study, we implement AQI by extending a transformer-based LLM with more than 600 specialized operators. We evaluate the resulting system on creative reasoning benchmarks spanning ten domains under an LLM-as-a-judge protocol. The results show that AQI consistently outperforms strong baseline models, yielding statistically significant improvements and reduced cross-domain variance. These findings demonstrate that noncommutative algebraic dynamics can serve as a practical and reproducible foundation for machine creativity. Notably, this architecture has already been deployed in real-world enterprise environments.",
    "authors": [
      "Kazuo Yano",
      "Jonghyeok Lee",
      "Tae Ishitomi",
      "Hironobu Kawaguchi",
      "Akira Koyama",
      "Masakuni Ota",
      "Yuki Ota",
      "Nobuo Sato",
      "Keita Shimada",
      "Sho Takematsu",
      "Ayaka Tobinai",
      "Satomi Tsuji",
      "Kazunori Yanagi",
      "Keiko Yano",
      "Manabu Harada",
      "Yuki Matsuda",
      "Kazunori Matsumoto",
      "Kenichi Matsumura",
      "Hamae Matsuo",
      "Yumi Miyazaki",
      "Kotaro Murai",
      "Tatsuya Ohshita",
      "Marie Seki",
      "Shun Tanoue",
      "Tatsuki Terakado",
      "Yuko Ichimaru",
      "Mirei Saito",
      "Akihiro Otsuka",
      "Koji Ara"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14130v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14130v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2602.14078v1",
    "title": "Policy Gradient with Adaptive Entropy Annealing for Continual Fine-Tuning",
    "summary": "Despite their success, large pretrained vision models remain vulnerable to catastrophic forgetting when adapted to new tasks in class-incremental settings. Parameter-efficient fine-tuning (PEFT) alleviates this by restricting trainable parameters, yet most approaches still rely on cross-entropy (CE) loss, a surrogate for the 0-1 loss, to learn from new data. We revisit this choice and revive the true objective (0-1 loss) through a reinforcement learning perspective. By formulating classification as a one-step Markov Decision Process, we derive an Expected Policy Gradient (EPG) method that directly minimizes misclassification error with a low-variance gradient estimation. Our analysis shows that CE can be interpreted as EPG with an additional sample-weighting mechanism: CE encourages exploration by emphasizing low-confidence samples, while EPG prioritizes high-confidence ones. Building on this insight, we propose adaptive entropy annealing (aEPG), a training strategy that transitions from exploratory (CE-like) to exploitative (EPG-like) learning. aEPG-based methods outperform CE-based methods across diverse benchmarks and with various PEFT modules. More broadly, we evaluate various entropy regularization methods and demonstrate that lower entropy of the output prediction distribution enhances adaptation in pretrained vision models.",
    "authors": [
      "Yaqian Zhang",
      "Bernhard Pfahringer",
      "Eibe Frank",
      "Albert Bifet"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14078v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14078v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2602.14028v1",
    "title": "GRRM: Group Relative Reward Modeling for Machine Translation",
    "summary": "While Group Relative Policy Optimization (GRPO) offers a powerful framework for LLM post-training, its effectiveness in open-ended domains like Machine Translation hinges on accurate intra-group ranking. We identify that standard Scalar Quality Metrics (SQM) fall short in this context; by evaluating candidates in isolation, they lack the comparative context necessary to distinguish fine-grained linguistic nuances. To address this, we introduce the Group Quality Metric (GQM) paradigm and instantiate it via the Group Relative Reward Model (GRRM). Unlike traditional independent scorers, GRRM processes the entire candidate group jointly, leveraging comparative analysis to rigorously resolve relative quality and adaptive granularity. Empirical evaluations confirm that GRRM achieves competitive ranking accuracy among all baselines. Building on this foundation, we integrate GRRM into the GRPO training loop to optimize the translation policy. Experimental results demonstrate that our framework not only improves general translation quality but also unlocks reasoning capabilities comparable to state-of-the-art reasoning models. We release codes, datasets, and model checkpoints at https://github.com/NJUNLP/GRRM.",
    "authors": [
      "Sen Yang",
      "Shanbo Cheng",
      "Lu Xu",
      "Jianbing Zhang",
      "Shujian Huang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14028v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14028v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2602.14178v1",
    "title": "UniWeTok: An Unified Binary Tokenizer with Codebook Size $\\mathit{2^{128}}$ for Unified Multimodal Large Language Model",
    "summary": "Unified Multimodal Large Language Models (MLLMs) require a visual representation that simultaneously supports high-fidelity reconstruction, complex semantic extraction, and generative suitability. However, existing visual tokenizers typically struggle to satisfy these conflicting objectives within a single framework. In this paper, we introduce UniWeTok, a unified discrete tokenizer designed to bridge this gap using a massive binary codebook ($\\mathit{2^{128}}$). For training framework, we introduce Pre-Post Distillation and a Generative-Aware Prior to enhance the semantic extraction and generative prior of the discrete tokens. In terms of model architecture, we propose a convolution-attention hybrid architecture with the SigLu activation function. SigLu activation not only bounds the encoder output and stabilizes the semantic distillation process but also effectively addresses the optimization conflict between token entropy loss and commitment loss. We further propose a three-stage training framework designed to enhance UniWeTok's adaptability cross various image resolutions and perception-sensitive scenarios, such as those involving human faces and textual content. On ImageNet, UniWeTok achieves state-of-the-art image generation performance (FID: UniWeTok 1.38 vs. REPA 1.42) while requiring a remarkably low training compute (Training Tokens: UniWeTok 33B vs. REPA 262B). On general-domain, UniWeTok demonstrates highly competitive capabilities across a broad range of tasks, including multimodal understanding, image generation (DPG Score: UniWeTok 86.63 vs. FLUX.1 [Dev] 83.84), and editing (GEdit Overall Score: UniWeTok 5.09 vs. OmniGen 5.06). We release code and models to facilitate community exploration of unified tokenizer and MLLM.",
    "authors": [
      "Shaobin Zhuang",
      "Yuang Ai",
      "Jiaming Han",
      "Weijia Mao",
      "Xiaohui Li",
      "Fangyikang Wang",
      "Xiao Wang",
      "Yan Li",
      "Shanchuan Lin",
      "Kun Xu",
      "Zhenheng Yang",
      "Huaibo Huang",
      "Xiangyu Yue",
      "Hao Chen",
      "Yali Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14178v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14178v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2602.14134v1",
    "title": "DenseMLLM: Standard Multimodal LLMs are Intrinsic Dense Predictors",
    "summary": "Multimodal Large Language Models (MLLMs) have demonstrated exceptional capabilities in high-level visual understanding. However, extending these models to fine-grained dense prediction tasks, such as semantic segmentation and depth estimation, typically necessitates the incorporation of complex, task-specific decoders and other customizations. This architectural fragmentation increases model complexity and deviates from the generalist design of MLLMs, ultimately limiting their practicality. In this work, we challenge this paradigm by accommodating standard MLLMs to perform dense predictions without requiring additional task-specific decoders. The proposed model is called DenseMLLM, grounded in the standard architecture with a novel vision token supervision strategy for multiple labels and tasks. Despite its minimalist design, our model achieves highly competitive performance across a wide range of dense prediction and vision-language benchmarks, demonstrating that a standard, general-purpose MLLM can effectively support dense perception without architectural specialization.",
    "authors": [
      "Yi Li",
      "Hongze Shen",
      "Lexiang Tang",
      "Xin Li",
      "Xinpeng Ding",
      "Yinsong Liu",
      "Deqiang Jiang",
      "Xing Sun",
      "Xiaomeng Li"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14134v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14134v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2602.14162v1",
    "title": "Index Light, Reason Deep: Deferred Visual Ingestion for Visual-Dense Document Question Answering",
    "summary": "Existing multimodal document question answering methods universally adopt a supply-side ingestion strategy: running a Vision-Language Model (VLM) on every page during indexing to generate comprehensive descriptions, then answering questions through text retrieval. However, this \"pre-ingestion\" approach is costly (a 113-page engineering drawing package requires approximately 80,000 VLM tokens), end-to-end unreliable (VLM outputs may fail to be correctly retrieved due to format mismatches in the retrieval infrastructure), and irrecoverable once it fails. This paper proposes the Deferred Visual Ingestion (DVI) framework, adopting a demand-side ingestion strategy: the indexing phase performs only lightweight metadata extraction, deferring visual understanding to the moment users pose specific questions. DVI's core principle is \"Index for locating, not understanding\"--achieving page localization through structured metadata indexes and BM25 full-text search, then sending original images along with specific questions to a VLM for targeted analysis. Experiments on two real industrial engineering drawings (113 pages + 7 pages) demonstrate that DVI achieves comparable overall accuracy at zero ingestion VLM cost (46.7% vs. 48.9%), an effectiveness rate of 50% on visually necessary queries (vs. 0% for pre-ingestion), and 100% page localization (98% search space compression). DVI also supports interactive refinement and progressive caching, transforming the \"QA accuracy\" problem into a \"page localization\" problem--once the correct drawing page is found, obtaining the answer becomes a matter of interaction rounds.",
    "authors": [
      "Tao Xu"
    ],
    "categories": [
      "cs.CL",
      "cs.CV",
      "cs.IR"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14162v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14162v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.14077v1",
    "title": "GTS: Inference-Time Scaling of Latent Reasoning with a Learnable Gaussian Thought Sampler",
    "summary": "Inference-time scaling (ITS) in latent reasoning models typically introduces stochasticity through heuristic perturbations, such as dropout or fixed Gaussian noise. While these methods increase trajectory diversity, their exploration behavior is not explicitly modeled and can be inefficient under finite sampling budgets. We observe that stronger perturbations do not necessarily translate into more effective candidate trajectories, as unguided noise may disrupt internal decision structure rather than steer it. To provide a more structured alternative, we model latent thought exploration as conditional sampling from learnable densities and instantiate this idea as a Gaussian Thought Sampler (GTS). GTS predicts context-dependent perturbation distributions over continuous reasoning states and is trained with GRPO-style policy optimization while keeping the backbone frozen. Experiments on GSM8K with two latent reasoning architectures show that GTS achieves more reliable inference-time scaling than heuristic baselines. These findings indicate that improving latent ITS requires structured and optimizable exploration mechanisms rather than simply amplifying stochasticity.",
    "authors": [
      "Minghan Wang",
      "Ye Bai",
      "Thuy-Trang Vu",
      "Ehsan Shareghi",
      "Gholamreza Haffari"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14077v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14077v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.14042v1",
    "title": "Restoration Adaptation for Semantic Segmentation on Low Quality Images",
    "summary": "In real-world scenarios, the performance of semantic segmentation often deteriorates when processing low-quality (LQ) images, which may lack clear semantic structures and high-frequency details. Although image restoration techniques offer a promising direction for enhancing degraded visual content, conventional real-world image restoration (Real-IR) models primarily focus on pixel-level fidelity and often fail to recover task-relevant semantic cues, limiting their effectiveness when directly applied to downstream vision tasks. Conversely, existing segmentation models trained on high-quality data lack robustness under real-world degradations. In this paper, we propose Restoration Adaptation for Semantic Segmentation (RASS), which effectively integrates semantic image restoration into the segmentation process, enabling high-quality semantic segmentation on the LQ images directly. Specifically, we first propose a Semantic-Constrained Restoration (SCR) model, which injects segmentation priors into the restoration model by aligning its cross-attention maps with segmentation masks, encouraging semantically faithful image reconstruction. Then, RASS transfers semantic restoration knowledge into segmentation through LoRA-based module merging and task-specific fine-tuning, thereby enhancing the model's robustness to LQ images. To validate the effectiveness of our framework, we construct a real-world LQ image segmentation dataset with high-quality annotations, and conduct extensive experiments on both synthetic and real-world LQ benchmarks. The results show that SCR and RASS significantly outperform state-of-the-art methods in segmentation and restoration tasks. Code, models, and datasets will be available at https://github.com/Ka1Guan/RASS.git.",
    "authors": [
      "Kai Guan",
      "Rongyuan Wu",
      "Shuai Li",
      "Wentao Zhu",
      "Wenjun Zeng",
      "Lei Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14042v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14042v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.13954v1",
    "title": "Eureka-Audio: Triggering Audio Intelligence in Compact Language Models",
    "summary": "We present Eureka-Audio, a compact yet high-performance audio language model that achieves competitive performance against models that are 4 to 18 times larger across a broad range of audio understanding benchmarks. Despite containing only 1.7B parameters, Eureka-Audio demonstrates strong performance on automatic speech recognition (ASR), audio understanding, and dense audio captioning, matching or surpassing multiple 7B to 30B audio and omni-modal baselines. The model adopts a unified end-to-end architecture composed of a lightweight language backbone, a Whisper-based audio encoder, and a sparsely activated Mixture-of-Experts (MoE) adapter that explicitly accounts for audio heterogeneity and alleviates cross-modal optimization conflicts under limited capacity. To further enhance paralinguistic reasoning, we introduce DataFlux, a closed loop audio instruction data synthesis and verification pipeline that constructs high quality, logically consistent supervision from raw audio. Extensive evaluations across ASR, knowledge reasoning, safety, instruction following, and paralinguistic benchmarks, demonstrate that Eureka-Audio achieves an efficient balance between computational cost and performance. These results establish Eureka Audio as a strong and practical baseline for lightweight audio understanding models.",
    "authors": [
      "Dan Zhang",
      "Yishu Lei",
      "Jing Hu",
      "Shuwei He",
      "Songhe Deng",
      "Xianlong Luo",
      "Danxiang Zhu",
      "Shikun Feng",
      "Rui Liu",
      "Jingzhou He",
      "Yu Sun",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13954v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13954v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.14143v1",
    "title": "ROAST: Rollout-based On-distribution Activation Steering Technique",
    "summary": "Activation steering provides parameter-efficient control over large language models (LLMs) at inference time, but many methods rely on off-distribution supervision and discrete masking, leading to brittle interventions. We propose ROAST (Rollout-based On-distribution Activation Steering Technique), which estimates steering directions from the model's own on-distribution rollouts via ROC and avoids hard sparsification via Continuous Soft Scaling (CSS) and Grouped Mean Normalization. Our empirical analysis reveals that while activation magnitude correlates moderately with directional consistency, the variance in magnitude is significant and often disproportionate to semantic quality. This suggests that high-magnitude activations risk dominating the global steering direction if not properly normalized. To address this, ROAST employs grouped normalization to balance contributions across samples, ensuring a more robust estimation of the consensus steering direction. Across models (0.6B to 32B), ROAST consistently improves performance on diverse tasks (e.g., +9.7% on GSM8K for Qwen3-0.6B and +12.1% on TruthfulQA for GLM4-32B), and analyses show that CSS better preserves activation energy.",
    "authors": [
      "Xuanbo Su",
      "Hao Luo",
      "Yingfang Zhang",
      "Lijun Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14143v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14143v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.14098v1",
    "title": "ForgeryVCR: Visual-Centric Reasoning via Efficient Forensic Tools in MLLMs for Image Forgery Detection and Localization",
    "summary": "Existing Multimodal Large Language Models (MLLMs) for image forgery detection and localization predominantly operate under a text-centric Chain-of-Thought (CoT) paradigm. However, forcing these models to textually characterize imperceptible low-level tampering traces inevitably leads to hallucinations, as linguistic modalities are insufficient to capture such fine-grained pixel-level inconsistencies. To overcome this, we propose ForgeryVCR, a framework that incorporates a forensic toolbox to materialize imperceptible traces into explicit visual intermediates via Visual-Centric Reasoning. To enable efficient tool utilization, we introduce a Strategic Tool Learning post-training paradigm, encompassing gain-driven trajectory construction for Supervised Fine-Tuning (SFT) and subsequent Reinforcement Learning (RL) optimization guided by a tool utility reward. This paradigm empowers the MLLM to act as a proactive decision-maker, learning to spontaneously invoke multi-view reasoning paths including local zoom-in for fine-grained inspection and the analysis of invisible inconsistencies in compression history, noise residuals, and frequency domains. Extensive experiments reveal that ForgeryVCR achieves state-of-the-art (SOTA) performance in both detection and localization tasks, demonstrating superior generalization and robustness with minimal tool redundancy. The project page is available at https://youqiwong.github.io/projects/ForgeryVCR/.",
    "authors": [
      "Youqi Wang",
      "Shen Chen",
      "Haowei Wang",
      "Rongxuan Peng",
      "Taiping Yao",
      "Shunquan Tan",
      "Changsheng Chen",
      "Bin Li",
      "Shouhong Ding"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14098v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14098v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.14009v1",
    "title": "Named Entity Recognition for Payment Data Using NLP",
    "summary": "Named Entity Recognition (NER) has emerged as a critical component in automating financial transaction processing, particularly in extracting structured information from unstructured payment data. This paper presents a comprehensive analysis of state-of-the-art NER algorithms specifically designed for payment data extraction, including Conditional Random Fields (CRF), Bidirectional Long Short-Term Memory with CRF (BiLSTM-CRF), and transformer-based models such as BERT and FinBERT. We conduct extensive experiments on a dataset of 50,000 annotated payment transactions across multiple payment formats including SWIFT MT103, ISO 20022, and domestic payment systems. Our experimental results demonstrate that fine-tuned BERT models achieve an F1-score of 94.2% for entity extraction, outperforming traditional CRF-based approaches by 12.8 percentage points. Furthermore, we introduce PaymentBERT, a novel hybrid architecture combining domain-specific financial embeddings with contextual representations, achieving state-of-the-art performance with 95.7% F1-score while maintaining real-time processing capabilities. We provide detailed analysis of cross-format generalization, ablation studies, and deployment considerations. This research provides practical insights for financial institutions implementing automated sanctions screening, anti-money laundering (AML) compliance, and payment processing systems.",
    "authors": [
      "Srikumar Nayak"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14009v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14009v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.13953v1",
    "title": "QuRL: Efficient Reinforcement Learning with Quantized Rollout",
    "summary": "Reinforcement learning with verifiable rewards (RLVR) has become a trending paradigm for training reasoning large language models (LLMs). However, due to the autoregressive decoding nature of LLMs, the rollout process becomes the efficiency bottleneck of RL training, consisting of up to 70\\% of the total training time. In this work, we propose Quantized Reinforcement Learning (QuRL) that uses a quantized actor for accelerating the rollout. We address two challenges in QuRL. First, we propose Adaptive Clipping Range (ACR) that dynamically adjusts the clipping ratio based on the policy ratio between the full-precision actor and the quantized actor, which is essential for mitigating long-term training collapse. Second, we identify the weight update problem, where weight changes between RL steps are extremely small, making it difficult for the quantization operation to capture them effectively. We mitigate this problem through the invariant scaling technique that reduces quantization noise and increases weight update. We evaluate our method with INT8 and FP8 quantization experiments on DeepScaleR and DAPO, and achieve 20% to 80% faster rollout during training.",
    "authors": [
      "Yuhang Li",
      "Reena Elangovan",
      "Xin Dong",
      "Priyadarshini Panda",
      "Brucek Khailany"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13953v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13953v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.13935v1",
    "title": "Statistical Early Stopping for Reasoning Models",
    "summary": "While LLMs have seen substantial improvement in reasoning capabilities, they also sometimes overthink, generating unnecessary reasoning steps, particularly under uncertainty, given ill-posed or ambiguous queries. We introduce statistically principled early stopping methods that monitor uncertainty signals during generation to mitigate this issue. Our first approach is parametric: it models inter-arrival times of uncertainty keywords as a renewal process and applies sequential testing for stopping. Our second approach is nonparametric and provides finite-sample guarantees on the probability of halting too early on well-posed queries. We conduct empirical evaluations on reasoning tasks across several domains and models. Our results indicate that uncertainty-aware early stopping can improve both efficiency and reliability in LLM reasoning, and we observe especially significant gains for math reasoning.",
    "authors": [
      "Yangxinyu Xie",
      "Tao Wang",
      "Soham Mallick",
      "Yan Sun",
      "Georgy Noarov",
      "Mengxin Yu",
      "Tanwi Mallick",
      "Weijie J. Su",
      "Edgar Dobriban"
    ],
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13935v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13935v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.14154v1",
    "title": "A Penalty Approach for Differentiation Through Black-Box Quadratic Programming Solvers",
    "summary": "Differentiating through the solution of a quadratic program (QP) is a central problem in differentiable optimization. Most existing approaches differentiate through the Karush--Kuhn--Tucker (KKT) system, but their computational cost and numerical robustness can degrade at scale. To address these limitations, we propose dXPP, a penalty-based differentiation framework that decouples QP solving from differentiation. In the solving step (forward pass), dXPP is solver-agnostic and can leverage any black-box QP solver. In the differentiation step (backward pass), we map the solution to a smooth approximate penalty problem and implicitly differentiate through it, requiring only the solution of a much smaller linear system in the primal variables. This approach bypasses the difficulties inherent in explicit KKT differentiation and significantly improves computational efficiency and robustness. We evaluate dXPP on various tasks, including randomly generated QPs, large-scale sparse projection problems, and a real-world multi-period portfolio optimization task. Empirical results demonstrate that dXPP is competitive with KKT-based differentiation methods and achieves substantial speedups on large-scale problems.",
    "authors": [
      "Yuxuan Linghu",
      "Zhiyuan Liu",
      "Qi Deng"
    ],
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14154v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14154v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.14080v1",
    "title": "Empty Shelves or Lost Keys? Recall Is the Bottleneck for Parametric Factuality",
    "summary": "Standard factuality evaluations of LLMs treat all errors alike, obscuring whether failures arise from missing knowledge (empty shelves) or from limited access to encoded facts (lost keys). We propose a behavioral framework that profiles factual knowledge at the level of facts rather than questions, characterizing each fact by whether it is encoded, and then by how accessible it is: cannot be recalled, can be directly recalled, or can only be recalled with inference-time computation (thinking). To support such profiling, we introduce WikiProfile, a new benchmark constructed via an automated pipeline with a prompted LLM grounded in web search. Across 4 million responses from 13 LLMs, we find that encoding is nearly saturated in frontier models on our benchmark, with GPT-5 and Gemini-3 encoding 95--98% of facts. However, recall remains a major bottleneck: many errors previously attributed to missing knowledge instead stem from failures to access it. These failures are systematic and disproportionately affect long-tail facts and reverse questions. Finally, we show that thinking improves recall and can recover a substantial fraction of failures, indicating that future gains may rely less on scaling and more on methods that improve how models utilize what they already encode.",
    "authors": [
      "Nitay Calderon",
      "Eyal Ben-David",
      "Zorik Gekhman",
      "Eran Ofek",
      "Gal Yona"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14080v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14080v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.14073v1",
    "title": "Annotation-Efficient Vision-Language Model Adaptation to the Polish Language Using the LLaVA Framework",
    "summary": "Most vision-language models (VLMs) are trained on English-centric data, limiting their performance in other languages and cultural contexts. This restricts their usability for non-English-speaking users and hinders the development of multimodal systems that reflect diverse linguistic and cultural realities. In this work, we reproduce and adapt the LLaVA-Next methodology to create a set of Polish VLMs. We rely on a fully automated pipeline for translating and filtering existing multimodal datasets, and complement this with synthetic Polish data for OCR and culturally specific tasks. Despite relying almost entirely on automatic translation and minimal manual intervention to the training data, our approach yields strong results: we observe a +9.5% improvement over LLaVA-1.6-Vicuna-13B on a Polish-adapted MMBench, along with higher-quality captions in generative evaluations, as measured by human annotators in terms of linguistic correctness. These findings highlight that large-scale automated translation, combined with lightweight filtering, can effectively bootstrap high-quality multimodal models for low-resource languages. Some challenges remain, particularly in cultural coverage and evaluation. To facilitate further research, we make our models and evaluation dataset publicly available.",
    "authors": [
      "Grzegorz Statkiewicz",
      "Alicja Dobrzeniecka",
      "Karolina Seweryn",
      "Aleksandra KrasnodÄbska",
      "Karolina Piosek",
      "Katarzyna Bogusz",
      "Sebastian Cygert",
      "Wojciech Kusa"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14073v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14073v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.14051v1",
    "title": "Decentralized Federated Learning With Energy Harvesting Devices",
    "summary": "Decentralized federated learning (DFL) enables edge devices to collaboratively train models through local training and fully decentralized device-to-device (D2D) model exchanges. However, these energy-intensive operations often rapidly deplete limited device batteries, reducing their operational lifetime and degrading the learning performance. To address this limitation, we apply energy harvesting technique to DFL systems, allowing edge devices to extract ambient energy and operate sustainably. We first derive the convergence bound for wireless DFL with energy harvesting, showing that the convergence is influenced by partial device participation and transmission packet drops, both of which further depend on the available energy supply. To accelerate convergence, we formulate a joint device scheduling and power control problem and model it as a multi-agent Markov decision process (MDP). Traditional MDP algorithms (e.g., value or policy iteration) require a centralized coordinator with access to all device states and exhibit exponential complexity in the number of devices, making them impractical for large-scale decentralized networks. To overcome these challenges, we propose a fully decentralized policy iteration algorithm that leverages only local state information from two-hop neighboring devices, thereby substantially reducing both communication overhead and computational complexity. We further provide a theoretical analysis showing that the proposed decentralized algorithm achieves asymptotic optimality. Finally, comprehensive numerical experiments on real-world datasets are conducted to validate the theoretical results and corroborate the effectiveness of the proposed algorithm.",
    "authors": [
      "Kai Zhang",
      "Xuanyu Cao",
      "Khaled B. Letaief"
    ],
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14051v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14051v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.14049v1",
    "title": "UniST-Pred: A Robust Unified Framework for Spatio-Temporal Traffic Forecasting in Transportation Networks Under Disruptions",
    "summary": "Spatio-temporal traffic forecasting is a core component of intelligent transportation systems, supporting various downstream tasks such as signal control and network-level traffic management. In real-world deployments, forecasting models must operate under structural and observational uncertainties, conditions that are rarely considered in model design. Recent approaches achieve strong short-term predictive performance by tightly coupling spatial and temporal modeling, often at the cost of increased complexity and limited modularity. In contrast, efficient time-series models capture long-range temporal dependencies without relying on explicit network structure. We propose UniST-Pred, a unified spatio-temporal forecasting framework that first decouples temporal modeling from spatial representation learning, then integrates both through adaptive representation-level fusion. To assess robustness of the proposed approach, we construct a dataset based on an agent-based, microscopic traffic simulator (MATSim) and evaluate UniST-Pred under severe network disconnection scenarios. Additionally, we benchmark UniST-Pred on standard traffic prediction datasets, demonstrating its competitive performance against existing well-established models despite a lightweight design. The results illustrate that UniST-Pred maintains strong predictive performance across both real-world and simulated datasets, while also yielding interpretable spatio-temporal representations under infrastructure disruptions. The source code and the generated dataset are available at https://anonymous.4open.science/r/UniST-Pred-EF27",
    "authors": [
      "Yue Wang",
      "Areg Karapetyan",
      "Djellel Difallah",
      "Samer Madanat"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14049v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14049v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.13980v1",
    "title": "Cognitive Chunking for Soft Prompts: Accelerating Compressor Learning via Block-wise Causal Masking",
    "summary": "Providing extensive context via prompting is vital for leveraging the capabilities of Large Language Models (LLMs). However, lengthy contexts significantly increase inference latency, as the computational cost of self-attention grows quadratically with sequence length. To mitigate this issue, context compression-particularly soft prompt compressio-has emerged as a widely studied solution, which converts long contexts into shorter memory embeddings via a trained compressor. Existing methods typically compress the entire context indiscriminately into a set of memory tokens, requiring the compressor to capture global dependencies and necessitating extensive pre-training data to learn effective patterns. Inspired by the chunking mechanism in human working memory and empirical observations of the spatial specialization of memory embeddings relative to original tokens, we propose Parallelized Iterative Compression (PIC). By simply modifying the Transformer's attention mask, PIC explicitly restricts the receptive field of memory tokens to sequential local chunks, thereby lowering the difficulty of compressor training. Experiments across multiple downstream tasks demonstrate that PIC consistently outperforms competitive baselines, with superiority being particularly pronounced in high compression scenarios (e.g., achieving relative improvements of 29.8\\% in F1 score and 40.7\\% in EM score on QA tasks at the $64\\times$ compression ratio). Furthermore, PIC significantly expedites the training process. Specifically, when training the 16$\\times$ compressor, it surpasses the peak performance of the competitive baseline while effectively reducing the training time by approximately 40\\%.",
    "authors": [
      "Guojie Liu",
      "Yiqi Wang",
      "Yanfeng Yang",
      "Wenqi Fan",
      "Songlei Jian",
      "Jianfeng Zhang",
      "Jie Yu"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13980v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13980v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.13967v1",
    "title": "Neuromem: A Granular Decomposition of the Streaming Lifecycle in External Memory for LLMs",
    "summary": "Most evaluations of External Memory Module assume a static setting: memory is built offline and queried at a fixed state. In practice, memory is streaming: new facts arrive continuously, insertions interleave with retrievals, and the memory state evolves while the model is serving queries. In this regime, accuracy and cost are governed by the full memory lifecycle, which encompasses the ingestion, maintenance, retrieval, and integration of information into generation. We present Neuromem, a scalable testbed that benchmarks External Memory Modules under an interleaved insertion-and-retrieval protocol and decomposes its lifecycle into five dimensions including memory data structure, normalization strategy, consolidation policy, query formulation strategy, and context integration mechanism. Using three representative datasets LOCOMO, LONGMEMEVAL, and MEMORYAGENTBENCH, Neuromem evaluates interchangeable variants within a shared serving stack, reporting token-level F1 and insertion/retrieval latency. Overall, we observe that performance typically degrades as memory grows across rounds, and time-related queries remain the most challenging category. The memory data structure largely determines the attainable quality frontier, while aggressive compression and generative integration mechanisms mostly shift cost between insertion and retrieval with limited accuracy gain.",
    "authors": [
      "Ruicheng Zhang",
      "Xinyi Li",
      "Tianyi Xu",
      "Shuhao Zhang",
      "Xiaofei Liao",
      "Hai Jin"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13967v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13967v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.13958v1",
    "title": "Chemical Language Models for Natural Products: A State-Space Model Approach",
    "summary": "Language models are widely used in chemistry for molecular property prediction and small-molecule generation, yet Natural Products (NPs) remain underexplored despite their importance in drug discovery. To address this gap, we develop NP-specific chemical language models (NPCLMs) by pre-training state-space models (Mamba and Mamba-2) and comparing them with transformer baselines (GPT). Using a dataset of about 1M NPs, we present the first systematic comparison of selective state-space models and transformers for NP-focused tasks, together with eight tokenization strategies including character-level, Atom-in-SMILES (AIS), byte-pair encoding (BPE), and NP-specific BPE. We evaluate molecule generation (validity, uniqueness, novelty) and property prediction (membrane permeability, taste, anti-cancer activity) using MCC and AUC-ROC. Mamba generates 1-2 percent more valid and unique molecules than Mamba-2 and GPT, with fewer long-range dependency errors, while GPT yields slightly more novel structures. For property prediction, Mamba variants outperform GPT by 0.02-0.04 MCC under random splits, while scaffold splits show comparable performance. Results demonstrate that domain-specific pre-training on about 1M NPs can match models trained on datasets over 100 times larger.",
    "authors": [
      "Ho-Hsuan Wang",
      "Afnan Sultan",
      "Andrea Volkamer",
      "Dietrich Klakow"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13958v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13958v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.13939v1",
    "title": "An Adaptive Model Selection Framework for Demand Forecasting under Horizon-Induced Degradation to Support Business Strategy and Operations",
    "summary": "Business environments characterized by structural demand intermittency, high variability, and multi-step planning horizons require robust and reproducible model selection mechanisms. Empirical evidence shows that no forecasting model is universally dominant and that relative rankings vary across error metrics, demand regimes, and forecast horizons, generating ambiguity in multi-SKU decision contexts. This study proposes AHSIV (Adaptive Hybrid Selector for Intermittency and Variability), a horizon-aware and regime-conditioned model selection framework designed to address horizon-induced ranking instability. The proposed approach integrates scaled and absolute error metrics adjusted through a Metric Degradation by Forecast Horizon (MDFH) procedure, structural demand classification, multi-objective Pareto dominance, and hierarchical bias refinement within a unified decision architecture. The empirical evaluation is conducted on the Walmart, M3, M4, and M5 datasets under multiple train-test partition schemes and twelve-step forecasting horizons. Results indicate that AHSIV achieves statistical equivalence with the strongest monometric baseline in terms of aggregated performance while increasing the frequency of horizon-specific best-model selection. The findings demonstrate that model selection in heterogeneous demand environments cannot be treated as a static ranking problem, and that horizon-consistent, structurally adaptive mechanisms provide a principled, operationally coherent solution for multi-SKU forecasting.",
    "authors": [
      "Adolfo GonzÃ¡lez",
      "VÃ­ctor Parada"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13939v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13939v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.14193v1",
    "title": "Learning Part-Aware Dense 3D Feature Field for Generalizable Articulated Object Manipulation",
    "summary": "Articulated object manipulation is essential for various real-world robotic tasks, yet generalizing across diverse objects remains a major challenge. A key to generalization lies in understanding functional parts (e.g., door handles and knobs), which indicate where and how to manipulate across diverse object categories and shapes. Previous works attempted to achieve generalization by introducing foundation features, while these features are mostly 2D-based and do not specifically consider functional parts. When lifting these 2D features to geometry-profound 3D space, challenges arise, such as long runtimes, multi-view inconsistencies, and low spatial resolution with insufficient geometric information. To address these issues, we propose Part-Aware 3D Feature Field (PA3FF), a novel dense 3D feature with part awareness for generalizable articulated object manipulation. PA3FF is trained by 3D part proposals from a large-scale labeled dataset, via a contrastive learning formulation. Given point clouds as input, PA3FF predicts a continuous 3D feature field in a feedforward manner, where the distance between point features reflects the proximity of functional parts: points with similar features are more likely to belong to the same part. Building on this feature, we introduce the Part-Aware Diffusion Policy (PADP), an imitation learning framework aimed at enhancing sample efficiency and generalization for robotic manipulation. We evaluate PADP on several simulated and real-world tasks, demonstrating that PA3FF consistently outperforms a range of 2D and 3D representations in manipulation scenarios, including CLIP, DINOv2, and Grounded-SAM. Beyond imitation learning, PA3FF enables diverse downstream methods, including correspondence learning and segmentation tasks, making it a versatile foundation for robotic manipulation. Project page: https://pa3ff.github.io",
    "authors": [
      "Yue Chen",
      "Muqing Jiang",
      "Kaifeng Zheng",
      "Jiaqi Liang",
      "Chenrui Tie",
      "Haoran Lu",
      "Ruihai Wu",
      "Hao Dong"
    ],
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14193v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14193v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2602.14188v1",
    "title": "GPT-5 vs Other LLMs in Long Short-Context Performance",
    "summary": "With the significant expansion of the context window in Large Language Models (LLMs), these models are theoretically capable of processing millions of tokens in a single pass. However, research indicates a significant gap between this theoretical capacity and the practical ability of models to robustly utilize information within long contexts, especially in tasks that require a comprehensive understanding of numerous details. This paper evaluates the performance of four state-of-the-art models (Grok-4, GPT-4, Gemini 2.5, and GPT-5) on long short-context tasks. For this purpose, three datasets were used: two supplementary datasets for retrieving culinary recipes and math problems, and a primary dataset of 20K social media posts for depression detection. The results show that as the input volume on the social media dataset exceeds 5K posts (70K tokens), the performance of all models degrades significantly, with accuracy dropping to around 50-53% for 20K posts. Notably, in the GPT-5 model, despite the sharp decline in accuracy, its precision remained high at approximately 95%, a feature that could be highly effective for sensitive applications like depression detection. This research also indicates that the \"lost in the middle\" problem has been largely resolved in newer models. This study emphasizes the gap between the theoretical capacity and the actual performance of models on complex, high-volume data tasks and highlights the importance of metrics beyond simple accuracy for practical applications.",
    "authors": [
      "Nima Esmi",
      "Maryam Nezhad-Moghaddam",
      "Fatemeh Borhani",
      "Asadollah Shahbahrami",
      "Amin Daemdoost",
      "Georgi Gaydadjiev"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14188v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14188v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2602.14093v1",
    "title": "GUI-GENESIS: Automated Synthesis of Efficient Environments with Verifiable Rewards for GUI Agent Post-Training",
    "summary": "Post-training GUI agents in interactive environments is critical for developing generalization and long-horizon planning capabilities. However, training on real-world applications is hindered by high latency, poor reproducibility, and unverifiable rewards relying on noisy visual proxies. To address the limitations, we present GUI-GENESIS, the first framework to automatically synthesize efficient GUI training environments with verifiable rewards. GUI-GENESIS reconstructs real-world applications into lightweight web environments using multimodal code models and equips them with code-native rewards, executable assertions that provide deterministic reward signals and eliminate visual estimation noise. Extensive experiments show that GUI-GENESIS reduces environment latency by 10 times and costs by over $28,000 per epoch compared to training on real applications. Notably, agents trained with GUI-GENESIS outperform the base model by 14.54% and even real-world RL baselines by 3.27% on held-out real-world tasks. Finally, we observe that models can synthesize environments they cannot yet solve, highlighting a pathway for self-improving agents.",
    "authors": [
      "Yuan Cao",
      "Dezhi Ran",
      "Mengzhou Wu",
      "Yuzhe Guo",
      "Xin Chen",
      "Ang Li",
      "Gang Cao",
      "Gong Zhi",
      "Hao Yu",
      "Linyi Li",
      "Wei Yang",
      "Tao Xie"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14093v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14093v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2602.13979v1",
    "title": "Chain-of-Thought Reasoning with Large Language Models for Clinical Alzheimer's Disease Assessment and Diagnosis",
    "summary": "Alzheimer's disease (AD) has become a prevalent neurodegenerative disease worldwide. Traditional diagnosis still relies heavily on medical imaging and clinical assessment by physicians, which is often time-consuming and resource-intensive in terms of both human expertise and healthcare resources. In recent years, large language models (LLMs) have been increasingly applied to the medical field using electronic health records (EHRs), yet their application in Alzheimer's disease assessment remains limited, particularly given that AD involves complex multifactorial etiologies that are difficult to observe directly through imaging modalities. In this work, we propose leveraging LLMs to perform Chain-of-Thought (CoT) reasoning on patients' clinical EHRs. Unlike direct fine-tuning of LLMs on EHR data for AD classification, our approach utilizes LLM-generated CoT reasoning paths to provide the model with explicit diagnostic rationale for AD assessment, followed by structured CoT-based predictions. This pipeline not only enhances the model's ability to diagnose intrinsically complex factors but also improves the interpretability of the prediction process across different stages of AD progression. Experimental results demonstrate that the proposed CoT-based diagnostic framework significantly enhances stability and diagnostic performance across multiple CDR grading tasks, achieving up to a 15% improvement in F1 score compared to the zero-shot baseline method.",
    "authors": [
      "Tongze Zhang",
      "Jun-En Ding",
      "Melik Ozolcer",
      "Fang-Ming Hung",
      "Albert Chih-Chieh Yang",
      "Feng Liu",
      "Yi-Rou Ji",
      "Sang Won Bae"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13979v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13979v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2602.14172v1",
    "title": "Investigation for Relative Voice Impression Estimation",
    "summary": "Paralinguistic and non-linguistic aspects of speech strongly influence listener impressions. While most research focuses on absolute impression scoring, this study investigates relative voice impression estimation (RIE), a framework for predicting the perceptual difference between two utterances from the same speaker. The estimation target is a low-dimensional vector derived from subjective evaluations, quantifying the perceptual shift of the second utterance relative to the first along an antonymic axis (e.g., ``Dark--Bright''). To isolate expressive and prosodic variation, we used recordings of a professional speaker reading a text in various styles. We compare three modeling approaches: classical acoustic features commonly used for speech emotion recognition, self-supervised speech representations, and multimodal large language models (MLLMs). Our results demonstrate that models using self-supervised representations outperform methods with classical acoustic features, particularly in capturing complex and dynamic impressions (e.g., ``Cold--Warm'') where classical features fail. In contrast, current MLLMs prove unreliable for this fine-grained pairwise task. This study provides the first systematic investigation of RIE and demonstrates the strength of self-supervised speech models in capturing subtle perceptual variations.",
    "authors": [
      "Keinichi Fujita",
      "Yusuke Ijima"
    ],
    "categories": [
      "cs.SD",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14172v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14172v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.14159v1",
    "title": "Synergistic Intra- and Cross-Layer Regularization Losses for MoE Expert Specialization",
    "summary": "Sparse Mixture-of-Experts (MoE) models scale Transformers efficiently but suffer from expert overlap -- redundant representations across experts and routing ambiguity, resulting in severely underutilized model capacity. While architectural solutions like DeepSeekMoE promote specialization, they require substantial structural modifications and rely solely on intra-layer signals. In this paper, we propose two plug-and-play regularization losses that enhance MoE specialization and routing efficiency without modifying router or model architectures. First, an intra-layer specialization loss penalizes cosine similarity between experts' SwiGLU activations on identical tokens, encouraging experts to specialize in complementary knowledge. Second, a cross-layer coupling loss maximizes joint Top-$k$ routing probabilities across adjacent layers, establishing coherent expert pathways through network depth while reinforcing intra-layer expert specialization. Both losses are orthogonal to the standard load-balancing loss and compatible with both the shared-expert architecture in DeepSeekMoE and vanilla top-$k$ MoE architectures. We implement both losses as a drop-in Megatron-LM module. Extensive experiments across pre-training, fine-tuning, and zero-shot benchmarks demonstrate consistent task gains, higher expert specialization, and lower-entropy routing; together, these improvements translate into faster inference via more stable expert pathways.",
    "authors": [
      "Rizhen Hu",
      "Yuan Cao",
      "Boao Kong",
      "Mou Sun",
      "Kun Yuan"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14159v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14159v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.14140v1",
    "title": "Detection of On-Ground Chestnuts Using Artificial Intelligence Toward Automated Picking",
    "summary": "Traditional mechanized chestnut harvesting is too costly for small producers, non-selective, and prone to damaging nuts. Accurate, reliable detection of chestnuts on the orchard floor is crucial for developing low-cost, vision-guided automated harvesting technology. However, developing a reliable chestnut detection system faces challenges in complex environments with shading, varying natural light conditions, and interference from weeds, fallen leaves, stones, and other foreign on-ground objects, which have remained unaddressed. This study collected 319 images of chestnuts on the orchard floor, containing 6524 annotated chestnuts. A comprehensive set of 29 state-of-the-art real-time object detectors, including 14 in the YOLO (v11-13) and 15 in the RT-DETR (v1-v4) families at varied model scales, was systematically evaluated through replicated modeling experiments for chestnut detection. Experimental results show that the YOLOv12m model achieves the best mAP@0.5 of 95.1% among all the evaluated models, while the RT-DETRv2-R101 was the most accurate variant among RT-DETR models, with mAP@0.5 of 91.1%. In terms of mAP@[0.5:0.95], the YOLOv11x model achieved the best accuracy of 80.1%. All models demonstrate significant potential for real-time chestnut detection, and YOLO models outperformed RT-DETR models in terms of both detection accuracy and inference, making them better suited for on-board deployment. Both the dataset and software programs in this study have been made publicly available at https://github.com/AgFood-Sensing-and-Intelligence-Lab/ChestnutDetection.",
    "authors": [
      "Kaixuan Fang",
      "Yuzhen Lu",
      "Xinyang Mu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14140v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14140v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.14099v1",
    "title": "SemanticFeels: Semantic Labeling during In-Hand Manipulation",
    "summary": "As robots become increasingly integrated into everyday tasks, their ability to perceive both the shape and properties of objects during in-hand manipulation becomes critical for adaptive and intelligent behavior. We present SemanticFeels, an extension of the NeuralFeels framework that integrates semantic labeling with neural implicit shape representation, from vision and touch. To illustrate its application, we focus on material classification: high-resolution Digit tactile readings are processed by a fine-tuned EfficientNet-B0 convolutional neural network (CNN) to generate local material predictions, which are then embedded into an augmented signed distance field (SDF) network that jointly predicts geometry and continuous material regions. Experimental results show that the system achieves a high correspondence between predicted and actual materials on both single- and multi-material objects, with an average matching accuracy of 79.87% across multiple manipulation trials on a multi-material object.",
    "authors": [
      "Anas Al Shikh Khalil",
      "Haozhi Qi",
      "Roberto Calandra"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14099v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14099v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.14071v1",
    "title": "Bidirectional Temporal Dynamics Modeling for EEG-based Driving Fatigue Recognition",
    "summary": "Driving fatigue is a major contributor to traffic accidents and poses a serious threat to road safety. Electroencephalography (EEG) provides a direct measurement of neural activity, yet EEG-based fatigue recognition is hindered by strong non-stationarity and asymmetric neural dynamics. To address these challenges, we propose DeltaGateNet, a novel framework that explicitly captures Bidirectional temporal dynamics for EEG-based driving fatigue recognition. Our key idea is to introduce a Bidirectional Delta module that decomposes first-order temporal differences into positive and negative components, enabling explicit modeling of asymmetric neural activation and suppression patterns. Furthermore, we design a Gated Temporal Convolution module to capture long-term temporal dependencies for each EEG channel using depthwise temporal convolutions and residual learning, preserving channel-wise specificity while enhancing temporal representation robustness. Extensive experiments conducted under both intra-subject and inter-subject evaluation settings on the public SEED-VIG and SADT driving fatigue datasets demonstrate that DeltaGateNet consistently outperforms existing methods. On SEED-VIG, DeltaGateNet achieves an intra-subject accuracy of 81.89% and an inter-subject accuracy of 55.55%. On the balanced SADT 2022 dataset, it attains intra-subject and inter-subject accuracies of 96.81% and 83.21%, respectively, while on the unbalanced SADT 2952 dataset, it achieves 96.84% intra-subject and 84.49% inter-subject accuracy. These results indicate that explicitly modeling Bidirectional temporal dynamics yields robust and generalizable performance under varying subject and class-distribution conditions.",
    "authors": [
      "YipTin Po",
      "Jianming Wang",
      "Yutao Miao",
      "Jiayan Zhang",
      "Yunxu Zhao",
      "Xiaomin Ouyang",
      "Zhihong Li",
      "Nevin L. Zhang"
    ],
    "categories": [
      "cs.OH",
      "cs.CV"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14071v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14071v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.14035v1",
    "title": "FloCA: Towards Faithful and Logically Consistent Flowchart Reasoning",
    "summary": "Flowchart-oriented dialogue (FOD) systems aim to guide users through multi-turn decision-making or operational procedures by following a domain-specific flowchart to achieve a task goal. In this work, we formalize flowchart reasoning in FOD as grounding user input to flowchart nodes at each dialogue turn while ensuring node transition is consistent with the correct flowchart path. Despite recent advances of LLMs in task-oriented dialogue systems, adapting them to FOD still faces two limitations: (1) LLMs lack an explicit mechanism to represent and reason over flowchart topology, and (2) they are prone to hallucinations, leading to unfaithful flowchart reasoning. To address these limitations, we propose FloCA, a zero-shot flowchart-oriented conversational agent. FloCA uses an LLM for intent understanding and response generation while delegating flowchart reasoning to an external tool that performs topology-constrained graph execution, ensuring faithful and logically consistent node transitions across dialogue turns. We further introduce an evaluation framework with an LLM-based user simulator and five new metrics covering reasoning accuracy and interaction efficiency. Extensive experiments on FLODIAL and PFDial datasets highlight the bottlenecks of existing LLM-based methods and demonstrate the superiority of FloCA. Our codes are available at https://github.com/Jinzi-Zou/FloCA-flowchart-reasoning.",
    "authors": [
      "Jinzi Zou",
      "Bolin Wang",
      "Liang Li",
      "Shuo Zhang",
      "Nuo Xu",
      "Junzhou Zhao"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14035v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14035v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.13964v1",
    "title": "HLE-Verified: A Systematic Verification and Structured Revision of Humanity's Last Exam",
    "summary": "Humanity's Last Exam (HLE) has become a widely used benchmark for evaluating frontier large language models on challenging, multi-domain questions. However, community-led analyses have raised concerns that HLE contains a non-trivial number of noisy items, which can bias evaluation results and distort cross-model comparisons. To address this challenge, we introduce HLE-Verified, a verified and revised version of HLE with a transparent verification protocol and fine-grained error taxonomy. Our construction follows a two-stage validation-and-repair workflow resulting in a certified benchmark. In Stage I, each item undergoes binary validation of the problem and final answer through domain-expert review and model-based cross-checks, yielding 641 verified items. In Stage II, flawed but fixable items are revised under strict constraints preserving the original evaluation intent, through dual independent expert repairs, model-assisted auditing, and final adjudication, resulting in 1,170 revised-and-certified items. The remaining 689 items are released as a documented uncertain set with explicit uncertainty sources and expertise tags for future refinement. We evaluate seven state-of-the-art language models on HLE and HLE-Verified, observing an average absolute accuracy gain of 7--10 percentage points on HLE-Verified. The improvement is particularly pronounced on items where the original problem statement and/or reference answer is erroneous, with gains of 30--40 percentage points. Our analyses further reveal a strong association between model confidence and the presence of errors in the problem statement or reference answer, supporting the effectiveness of our revisions. Overall, HLE-Verified improves HLE-style evaluations by reducing annotation noise and enabling more faithful measurement of model capabilities. Data is available at: https://github.com/SKYLENAGE-AI/HLE-Verified",
    "authors": [
      "Weiqi Zhai",
      "Zhihai Wang",
      "Jinghang Wang",
      "Boyu Yang",
      "Xiaogang Li",
      "Xiang Xu",
      "Bohan Wang",
      "Peng Wang",
      "Xingzhe Wu",
      "Anfeng Li",
      "Qiyuan Feng",
      "Yuhao Zhou",
      "Shoulin Han",
      "Wenjie Luo",
      "Yiyuan Li",
      "Yaxuan Wang",
      "Ruixian Luo",
      "Guojie Lin",
      "Peiyao Xiao",
      "Chengliang Xu",
      "Ben Wang",
      "Zeyu Wang",
      "Zichao Chen",
      "Jianan Ye",
      "Yijie Hu",
      "Jialong Chen",
      "Zongwen Shen",
      "Yuliang Xu",
      "An Yang",
      "Bowen Yu",
      "Dayiheng Liu",
      "Junyang Lin",
      "Hu Wei",
      "Que Shen",
      "Bing Zhao"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13964v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13964v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.13949v1",
    "title": "Experiential Reinforcement Learning",
    "summary": "Reinforcement learning has become the central approach for language models (LMs) to learn from environmental reward or feedback. In practice, the environmental feedback is usually sparse and delayed. Learning from such signals is challenging, as LMs must implicitly infer how observed failures should translate into behavioral changes for future iterations. We introduce Experiential Reinforcement Learning (ERL), a training paradigm that embeds an explicit experience-reflection-consolidation loop into the reinforcement learning process. Given a task, the model generates an initial attempt, receives environmental feedback, and produces a reflection that guides a refined second attempt, whose success is reinforced and internalized into the base policy. This process converts feedback into structured behavioral revision, improving exploration and stabilizing optimization while preserving gains at deployment without additional inference cost. Across sparse-reward control environments and agentic reasoning benchmarks, ERL consistently improves learning efficiency and final performance over strong reinforcement learning baselines, achieving gains of up to +81% in complex multi-step environments and up to +11% in tool-using reasoning tasks. These results suggest that integrating explicit self-reflection into policy training provides a practical mechanism for transforming feedback into durable behavioral improvement.",
    "authors": [
      "Taiwei Shi",
      "Sihao Chen",
      "Bowen Jiang",
      "Linxin Song",
      "Longqi Yang",
      "Jieyu Zhao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13949v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13949v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.14169v1",
    "title": "Deep Dense Exploration for LLM Reinforcement Learning via Pivot-Driven Resampling",
    "summary": "Effective exploration is a key challenge in reinforcement learning for large language models: discovering high-quality trajectories within a limited sampling budget from the vast natural language sequence space. Existing methods face notable limitations: GRPO samples exclusively from the root, saturating high-probability trajectories while leaving deep, error-prone states under-explored. Tree-based methods blindly disperse budgets across trivial or unrecoverable states, causing sampling dilution that fails to uncover rare correct suffixes and destabilizes local baselines. To address this, we propose Deep Dense Exploration (DDE), a strategy that focuses exploration on $\\textit{pivots}$-deep, recoverable states within unsuccessful trajectories. We instantiate DDE with DEEP-GRPO, which introduces three key innovations: (1) a lightweight data-driven utility function that automatically balances recoverability and depth bias to identify pivot states; (2) local dense resampling at each pivot to increase the probability of discovering correct subsequent trajectories; and (3) a dual-stream optimization objective that decouples global policy learning from local corrective updates. Experiments on mathematical reasoning benchmarks demonstrate that our method consistently outperforms GRPO, tree-based methods, and other strong baselines.",
    "authors": [
      "Yiran Guo",
      "Zhongjian Qiao",
      "Yingqi Xie",
      "Jie Liu",
      "Dan Ye",
      "Ruiqing Zhang",
      "Shuang Qiu",
      "Lijie Xu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14169v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14169v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.14038v1",
    "title": "Choosing How to Remember: Adaptive Memory Structures for LLM Agents",
    "summary": "Memory is critical for enabling large language model (LLM) based agents to maintain coherent behavior over long-horizon interactions. However, existing agent memory systems suffer from two key gaps: they rely on a one-size-fits-all memory structure and do not model memory structure selection as a context-adaptive decision, limiting their ability to handle heterogeneous interaction patterns and resulting in suboptimal performance. We propose a unified framework, FluxMem, that enables adaptive memory organization for LLM agents. Our framework equips agents with multiple complementary memory structures. It explicitly learns to select among these structures based on interaction-level features, using offline supervision derived from downstream response quality and memory utilization. To support robust long-horizon memory evolution, we further introduce a three-level memory hierarchy and a Beta Mixture Model-based probabilistic gate for distribution-aware memory fusion, replacing brittle similarity thresholds. Experiments on two long-horizon benchmarks, PERSONAMEM and LoCoMo, demonstrate that our method achieves average improvements of 9.18% and 6.14%.",
    "authors": [
      "Mingfei Lu",
      "Mengjia Wu",
      "Feng Liu",
      "Jiawei Xu",
      "Weikai Li",
      "Haoyang Wang",
      "Zhengdong Hu",
      "Ying Ding",
      "Yizhou Sun",
      "Jie Lu",
      "Yi Zhang"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14038v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14038v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.14030v1",
    "title": "MC$^2$Mark: Distortion-Free Multi-Bit Watermarking for Long Messages",
    "summary": "Large language models now produce text indistinguishable from human writing, which increases the need for reliable provenance tracing. Multi-bit watermarking can embed identifiers into generated text, but existing methods struggle to keep both text quality and watermark strength while carrying long messages. We propose MC$^2$Mark, a distortion-free multi-bit watermarking framework designed for reliable embedding and decoding of long messages. Our key technical idea is Multi-Channel Colored Reweighting, which encodes bits through structured token reweighting while keeping the token distribution unbiased, together with Multi-Layer Sequential Reweighting to strengthen the watermark signal and an evidence-accumulation detector for message recovery. Experiments show that MC$^2$Mark improves detectability and robustness over prior multi-bit watermarking methods while preserving generation quality, achieving near-perfect accuracy for short messages and exceeding the second-best method by nearly 30% for long messages.",
    "authors": [
      "Xuehao Cui",
      "Ruibo Chen",
      "Yihan Wu",
      "Heng Huang"
    ],
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14030v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14030v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.14024v1",
    "title": "EIDOS: Latent-Space Predictive Learning for Time Series Foundation Models",
    "summary": "Most time series foundation models are pretrained by directly predicting future observations, which often yields weakly structured latent representations that capture surface noise rather than coherent and predictable temporal dynamics. In this work, we introduce EIDOS, a foundation model family that shifts pretraining from future value prediction to latent-space predictive learning. We train a causal Transformer to predict the evolution of latent representations, encouraging the emergence of structured and temporally coherent latent states. To ensure stable targets for latent-space learning, we design a lightweight aggregation branch to construct target representations. EIDOS is optimized via a joint objective that integrates latent-space alignment, observational grounding to anchor representations to the input signal, and direct forecasting supervision. On the GIFT-Eval benchmark, EIDOS mitigates structural fragmentation in the representation space and achieves state-of-the-art performance. These results demonstrate that constraining models to learn predictable latent dynamics is a principled step toward more robust and reliable time series foundation models.",
    "authors": [
      "Xinxing Zhou",
      "Qingren Yao",
      "Yiji Zhao",
      "Chenghao Liu",
      "Flora Salim",
      "Xiaojie Yuan",
      "Yanlong Wen",
      "Ming Jin"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14024v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14024v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.13940v1",
    "title": "You Can Learn Tokenization End-to-End with Reinforcement Learning",
    "summary": "Tokenization is a hardcoded compression step which remains in the training pipeline of Large Language Models (LLMs), despite a general trend towards architectures becoming increasingly end-to-end. Prior work has shown promising results at scale in bringing this compression step inside the LLMs' architecture with heuristics to draw token boundaries, and also attempts to learn these token boundaries with straight-through estimates, which treat the problem of drawing discrete token boundaries as a continuous one. We show that these token boundaries can instead be learned using score function estimates, which have tighter theoretical guarantees due to directly optimizing the problem of drawing discrete token boundaries to minimize loss. We observe that techniques from reinforcement learning, such as time discounting, are necessary to reduce the variance of this score function sufficiently to make it practicable. We demonstrate that the resultant method outperforms prior proposed straight-through estimates, both qualitatively and quantitatively at the $100$ million parameter scale.",
    "authors": [
      "Sam Dauncey",
      "Roger Wattenhofer"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13940v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13940v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.14106v1",
    "title": "Anticipating Adversary Behavior in DevSecOps Scenarios through Large Language Models",
    "summary": "The most valuable asset of any cloud-based organization is data, which is increasingly exposed to sophisticated cyberattacks. Until recently, the implementation of security measures in DevOps environments was often considered optional by many government entities and critical national services operating in the cloud. This includes systems managing sensitive information, such as electoral processes or military operations, which have historically been valuable targets for cybercriminals. Resistance to security implementation is often driven by concerns over losing agility in software development, increasing the risk of accumulated vulnerabilities. Nowadays, patching software is no longer enough; adopting a proactive cyber defense strategy, supported by Artificial Intelligence (AI), is crucial to anticipating and mitigating threats. Thus, this work proposes integrating the Security Chaos Engineering (SCE) methodology with a new LLM-based flow to automate the creation of attack defense trees that represent adversary behavior and facilitate the construction of SCE experiments based on these graphical models, enabling teams to stay one step ahead of attackers and implement previously unconsidered defenses. Further detailed information about the experiment performed, along with the steps to replicate it, can be found in the following repository: https://github.com/mariomc14/devsecops-adversary-llm.git.",
    "authors": [
      "Mario MarÃ­n Caballero",
      "Miguel Betancourt Alonso",
      "Daniel DÃ­az-LÃ³pez",
      "Angel Luis Perales GÃ³mez",
      "Pantaleone Nespoli",
      "Gregorio MartÃ­nez PÃ©rez"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14106v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14106v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.14100v1",
    "title": "Character-aware Transformers Learn an Irregular Morphological Pattern Yet None Generalize Like Humans",
    "summary": "Whether neural networks can serve as cognitive models of morphological learning remains an open question. Recent work has shown that encoder-decoder models can acquire irregular patterns, but evidence that they generalize these patterns like humans is mixed. We investigate this using the Spanish \\emph{L-shaped morphome}, where only the first-person singular indicative (e.g., \\textit{pongo} `I put') shares its stem with all subjunctive forms (e.g., \\textit{ponga, pongas}) despite lacking apparent phonological, semantic, or syntactic motivation. We compare five encoder-decoder transformers varying along two dimensions: sequential vs. position-invariant positional encoding, and atomic vs. decomposed tag representations. Positional encoding proves decisive: position-invariant models recover the correct L-shaped paradigm clustering even when L-shaped verbs are scarce in training, whereas sequential positional encoding models only partially capture the pattern. Yet none of the models productively generalize this pattern to novel forms. Position-invariant models generalize the L-shaped stem across subjunctive cells but fail to extend it to the first-person singular indicative, producing a mood-based generalization rather than the L-shaped morphomic pattern. Humans do the opposite, generalizing preferentially to the first-person singular indicative over subjunctive forms. None of the models reproduce the human pattern, highlighting the gap between statistical pattern reproduction and morphological abstraction.",
    "authors": [
      "Akhilesh Kakolu Ramarao",
      "Kevin Tang",
      "Dinah Baer-Henney"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14100v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14100v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.14017v1",
    "title": "S2SServiceBench: A Multimodal Benchmark for Last-Mile S2S Climate Services",
    "summary": "Subseasonal-to-seasonal (S2S) forecasts play an essential role in providing a decision-critical weeks-to-months planning window for climate resilience and sustainability, yet a growing bottleneck is the last-mile gap: translating scientific forecasts into trusted, actionable climate services, requiring reliable multimodal understanding and decision-facing reasoning under uncertainty. Meanwhile, multimodal large language models (MLLMs) and corresponding agentic paradigms have made rapid progress in supporting various workflows, but it remains unclear whether they can reliably generate decision-making deliverables from operational service products (e.g., actionable signal comprehension, decision-making handoff, and decision analysis & planning) under uncertainty. We introduce S2SServiceBench, a multimodal benchmark for last-mile S2S climate services curated from an operational climate-service system to evaluate this capability. S2SServiceBenchcovers 10 service products with about 150+ expert-selected cases in total, spanning six application domains - Agriculture, Disasters, Energy, Finance, Health, and Shipping. Each case is instantiated at three service levels, yielding around 500 tasks and 1,000+ evaluation items across climate resilience and sustainability applications. Using S2SServiceBench, we benchmark state-of-the-art MLLMs and agents, and analyze performance across products and service levels, revealing persistent challenges in S2S service plot understanding and reasoning - namely, actionable signal comprehension, operationalizing uncertainty into executable handoffs, and stable, evidence-grounded analysis and planning for dynamic hazards-while offering actionable guidance for building future climate-service agents.",
    "authors": [
      "Chenyue Li",
      "Wen Deng",
      "Zhuotao Sun",
      "Mengxi Jin",
      "Hanzhe Cui",
      "Han Li",
      "Shentong Li",
      "Man Kit Yu",
      "Ming Long Lai",
      "Yuhao Yang",
      "Mengqian Lu",
      "Binhang Yuan"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14017v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14017v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.14011v1",
    "title": "KoopGen: Koopman Generator Networks for Representing and Predicting Dynamical Systems with Continuous Spectra",
    "summary": "Representing and predicting high-dimensional and spatiotemporally chaotic dynamical systems remains a fundamental challenge in dynamical systems and machine learning. Although data-driven models can achieve accurate short-term forecasts, they often lack stability, interpretability, and scalability in regimes dominated by broadband or continuous spectra. Koopman-based approaches provide a principled linear perspective on nonlinear dynamics, but existing methods rely on restrictive finite-dimensional assumptions or explicit spectral parameterizations that degrade in high-dimensional settings. Against these issues, we introduce KoopGen, a generator-based neural Koopman framework that models dynamics through a structured, state-dependent representation of Koopman generators. By exploiting the intrinsic Cartesian decomposition into skew-adjoint and self-adjoint components, KoopGen separates conservative transport from irreversible dissipation while enforcing exact operator-theoretic constraints during learning. Across systems ranging from nonlinear oscillators to high-dimensional chaotic and spatiotemporal dynamics, KoopGen improves prediction accuracy and stability, while clarifying which components of continuous-spectrum dynamics admit interpretable and learnable representations.",
    "authors": [
      "Liangyu Su",
      "Jun Shu",
      "Rui Liu",
      "Deyu Meng",
      "Zongben Xu"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14011v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14011v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.13942v1",
    "title": "A Theoretical Framework for LLM Fine-tuning Using Early Stopping for Non-random Initialization",
    "summary": "In the era of large language models (LLMs), fine-tuning pretrained models has become ubiquitous. Yet the theoretical underpinning remains an open question. A central question is why only a few epochs of fine-tuning are typically sufficient to achieve strong performance on many different tasks. In this work, we approach this question by developing a statistical framework, combining rigorous early stopping theory with the attention-based Neural Tangent Kernel (NTK) for LLMs, offering new theoretical insights on fine-tuning practices. Specifically, we formally extend classical NTK theory [Jacot et al., 2018] to non-random (i.e., pretrained) initializations and provide a convergence guarantee for attention-based fine-tuning. One key insight provided by the theory is that the convergence rate with respect to sample size is closely linked to the eigenvalue decay rate of the empirical kernel matrix induced by the NTK. We also demonstrate how the framework can be used to explain task vectors for multiple tasks in LLMs. Finally, experiments with modern language models on real-world datasets provide empirical evidence supporting our theoretical insights.",
    "authors": [
      "Zexuan Sun",
      "Garvesh Raskutti"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13942v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13942v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.14119v1",
    "title": "GeoFusionLRM: Geometry-Aware Self-Correction for Consistent 3D Reconstruction",
    "summary": "Single-image 3D reconstruction with large reconstruction models (LRMs) has advanced rapidly, yet reconstructions often exhibit geometric inconsistencies and misaligned details that limit fidelity. We introduce GeoFusionLRM, a geometry-aware self-correction framework that leverages the model's own normal and depth predictions to refine structural accuracy. Unlike prior approaches that rely solely on features extracted from the input image, GeoFusionLRM feeds back geometric cues through a dedicated transformer and fusion module, enabling the model to correct errors and enforce consistency with the conditioning image. This design improves the alignment between the reconstructed mesh and the input views without additional supervision or external signals. Extensive experiments demonstrate that GeoFusionLRM achieves sharper geometry, more consistent normals, and higher fidelity than state-of-the-art LRM baselines.",
    "authors": [
      "Ahmet Burak Yildirim",
      "Tuna Saygin",
      "Duygu Ceylan",
      "Aysegul Dundar"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14119v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14119v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.14108v1",
    "title": "Geometry-Aware Physics-Informed PointNets for Modeling Flows Across Porous Structures",
    "summary": "Predicting flows that occur both through and around porous bodies is challenging due to coupled physics across fluid and porous regions and the need to generalize across diverse geometries and boundary conditions. We address this problem using two Physics Informed learning approaches: Physics Informed PointNets (PIPN) and Physics Informed Geometry Aware Neural Operator (P-IGANO). We enforce the incompressible Navier Stokes equations in the free-flow region and a Darcy Forchheimer extension in the porous region within a unified loss and condition the networks on geometry and material parameters. Datasets are generated with OpenFOAM on 2D ducts containing porous obstacles and on 3D windbreak scenarios with tree canopies and buildings. We first verify the pipeline via the method of manufactured solutions, then assess generalization to unseen shapes, and for PI-GANO, to variable boundary conditions and parameter settings. The results show consistently low velocity and pressure errors in both seen and unseen cases, with accurate reproduction of the wake structures. Performance degrades primarily near sharp interfaces and in regions with large gradients. Overall, the study provides a first systematic evaluation of PIPN/PI-GANO for simultaneous through-and-around porous flows and shows their potential to accelerate design studies without retraining per geometry.",
    "authors": [
      "Luigi Ciceri",
      "Corrado Mio",
      "Jianyi Lin",
      "Gabriele Gianini"
    ],
    "categories": [
      "cs.LG",
      "physics.flu-dyn"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14108v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14108v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.14086v1",
    "title": "Neural Optimal Transport in Hilbert Spaces: Characterizing Spurious Solutions and Gaussian Smoothing",
    "summary": "We study Neural Optimal Transport in infinite-dimensional Hilbert spaces. In non-regular settings, Semi-dual Neural OT often generates spurious solutions that fail to accurately capture target distributions. We analytically characterize this spurious solution problem using the framework of regular measures, which generalize Lebesgue absolute continuity in finite dimensions. To resolve ill-posedness, we extend the semi-dual framework via a Gaussian smoothing strategy based on Brownian motion. Our primary theoretical contribution proves that under a regular source measure, the formulation is well-posed and recovers a unique Monge map. Furthermore, we establish a sharp characterization for the regularity of smoothed measures, proving that the success of smoothing depends strictly on the kernel of the covariance operator. Empirical results on synthetic functional data and time-series datasets demonstrate that our approach effectively suppresses spurious solutions and outperforms existing baselines.",
    "authors": [
      "Jae-Hwan Choi",
      "Jiwoo Yoon",
      "Dohyun Kwon",
      "Jaewoong Choi"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14086v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14086v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.14081v1",
    "title": "CCiV: A Benchmark for Structure, Rhythm and Quality in LLM-Generated Chinese \\textit{Ci} Poetry",
    "summary": "The generation of classical Chinese \\textit{Ci} poetry, a form demanding a sophisticated blend of structural rigidity, rhythmic harmony, and artistic quality, poses a significant challenge for large language models (LLMs). To systematically evaluate and advance this capability, we introduce \\textbf{C}hinese \\textbf{Ci}pai \\textbf{V}ariants (\\textbf{CCiV}), a benchmark designed to assess LLM-generated \\textit{Ci} poetry across these three dimensions: structure, rhythm, and quality. Our evaluation of 17 LLMs on 30 \\textit{Cipai} reveals two critical phenomena: models frequently generate valid but unexpected historical variants of a poetic form, and adherence to tonal patterns is substantially harder than structural rules. We further show that form-aware prompting can improve structural and tonal control for stronger models, while potentially degrading weaker ones. Finally, we observe weak and inconsistent alignment between formal correctness and literary quality in our sample. CCiV highlights the need for variant-aware evaluation and more holistic constrained creative generation methods.",
    "authors": [
      "Shangqing Zhao",
      "Yupei Ren",
      "Yuhao Zhou",
      "Xiaopeng Bai",
      "Man Lan"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14081v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14081v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.13977v1",
    "title": "WoVR: World Models as Reliable Simulators for Post-Training VLA Policies with RL",
    "summary": "Reinforcement learning (RL) promises to unlock capabilities beyond imitation learning for Vision-Language-Action (VLA) models, but its requirement for massive real-world interaction prevents direct deployment on physical robots. Recent work attempts to use learned world models as simulators for policy optimization, yet closed-loop imagined rollouts inevitably suffer from hallucination and long-horizon error accumulation. Such errors do not merely degrade visual fidelity; they corrupt the optimization signal, encouraging policies to exploit model inaccuracies rather than genuine task progress. We propose WoVR, a reliable world-model-based reinforcement learning framework for post-training VLA policies. Instead of assuming a faithful world model, WoVR explicitly regulates how RL interacts with imperfect imagined dynamics. It improves rollout stability through a controllable action-conditioned video world model, reshapes imagined interaction to reduce effective error depth via Keyframe-Initialized Rollouts, and maintains policy-simulator alignment through World Model-Policy co-evolution. Extensive experiments on LIBERO benchmarks and real-world robotic manipulation demonstrate that WoVR enables stable long-horizon imagined rollouts and effective policy optimization, improving average LIBERO success from 39.95% to 69.2% (+29.3 points) and real-robot success from 61.7% to 91.7% (+30.0 points). These results show that learned world models can serve as practical simulators for reinforcement learning when hallucination is explicitly controlled.",
    "authors": [
      "Zhennan Jiang",
      "Shangqing Zhou",
      "Yutong Jiang",
      "Zefang Huang",
      "Mingjie Wei",
      "Yuhui Chen",
      "Tianxing Zhou",
      "Zhen Guo",
      "Hao Lin",
      "Quanlu Zhang",
      "Yu Wang",
      "Haoran Li",
      "Chao Yu",
      "Dongbin Zhao"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13977v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13977v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.13936v1",
    "title": "A Generalizable Physics-guided Causal Model for Trajectory Prediction in Autonomous Driving",
    "summary": "Trajectory prediction for traffic agents is critical for safe autonomous driving. However, achieving effective zero-shot generalization in previously unseen domains remains a significant challenge. Motivated by the consistent nature of kinematics across diverse domains, we aim to incorporate domain-invariant knowledge to enhance zero-shot trajectory prediction capabilities. The key challenges include: 1) effectively extracting domain-invariant scene representations, and 2) integrating invariant features with kinematic models to enable generalized predictions. To address these challenges, we propose a novel generalizable Physics-guided Causal Model (PCM), which comprises two core components: a Disentangled Scene Encoder, which adopts intervention-based disentanglement to extract domain-invariant features from scenes, and a CausalODE Decoder, which employs a causal attention mechanism to effectively integrate kinematic models with meaningful contextual information. Extensive experiments on real-world autonomous driving datasets demonstrate our method's superior zero-shot generalization performance in unseen cities, significantly outperforming competitive baselines. The source code is released at https://github.com/ZY-Zong/Physics-guided-Causal-Model.",
    "authors": [
      "Zhenyu Zong",
      "Yuchen Wang",
      "Haohong Lin",
      "Lu Gan",
      "Huajie Shao"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13936v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13936v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.14161v1",
    "title": "When Benchmarks Lie: Evaluating Malicious Prompt Classifiers Under True Distribution Shift",
    "summary": "Detecting prompt injection and jailbreak attacks is critical for deploying LLM-based agents safely. As agents increasingly process untrusted data from emails, documents, tool outputs, and external APIs, robust attack detection becomes essential. Yet current evaluation practices and production systems have fundamental limitations. We present a comprehensive analysis using a diverse benchmark of 18 datasets spanning harmful requests, jailbreaks, indirect prompt injections, and extraction attacks. We propose Leave-One-Dataset-Out (LODO) evaluation to measure true out-of-distribution generalization, revealing that the standard practice of train-test splits from the same dataset sources severely overestimates performance: aggregate metrics show an 8.4 percentage point AUC inflation, but per-dataset gaps range from 1% to 25% accuracy-exposing heterogeneous failure modes. To understand why classifiers fail to generalize, we analyze Sparse Auto-Encoder (SAE) feature coefficients across LODO folds, finding that 28% of top features are dataset-dependent shortcuts whose class signal depends on specific dataset compositions rather than semantic content. We systematically compare production guardrails (PromptGuard 2, LlamaGuard) and LLM-as-judge approaches on our benchmark, finding all three fail on indirect attacks targeting agents (7-37% detection) and that PromptGuard 2 and LlamaGuard cannot evaluate agentic tool injection due to architectural limitations. Finally, we show that LODO-stable SAE features provide more reliable explanations for classifier decisions by filtering dataset artifacts. We release our evaluation framework at https://github.com/maxf-zn/prompt-mining to establish LODO as the appropriate protocol for prompt attack detection research.",
    "authors": [
      "Max Fomin"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14161v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14161v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.13985v1",
    "title": "Bridging AI and Clinical Reasoning: Abductive Explanations for Alignment on Critical Symptoms",
    "summary": "Artificial intelligence (AI) has demonstrated strong potential in clinical diagnostics, often achieving accuracy comparable to or exceeding that of human experts. A key challenge, however, is that AI reasoning frequently diverges from structured clinical frameworks, limiting trust, interpretability, and adoption. Critical symptoms, pivotal for rapid and accurate decision-making, may be overlooked by AI models even when predictions are correct. Existing post hoc explanation methods provide limited transparency and lack formal guarantees. To address this, we leverage formal abductive explanations, which offer consistent, guaranteed reasoning over minimal sufficient feature sets. This enables a clear understanding of AI decision-making and allows alignment with clinical reasoning. Our approach preserves predictive accuracy while providing clinically actionable insights, establishing a robust framework for trustworthy AI in medical diagnosis.",
    "authors": [
      "Belona Sonna",
      "Alban Grastien"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13985v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13985v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.14095v1",
    "title": "NEST: Nascent Encoded Steganographic Thoughts",
    "summary": "Monitoring chain-of-thought (CoT) reasoning is a foundational safety technique for large language model (LLM) agents; however, this oversight is compromised if models learn to conceal their reasoning. We explore the potential for steganographic CoT -- where models hide secret reasoning within innocuous text -- to inform risk assessment and deployment policies. We systematically evaluate the limits of steganographic capabilities across 28 models, ranging from past generations to the current frontier. We measure monitor evasion, refusal rates, encoding fidelity, and hidden task accuracy across four datasets, comparing steganographic acrostics against plain reasoning and filler-token baselines. We find that current models cannot yet sustain hidden reasoning for complex math and arithmetic tasks. However, in a simplified counting experiment, Claude Opus 4.5 achieved 92% accuracy on the hidden task, demonstrating nascent capability. Notably, in rare cases (<1%), GPT-5.2 might refuse steganographic instructions while simultaneously complying with them. Our findings underscore the need for continuous evaluation of steganographic risks. This study provides a methodology to preemptively detect and prevent hidden reasoning that might empower misaligned scheming and deceptive behavior.",
    "authors": [
      "Artem Karpov"
    ],
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14095v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14095v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.14027v1",
    "title": "Train Short, Inference Long: Training-free Horizon Extension for Autoregressive Video Generation",
    "summary": "Autoregressive video diffusion models have emerged as a scalable paradigm for long video generation. However, they often suffer from severe extrapolation failure, where rapid error accumulation leads to significant temporal degradation when extending beyond training horizons. We identify that this failure primarily stems from the \\textit{spectral bias} of 3D positional embeddings and the lack of \\textit{dynamic priors} in noise sampling. To address these issues, we propose \\textbf{FLEX} (\\textbf{F}requency-aware \\textbf{L}ength \\textbf{EX}tension), a training-free inference-time framework that bridges the gap between short-term training and long-term inference. FLEX introduces Frequency-aware RoPE Modulation to adaptively interpolate under-trained low-frequency components while extrapolating high-frequency ones to preserve multi-scale temporal discriminability. This is integrated with Antiphase Noise Sampling (ANS) to inject high-frequency dynamic priors and Inference-only Attention Sink to anchor global structure. Extensive evaluations on VBench demonstrate that FLEX significantly outperforms state-of-the-art models at $6\\times$ extrapolation (30s duration) and matches the performance of long-video fine-tuned baselines at $12\\times$ scale (60s duration). As a plug-and-play augmentation, FLEX seamlessly integrates into existing inference pipelines for horizon extension. It effectively pushes the generation limits of models such as LongLive, supporting consistent and dynamic video synthesis at a 4-minute scale. Project page is available at \\href{https://ga-lee.github.io/FLEX_demo}{https://ga-lee.github.io/FLEX}.",
    "authors": [
      "Jia Li",
      "Xiaomeng Fu",
      "Xurui Peng",
      "Weifeng Chen",
      "Youwei Zheng",
      "Tianyu Zhao",
      "Jiexi Wang",
      "Fangmin Chen",
      "Xing Wang",
      "Hayden Kwok-Hay So"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14027v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14027v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.14021v1",
    "title": "Flow4R: Unifying 4D Reconstruction and Tracking with Scene Flow",
    "summary": "Reconstructing and tracking dynamic 3D scenes remains a fundamental challenge in computer vision. Existing approaches often decouple geometry from motion: multi-view reconstruction methods assume static scenes, while dynamic tracking frameworks rely on explicit camera pose estimation or separate motion models. We propose Flow4R, a unified framework that treats camera-space scene flow as the central representation linking 3D structure, object motion, and camera motion. Flow4R predicts a minimal per-pixel property set-3D point position, scene flow, pose weight, and confidence-from two-view inputs using a Vision Transformer. This flow-centric formulation allows local geometry and bidirectional motion to be inferred symmetrically with a shared decoder in a single forward pass, without requiring explicit pose regressors or bundle adjustment. Trained jointly on static and dynamic datasets, Flow4R achieves state-of-the-art performance on 4D reconstruction and tracking tasks, demonstrating the effectiveness of the flow-central representation for spatiotemporal scene understanding.",
    "authors": [
      "Shenhan Qian",
      "Ganlin Zhang",
      "Shangzhe Wu",
      "Daniel Cremers"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14021v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14021v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.13971v1",
    "title": "DAIAN: Deep Adaptive Intent-Aware Network for CTR Prediction in Trigger-Induced Recommendation",
    "summary": "Recommendation systems are essential for personalizing e-commerce shopping experiences. Among these, Trigger-Induced Recommendation (TIR) has emerged as a key scenario, which utilizes a trigger item (explicitly represents a user's instantaneous interest), enabling precise, real-time recommendations. Although several trigger-based techniques have been proposed, most of them struggle to address the intent myopia issue, that is, a recommendation system overemphasizes the role of trigger items and narrowly focuses on suggesting commodities that are highly relevant to trigger items. Meanwhile, existing methods rely on collaborative behavior patterns between trigger and recommended items to identify the user's preferences, yet the sparsity of ID-based interaction restricts their effectiveness. To this end, we propose the Deep Adaptive Intent-Aware Network (DAIAN) that dynamically adapts to users' intent preferences. In general, we first extract the users' personalized intent representations by analyzing the correlation between a user's click and the trigger item, and accordingly retrieve the user's related historical behaviors to mine the user's diverse intent. Besides, sparse collaborative behaviors constrain the performance in capturing items associated with user intent. Hence, we reinforce similarity by leveraging a hybrid enhancer with ID and semantic information, followed by adaptive selection based on varying intents. Experimental results on public datasets and our industrial e-commerce datasets demonstrate the effectiveness of DAIAN.",
    "authors": [
      "Zhihao Lv",
      "Longtao Zhang",
      "Ailong He",
      "Shuzhi Cao",
      "Shuguang Han",
      "Jufeng Chen"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13971v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13971v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.13961v1",
    "title": "MarsRetrieval: Benchmarking Vision-Language Models for Planetary-Scale Geospatial Retrieval on Mars",
    "summary": "Data-driven approaches like deep learning are rapidly advancing planetary science, particularly in Mars exploration. Despite recent progress, most existing benchmarks remain confined to closed-set supervised visual tasks and do not support text-guided retrieval for geospatial discovery. We introduce MarsRetrieval, a retrieval benchmark for evaluating vision-language models for Martian geospatial discovery. MarsRetrieval includes three tasks: (1) paired image-text retrieval, (2) landform retrieval, and (3) global geo-localization, covering multiple spatial scales and diverse geomorphic origins. We propose a unified retrieval-centric protocol to benchmark multimodal embedding architectures, including contrastive dual-tower encoders and generative vision-language models. Our evaluation shows MarsRetrieval is challenging: even strong foundation models often fail to capture domain-specific geomorphic distinctions. We further show that domain-specific fine-tuning is critical for generalizable geospatial discovery in planetary settings. Our code is available at https://github.com/ml-stat-Sustech/MarsRetrieval",
    "authors": [
      "Shuoyuan Wang",
      "Yiran Wang",
      "Hongxin Wei"
    ],
    "categories": [
      "cs.CV",
      "astro-ph.IM",
      "cs.CL"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13961v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13961v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.14189v1",
    "title": "Knowing When Not to Answer: Abstention-Aware Scientific Reasoning",
    "summary": "Large language models are increasingly used to answer and verify scientific claims, yet existing evaluations typically assume that a model must always produce a definitive answer. In scientific settings, however, unsupported or uncertain conclusions can be more harmful than abstaining. We study this problem through an abstention-aware verification framework that decomposes scientific claims into minimal conditions, audits each condition against available evidence using natural language inference (NLI), and selectively decides whether to support, refute, or abstain. We evaluate this framework across two complementary scientific benchmarks: SciFact and PubMedQA, covering both closed-book and open-domain evidence settings. Experiments are conducted with six diverse language models, including encoder-decoder, open-weight chat models, and proprietary APIs. Across all benchmarks and models, we observe that raw accuracy varies only modestly across architectures, while abstention plays a critical role in controlling error. In particular, confidence-based abstention substantially reduces risk at moderate coverage levels, even when absolute accuracy improvements are limited. Our results suggest that in scientific reasoning tasks, the primary challenge is not selecting a single best model, but rather determining when available evidence is sufficient to justify an answer. This work highlights abstention-aware evaluation as a practical and model-agnostic lens for assessing scientific reliability, and provides a unified experimental basis for future work on selective reasoning in scientific domains. Code is available at https://github.com/sabdaljalil2000/ai4science .",
    "authors": [
      "Samir Abdaljalil",
      "Erchin Serpedin",
      "Hasan Kurban"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14189v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14189v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.14186v1",
    "title": "UniRef-Image-Edit: Towards Scalable and Consistent Multi-Reference Image Editing",
    "summary": "We present UniRef-Image-Edit, a high-performance multi-modal generation system that unifies single-image editing and multi-image composition within a single framework. Existing diffusion-based editing methods often struggle to maintain consistency across multiple conditions due to limited interaction between reference inputs. To address this, we introduce Sequence-Extended Latent Fusion (SELF), a unified input representation that dynamically serializes multiple reference images into a coherent latent sequence. During a dedicated training stage, all reference images are jointly constrained to fit within a fixed-length sequence under a global pixel-budget constraint. Building upon SELF, we propose a two-stage training framework comprising supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we jointly train on single-image editing and multi-image composition tasks to establish a robust generative prior. We adopt a progressive sequence length training strategy, in which all input images are initially resized to a total pixel budget of $1024^2$, and are then gradually increased to $1536^2$ and $2048^2$ to improve visual fidelity and cross-reference consistency. This gradual relaxation of compression enables the model to incrementally capture finer visual details while maintaining stable alignment across references. For the RL stage, we introduce Multi-Source GRPO (MSGRPO), to our knowledge the first reinforcement learning framework tailored for multi-reference image generation. MSGRPO optimizes the model to reconcile conflicting visual constraints, significantly enhancing compositional consistency. We will open-source the code, models, training data, and reward data for community research purposes.",
    "authors": [
      "Hongyang Wei",
      "Bin Wen",
      "Yancheng Long",
      "Yankai Yang",
      "Yuhang Hu",
      "Tianke Zhang",
      "Wei Chen",
      "Haonan Fan",
      "Kaiyu Jiang",
      "Jiankang Chen",
      "Changyi Liu",
      "Kaiyu Tang",
      "Haojie Ding",
      "Xiao Yang",
      "Jia Sun",
      "Huaiqing Wang",
      "Zhenyu Yang",
      "Xinyu Wei",
      "Xianglong He",
      "Yangguang Li",
      "Fan Yang",
      "Tingting Gao",
      "Lei Zhang",
      "Guorui Zhou",
      "Han Li"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14186v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14186v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.13960v1",
    "title": "Steady-State Behavior of Constant-Stepsize Stochastic Approximation: Gaussian Approximation and Tail Bounds",
    "summary": "Constant-stepsize stochastic approximation (SA) is widely used in learning for computational efficiency. For a fixed stepsize, the iterates typically admit a stationary distribution that is rarely tractable. Prior work shows that as the stepsize $Î±\\downarrow 0$, the centered-and-scaled steady state converges weakly to a Gaussian random vector. However, for fixed $Î±$, this weak convergence offers no usable error bound for approximating the steady-state by its Gaussian limit. This paper provides explicit, non-asymptotic error bounds for fixed $Î±$. We first prove general-purpose theorems that bound the Wasserstein distance between the centered-scaled steady state and an appropriate Gaussian distribution, under regularity conditions for drift and moment conditions for noise. To ensure broad applicability, we cover both i.i.d. and Markovian noise models. We then instantiate these theorems for three representative SA settings: (1) stochastic gradient descent (SGD) for smooth strongly convex objectives, (2) linear SA, and (3) contractive nonlinear SA. We obtain dimension- and stepsize-dependent, explicit bounds in Wasserstein distance of order $Î±^{1/2}\\log(1/Î±)$ for small $Î±$. Building on the Wasserstein approximation error, we further derive non-uniform Berry--Esseen-type tail bounds that compare the steady-state tail probability to Gaussian tails. We achieve an explicit error term that decays in both the deviation level and stepsize $Î±$. We adapt the same analysis for SGD beyond strongly convexity and study general convex objectives. We identify a non-Gaussian (Gibbs) limiting law under the correct scaling, which is validated numerically, and provide a corresponding pre-limit Wasserstein error bound.",
    "authors": [
      "Zedong Wang",
      "Yuyang Wang",
      "Ijay Narang",
      "Felix Wang",
      "Yuzhou Wang",
      "Siva Theja Maguluri"
    ],
    "categories": [
      "cs.LG",
      "math.PR"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13960v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13960v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.14122v1",
    "title": "EgoSound: Benchmarking Sound Understanding in Egocentric Videos",
    "summary": "Multimodal Large Language Models (MLLMs) have recently achieved remarkable progress in vision-language understanding. Yet, human perception is inherently multisensory, integrating sight, sound, and motion to reason about the world. Among these modalities, sound provides indispensable cues about spatial layout, off-screen events, and causal interactions, particularly in egocentric settings where auditory and visual signals are tightly coupled. To this end, we introduce EgoSound, the first benchmark designed to systematically evaluate egocentric sound understanding in MLLMs. EgoSound unifies data from Ego4D and EgoBlind, encompassing both sighted and sound-dependent experiences. It defines a seven-task taxonomy spanning intrinsic sound perception, spatial localization, causal inference, and cross-modal reasoning. Constructed through a multi-stage auto-generative pipeline, EgoSound contains 7315 validated QA pairs across 900 videos. Comprehensive experiments on nine state-of-the-art MLLMs reveal that current models exhibit emerging auditory reasoning abilities but remain limited in fine-grained spatial and causal understanding. EgoSound establishes a challenging foundation for advancing multisensory egocentric intelligence, bridging the gap between seeing and truly hearing the world.",
    "authors": [
      "Bingwen Zhu",
      "Yuqian Fu",
      "Qiaole Dong",
      "Guolei Sun",
      "Tianwen Qian",
      "Yuzheng Wu",
      "Danda Pani Paudel",
      "Xiangyang Xue",
      "Yanwei Fu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14122v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14122v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.14117v1",
    "title": "Toward Autonomous O-RAN: A Multi-Scale Agentic AI Framework for Real-Time Network Control and Management",
    "summary": "Open Radio Access Networks (O-RAN) promise flexible 6G network access through disaggregated, software-driven components and open interfaces, but this programmability also increases operational complexity. Multiple control loops coexist across the service management layer and RAN Intelligent Controller (RIC), while independently developed control applications can interact in unintended ways. In parallel, recent advances in generative Artificial Intelligence (AI) are enabling a shift from isolated AI models toward agentic AI systems that can interpret goals, coordinate multiple models and control functions, and adapt their behavior over time. This article proposes a multi-scale agentic AI framework for O-RAN that organizes RAN intelligence as a coordinated hierarchy across the Non-Real-Time (Non-RT), Near-Real-Time (Near-RT), and Real-Time (RT) control loops: (i) A Large Language Model (LLM) agent in the Non-RT RIC translates operator intent into policies and governs model lifecycles. (ii) Small Language Model (SLM) agents in the Near-RT RIC execute low-latency optimization and can activate, tune, or disable existing control applications; and (iii) Wireless Physical-layer Foundation Model (WPFM) agents near the distributed unit provide fast inference close to the air interface. We describe how these agents cooperate through standardized O-RAN interfaces and telemetry. Using a proof-of-concept implementation built on open-source models, software, and datasets, we demonstrate the proposed agentic approach in two representative scenarios: robust operation under non-stationary conditions and intent-driven slice resource control.",
    "authors": [
      "Hojjat Navidan",
      "Mohammad Cheraghinia",
      "Jaron Fontaine",
      "Mohamed Seif",
      "Eli De Poorter",
      "H. Vincent Poor",
      "Ingrid Moerman",
      "Adnan Shahid"
    ],
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14117v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14117v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.14069v1",
    "title": "Open Rubric System: Scaling Reinforcement Learning with Pairwise Adaptive Rubric",
    "summary": "Scalar reward models compress multi-dimensional human preferences into a single opaque score, creating an information bottleneck that often leads to brittleness and reward hacking in open-ended alignment. We argue that robust alignment for non-verifiable tasks is fundamentally a principle generalization problem: reward should not be a learned function internalized into a judge, but an explicit reasoning process executed under inspectable principles. To operationalize this view, we present the Open Rubric System (OpenRS), a plug-and-play, rubrics-based LLM-as-a-Judge framework built around Pairwise Adaptive Meta-Rubrics (PAMR) and lightweight Pointwise Verifiable Rubrics (PVRs), which provide both hard-constraint guardrails and verifiable reward components when ground-truth or programmatic checks are available. OpenRS uses an explicit meta-rubric -- a constitution-like specification that governs how rubrics are instantiated, weighted, and enforced -- and instantiates adaptive rubrics on the fly by conditioning on the semantic differences between two candidate responses. It then performs criterion-wise pairwise comparisons and aggregates criterion-level preferences externally, avoiding pointwise weighted scalarization while improving discriminability in open-ended settings. To keep principles consistent yet editable across various domains, we introduce a two-level meta-rubric refinement pipeline (automated evolutionary refinement for general principles and a reproducible human-in-the-loop procedure for domain principles), complemented with pointwise verifiable rubrics that act as both guardrails against degenerate behaviors and a source of verifiable reward for objective sub-tasks. Finally, we instantiate OpenRS as reward supervision in pairwise RL training.",
    "authors": [
      "Ruipeng Jia",
      "Yunyi Yang",
      "Yuxin Wu",
      "Yongbo Gai",
      "Siyuan Tao",
      "Mengyu Zhou",
      "Jianhe Lin",
      "Xiaoxi Jiang",
      "Guanjun Jiang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14069v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14069v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.14050v1",
    "title": "Position Encoding with Random Float Sampling Enhances Length Generalization of Transformers",
    "summary": "Length generalization is the ability of language models to maintain performance on inputs longer than those seen during pretraining. In this work, we introduce a simple yet powerful position encoding (PE) strategy, Random Float Sampling (RFS), that generalizes well to lengths unseen during pretraining or fine-tuning. In particular, instead of selecting position indices from a predefined discrete set, RFS uses randomly sampled continuous values, thereby avoiding out-of-distribution (OOD) issues on unseen lengths by exposing the model to diverse indices during training. Since assigning indices to tokens is a common and fundamental procedure in widely used PEs, the advantage of RFS can easily be incorporated into, for instance, the absolute sinusoidal encoding, RoPE, and ALiBi. Experiments corroborate its effectiveness by showing that RFS results in superior performance in length generalization tasks as well as zero-shot commonsense reasoning benchmarks.",
    "authors": [
      "Atsushi Shimizu",
      "Shohei Taniguchi",
      "Yutaka Matsuo"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14050v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14050v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.14039v1",
    "title": "Geometry-Preserving Aggregation for Mixture-of-Experts Embedding Models",
    "summary": "Mixture-of-Experts (MoE) embedding models combine expert outputs using weighted linear summation, implicitly assuming a linear subspace structure in the embedding space. This assumption is shown to be inconsistent with the geometry of expert representations. Geometric analysis of a modern MoE embedding model reveals that expert outputs lie on a shared hyperspherical manifold characterized by tightly concentrated norms and substantial angular separation. Under this geometry, linear aggregation induces inward collapse toward the manifold interior, distorting vector magnitude and direction and reducing embedding comparability. To address this inconsistency, Spherical Barycentric Aggregation (SBA) is introduced as a geometry-preserving aggregation operator that separates radial and angular components to maintain hyperspherical structure while remaining fully compatible with existing routing mechanisms. Experiments on selected tasks from the Massive Text Embedding Benchmark (MTEB), including semantic similarity, clustering, and duplicate question detection, demonstrate consistent performance improvements with identical training cost and full stability. Additional geometric analyses confirm that SBA prevents aggregation-induced collapse and preserves hyperspherical consistency, highlighting the importance of geometry-aware aggregation in MoE embedding architectures.",
    "authors": [
      "Sajjad Kachuee",
      "Mohammad Sharifkhani"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14039v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14039v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.14157v1",
    "title": "When Test-Time Guidance Is Enough: Fast Image and Video Editing with Diffusion Guidance",
    "summary": "Text-driven image and video editing can be naturally cast as inpainting problems, where masked regions are reconstructed to remain consistent with both the observed content and the editing prompt. Recent advances in test-time guidance for diffusion and flow models provide a principled framework for this task; however, existing methods rely on costly vector--Jacobian product (VJP) computations to approximate the intractable guidance term, limiting their practical applicability. Building upon the recent work of Moufad et al. (2025), we provide theoretical insights into their VJP-free approximation and substantially extend their empirical evaluation to large-scale image and video editing benchmarks. Our results demonstrate that test-time guidance alone can achieve performance comparable to, and in some cases surpass, training-based methods.",
    "authors": [
      "Ahmed Ghorbel",
      "Badr Moufad",
      "Navid Bagheri Shouraki",
      "Alain Oliviero Durmus",
      "Thomas Hirtz",
      "Eric Moulines",
      "Jimmy Olsson",
      "Yazid Janati"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14157v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14157v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.14147v1",
    "title": "LaViDa-R1: Advancing Reasoning for Unified Multimodal Diffusion Language Models",
    "summary": "Diffusion language models (dLLMs) recently emerged as a promising alternative to auto-regressive LLMs. The latest works further extended it to multimodal understanding and generation tasks. In this work, we propose LaViDa-R1, a multimodal, general-purpose reasoning dLLM. Unlike existing works that build reasoning dLLMs through task-specific reinforcement learning, LaViDa-R1 incorporates diverse multimodal understanding and generation tasks in a unified manner. In particular, LaViDa-R1 is built with a novel unified post-training framework that seamlessly integrates supervised finetuning (SFT) and multi-task reinforcement learning (RL). It employs several novel training techniques, including answer-forcing, tree search, and complementary likelihood estimation, to enhance effectiveness and scalability. Extensive experiments demonstrate LaViDa-R1's strong performance on a wide range of multimodal tasks, including visual math reasoning, reason-intensive grounding, and image editing.",
    "authors": [
      "Shufan Li",
      "Yuchen Zhu",
      "Jiuxiang Gu",
      "Kangning Liu",
      "Zhe Lin",
      "Yongxin Chen",
      "Molei Tao",
      "Aditya Grover",
      "Jason Kuen"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14147v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14147v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.14135v1",
    "title": "ForesightSafety Bench: A Frontier Risk Evaluation and Governance Framework towards Safe AI",
    "summary": "Rapidly evolving AI exhibits increasingly strong autonomy and goal-directed capabilities, accompanied by derivative systemic risks that are more unpredictable, difficult to control, and potentially irreversible. However, current AI safety evaluation systems suffer from critical limitations such as restricted risk dimensions and failed frontier risk detection. The lagging safety benchmarks and alignment technologies can hardly address the complex challenges posed by cutting-edge AI models. To bridge this gap, we propose the \"ForesightSafety Bench\" AI Safety Evaluation Framework, beginning with 7 major Fundamental Safety pillars and progressively extends to advanced Embodied AI Safety, AI4Science Safety, Social and Environmental AI risks, Catastrophic and Existential Risks, as well as 8 critical industrial safety domains, forming a total of 94 refined risk dimensions. To date, the benchmark has accumulated tens of thousands of structured risk data points and assessment results, establishing a widely encompassing, hierarchically clear, and dynamically evolving AI safety evaluation framework. Based on this benchmark, we conduct systematic evaluation and in-depth analysis of over twenty mainstream advanced large models, identifying key risk patterns and their capability boundaries. The safety capability evaluation results reveals the widespread safety vulnerabilities of frontier AI across multiple pillars, particularly focusing on Risky Agentic Autonomy, AI4Science Safety, Embodied AI Safety, Social AI Safety and Catastrophic and Existential Risks. Our benchmark is released at https://github.com/Beijing-AISI/ForesightSafety-Bench. The project website is available at https://foresightsafety-bench.beijing-aisi.ac.cn/.",
    "authors": [
      "Haibo Tong",
      "Feifei Zhao",
      "Linghao Feng",
      "Ruoyu Wu",
      "Ruolin Chen",
      "Lu Jia",
      "Zhou Zhao",
      "Jindong Li",
      "Tenglong Li",
      "Erliang Lin",
      "Shuai Yang",
      "Enmeng Lu",
      "Yinqian Sun",
      "Qian Zhang",
      "Zizhe Ruan",
      "Zeyang Yue",
      "Ping Wu",
      "Huangrui Li",
      "Chengyi Sun",
      "Yi Zeng"
    ],
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.CY"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14135v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14135v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.14111v1",
    "title": "Sanity Checks for Sparse Autoencoders: Do SAEs Beat Random Baselines?",
    "summary": "Sparse Autoencoders (SAEs) have emerged as a promising tool for interpreting neural networks by decomposing their activations into sparse sets of human-interpretable features. Recent work has introduced multiple SAE variants and successfully scaled them to frontier models. Despite much excitement, a growing number of negative results in downstream tasks casts doubt on whether SAEs recover meaningful features. To directly investigate this, we perform two complementary evaluations. On a synthetic setup with known ground-truth features, we demonstrate that SAEs recover only $9\\%$ of true features despite achieving $71\\%$ explained variance, showing that they fail at their core task even when reconstruction is strong. To evaluate SAEs on real activations, we introduce three baselines that constrain SAE feature directions or their activation patterns to random values. Through extensive experiments across multiple SAE architectures, we show that our baselines match fully-trained SAEs in interpretability (0.87 vs 0.90), sparse probing (0.69 vs 0.72), and causal editing (0.73 vs 0.72). Together, these results suggest that SAEs in their current state do not reliably decompose models' internal mechanisms.",
    "authors": [
      "Anton Korznikov",
      "Andrey Galichin",
      "Alexey Dontsov",
      "Oleg Rogov",
      "Ivan Oseledets",
      "Elena Tutubalina"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14111v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14111v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.14040v1",
    "title": "Explainability-Inspired Layer-Wise Pruning of Deep Neural Networks for Efficient Object Detection",
    "summary": "Deep neural networks (DNNs) have achieved remarkable success in object detection tasks, but their increasing complexity poses significant challenges for deployment on resource-constrained platforms. While model compression techniques such as pruning have emerged as essential tools, traditional magnitude-based pruning methods do not necessarily align with the true functional contribution of network components to task-specific performance. In this work, we present an explainability-inspired, layer-wise pruning framework tailored for efficient object detection. Our approach leverages a SHAP-inspired gradient--activation attribution to estimate layer importance, providing a data-driven proxy for functional contribution rather than relying solely on static weight magnitudes. We conduct comprehensive experiments across diverse object detection architectures, including ResNet-50, MobileNetV2, ShuffleNetV2, Faster R-CNN, RetinaNet, and YOLOv8, evaluating performance on the Microsoft COCO 2017 validation set. The results show that the proposed attribution-inspired pruning consistently identifies different layers as least important compared to L1-norm-based methods, leading to improved accuracy--efficiency trade-offs. Notably, for ShuffleNetV2, our method yields a 10\\% empirical increase in inference speed, whereas L1-pruning degrades performance by 13.7\\%. For RetinaNet, the proposed approach preserves the baseline mAP (0.151) with negligible impact on inference speed, while L1-pruning incurs a 1.3\\% mAP drop for a 6.2\\% speed increase. These findings highlight the importance of data-driven layer importance assessment and demonstrate that explainability-inspired compression offers a principled direction for deploying deep neural networks on edge and resource-constrained platforms while preserving both performance and interpretability.",
    "authors": [
      "Abhinav Shukla",
      "Nachiket Tapas"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14040v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14040v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.14002v1",
    "title": "The Sufficiency-Conciseness Trade-off in LLM Self-Explanation from an Information Bottleneck Perspective",
    "summary": "Large Language Models increasingly rely on self-explanations, such as chain of thought reasoning, to improve performance on multi step question answering. While these explanations enhance accuracy, they are often verbose and costly to generate, raising the question of how much explanation is truly necessary. In this paper, we examine the trade-off between sufficiency, defined as the ability of an explanation to justify the correct answer, and conciseness, defined as the reduction in explanation length. Building on the information bottleneck principle, we conceptualize explanations as compressed representations that retain only the information essential for producing correct answers.To operationalize this view, we introduce an evaluation pipeline that constrains explanation length and assesses sufficiency using multiple language models on the ARC Challenge dataset. To broaden the scope, we conduct experiments in both English, using the original dataset, and Persian, as a resource-limited language through translation. Our experiments show that more concise explanations often remain sufficient, preserving accuracy while substantially reducing explanation length, whereas excessive compression leads to performance degradation.",
    "authors": [
      "Ali Zahedzadeh",
      "Behnam Bahrak"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14002v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14002v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.13994v1",
    "title": "Inject Where It Matters: Training-Free Spatially-Adaptive Identity Preservation for Text-to-Image Personalization",
    "summary": "Personalized text-to-image generation aims to integrate specific identities into arbitrary contexts. However, existing tuning-free methods typically employ Spatially Uniform Visual Injection, causing identity features to contaminate non-facial regions (e.g., backgrounds and lighting) and degrading text adherence. To address this without expensive fine-tuning, we propose SpatialID, a training-free spatially-adaptive identity modulation framework. SpatialID fundamentally decouples identity injection into face-relevant and context-free regions using a Spatial Mask Extractor derived from cross-attention responses. Furthermore, we introduce a Temporal-Spatial Scheduling strategy that dynamically adjusts spatial constraints - transitioning from Gaussian priors to attention-based masks and adaptive relaxation - to align with the diffusion generation dynamics. Extensive experiments on IBench demonstrate that SpatialID achieves state-of-the-art performance in text adherence (CLIP-T: 0.281), visual consistency (CLIP-I: 0.827), and image quality (IQ: 0.523), significantly eliminating background contamination while maintaining robust identity preservation.",
    "authors": [
      "Guandong Li",
      "Mengxia Ye"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13994v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13994v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.14044v1",
    "title": "Context Shapes LLMs Retrieval-Augmented Fact-Checking Effectiveness",
    "summary": "Large language models (LLMs) show strong reasoning abilities across diverse tasks, yet their performance on extended contexts remains inconsistent. While prior research has emphasized mid-context degradation in question answering, this study examines the impact of context in LLM-based fact verification. Using three datasets (HOVER, FEVEROUS, and ClimateFEVER) and five open-source models accross different parameters sizes (7B, 32B and 70B parameters) and model families (Llama-3.1, Qwen2.5 and Qwen3), we evaluate both parametric factual knowledge and the impact of evidence placement across varying context lengths. We find that LLMs exhibit non-trivial parametric knowledge of factual claims and that their verification accuracy generally declines as context length increases. Similarly to what has been shown in previous works, in-context evidence placement plays a critical role with accuracy being consistently higher when relevant evidence appears near the beginning or end of the prompt and lower when placed mid-context. These results underscore the importance of prompt structure in retrieval-augmented fact-checking systems.",
    "authors": [
      "Pietro Bernardelle",
      "Stefano Civelli",
      "Kevin Roitero",
      "Gianluca Demartini"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14044v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14044v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.14068v1",
    "title": "CoCoEdit: Content-Consistent Image Editing via Region Regularized Reinforcement Learning",
    "summary": "Image editing has achieved impressive results with the development of large-scale generative models. However, existing models mainly focus on the editing effects of intended objects and regions, often leading to unwanted changes in unintended regions. We present a post-training framework for Content-Consistent Editing (CoCoEdit) via region regularized reinforcement learning. We first augment existing editing datasets with refined instructions and masks, from which 40K diverse and high quality samples are curated as training set. We then introduce a pixel-level similarity reward to complement MLLM-based rewards, enabling models to ensure both editing quality and content consistency during the editing process. To overcome the spatial-agnostic nature of the rewards, we propose a region-based regularizer, aiming to preserve non-edited regions for high-reward samples while encouraging editing effects for low-reward samples. For evaluation, we annotate editing masks for GEdit-Bench and ImgEdit-Bench, introducing pixel-level similarity metrics to measure content consistency and editing quality. Applying CoCoEdit to Qwen-Image-Edit and FLUX-Kontext, we achieve not only competitive editing scores with state-of-the-art models, but also significantly better content consistency, measured by PSNR/SSIM metrics and human subjective ratings.",
    "authors": [
      "Yuhui Wu",
      "Chenxi Xie",
      "Ruibin Li",
      "Liyi Chen",
      "Qiaosi Yi",
      "Lei Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14068v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14068v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.14029v1",
    "title": "Why Self-Training Helps and Hurts: Denoising vs. Signal Forgetting",
    "summary": "Iterative self-training (self-distillation) repeatedly refits a model on pseudo-labels generated by its own predictions. We study this procedure in overparameterized linear regression: an initial estimator is trained on noisy labels, and each subsequent iterate is trained on fresh covariates with noiseless pseudo-labels from the previous model. In the high-dimensional regime, we derive deterministic-equivalent recursions for the prediction risk and effective noise across iterations, and prove that the empirical quantities concentrate sharply around these limits. The recursion separates two competing forces: a systematic component that grows with iteration due to progressive signal forgetting, and a stochastic component that decays due to denoising via repeated data-dependent projections. Their interaction yields a $U$-shaped test-risk curve and an optimal early-stopping time. In spiked covariance models, iteration further acts as an iteration-dependent spectral filter that preserves strong eigendirections while suppressing weaker ones, inducing an implicit form of soft feature selection distinct from ridge regression. Finally, we propose an iterated generalized cross-validation criterion and prove its uniform consistency for estimating the risk along the self-training trajectory, enabling fully data-driven selection of the stopping time and regularization. Experiments on synthetic covariances validate the theory and illustrate the predicted denoising-forgetting trade-off.",
    "authors": [
      "Mingqi Wu",
      "Archer Y. Yang",
      "Qiang Sun"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14029v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14029v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.13944v1",
    "title": "Fusing Pixels and Genes: Spatially-Aware Learning in Computational Pathology",
    "summary": "Recent years have witnessed remarkable progress in multimodal learning within computational pathology. Existing models primarily rely on vision and language modalities; however, language alone lacks molecular specificity and offers limited pathological supervision, leading to representational bottlenecks. In this paper, we propose STAMP, a Spatial Transcriptomics-Augmented Multimodal Pathology representation learning framework that integrates spatially-resolved gene expression profiles to enable molecule-guided joint embedding of pathology images and transcriptomic data. Our study shows that self-supervised, gene-guided training provides a robust and task-agnostic signal for learning pathology image representations. Incorporating spatial context and multi-scale information further enhances model performance and generalizability. To support this, we constructed SpaVis-6M, the largest Visium-based spatial transcriptomics dataset to date, and trained a spatially-aware gene encoder on this resource. Leveraging hierarchical multi-scale contrastive alignment and cross-scale patch localization mechanisms, STAMP effectively aligns spatial transcriptomics with pathology images, capturing spatial structure and molecular variation. We validate STAMP across six datasets and four downstream tasks, where it consistently achieves strong performance. These results highlight the value and necessity of integrating spatially resolved molecular supervision for advancing multimodal learning in computational pathology. The code is included in the supplementary materials. The pretrained weights and SpaVis-6M are available at: https://github.com/Hanminghao/STAMP.",
    "authors": [
      "Minghao Han",
      "Dingkang Yang",
      "Linhao Qu",
      "Zizhi Chen",
      "Gang Li",
      "Han Wang",
      "Jiacong Wang",
      "Lihua Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13944v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13944v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.13934v1",
    "title": "Why Code, Why Now: Learnability, Computability, and the Real Limits of Machine Learning",
    "summary": "Code generation has progressed more reliably than reinforcement learning, largely because code has an information structure that makes it learnable. Code provides dense, local, verifiable feedback at every token, whereas most reinforcement learning problems do not. This difference in feedback quality is not binary but graded. We propose a five-level hierarchy of learnability based on information structure and argue that the ceiling on ML progress depends less on model size than on whether a task is learnable at all. The hierarchy rests on a formal distinction among three properties of computational problems (expressibility, computability, and learnability). We establish their pairwise relationships, including where implications hold and where they fail, and present a unified template that makes the structural differences explicit. The analysis suggests why supervised learning on code scales predictably while reinforcement learning does not, and why the common assumption that scaling alone will solve remaining ML challenges warrants scrutiny.",
    "authors": [
      "Zhimin Zhao"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13934v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13934v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.14062v1",
    "title": "From Scarcity to Scale: A Release-Level Analysis of the Pashto Common Voice Dataset",
    "summary": "Large, openly licensed speech datasets are essential for building automatic speech recognition (ASR) systems, yet many widely spoken languages remain underrepresented in public resources. Pashto, spoken by more than 60 million people, has historically lacked large-scale openly licensed speech data suitable for modern ASR development.   This paper presents a release-level analysis of the Pashto component of the Mozilla Common Voice corpus, focusing on version 24.0 (December 2025) and contextualizing trends across major releases. We document rapid growth from 1.49 recorded hours in mid-2023 to 2,768.7 total hours in 2025, including 975.89 validated hours available for supervised ASR training.   Beyond scale, we analyze validation throughput, contributor participation inequality, demographic metadata completeness, and sentence-level concentration in the validated subset. We find that participation is extremely concentrated (Gini = 0.941), age representation is strongly skewed toward young adults, and 41.97\\% of clips lack self-reported gender labels, limiting subgroup auditing based on metadata. At the textual level, prompt reuse is moderate: 35.88\\% of unique sentences account for 50\\% of validated clips, suggesting that structural concentration is driven primarily by uneven contributor activity rather than dominance of a small prompt set.   These results provide a quantitative audit of a rapidly scaling low-resource speech corpus and highlight practical priorities for improving dataset maturity, including expanded validation capacity and broader demographic participation.",
    "authors": [
      "Jandad Jahani",
      "Mursal Dawodi",
      "Jawid Ahmad Baktash"
    ],
    "categories": [
      "cs.CL",
      "cs.SD"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14062v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14062v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2602.14020v1",
    "title": "Computable Bernstein Certificates for Cross-Fitted Clipped Covariance Estimation",
    "summary": "We study operator-norm covariance estimation from heavy-tailed samples that may include a small fraction of arbitrary outliers. A simple and widely used safeguard is \\emph{Euclidean norm clipping}, but its accuracy depends critically on an unknown clipping level. We propose a cross-fitted clipped covariance estimator equipped with \\emph{fully computable} Bernstein-type deviation certificates, enabling principled data-driven tuning via a selector (\\emph{MinUpper}) that balances certified stochastic error and a robust hold-out proxy for clipping bias. The resulting procedure adapts to intrinsic complexity measures such as effective rank under mild tail regularity and retains meaningful guarantees under only finite fourth moments. Experiments on contaminated spiked-covariance benchmarks illustrate stable performance and competitive accuracy across regimes.",
    "authors": [
      "Even He",
      "Zaizai Yan"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14020v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14020v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2602.13993v1",
    "title": "Elastic Diffusion Transformer",
    "summary": "Diffusion Transformers (DiT) have demonstrated remarkable generative capabilities but remain highly computationally expensive. Previous acceleration methods, such as pruning and distillation, typically rely on a fixed computational capacity, leading to insufficient acceleration and degraded generation quality. To address this limitation, we propose \\textbf{Elastic Diffusion Transformer (E-DiT)}, an adaptive acceleration framework for DiT that effectively improves efficiency while maintaining generation quality. Specifically, we observe that the generative process of DiT exhibits substantial sparsity (i.e., some computations can be skipped with minimal impact on quality), and this sparsity varies significantly across samples. Motivated by this observation, E-DiT equips each DiT block with a lightweight router that dynamically identifies sample-dependent sparsity from the input latent. Each router adaptively determines whether the corresponding block can be skipped. If the block is not skipped, the router then predicts the optimal MLP width reduction ratio within the block. During inference, we further introduce a block-level feature caching mechanism that leverages router predictions to eliminate redundant computations in a training-free manner. Extensive experiments across 2D image (Qwen-Image and FLUX) and 3D asset (Hunyuan3D-3.0) demonstrate the effectiveness of E-DiT, achieving up to $\\sim$2$\\times$ speedup with negligible loss in generation quality. Code will be available at https://github.com/wangjiangshan0725/Elastic-DiT.",
    "authors": [
      "Jiangshan Wang",
      "Zeqiang Lai",
      "Jiarui Chen",
      "Jiayi Guo",
      "Hang Guo",
      "Xiu Li",
      "Xiangyu Yue",
      "Chunchao Guo"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.13993v1",
    "pdf_url": "https://arxiv.org/pdf/2602.13993v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2602.14153v1",
    "title": "ARport: An Augmented Reality System for Markerless Image-Guided Port Placement in Robotic Surgery",
    "summary": "Purpose: Precise port placement is a critical step in robot-assisted surgery, where port configuration influences both visual access to the operative field and instrument maneuverability. To bridge the gap between preoperative planning and intraoperative execution, we present ARport, an augmented reality (AR) system that automatically maps pre-planned trocar layouts onto the patient's body surface, providing intuitive spatial guidance during surgical preparation. Methods: ARport, implemented on an optical see-through head-mounted display (OST-HMD), operates without any external sensors or markers, simplifying setup and enhancing workflow integration. It reconstructs the operative scene from RGB, depth, and pose data captured by the OST-HMD, extracts the patient's body surface using a foundation model, and performs surface-based markerless registration to align preoperative anatomical models to the extracted patient's body surface, enabling in-situ visualization of planned trocar layouts. A demonstration video illustrating the overall workflow is available online. Results: In full-scale human-phantom experiments, ARport accurately overlaid pre-planned trocar sites onto the physical phantom, achieving consistent spatial correspondence between virtual plans and real anatomy. Conclusion: ARport provides a fully marker-free and hardware-minimal solution for visualizing preoperative trocar plans directly on the patient's body surface. The system facilitates efficient intraoperative setup and demonstrates potential for seamless integration into routine clinical workflows.",
    "authors": [
      "Zheng Han",
      "Zixin Yang",
      "Yonghao Long",
      "Lin Zhang",
      "Peter Kazanzides",
      "Qi Dou"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14153v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14153v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2602.14048v1",
    "title": "ProAct: A Dual-System Framework for Proactive Embodied Social Agents",
    "summary": "Embodied social agents have recently advanced in generating synchronized speech and gestures. However, most interactive systems remain fundamentally reactive, responding only to current sensory inputs within a short temporal window. Proactive social behavior, in contrast, requires deliberation over accumulated context and intent inference, which conflicts with the strict latency budget of real-time interaction. We present \\emph{ProAct}, a dual-system framework that reconciles this time-scale conflict by decoupling a low-latency \\emph{Behavioral System} for streaming multimodal interaction from a slower \\emph{Cognitive System} which performs long-horizon social reasoning and produces high-level proactive intentions. To translate deliberative intentions into continuous non-verbal behaviors without disrupting fluency, we introduce a streaming flow-matching model conditioned on intentions via ControlNet. This mechanism supports asynchronous intention injection, enabling seamless transitions between reactive and proactive gestures within a single motion stream. We deploy ProAct on a physical humanoid robot and evaluate both motion quality and interactive effectiveness. In real-world interaction user studies, participants and observers consistently prefer ProAct over reactive variants in perceived proactivity, social presence, and overall engagement, demonstrating the benefits of dual-system proactive control for embodied social interaction.",
    "authors": [
      "Zeyi Zhang",
      "Zixi Kang",
      "Ruijie Zhao",
      "Yusen Feng",
      "Biao Jiang",
      "Libin Liu"
    ],
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.GR"
    ],
    "published": "2026-02-15",
    "url": "https://arxiv.org/abs/2602.14048v1",
    "pdf_url": "https://arxiv.org/pdf/2602.14048v1.pdf",
    "date": "2026-02-17",
    "source": "arxiv",
    "research_score": 0.46
  }
]