[
  {
    "arxiv_id": "2602.11683v1",
    "title": "ThinkRouter: Efficient Reasoning via Routing Thinking between Latent and Discrete Spaces",
    "summary": "Recent work explores latent reasoning to improve reasoning efficiency by replacing explicit reasoning trajectories with continuous representations in a latent space, yet its effectiveness varies across settings. Analysis of model confidence dynamics under latent reasoning reveals that thinking trajectories ending in incorrect answers contain fewer low-confidence steps than those ending in correct answers. Meanwhile, we suggest that soft embeddings aggregated by multiple low-confidence thinking alternatives may introduce and propagate noise, leading to high confidence in unreliable reasoning trajectories. Motivated by these observations, ThinkRouter, an inference-time confidence-aware routing mechanism is proposed to avoid high confidence and noise for efficient reasoning. ThinkRouter routes thinking to the discrete token space when model confidence is low, and to the latent space otherwise. Extensive experiments on STEM reasoning and coding benchmarks across diverse large reasoning models demonstrate that ThinkRouter outperforms explicit CoT, random routing, and latent reasoning baselines in terms of accuracy, achieving an average improvement of 19.70 points in Pass@1, while reducing generation length by up to 15.55%. Further comprehensive analysis reveals that ThinkRouter can calibrate errors arising from explicit CoT and latent reasoning, and accelerates end-of-thinking token generation by globally lowering model confidence.",
    "authors": [
      "Xin Xu",
      "Tong Yu",
      "Xiang Chen",
      "Haoliang Wang",
      "Julian McAuley",
      "Saayan Mitra"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11683v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11683v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.88
  },
  {
    "arxiv_id": "2602.12018v1",
    "title": "Artificial intelligence is creating a new global linguistic hierarchy",
    "summary": "Artificial intelligence (AI) has the potential to transform healthcare, education, governance and socioeconomic equity, but its benefits remain concentrated in a small number of languages (Bender, 2019; Blasi et al., 2022; Joshi et al., 2020; Ranathunga and de Silva, 2022; Young, 2015). Language AI - the technologies that underpin widely-used conversational systems such as ChatGPT - could provide major benefits if available in people's native languages, yet most of the world's 7,000+ linguistic communities currently lack access and face persistent digital marginalization. Here we present a global longitudinal analysis of social, economic and infrastructural conditions across languages to assess systemic inequalities in language AI. We first analyze the existence of AI resources for 6003 languages. We find that despite efforts of the community to broaden the reach of language technologies (Bapna et al., 2022; Costa-Jussà et al., 2022), the dominance of a handful of languages is exacerbating disparities on an unprecedented scale, with divides widening exponentially rather than narrowing. Further, we contrast the longitudinal diffusion of AI with that of earlier IT technologies, revealing a distinctive hype-driven pattern of spread. To translate our findings into practical insights and guide prioritization efforts, we introduce the Language AI Readiness Index (EQUATE), which maps the state of technological, socio-economic, and infrastructural prerequisites for AI deployment across languages. The index highlights communities where capacity exists but remains underutilized, and provides a framework for accelerating more equitable diffusion of language AI. Our work contributes to setting the baseline for a transition towards more sustainable and equitable language technologies.",
    "authors": [
      "Giulia Occhini",
      "Kumiko Tanaka-Ishii",
      "Anna Barford",
      "Refael Tikochinski",
      "Songbo Hu",
      "Roi Reichart",
      "Yijie Zhou",
      "Hannah Claus",
      "Ulla Petti",
      "Ivan Vulić",
      "Ramit Debnath",
      "Anna Korhonen"
    ],
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12018v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12018v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.85
  },
  {
    "arxiv_id": "2602.11754v1",
    "title": "Cooperation Breakdown in LLM Agents Under Communication Delays",
    "summary": "LLM-based multi-agent systems (LLM-MAS), in which autonomous AI agents cooperate to solve tasks, are gaining increasing attention. For such systems to be deployed in society, agents must be able to establish cooperation and coordination under real-world computational and communication constraints. We propose the FLCOA framework (Five Layers for Cooperation/Coordination among Autonomous Agents) to conceptualize how cooperation and coordination emerge in groups of autonomous agents, and highlight that the influence of lower-layer factors - especially computational and communication resources - has been largely overlooked. To examine the effect of communication delay, we introduce a Continuous Prisoner's Dilemma with Communication Delay and conduct simulations with LLM-based agents. As delay increases, agents begin to exploit slower responses even without explicit instructions. Interestingly, excessive delay reduces cycles of exploitation, yielding a U-shaped relationship between delay magnitude and mutual cooperation. These results suggest that fostering cooperation requires attention not only to high-level institutional design but also to lower-layer factors such as communication delay and resource allocation, pointing to new directions for MAS research.",
    "authors": [
      "Keita Nishimoto",
      "Kimitaka Asatani",
      "Ichiro Sakata"
    ],
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11754v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11754v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2602.11656v1",
    "title": "SToRM: Supervised Token Reduction for Multi-modal LLMs toward efficient end-to-end autonomous driving",
    "summary": "In autonomous driving, end-to-end (E2E) driving systems that predict control commands directly from sensor data have achieved significant advancements. For safe driving in unexpected scenarios, these systems may additionally rely on human interventions such as natural language instructions. Using a multi-modal large language model (MLLM) facilitates human-vehicle interaction and can improve performance in such scenarios. However, this approach requires substantial computational resources due to its reliance on an LLM and numerous visual tokens from sensor inputs, which are limited in autonomous vehicles. Many MLLM studies have explored reducing visual tokens, but often suffer end-task performance degradation compared to using all tokens.   To enable efficient E2E driving while maintaining performance comparable to using all tokens, this paper proposes the first Supervised Token Reduction framework for multi-modal LLMs (SToRM). The proposed framework consists of three key elements. First, a lightweight importance predictor with short-term sliding windows estimates token importance scores. Second, a supervised training approach uses an auxiliary path to obtain pseudo-supervision signals from an all-token LLM pass. Third, an anchor-context merging module partitions tokens into anchors and context tokens, and merges context tokens into relevant anchors to reduce redundancy while minimizing information loss. Experiments on the LangAuto benchmark show that SToRM outperforms state-of-the-art E2E driving MLLMs under the same reduced-token budget, maintaining all-token performance while reducing computational cost by up to 30x.",
    "authors": [
      "Seo Hyun Kim",
      "Jin Bok Park",
      "Do Yeon Koo",
      "Ho Gun Park",
      "Il Yong Chun"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11656v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11656v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.79
  },
  {
    "arxiv_id": "2602.12055v1",
    "title": "Multi UAVs Preflight Planning in a Shared and Dynamic Airspace",
    "summary": "Preflight planning for large-scale Unmanned Aerial Vehicle (UAV) fleets in dynamic, shared airspace presents significant challenges, including temporal No-Fly Zones (NFZs), heterogeneous vehicle profiles, and strict delivery deadlines. While Multi-Agent Path Finding (MAPF) provides a formal framework, existing methods often lack the scalability and flexibility required for real-world Unmanned Traffic Management (UTM). We propose DTAPP-IICR: a Delivery-Time Aware Prioritized Planning method with Incremental and Iterative Conflict Resolution. Our framework first generates an initial solution by prioritizing missions based on urgency. Secondly, it computes roundtrip trajectories using SFIPP-ST, a novel 4D single-agent planner (Safe Flight Interval Path Planning with Soft and Temporal Constraints). SFIPP-ST handles heterogeneous UAVs, strictly enforces temporal NFZs, and models inter-agent conflicts as soft constraints. Subsequently, an iterative Large Neighborhood Search, guided by a geometric conflict graph, efficiently resolves any residual conflicts. A completeness-preserving directional pruning technique further accelerates the 3D search. On benchmarks with temporal NFZs, DTAPP-IICR achieves near-100% success with fleets of up to 1,000 UAVs and gains up to 50% runtime reduction from pruning, outperforming batch Enhanced Conflict-Based Search in the UTM context. Scaling successfully in realistic city-scale operations where other priority-based methods fail even at moderate deployments, DTAPP-IICR is positioned as a practical and scalable solution for preflight planning in dense, dynamic urban airspace.",
    "authors": [
      "Amath Sow",
      "Mauricio Rodriguez Cesen",
      "Fabiola Martins Campos de Oliveira",
      "Mariusz Wzorek",
      "Daniel de Leng",
      "Mattias Tiger",
      "Fredrik Heintz",
      "Christian Esteve Rothenberg"
    ],
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.RO"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12055v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12055v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2602.11636v1",
    "title": "ScalSelect: Scalable Training-Free Multimodal Data Selection for Efficient Visual Instruction Tuning",
    "summary": "Large-scale Visual Instruction Tuning (VIT) has become a key paradigm for advancing the performance of vision-language models (VLMs) across various multimodal tasks. However, training on the large-scale datasets is computationally expensive and inefficient due to redundancy in the data, which motivates the need for multimodal data selection to improve training efficiency. Existing data selection methods for VIT either require costly training or gradient computation. Training-free alternatives often depend on proxy models or datasets, instruction-agnostic representations, and pairwise similarity with quadratic complexity, limiting scalability and representation fidelity. In this work, we propose ScalSelect, a scalable training-free multimodal data selection method with linear-time complexity with respect to the number of samples, eliminating the need for external models or auxiliary datasets. ScalSelect first constructs sample representations by extracting visual features most attended by instruction tokens in the target VLM, capturing instruction-relevant information. It then identifies samples whose representations best approximate the dominant subspace of the full dataset representations, enabling scalable importance scoring without pairwise comparisons. Extensive experiments across multiple VLMs, datasets, and selection budgets demonstrate that ScalSelect achieves over 97.5% of the performance of training on the full dataset using only 16% of the data, and even outperforms full-data training in some settings. The code is available at \\href{https://github.com/ChangtiWu/ScalSelect}{ScalSelect}.",
    "authors": [
      "Changti Wu",
      "Jiahuai Mao",
      "Yuzhuo Miao",
      "Shijie Lian",
      "Bin Yu",
      "Xiaopeng Lin",
      "Cong Huang",
      "Lei Zhang",
      "Kai Chen"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11636v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11636v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2602.12125v1",
    "title": "Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation",
    "summary": "On-policy distillation (OPD), which aligns the student with the teacher's logit distribution on student-generated trajectories, has demonstrated strong empirical gains in improving student performance and often outperforms off-policy distillation and reinforcement learning (RL) paradigms. In this work, we first theoretically show that OPD is a special case of dense KL-constrained RL where the reward function and the KL regularization are always weighted equally and the reference model can by any model. Then, we propose the Generalized On-Policy Distillation (G-OPD) framework, which extends the standard OPD objective by introducing a flexible reference model and a reward scaling factor that controls the relative weight of the reward term against the KL regularization. Through comprehensive experiments on math reasoning and code generation tasks, we derive two novel insights: (1) Setting the reward scaling factor to be greater than 1 (i.e., reward extrapolation), which we term ExOPD, consistently improves over standard OPD across a range of teacher-student size pairings. In particular, in the setting where we merge the knowledge from different domain experts, obtained by applying domain-specific RL to the same student model, back into the original student, ExOPD enables the student to even surpass the teacher's performance boundary and outperform the domain teachers. (2) Building on ExOPD, we further find that in the strong-to-weak distillation setting (i.e., distilling a smaller student from a larger teacher), performing reward correction by choosing the reference model as the teacher's base model before RL yields a more accurate reward signal and further improves distillation performance. However, this choice assumes access to the teacher's pre-RL variant and incurs more computational overhead. We hope our work offers new insights for future research on OPD.",
    "authors": [
      "Wenkai Yang",
      "Weijie Liu",
      "Ruobing Xie",
      "Kai Yang",
      "Saiyong Yang",
      "Yankai Lin"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12125v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12125v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.77
  },
  {
    "arxiv_id": "2602.11958v1",
    "title": "RAM-Net: Expressive Linear Attention with Selectively Addressable Memory",
    "summary": "While linear attention architectures offer efficient inference, compressing unbounded history into a fixed-size memory inherently limits expressivity and causes information loss. To address this limitation, we introduce Random Access Memory Network (RAM-Net), a novel architecture designed to bridge the gap between the representational capacity of full attention and the memory efficiency of linear models. The core of RAM-Net maps inputs to high-dimensional sparse vectors serving as explicit addresses, allowing the model to selectively access a massive memory state. This design enables exponential state size scaling without additional parameters, which significantly mitigates signal interference and enhances retrieval fidelity. Moreover, the inherent sparsity ensures exceptional computational efficiency, as state updates are confined to minimal entries. Extensive experiments demonstrate that RAM-Net consistently surpasses state-of-the-art baselines in fine-grained long-range retrieval tasks and achieves competitive performance in standard language modeling and zero-shot commonsense reasoning benchmarks, validating its superior capability to capture complex dependencies with significantly reduced computational overhead.",
    "authors": [
      "Kaicheng Xiao",
      "Haotian Li",
      "Liran Dong",
      "Guoliang Xing"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11958v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11958v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.77
  },
  {
    "arxiv_id": "2602.11812v1",
    "title": "Predicting LLM Output Length via Entropy-Guided Representations",
    "summary": "The long-tailed distribution of sequence lengths in LLM serving and reinforcement learning (RL) sampling causes significant computational waste due to excessive padding in batched inference. Existing methods rely on auxiliary models for static length prediction, but they incur high overhead, generalize poorly, and fail in stochastic \"one-to-many\" sampling scenarios. We introduce a lightweight framework that reuses the main model's internal hidden states for efficient length prediction. Our framework features two core components: 1) Entropy-Guided Token Pooling (EGTP), which uses on-the-fly activations and token entropy for highly accurate static prediction with negligible cost, and 2) Progressive Length Prediction (PLP), which dynamically estimates the remaining length at each decoding step to handle stochastic generation. To validate our approach, we build and release ForeLen, a comprehensive benchmark with long-sequence, Chain-of-Thought, and RL data. On ForeLen, EGTP achieves state-of-the-art accuracy, reducing MAE by 29.16\\% over the best baseline. Integrating our methods with a length-aware scheduler yields significant end-to-end throughput gains. Our work provides a new technical and evaluation baseline for efficient LLM inference.",
    "authors": [
      "Huanyi Xie",
      "Yubin Chen",
      "Liangyu Wang",
      "Lijie Hu",
      "Di Wang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11812v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11812v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2602.11693v1",
    "title": "OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars",
    "summary": "Creating high-fidelity, animatable 3D avatars from a single image remains a formidable challenge. We identified three desirable attributes of avatar generation: 1) the method should be feed-forward, 2) model a 360° full-head, and 3) should be animation-ready. However, current work addresses only two of the three points simultaneously. To address these limitations, we propose OMEGA-Avatar, the first feed-forward framework that simultaneously generates a generalizable, 360°-complete, and animatable 3D Gaussian head from a single image. Starting from a feed-forward and animatable framework, we address the 360° full-head avatar generation problem with two novel components. First, to overcome poor hair modeling in full-head avatar generation, we introduce a semantic-aware mesh deformation module that integrates multi-view normals to optimize a FLAME head with hair while preserving its topology structure. Second, to enable effective feed-forward decoding of full-head features, we propose a multi-view feature splatting module that constructs a shared canonical UV representation from features across multiple views through differentiable bilinear splatting, hierarchical UV mapping, and visibility-aware fusion. This approach preserves both global structural coherence and local high-frequency details across all viewpoints, ensuring 360° consistency without per-instance optimization. Extensive experiments demonstrate that OMEGA-Avatar achieves state-of-the-art performance, significantly outperforming existing baselines in 360° full-head completeness while robustly preserving identity across different viewpoints.",
    "authors": [
      "Zehao Xia",
      "Yiqun Wang",
      "Zhengda Lu",
      "Kai Liu",
      "Jun Xiao",
      "Peter Wonka"
    ],
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11693v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11693v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2602.12107v1",
    "title": "On the Complexity of Offline Reinforcement Learning with $Q^\\star$-Approximation and Partial Coverage",
    "summary": "We study offline reinforcement learning under $Q^\\star$-approximation and partial coverage, a setting that motivates practical algorithms such as Conservative $Q$-Learning (CQL; Kumar et al., 2020) but has received limited theoretical attention. Our work is inspired by the following open question: \"Are $Q^\\star$-realizability and Bellman completeness sufficient for sample-efficient offline RL under partial coverage?\"   We answer in the negative by establishing an information-theoretic lower bound. Going substantially beyond this, we introduce a general framework that characterizes the intrinsic complexity of a given $Q^\\star$ function class, inspired by model-free decision-estimation coefficients (DEC) for online RL (Foster et al., 2023b; Liu et al., 2025b). This complexity recovers and improves the quantities underlying the guarantees of Chen and Jiang (2022) and Uehara et al. (2023), and extends to broader settings. Our decision-estimation decomposition can be combined with a wide range of $Q^\\star$ estimation procedures, modularizing and generalizing existing approaches.   Beyond the general framework, we make further contributions: By developing a novel second-order performance difference lemma, we obtain the first $ε^{-2}$ sample complexity under partial coverage for soft $Q$-learning, improving the $ε^{-4}$ bound of Uehara et al. (2023). We remove Chen and Jiang's (2022) need for additional online interaction when the value gap of $Q^\\star$ is unknown. We also give the first characterization of offline learnability for general low-Bellman-rank MDPs without Bellman completeness (Jiang et al., 2017; Du et al., 2021; Jin et al., 2021), a canonical setting in online RL that remains unexplored in offline RL except for special cases. Finally, we provide the first analysis for CQL under $Q^\\star$-realizability and Bellman completeness beyond the tabular case.",
    "authors": [
      "Haolin Liu",
      "Braham Snyder",
      "Chen-Yu Wei"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12107v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12107v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2602.11940v1",
    "title": "Temporally Unified Adversarial Perturbations for Time Series Forecasting",
    "summary": "While deep learning models have achieved remarkable success in time series forecasting, their vulnerability to adversarial examples remains a critical security concern. However, existing attack methods in the forecasting field typically ignore the temporal consistency inherent in time series data, leading to divergent and contradictory perturbation values for the same timestamp across overlapping samples. This temporally inconsistent perturbations problem renders adversarial attacks impractical for real-world data manipulation. To address this, we introduce Temporally Unified Adversarial Perturbations (TUAPs), which enforce a temporal unification constraint to ensure identical perturbations for each timestamp across all overlapping samples. Moreover, we propose a novel Timestamp-wise Gradient Accumulation Method (TGAM) that provides a modular and efficient approach to effectively generate TUAPs by aggregating local gradient information from overlapping samples. By integrating TGAM with momentum-based attack algorithms, we ensure strict temporal consistency while fully utilizing series-level gradient information to explore the adversarial perturbation space. Comprehensive experiments on three benchmark datasets and four representative state-of-the-art models demonstrate that our proposed method significantly outperforms baselines in both white-box and black-box transfer attack scenarios under TUAP constraints. Moreover, our method also exhibits superior transfer attack performance even without TUAP constraints, demonstrating its effectiveness and superiority in generating adversarial perturbations for time series forecasting models.",
    "authors": [
      "Ruixian Su",
      "Yukun Bao",
      "Xinze Zhang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11940v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11940v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2602.11759v1",
    "title": "TUBO: A Tailored ML Framework for Reliable Network Traffic Forecasting",
    "summary": "Traffic forecasting based network operation optimization and management offers enormous promise but also presents significant challenges from traffic forecasting perspective. While deep learning models have proven to be relatively more effective than traditional statistical methods for time series forecasting, their reliability is not satisfactory due to their inability to effectively handle unique characteristics of network traffic. In particular, the burst and complex traffic patterns makes the existing models less reliable, as each type of deep learning model has limited capability in capturing traffic patterns. To address this issue, we introduce TUBO, a novel machine learning framework custom designed for reliable network traffic forecasting. TUBO features two key components: burst processing for handling significant traffic fluctuations and model selection for adapting to varying traffic patterns using a pool of models. A standout feature of TUBO is its ability to provide deterministic predictions along with quantified uncertainty, which serves as a cue for identifying the most reliable forecasts. Evaluations on three real-world network demand matrix (DM) datasets (Abilene, GEANT, and CERNET) show that TUBO significantly outperforms existing methods on forecasting accuracy (by 4 times), and also achieves up to 94% accuracy in burst occurrence forecasting. Furthermore, we also consider traffic demand forecasting based proactive traffic engineering (TE) as a downstream use case. Our results show that compared to reactive approaches and proactive TE using the best existing DM forecasting methods, proactive TE powered by TUBO improves aggregated throughput by 9 times and 3 times, respectively.",
    "authors": [
      "Zhihang Yuan",
      "Leyang Xue",
      "Waleed Ahsan",
      "Mahesh K. Marina"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11759v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11759v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2602.11717v1",
    "title": "Beyond Parameter Arithmetic: Sparse Complementary Fusion for Distribution-Aware Model Merging",
    "summary": "Model merging has emerged as a promising paradigm for composing the capabilities of large language models by directly operating in weight space, enabling the integration of specialized models without costly retraining. However, existing merging methods largely rely on parameter-space heuristics, which often introduce severe interference, leading to degraded generalization and unstable generation behaviors such as repetition and incoherent outputs. In this work, we propose Sparse Complementary Fusion with reverse KL (SCF-RKL), a novel model merging framework that explicitly controls functional interference through sparse, distribution-aware updates. Instead of assuming linear additivity in parameter space, SCF-RKL measures the functional divergence between models using reverse Kullback-Leibler divergence and selectively incorporates complementary parameters. This mode-seeking, sparsity-inducing design effectively preserves stable representations while integrating new capabilities. We evaluate SCF-RKL across a wide range of model scales and architectures, covering both reasoning-focused and instruction-tuned models. Extensive experiments on 24 benchmarks spanning advanced reasoning, general reasoning and knowledge, instruction following, and safety demonstrate, vision classification that SCF-RKL consistently outperforms existing model merging methods while maintaining strong generalization and generation stability.",
    "authors": [
      "Weihong Lin",
      "Lin Sun",
      "Qilong Shi",
      "Aomufei Yuan",
      "Yuxuan Tian",
      "Zhengyang Wang",
      "Guangxiang Zhao",
      "Xiangzheng Zhang",
      "Tong Yang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11717v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11717v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2602.12092v1",
    "title": "DeepSight: An All-in-One LM Safety Toolkit",
    "summary": "As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) safety workflow, evaluation, diagnosis, and alignment are often handled by separate tools. Specifically, safety evaluation can only locate external behavioral risks but cannot figure out internal root causes. Meanwhile, safety diagnosis often drifts from concrete risk scenarios and remains at the explainable level. In this way, safety alignment lack dedicated explanations of changes in internal mechanisms, potentially degrading general capabilities. To systematically address these issues, we propose an open-source project, namely DeepSight, to practice a new safety evaluation-diagnosis integrated paradigm. DeepSight is low-cost, reproducible, efficient, and highly scalable large-scale model safety evaluation project consisting of a evaluation toolkit DeepSafe and a diagnosis toolkit DeepScan. By unifying task and data protocols, we build a connection between the two stages and transform safety evaluation from black-box to white-box insight. Besides, DeepSight is the first open source toolkit that support the frontier AI risk evaluation and joint safety evaluation and diagnosis.",
    "authors": [
      "Bo Zhang",
      "Jiaxuan Guo",
      "Lijun Li",
      "Dongrui Liu",
      "Sujin Chen",
      "Guanxu Chen",
      "Zhijie Zheng",
      "Qihao Lin",
      "Lewen Yan",
      "Chen Qian",
      "Yijin Zhou",
      "Yuyao Wu",
      "Shaoxiong Guo",
      "Tianyi Du",
      "Jingyi Yang",
      "Xuhao Hu",
      "Ziqi Miao",
      "Xiaoya Lu",
      "Jing Shao",
      "Xia Hu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12092v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12092v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2602.11782v1",
    "title": "FlowMind: Execute-Summarize for Structured Workflow Generation from LLM Reasoning",
    "summary": "LLMs can solve complex tasks through reasoning and tool use, but accurately translating these solutions into structured workflows remains challenging. We model workflows as sequences of tool use and reformulate the problem as designing a mechanism that can both solve tasks and reliably construct workflows. Prior approaches that build workflows during execution often suffer from inaccuracies due to interference between the two processes. We propose an Execute-Summarize(ES) framework that decouples task execution from workflow construction: the model first completes the task using available tools, then independently reconstructs a structured workflow from execution traces. This separation improves workflow accuracy and robustness. We introduce FlowBench and show through extensive experiments that our approach outperforms existing methods, providing a reliable paradigm for grounding free-form LLM reasoning into structured workflows.",
    "authors": [
      "Yihao Liu",
      "Ziyun Zhang",
      "Zile He",
      "Huaqian Cai"
    ],
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11782v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11782v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2602.11738v1",
    "title": "U-Former ODE: Fast Probabilistic Forecasting of Irregular Time Series",
    "summary": "Probabilistic forecasting of irregularly sampled time series is crucial in domains such as healthcare and finance, yet it remains a formidable challenge. Existing Neural Controlled Differential Equation (Neural CDE) approaches, while effective at modelling continuous dynamics, suffer from slow, inherently sequential computation, which restricts scalability and limits access to global context. We introduce UFO (U-Former ODE), a novel architecture that seamlessly integrates the parallelizable, multiscale feature extraction of U-Nets, the powerful global modelling of Transformers, and the continuous-time dynamics of Neural CDEs. By constructing a fully causal, parallelizable model, UFO achieves a global receptive field while retaining strong sensitivity to local temporal dynamics. Extensive experiments on five standard benchmarks -- covering both regularly and irregularly sampled time series -- demonstrate that UFO consistently outperforms ten state-of-the-art neural baselines in predictive accuracy. Moreover, UFO delivers up to 15$\\times$ faster inference compared to conventional Neural CDEs, with consistently strong performance on long and highly multivariate sequences.",
    "authors": [
      "Ilya Kuleshov",
      "Alexander Marusov",
      "Alexey Zaytsev"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11738v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11738v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2602.11729v1",
    "title": "Cross-Architecture Model Diffing with Crosscoders: Unsupervised Discovery of Differences Between LLMs",
    "summary": "Model diffing, the process of comparing models' internal representations to identify their differences, is a promising approach for uncovering safety-critical behaviors in new models. However, its application has so far been primarily focused on comparing a base model with its finetune. Since new LLM releases are often novel architectures, cross-architecture methods are essential to make model diffing widely applicable. Crosscoders are one solution capable of cross-architecture model diffing but have only ever been applied to base vs finetune comparisons. We provide the first application of crosscoders to cross-architecture model diffing and introduce Dedicated Feature Crosscoders (DFCs), an architectural modification designed to better isolate features unique to one model. Using this technique, we find in an unsupervised fashion features including Chinese Communist Party alignment in Qwen3-8B and Deepseek-R1-0528-Qwen3-8B, American exceptionalism in Llama3.1-8B-Instruct, and a copyright refusal mechanism in GPT-OSS-20B. Together, our results work towards establishing cross-architecture crosscoder model diffing as an effective method for identifying meaningful behavioral differences between AI models.",
    "authors": [
      "Thomas Jiralerspong",
      "Trenton Bricken"
    ],
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11729v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11729v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2602.12116v1",
    "title": "P-GenRM: Personalized Generative Reward Model with Test-time User-based Scaling",
    "summary": "Personalized alignment of large language models seeks to adapt responses to individual user preferences, typically via reinforcement learning. A key challenge is obtaining accurate, user-specific reward signals in open-ended scenarios. Existing personalized reward models face two persistent limitations: (1) oversimplifying diverse, scenario-specific preferences into a small, fixed set of evaluation principles, and (2) struggling with generalization to new users with limited feedback. To this end, we propose P-GenRM, the first Personalized Generative Reward Model with test-time user-based scaling. P-GenRM transforms preference signals into structured evaluation chains that derive adaptive personas and scoring rubrics across various scenarios. It further clusters users into User Prototypes and introduces a dual-granularity scaling mechanism: at the individual level, it adaptively scales and aggregates each user's scoring scheme; at the prototype level, it incorporates preferences from similar users. This design mitigates noise in inferred preferences and enhances generalization to unseen users through prototype-based transfer. Empirical results show that P-GenRM achieves state-of-the-art results on widely-used personalized reward model benchmarks, with an average improvement of 2.31%, and demonstrates strong generalization on an out-of-distribution dataset. Notably, Test-time User-based scaling provides an additional 3% boost, demonstrating stronger personalized alignment with test-time scalability.",
    "authors": [
      "Pinyi Zhang",
      "Ting-En Lin",
      "Yuchuan Wu",
      "Jingyang Chen",
      "Zongqi Wang",
      "Hua Yang",
      "Ze Xu",
      "Fei Huang",
      "Kai Zhang",
      "Yongbin Li"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12116v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12116v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2602.11851v1",
    "title": "Resource-Aware Deployment Optimization for Collaborative Intrusion Detection in Layered Networks",
    "summary": "Collaborative Intrusion Detection Systems (CIDS) are increasingly adopted to counter cyberattacks, as their collaborative nature enables them to adapt to diverse scenarios across heterogeneous environments. As distributed critical infrastructure operates in rapidly evolving environments, such as drones in both civil and military domains, there is a growing need for CIDS architectures that can flexibly accommodate these dynamic changes. In this study, we propose a novel CIDS framework designed for easy deployment across diverse distributed environments. The framework dynamically optimizes detector allocation per node based on available resources and data types, enabling rapid adaptation to new operational scenarios with minimal computational overhead. We first conducted a comprehensive literature review to identify key characteristics of existing CIDS architectures. Based on these insights and real-world use cases, we developed our CIDS framework, which we evaluated using several distributed datasets that feature different attack chains and network topologies. Notably, we introduce a public dataset based on a realistic cyberattack targeting a ground drone aimed at sabotaging critical infrastructure. Experimental results demonstrate that the proposed CIDS framework can achieve adaptive, efficient intrusion detection in distributed settings, automatically reconfiguring detectors to maintain an optimal configuration, without requiring heavy computation, since all experiments were conducted on edge devices.",
    "authors": [
      "André García Gómez",
      "Ines Rieger",
      "Wolfgang Hotwagner",
      "Max Landauer",
      "Markus Wurzenberger",
      "Florian Skopik",
      "Edgar Weippl"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11851v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11851v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2602.11961v1",
    "title": "Scaling Model and Data for Multilingual Machine Translation with Open Large Language Models",
    "summary": "Open large language models (LLMs) have demonstrated improving multilingual capabilities in recent years. In this paper, we present a study of open LLMs for multilingual machine translation (MT) across a range of languages, and investigate the effects of model scaling and data scaling when adapting open LLMs to multilingual MT through continual pretraining and instruction finetuning. Based on the Gemma3 model family, we develop MiLMMT-46, which achieves top-tier multilingual translation performance across 46 languages. Extensive experiments show that MiLMMT-46 consistently outperforms recent state-of-the-art (SOTA) models, including Seed-X, HY-MT-1.5, and TranslateGemma, and achieves competitive performance with strong proprietary systems such as Google Translate and Gemini 3 Pro.",
    "authors": [
      "Yuzhe Shang",
      "Pengzhi Gao",
      "Wei Liu",
      "Jian Luan",
      "Jinsong Su"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11961v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11961v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2602.11686v1",
    "title": "LAER-MoE: Load-Adaptive Expert Re-layout for Efficient Mixture-of-Experts Training",
    "summary": "Expert parallelism is vital for effectively training Mixture-of-Experts (MoE) models, enabling different devices to host distinct experts, with each device processing different input data. However, during expert parallel training, dynamic routing results in significant load imbalance among experts: a handful of overloaded experts hinder overall iteration, emerging as a training bottleneck.   In this paper, we introduce LAER-MoE, an efficient MoE training framework. The core of LAER-MoE is a novel parallel paradigm, Fully Sharded Expert Parallel (FSEP), which fully partitions each expert parameter by the number of devices and restores partial experts at expert granularity through All-to-All communication during training. This allows for flexible re-layout of expert parameters during training to enhance load balancing. In particular, we perform fine-grained scheduling of communication operations to minimize communication overhead. Additionally, we develop a load balancing planner to formulate re-layout strategies of experts and routing schemes for tokens during training. We perform experiments on an A100 cluster, and the results indicate that our system achieves up to 1.69x acceleration compared to the current state-of-the-art training systems. Source code available at https://github.com/PKU-DAIR/Hetu-Galvatron/tree/laer-moe.",
    "authors": [
      "Xinyi Liu",
      "Yujie Wang",
      "Fangcheng Fu",
      "Xuefeng Xiao",
      "Huixia Li",
      "Jiashi Li",
      "Bin Cui"
    ],
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11686v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11686v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2602.12113v1",
    "title": "Stop Unnecessary Reflection: Training LRMs for Efficient Reasoning with Adaptive Reflection and Length Coordinated Penalty",
    "summary": "Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning tasks by employing test-time scaling. However, they often generate over-long chains-of-thought that, driven by substantial reflections such as repetitive self-questioning and circular reasoning, lead to high token consumption, substantial computational overhead, and increased latency without improving accuracy, particularly in smaller models. Our observation reveals that increasing problem complexity induces more excessive and unnecessary reflection, which in turn reduces accuracy and increases token overhead. To address this challenge, we propose Adaptive Reflection and Length Coordinated Penalty (ARLCP), a novel reinforcement learning framework designed to dynamically balance reasoning efficiency and solution accuracy. ARLCP introduces two key innovations: (1) a reflection penalty that adaptively curtails unnecessary reflective steps while preserving essential reasoning, and (2) a length penalty calibrated to the estimated complexity of the problem. By coordinating these penalties, ARLCP encourages the model to generate more concise and effective reasoning paths. We evaluate our method on five mathematical reasoning benchmarks using DeepSeek-R1-Distill-Qwen-1.5B and DeepSeek-R1-Distill-Qwen-7B models. Experimental results show that ARLCP achieves a superior efficiency-accuracy trade-off compared to existing approaches. For the 1.5B model, it reduces the average response length by 53.1% while simultaneously improving accuracy by 5.8%. For the 7B model, it achieves a 35.0% reduction in length with a 2.7% accuracy gain. The code is released at https://github.com/ZeweiYu1/ARLCP .",
    "authors": [
      "Zewei Yu",
      "Lirong Gao",
      "Yuke Zhu",
      "Bo Zheng",
      "Sheng Guo",
      "Haobo Wang",
      "Junbo Zhao"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12113v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12113v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2602.12112v1",
    "title": "Few-Shot Design Optimization by Exploiting Auxiliary Information",
    "summary": "Many real-world design problems involve optimizing an expensive black-box function $f(x)$, such as hardware design or drug discovery. Bayesian Optimization has emerged as a sample-efficient framework for this problem. However, the basic setting considered by these methods is simplified compared to real-world experimental setups, where experiments often generate a wealth of useful information. We introduce a new setting where an experiment generates high-dimensional auxiliary information $h(x)$ along with the performance measure $f(x)$; moreover, a history of previously solved tasks from the same task family is available for accelerating optimization. A key challenge of our setting is learning how to represent and utilize $h(x)$ for efficiently solving new optimization tasks beyond the task history. We develop a novel approach for this setting based on a neural model which predicts $f(x)$ for unseen designs given a few-shot context containing observations of $h(x)$. We evaluate our method on two challenging domains, robotic hardware design and neural network hyperparameter tuning, and introduce a novel design problem and large-scale benchmark for the former. On both domains, our method utilizes auxiliary feedback effectively to achieve more accurate few-shot prediction and faster optimization of design tasks, significantly outperforming several methods for multi-task optimization.",
    "authors": [
      "Arjun Mani",
      "Carl Vondrick",
      "Richard Zemel"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12112v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12112v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2602.11957v1",
    "title": "Are Two LLMs Better Than One? A Student-Teacher Dual-Head LLMs Architecture for Pharmaceutical Content Optimization",
    "summary": "Large language models (LLMs) are increasingly used to create content in regulated domains such as pharmaceuticals, where outputs must be scientifically accurate and legally compliant. Manual quality control (QC) is slow, error prone, and can become a publication bottleneck. We introduce LRBTC, a modular LLM and vision language model (VLM) driven QC architecture covering Language, Regulatory, Brand, Technical, and Content Structure checks. LRBTC combines a Student-Teacher dual model architecture, human in the loop (HITL) workflow with waterfall rule filtering to enable scalable, verifiable content validation and optimization. On AIReg-Bench, our approach achieves 83.0% F1 and 97.5% recall, reducing missed violations by 5x compared with Gemini 2.5 Pro. On CSpelling, it improves mean accuracy by 26.7%. Error analysis further reveals that while current models are strong at detecting misspellings (92.5 recall), they fail to identify complex medical grammatical (25.0 recall) and punctuation (41.7 recall) errors, highlighting a key area for future work. This work provides a practical, plug and play solution for reliable, transparent quality control of content in high stakes, compliance critical industries. We also provide access to our Demo under MIT Licenses.",
    "authors": [
      "Suyash Mishra",
      "Qiang Li",
      "Anubhav Girdhar"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11957v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11957v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2602.11942v1",
    "title": "Synthesis of Late Gadolinium Enhancement Images via Implicit Neural Representations for Cardiac Scar Segmentation",
    "summary": "Late gadolinium enhancement (LGE) imaging is the clinical standard for myocardial scar assessment, but limited annotated datasets hinder the development of automated segmentation methods. We propose a novel framework that synthesises both LGE images and their corresponding segmentation masks using implicit neural representations (INRs) combined with denoising diffusion models. Our approach first trains INRs to capture continuous spatial representations of LGE data and associated myocardium and fibrosis masks. These INRs are then compressed into compact latent embeddings, preserving essential anatomical information. A diffusion model operates on this latent space to generate new representations, which are decoded into synthetic LGE images with anatomically consistent segmentation masks. Experiments on 133 cardiac MRI scans suggest that augmenting training data with 200 synthetic volumes contributes to improved fibrosis segmentation performance, with the Dice score showing an increase from 0.509 to 0.524. Our approach provides an annotation-free method to help mitigate data scarcity.The code for this research is publicly available.",
    "authors": [
      "Soufiane Ben Haddou",
      "Laura Alvarez-Florez",
      "Erik J. Bekkers",
      "Fleur V. Y. Tjong",
      "Ahmad S. Amin",
      "Connie R. Bezzina",
      "Ivana Išgum"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11942v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11942v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2602.11933v1",
    "title": "Cross-Modal Robustness Transfer (CMRT): Training Robust Speech Translation Models Using Adversarial Text",
    "summary": "End-to-End Speech Translation (E2E-ST) has seen significant advancements, yet current models are primarily benchmarked on curated, \"clean\" datasets. This overlooks critical real-world challenges, such as morphological robustness to inflectional variations common in non-native or dialectal speech. In this work, we adapt a text-based adversarial attack targeting inflectional morphology to the speech domain and demonstrate that state-of-the-art E2E-ST models are highly vulnerable it. While adversarial training effectively mitigates such risks in text-based tasks, generating high-quality adversarial speech data remains computationally expensive and technically challenging. To address this, we propose Cross-Modal Robustness Transfer (CMRT), a framework that transfers adversarial robustness from the text modality to the speech modality. Our method eliminates the requirement for adversarial speech data during training. Extensive experiments across four language pairs demonstrate that CMRT improves adversarial robustness by an average of more than 3 BLEU points, establishing a new baseline for robust E2E-ST without the overhead of generating adversarial speech.",
    "authors": [
      "Abderrahmane Issam",
      "Yusuf Can Semerci",
      "Jan Scholtes",
      "Gerasimos Spanakis"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11933v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11933v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2602.11908v1",
    "title": "When Should LLMs Be Less Specific? Selective Abstraction for Reliable Long-Form Text Generation",
    "summary": "LLMs are widely used, yet they remain prone to factual errors that erode user trust and limit adoption in high-risk settings. One approach to mitigate this risk is to equip models with uncertainty estimation mechanisms that abstain when confidence is low. However, this binary \"all-or-nothing\" approach is excessively restrictive in long-form settings, often discarding valuable information. We introduce Selective Abstraction (SA), a framework that enables LLMs to trade specificity for reliability by selectively reducing the detail of uncertain content. We first formalize SA through the lenses of selective risk and coverage. We then propose Atom-wise Selective Abstraction, a claim-level instantiation that decomposes responses into atomic claims (short, self-contained statements each expressing a single fact) and replaces uncertain atoms with higher confidence, less specific abstractions. To evaluate this framework, we develop a novel end-to-end pipeline for open-ended generation that instantiates risk as factual correctness and measures coverage using an information-theoretic measure of retained information. Across six open-source models on the FactScore and LongFact-Objects benchmarks, atom-wise SA consistently outperforms existing baselines, improving the area under the risk-coverage curve (AURC) by up to 27.73% over claim removal, demonstrating that reducing specificity can boost accuracy and reliability while preserving most of their original meaning.",
    "authors": [
      "Shani Goren",
      "Ido Galil",
      "Ran El-Yaniv"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11908v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11908v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2602.11730v1",
    "title": "STVG-R1: Incentivizing Instance-Level Reasoning and Grounding in Videos via Reinforcement Learning",
    "summary": "In vision-language models (VLMs), misalignment between textual descriptions and visual coordinates often induces hallucinations. This issue becomes particularly severe in dense prediction tasks such as spatial-temporal video grounding (STVG). Prior approaches typically focus on enhancing visual-textual alignment or attaching auxiliary decoders. However, these strategies inevitably introduce additional trainable modules, leading to significant annotation costs and computational overhead. In this work, we propose a novel visual prompting paradigm that avoids the difficult problem of aligning coordinates across modalities. Specifically, we reformulate per-frame coordinate prediction as a compact instance-level identification problem by assigning each object a unique, temporally consistent ID. These IDs are embedded into the video as visual prompts, providing explicit and interpretable inputs to the VLMs. Furthermore, we introduce STVG-R1, the first reinforcement learning framework for STVG, which employs a task-driven reward to jointly optimize temporal accuracy, spatial consistency, and structural format regularization. Extensive experiments on six benchmarks demonstrate the effectiveness of our approach. STVG-R1 surpasses the baseline Qwen2.5-VL-7B by a remarkable margin of 20.9% on m_IoU on the HCSTVG-v2 benchmark, establishing a new state of the art (SOTA). Surprisingly, STVG-R1 also exhibits strong zero-shot generalization to multi-object referring video object segmentation tasks, achieving a SOTA 47.3% J&F on MeViS.",
    "authors": [
      "Xiaowen Zhang",
      "Zhi Gao",
      "Licheng Jiao",
      "Lingling Li",
      "Qing Li"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11730v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11730v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2602.11726v1",
    "title": "Dopamine: Brain Modes, Not Brains",
    "summary": "Parameter-efficient fine-tuning (PEFT) methods such as \\lora{} adapt large pretrained models by adding small weight-space updates. While effective, weight deltas are hard to interpret mechanistically, and they do not directly expose \\emph{which} internal computations are reused versus bypassed for a new task. We explore an alternative view inspired by neuromodulation: adaptation as a change in \\emph{mode} -- selecting and rescaling existing computations -- rather than rewriting the underlying weights. We propose \\methodname{}, a simple activation-space PEFT technique that freezes base weights and learns per-neuron \\emph{thresholds} and \\emph{gains}. During training, a smooth gate decides whether a neuron's activation participates; at inference the gate can be hardened to yield explicit conditional computation and neuron-level attributions.   As a proof of concept, we study ``mode specialization'' on MNIST (0$^\\circ$) versus rotated MNIST (45$^\\circ$). We pretrain a small MLP on a 50/50 mixture (foundation), freeze its weights, and then specialize to the rotated mode using \\methodname{}. Across seeds, \\methodname{} improves rotated accuracy over the frozen baseline while using only a few hundred trainable parameters per layer, and exhibits partial activation sparsity (a minority of units strongly active). Compared to \\lora{}, \\methodname{} trades some accuracy for substantially fewer trainable parameters and a more interpretable ``which-neurons-fire'' mechanism. We discuss limitations, including reduced expressivity when the frozen base lacks features needed for the target mode.",
    "authors": [
      "Shervin Ghasemlou"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11726v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11726v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2602.11690v1",
    "title": "ANML: Attribution-Native Machine Learning with Guaranteed Robustness",
    "summary": "Frontier AI systems increasingly train on specialized expert data, from clinical records to proprietary research to curated datasets, yet current training pipelines treat all samples identically. A Nobel laureate's contribution receives the same weight as an unverified submission. We introduce ANML (Attribution-Native Machine Learning), a framework that weights training samples by four quality factors: gradient-based consistency (q), verification status (v), contributor reputation (r), and temporal relevance (T). By combining what the model observes (gradient signals) with what the system knows about data provenance (external signals), ANML produces per-contributor quality weights that simultaneously improve model performance and enable downstream attribution. Across 5 datasets (178-32,561 samples), ANML achieves 33-72% error reduction over gradient-only baselines. Quality-weighted training is data-efficient: 20% high-quality data outperforms 100% uniformly weighted data by 47%. A Two-Stage Adaptive gating mechanism guarantees that ANML never underperforms the best available baseline, including under strategic joint attacks combining credential faking with gradient alignment. When per-sample detection fails against subtle corruption, contributor-level attribution provides 1.3-5.3x greater improvement than sample-level methods, with the advantage growing as corruption becomes harder to detect.",
    "authors": [
      "Oliver Zahn",
      "Matt Beton",
      "Simran Chana"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11690v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11690v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2602.11980v1",
    "title": "Spatial Chain-of-Thought: Bridging Understanding and Generation Models for Spatial Reasoning Generation",
    "summary": "While diffusion models have shown exceptional capabilities in aesthetic image synthesis, they often struggle with complex spatial understanding and reasoning. Existing approaches resort to Multimodal Large Language Models (MLLMs) to enhance this capability. However, they either incur high computational costs through joint training or suffer from spatial information loss when relying solely on textual prompts. To alleviate these limitations, we propose a Spatial Chain-of-Thought (SCoT) framework, a plug-and-play approach that effectively bridges the reasoning capabilities of MLLMs with the generative power of diffusion models. Specifically, we first enhance the diffusion model's layout awareness by training it on an interleaved text-coordinate instruction format. We then leverage state-of-the-art MLLMs as planners to generate comprehensive layout plans, transferring their spatial planning capabilities directly to the generation process. Extensive experiments demonstrate that our method achieves state-of-the-art performance on image generation benchmarks and significantly outperforms baselines on complex reasoning tasks, while also showing strong efficacy in image editing scenarios.",
    "authors": [
      "Wei Chen",
      "Yancheng Long",
      "Mingqiao Liu",
      "Haojie Ding",
      "Yankai Yang",
      "Hongyang Wei",
      "Yi-Fan Zhang",
      "Bin Wen",
      "Fan Yang",
      "Tingting Gao",
      "Han Li",
      "Long Chen"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11980v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11980v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2602.11793v1",
    "title": "More Haste, Less Speed: Weaker Single-Layer Watermark Improves Distortion-Free Watermark Ensembles",
    "summary": "Watermarking has emerged as a crucial technique for detecting and attributing content generated by large language models. While recent advancements have utilized watermark ensembles to enhance robustness, prevailing methods typically prioritize maximizing the strength of the watermark at every individual layer. In this work, we identify a critical limitation in this \"stronger-is-better\" approach: strong watermarks significantly reduce the entropy of the token distribution, which paradoxically weakens the effectiveness of watermarking in subsequent layers. We theoretically and empirically show that detectability is bounded by entropy and that watermark ensembles induce a monotonic decrease in both entropy and the expected green-list ratio across layers. To address this inherent trade-off, we propose a general framework that utilizes weaker single-layer watermarks to preserve the entropy required for effective multi-layer ensembling. Empirical evaluations demonstrate that this counter-intuitive strategy mitigates signal decay and consistently outperforms strong baselines in both detectability and robustness.",
    "authors": [
      "Ruibo Chen",
      "Yihan Wu",
      "Xuehao Cui",
      "Jingqi Zhang",
      "Heng Huang"
    ],
    "categories": [
      "cs.CR",
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11793v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11793v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2602.11715v1",
    "title": "DICE: Diffusion Large Language Models Excel at Generating CUDA Kernels",
    "summary": "Diffusion large language models (dLLMs) have emerged as a compelling alternative to autoregressive (AR) LLMs, owing to their capacity for parallel token generation. This paradigm is particularly well-suited for code generation, where holistic structural planning and non-sequential refinement are critical. Despite this potential, tailoring dLLMs for CUDA kernel generation remains challenging, obstructed not only by the high specialization but also by the severe lack of high-quality training data. To address these challenges, we construct CuKe, an augmented supervised fine-tuning dataset optimized for high-performance CUDA kernels. On top of it, we propose a bi-phase curated reinforcement learning (BiC-RL) framework consisting of a CUDA kernel infilling stage and an end-to-end CUDA kernel generation stage. Leveraging this training framework, we introduce DICE, a series of diffusion large language models designed for CUDA kernel generation, spanning three parameter scales, 1.7B, 4B, and 8B. Extensive experiments on KernelBench demonstrate that DICE significantly outperforms both autoregressive and diffusion LLMs of comparable scale, establishing a new state-of-the-art for CUDA kernel generation.",
    "authors": [
      "Haolei Bai",
      "Lingcheng Kong",
      "Xueyi Chen",
      "Jianmian Wang",
      "Zhiqiang Tao",
      "Huan Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11715v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11715v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2602.12078v1",
    "title": "Tiny Recursive Reasoning with Mamba-2 Attention Hybrid",
    "summary": "Recent work on recursive reasoning models like TRM demonstrates that tiny networks (7M parameters) can achieve strong performance on abstract reasoning tasks through latent recursion -- iterative refinement in hidden representation space without emitting intermediate tokens. This raises a natural question about operator choice: Mamba-2's state space recurrence is itself a form of iterative refinement, making it a natural candidate for recursive reasoning -- but does introducing Mamba-2 into the recursive scaffold preserve reasoning capability? We investigate this by replacing the Transformer blocks in TRM with Mamba-2 hybrid operators while maintaining parameter parity (6.83M vs 6.86M parameters). On ARC-AGI-1, we find that the hybrid improves pass@2 (the official metric) by +2.0\\% (45.88\\% vs 43.88\\%) and consistently outperforms at higher K values (+4.75\\% at pass@100), whilst maintaining pass@1 parity. This suggests improved candidate coverage -- the model generates correct solutions more reliably -- with similar top-1 selection. Our results validate that Mamba-2 hybrid operators preserve reasoning capability within the recursive scaffold, establishing SSM-based operators as viable candidates in the recursive operator design space and taking a first step towards understanding the best mixing strategies for recursive reasoning.",
    "authors": [
      "Wenlong Wang",
      "Fergal Reid"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12078v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12078v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2602.12015v1",
    "title": "Disentangling Ambiguity from Instability in Large Language Models: A Clinical Text-to-SQL Case Study",
    "summary": "Deploying large language models for clinical Text-to-SQL requires distinguishing two qualitatively different causes of output diversity: (i) input ambiguity that should trigger clarification, and (ii) model instability that should trigger human review. We propose CLUES, a framework that models Text-to-SQL as a two-stage process (interpretations --> answers) and decomposes semantic uncertainty into an ambiguity score and an instability score. The instability score is computed via the Schur complement of a bipartite semantic graph matrix. Across AmbigQA/SituatedQA (gold interpretations) and a clinical Text-to-SQL benchmark (known interpretations), CLUES improves failure prediction over state-of-the-art Kernel Language Entropy. In deployment settings, it remains competitive while providing a diagnostic decomposition unavailable from a single score. The resulting uncertainty regimes map to targeted interventions - query refinement for ambiguity, model improvement for instability. The high-ambiguity/high-instability regime contains 51% of errors while covering 25% of queries, enabling efficient triage.",
    "authors": [
      "Angelo Ziletti",
      "Leonardo D'Ambrosi"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12015v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12015v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2602.11978v1",
    "title": "Accelerating Robotic Reinforcement Learning with Agent Guidance",
    "summary": "Reinforcement Learning (RL) offers a powerful paradigm for autonomous robots to master generalist manipulation skills through trial-and-error. However, its real-world application is stifled by severe sample inefficiency. Recent Human-in-the-Loop (HIL) methods accelerate training by using human corrections, yet this approach faces a scalability barrier. Reliance on human supervisors imposes a 1:1 supervision ratio that limits fleet expansion, suffers from operator fatigue over extended sessions, and introduces high variance due to inconsistent human proficiency. We present Agent-guided Policy Search (AGPS), a framework that automates the training pipeline by replacing human supervisors with a multimodal agent. Our key insight is that the agent can be viewed as a semantic world model, injecting intrinsic value priors to structure physical exploration. By using executable tools, the agent provides precise guidance via corrective waypoints and spatial constraints for exploration pruning. We validate our approach on two tasks, ranging from precision insertion to deformable object manipulation. Results demonstrate that AGPS outperforms HIL methods in sample efficiency. This automates the supervision pipeline, unlocking the path to labor-free and scalable robot learning. Project website: https://agps-rl.github.io/agps.",
    "authors": [
      "Haojun Chen",
      "Zili Zou",
      "Chengdong Ma",
      "Yaoxiang Pu",
      "Haotong Zhang",
      "Yuanpei Chen",
      "Yaodong Yang"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11978v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11978v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2602.11965v1",
    "title": "Manifold-Aware Temporal Domain Generalization for Large Language Models",
    "summary": "Temporal distribution shifts are pervasive in real-world deployments of Large Language Models (LLMs), where data evolves continuously over time. While Temporal Domain Generalization (TDG) seeks to model such structured evolution, existing approaches characterize model adaptation in the full parameter space. This formulation becomes computationally infeasible for modern LLMs. This paper introduces a geometric reformulation of TDG under parameter-efficient fine-tuning. We establish that the low-dimensional temporal structure underlying model evolution can be preserved under parameter-efficient reparameterization, enabling temporal modeling without operating in the ambient parameter space. Building on this principle, we propose Manifold-aware Temporal LoRA (MaT-LoRA), which constrains temporal updates to a shared low-dimensional manifold within a low-rank adaptation subspace, and models its evolution through a structured temporal core. This reparameterization dramatically reduces temporal modeling complexity while retaining expressive power. Extensive experiments on synthetic and real-world datasets, including scientific documents, news publishers, and review ratings, demonstrate that MaT-LoRA achieves superior temporal generalization performance with practical scalability for LLMs.",
    "authors": [
      "Yiheng Yao",
      "Zekun Cai",
      "Xinyuan Song",
      "Hiroki Hill Kobayashi",
      "Xuan Song",
      "Ryosuke Shibasaki",
      "Liang Zhao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11965v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11965v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2602.11858v1",
    "title": "Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception",
    "summary": "Multimodal Large Language Models (MLLMs) excel at broad visual understanding but still struggle with fine-grained perception, where decisive evidence is small and easily overwhelmed by global context. Recent \"Thinking-with-Images\" methods alleviate this by iteratively zooming in and out regions of interest during inference, but incur high latency due to repeated tool calls and visual re-encoding. To address this, we propose Region-to-Image Distillation, which transforms zooming from an inference-time tool into a training-time primitive, thereby internalizing the benefits of agentic zooming into a single forward pass of an MLLM. In particular, we first zoom in to micro-cropped regions to let strong teacher models generate high-quality VQA data, and then distill this region-grounded supervision back to the full image. After training on such data, the smaller student model improves \"single-glance\" fine-grained perception without tool use. To rigorously evaluate this capability, we further present ZoomBench, a hybrid-annotated benchmark of 845 VQA data spanning six fine-grained perceptual dimensions, together with a dual-view protocol that quantifies the global--regional \"zooming gap\". Experiments show that our models achieve leading performance across multiple fine-grained perception benchmarks, and also improve general multimodal cognition on benchmarks such as visual reasoning and GUI agents. We further discuss when \"Thinking-with-Images\" is necessary versus when its gains can be distilled into a single forward pass. Our code is available at https://github.com/inclusionAI/Zooming-without-Zooming.",
    "authors": [
      "Lai Wei",
      "Liangbo He",
      "Jun Lan",
      "Lingzhong Dong",
      "Yutong Cai",
      "Siyuan Li",
      "Huijia Zhu",
      "Weiqiang Wang",
      "Linghe Kong",
      "Yue Wang",
      "Zhuosheng Zhang",
      "Weiran Huang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11858v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11858v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2602.11836v1",
    "title": "ULTRA:Urdu Language Transformer-based Recommendation Architecture",
    "summary": "Urdu, as a low-resource language, lacks effective semantic content recommendation systems, particularly in the domain of personalized news retrieval. Existing approaches largely rely on lexical matching or language-agnostic techniques, which struggle to capture semantic intent and perform poorly under varying query lengths and information needs. This limitation results in reduced relevance and adaptability in Urdu content recommendation. We propose ULTRA (Urdu Language Transformer-based Recommendation Architecture),an adaptive semantic recommendation framework designed to address these challenges. ULTRA introduces a dual-embedding architecture with a query-length aware routing mechanism that dynamically distinguishes between short, intent-focused queries and longer, context-rich queries. Based on a threshold-driven decision process, user queries are routed to specialized semantic pipelines optimized for either title/headline-level or full-content/document level representations, ensuring appropriate semantic granularity during retrieval. The proposed system leverages transformer-based embeddings and optimized pooling strategies to move beyond surface-level keyword matching and enable context-aware similarity search. Extensive experiments conducted on a large-scale Urdu news corpus demonstrate that the proposed architecture consistently improves recommendation relevance across diverse query types. Results show gains in precision above 90% compared to single-pipeline baselines, highlighting the effectiveness of query-adaptive semantic alignment for low-resource languages. The findings establish ULTRA as a robust and generalizable content recommendation architecture, offering practical design insights for semantic retrieval systems in low-resource language settings.",
    "authors": [
      "Alishbah Bashir",
      "Fatima Qaiser",
      "Ijaz Hussain"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11836v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11836v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2602.11761v1",
    "title": "MiniCPM-SALA: Hybridizing Sparse and Linear Attention for Efficient Long-Context Modeling",
    "summary": "The evolution of large language models (LLMs) towards applications with ultra-long contexts faces challenges posed by the high computational and memory costs of the Transformer architecture. While existing sparse and linear attention mechanisms attempt to mitigate these issues, they typically involve a trade-off between memory efficiency and model performance. This paper introduces MiniCPM-SALA, a 9B-parameter hybrid architecture that integrates the high-fidelity long-context modeling of sparse attention (InfLLM-V2) with the global efficiency of linear attention (Lightning Attention). By employing a layer selection algorithm to integrate these mechanisms in a 1:3 ratio and utilizing a hybrid positional encoding (HyPE), the model maintains efficiency and performance for long-context tasks. Furthermore, we introduce a cost-effective continual training framework that transforms pre-trained Transformer-based models into hybrid models, which reduces training costs by approximately 75% compared to training from scratch. Extensive experiments show that MiniCPM-SALA maintains general capabilities comparable to full-attention models while offering improved efficiency. On a single NVIDIA A6000D GPU, the model achieves up to 3.5x the inference speed of the full-attention model at the sequence length of 256K tokens and supports context lengths of up to 1M tokens, a scale where traditional full-attention 8B models fail because of memory constraints.",
    "authors": [
      " MiniCPM Team",
      "Wenhao An",
      "Yingfa Chen",
      "Yewei Fang",
      "Jiayi Li",
      "Xin Li",
      "Yaohui Li",
      "Yishan Li",
      "Yuxuan Li",
      "Biyuan Lin",
      "Chuan Liu",
      "Hezi Liu",
      "Siyuan Liu",
      "Hongya Lyu",
      "Yinxu Pan",
      "Shixin Ren",
      "Xingyu Shen",
      "Zhou Su",
      "Haojun Sun",
      "Yangang Sun",
      "Zhen Leng Thai",
      "Xin Tian",
      "Rui Wang",
      "Xiaorong Wang",
      "Yudong Wang",
      "Bo Wu",
      "Xiaoyue Xu",
      "Dong Xu",
      "Shuaikang Xue",
      "Jiawei Yang",
      "Bowen Zhang",
      "Jinqian Zhang",
      "Letian Zhang",
      "Shengnan Zhang",
      "Xinyu Zhang",
      "Xinyuan Zhang",
      "Zhu Zhang",
      "Hengyu Zhao",
      "Jiacheng Zhao",
      "Jie Zhou",
      "Zihan Zhou",
      "Shuo Wang",
      "Chaojun Xiao",
      "Xu Han",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11761v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11761v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2602.11749v1",
    "title": "AIR: Improving Agent Safety through Incident Response",
    "summary": "Large Language Model (LLM) agents are increasingly deployed in practice across a wide range of autonomous applications. Yet current safety mechanisms for LLM agents focus almost exclusively on preventing failures in advance, providing limited capabilities for responding to, containing, or recovering from incidents after they inevitably arise. In this work, we introduce AIR, the first incident response framework for LLM agent systems. AIR defines a domain-specific language for managing the incident response lifecycle autonomously in LLM agent systems, and integrates it into the agent's execution loop to (1) detect incidents via semantic checks grounded in the current environment state and recent context, (2) guide the agent to execute containment and recovery actions via its tools, and (3) synthesize guardrail rules during eradication to block similar incidents in future executions. We evaluate AIR on three representative agent types. Results show that AIR achieves detection, remediation, and eradication success rates all exceeding 90%. Extensive experiments further confirm the necessity of AIR's key design components, show the timeliness and moderate overhead of AIR, and demonstrate that LLM-generated rules can approach the effectiveness of developer-authored rules across domains. These results show that incident response is both feasible and essential as a first-class mechanism for improving agent safety.",
    "authors": [
      "Zibo Xiao",
      "Jun Sun",
      "Junjie Chen"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11749v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11749v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2602.11638v1",
    "title": "Variation-aware Flexible 3D Gaussian Editing",
    "summary": "Indirect editing methods for 3D Gaussian Splatting (3DGS) have recently witnessed significant advancements. These approaches operate by first applying edits in the rendered 2D space and subsequently projecting the modifications back into 3D. However, this paradigm inevitably introduces cross-view inconsistencies and constrains both the flexibility and efficiency of the editing process. To address these challenges, we present VF-Editor, which enables native editing of Gaussian primitives by predicting attribute variations in a feedforward manner. To accurately and efficiently estimate these variations, we design a novel variation predictor distilled from 2D editing knowledge. The predictor encodes the input to generate a variation field and employs two learnable, parallel decoding functions to iteratively infer attribute changes for each 3D Gaussian. Thanks to its unified design, VF-Editor can seamlessly distill editing knowledge from diverse 2D editors and strategies into a single predictor, allowing for flexible and effective knowledge transfer into the 3D domain. Extensive experiments on both public and private datasets reveal the inherent limitations of indirect editing pipelines and validate the effectiveness and flexibility of our approach.",
    "authors": [
      "Hao Qin",
      "Yukai Sun",
      "Meng Wang",
      "Ming Kong",
      "Mengxu Lu",
      "Qiang Zhu"
    ],
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11638v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11638v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2602.12087v1",
    "title": "Geometry of Uncertainty: Learning Metric Spaces for Multimodal State Estimation in RL",
    "summary": "Estimating the state of an environment from high-dimensional, multimodal, and noisy observations is a fundamental challenge in reinforcement learning (RL). Traditional approaches rely on probabilistic models to account for the uncertainty, but often require explicit noise assumptions, in turn limiting generalization. In this work, we contribute a novel method to learn a structured latent representation, in which distances between states directly correlate with the minimum number of actions required to transition between them. The proposed metric space formulation provides a geometric interpretation of uncertainty without the need for explicit probabilistic modeling. To achieve this, we introduce a multimodal latent transition model and a sensor fusion mechanism based on inverse distance weighting, allowing for the adaptive integration of multiple sensor modalities without prior knowledge of noise distributions. We empirically validate the approach on a range of multimodal RL tasks, demonstrating improved robustness to sensor noise and superior state estimation compared to baseline methods. Our experiments show enhanced performance of an RL agent via the learned representation, eliminating the need of explicit noise augmentation. The presented results suggest that leveraging transition-aware metric spaces provides a principled and scalable solution for robust state estimation in sequential decision-making.",
    "authors": [
      "Alfredo Reichlin",
      "Adriano Pacciarelli",
      "Danica Kragic",
      "Miguel Vasco"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12087v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12087v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.11973v1",
    "title": "Calibrated Bayesian Deep Learning for Explainable Decision Support Systems Based on Medical Imaging",
    "summary": "In critical decision support systems based on medical imaging, the reliability of AI-assisted decision-making is as relevant as predictive accuracy. Although deep learning models have demonstrated significant accuracy, they frequently suffer from miscalibration, manifested as overconfidence in erroneous predictions. To facilitate clinical acceptance, it is imperative that models quantify uncertainty in a manner that correlates with prediction correctness, allowing clinicians to identify unreliable outputs for further review. In order to address this necessity, the present paper proposes a generalizable probabilistic optimization framework grounded in Bayesian deep learning. Specifically, a novel Confidence-Uncertainty Boundary Loss (CUB-Loss) is introduced that imposes penalties on high-certainty errors and low-certainty correct predictions, explicitly enforcing alignment between prediction correctness and uncertainty estimates. Complementing this training-time optimization, a Dual Temperature Scaling (DTS) strategy is devised for post-hoc calibration, further refining the posterior distribution to improve intuitive explainability. The proposed framework is validated on three distinct medical imaging tasks: automatic screening of pneumonia, diabetic retinopathy detection, and identification of skin lesions. Empirical results demonstrate that the proposed approach achieves consistent calibration improvements across diverse modalities, maintains robust performance in data-scarce scenarios, and remains effective on severely imbalanced datasets, underscoring its potential for real clinical deployment.",
    "authors": [
      "Hua Xu",
      "Julián D. Arias-Londoño",
      "Juan I. Godino-Llorente"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11973v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11973v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.11918v1",
    "title": "MEME: Modeling the Evolutionary Modes of Financial Markets",
    "summary": "LLMs have demonstrated significant potential in quantitative finance by processing vast unstructured data to emulate human-like analytical workflows. However, current LLM-based methods primarily follow either an Asset-Centric paradigm focused on individual stock prediction or a Market-Centric approach for portfolio allocation, often remaining agnostic to the underlying reasoning that drives market movements. In this paper, we propose a Logic-Oriented perspective, modeling the financial market as a dynamic, evolutionary ecosystem of competing investment narratives, termed Modes of Thought. To operationalize this view, we introduce MEME (Modeling the Evolutionary Modes of Financial Markets), designed to reconstruct market dynamics through the lens of evolving logics. MEME employs a multi-agent extraction module to transform noisy data into high-fidelity Investment Arguments and utilizes Gaussian Mixture Modeling to uncover latent consensus within a semantic space. To model semantic drift among different market conditions, we also implement a temporal evaluation and alignment mechanism to track the lifecycle and historical profitability of these modes. By prioritizing enduring market wisdom over transient anomalies, MEME ensures that portfolio construction is guided by robust reasoning. Extensive experiments on three heterogeneous Chinese stock pools from 2023 to 2025 demonstrate that MEME consistently outperforms seven SOTA baselines. Further ablation studies, sensitivity analysis, lifecycle case study and cost analysis validate MEME's capacity to identify and adapt to the evolving consensus of financial markets. Our implementation can be found at https://github.com/gta0804/MEME.",
    "authors": [
      "Taian Guo",
      "Haiyang Shen",
      "Junyu Luo",
      "Zhongshi Xing",
      "Hanchun Lian",
      "Jinsheng Huang",
      "Binqi Chen",
      "Luchen Liu",
      "Yun Ma",
      "Ming Zhang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11918v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11918v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.11854v1",
    "title": "Robust Optimization Approach and Learning Based Hide-and-Seek Game for Resilient Network Design",
    "summary": "We study the design of resilient and reliable communication networks in which a signal can be transferred only up to a limited distance before its quality falls below an acceptable threshold. When excessive signal degradation occurs, regeneration is required through regenerators installed at selected network nodes. In this work, both network links and nodes are subject to uncertainty. The installation costs of regenerators are modeled using a budgeted uncertainty set. In addition, link lengths follow a dynamic budgeted uncertainty set introduced in this paper, where deviations may vary over time. Robust optimization seeks solutions whose performance is guaranteed under all scenarios represented by the underlying uncertainty set. Accordingly, the objective is to identify a minimum-cost subset of nodes for regenerator deployment that ensures full network connectivity, even under the worst possible realizations of uncertainty. To solve the problem, we first formulate it within a robust optimization framework, and then develop scalable solution methods based on column-and-constraint generation, Benders decomposition, and iterative robust optimization. In addition, we formulate a learning-based hide-and-seek game to further analyze the problem structure. The proposed approaches are evaluated against classical static budgeted robust models and deterministic worst-case formulations. Both theoretical analysis and computational results demonstrate the effectiveness and advantages of our methodology.",
    "authors": [
      "Mohammad Khosravi",
      "Setareh Maghsudi"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11854v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11854v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.11779v1",
    "title": "Temperature as a Meta-Policy: Adaptive Temperature in LLM Reinforcement Learning",
    "summary": "Temperature is a crucial hyperparameter in large language models (LLMs), controlling the trade-off between exploration and exploitation during text generation. High temperatures encourage diverse but noisy outputs, while low temperatures produce focused outputs but may cause premature convergence. Yet static or heuristic temperature schedules fail to adapt to the dynamic demands of reinforcement learning (RL) throughout training, often limiting policy improvement. We propose Temperature Adaptive Meta Policy Optimization (TAMPO), a new framework that recasts temperature control as a learnable meta-policy. TAMPO operates through a hierarchical two-loop process. In the inner loop, the LLM policy is updated (e.g., using GRPO) with trajectories sampled at the temperature selected by the meta-policy. In the outer loop, meta-policy updates the distribution over candidate temperatures by rewarding those that maximize the likelihood of high-advantage trajectories. This trajectory-guided, reward-driven mechanism enables online adaptation without additional rollouts, directly aligning exploration with policy improvement. On five mathematical reasoning benchmarks, TAMPO outperforms baselines using fixed or heuristic temperatures, establishing temperature as an effective learnable meta-policy for adaptive exploration in LLM reinforcement learning. Accepted at ICLR 2026.",
    "authors": [
      "Haoran Dang",
      "Cuiling Lan",
      "Hai Wan",
      "Xibin Zhao",
      "Yan Lu"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11779v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11779v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.11769v1",
    "title": "Light4D: Training-Free Extreme Viewpoint 4D Video Relighting",
    "summary": "Recent advances in diffusion-based generative models have established a new paradigm for image and video relighting. However, extending these capabilities to 4D relighting remains challenging, due primarily to the scarcity of paired 4D relighting training data and the difficulty of maintaining temporal consistency across extreme viewpoints. In this work, we propose Light4D, a novel training-free framework designed to synthesize consistent 4D videos under target illumination, even under extreme viewpoint changes. First, we introduce Disentangled Flow Guidance, a time-aware strategy that effectively injects lighting control into the latent space while preserving geometric integrity. Second, to reinforce temporal consistency, we develop Temporal Consistent Attention within the IC-Light architecture and further incorporate deterministic regularization to eliminate appearance flickering. Extensive experiments demonstrate that our method achieves competitive performance in temporal consistency and lighting fidelity, robustly handling camera rotations from -90 to 90. Code: https://github.com/AIGeeksGroup/Light4D. Website: https://aigeeksgroup.github.io/Light4D.",
    "authors": [
      "Zhenghuang Wu",
      "Kang Chen",
      "Zeyu Zhang",
      "Hao Tang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11769v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11769v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.11660v1",
    "title": "Clutt3R-Seg: Sparse-view 3D Instance Segmentation for Language-grounded Grasping in Cluttered Scenes",
    "summary": "Reliable 3D instance segmentation is fundamental to language-grounded robotic manipulation. Its critical application lies in cluttered environments, where occlusions, limited viewpoints, and noisy masks degrade perception. To address these challenges, we present Clutt3R-Seg, a zero-shot pipeline for robust 3D instance segmentation for language-grounded grasping in cluttered scenes. Our key idea is to introduce a hierarchical instance tree of semantic cues. Unlike prior approaches that attempt to refine noisy masks, our method leverages them as informative cues: through cross-view grouping and conditional substitution, the tree suppresses over- and under-segmentation, yielding view-consistent masks and robust 3D instances. Each instance is enriched with open-vocabulary semantic embeddings, enabling accurate target selection from natural language instructions. To handle scene changes during multi-stage tasks, we further introduce a consistency-aware update that preserves instance correspondences from only a single post-interaction image, allowing efficient adaptation without rescanning. Clutt3R-Seg is evaluated on both synthetic and real-world datasets, and validated on a real robot. Across all settings, it consistently outperforms state-of-the-art baselines in cluttered and sparse-view scenarios. Even on the most challenging heavy-clutter sequences, Clutt3R-Seg achieves an AP@25 of 61.66, over 2.2x higher than baselines, and with only four input views it surpasses MaskClustering with eight views by more than 2x. The code is available at: https://github.com/jeonghonoh/clutt3r-seg.",
    "authors": [
      "Jeongho Noh",
      "Tai Hyoung Rhee",
      "Eunho Lee",
      "Jeongyun Kim",
      "Sunwoo Lee",
      "Ayoung Kim"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11660v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11660v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.11653v1",
    "title": "GR-Diffusion: 3D Gaussian Representation Meets Diffusion in Whole-Body PET Reconstruction",
    "summary": "Positron emission tomography (PET) reconstruction is a critical challenge in molecular imaging, often hampered by noise amplification, structural blurring, and detail loss due to sparse sampling and the ill-posed nature of inverse problems. The three-dimensional discrete Gaussian representation (GR), which efficiently encodes 3D scenes using parameterized discrete Gaussian distributions, has shown promise in computer vision. In this work, we pro-pose a novel GR-Diffusion framework that synergistically integrates the geometric priors of GR with the generative power of diffusion models for 3D low-dose whole-body PET reconstruction. GR-Diffusion employs GR to generate a reference 3D PET image from projection data, establishing a physically grounded and structurally explicit benchmark that overcomes the low-pass limitations of conventional point-based or voxel-based methods. This reference image serves as a dual guide during the diffusion process, ensuring both global consistency and local accuracy. Specifically, we employ a hierarchical guidance mechanism based on the GR reference. Fine-grained guidance leverages differences to refine local details, while coarse-grained guidance uses multi-scale difference maps to correct deviations. This strategy allows the diffusion model to sequentially integrate the strong geometric prior from GR and recover sub-voxel information. Experimental results on the UDPET and Clinical datasets with varying dose levels show that GR-Diffusion outperforms state-of-the-art methods in enhancing 3D whole-body PET image quality and preserving physiological details.",
    "authors": [
      "Mengxiao Geng",
      "Zijie Chen",
      "Ran Hong",
      "Bingxuan Li",
      "Qiegen Liu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11653v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11653v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.11651v1",
    "title": "DMind-3: A Sovereign Edge--Local--Cloud AI System with Controlled Deliberation and Correction-Based Tuning for Safe, Low-Latency Transaction Execution",
    "summary": "This paper introduces DMind-3, a sovereign Edge-Local-Cloud intelligence stack designed to secure irreversible financial execution in Web3 environments against adversarial risks and strict latency constraints. While existing cloud-centric assistants compromise privacy and fail under network congestion, and purely local solutions lack global ecosystem context, DMind-3 resolves these tensions by decomposing capability into three cooperating layers: a deterministic signing-time intent firewall at the edge, a private high-fidelity reasoning engine on user hardware, and a policy-governed global context synthesizer in the cloud. We propose policy-driven selective offloading to route computation based on privacy sensitivity and uncertainty, supported by two novel training objectives: Hierarchical Predictive Synthesis (HPS) for fusing time-varying macro signals, and Contrastive Chain-of-Correction Supervised Fine-Tuning (C$^3$-SFT) to enhance local verification reliability. Extensive evaluations demonstrate that DMind-3 achieves a 93.7% multi-turn success rate in protocol-constrained tasks and superior domain reasoning compared to general-purpose baselines, providing a scalable framework where safety is bound to the edge execution primitive while maintaining sovereignty over sensitive user intent.",
    "authors": [
      "Enhao Huang",
      "Frank Li",
      "Tony Lin",
      "Lowes Yang"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11651v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11651v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2602.12105v1",
    "title": "Iskra: A System for Inverse Geometry Processing",
    "summary": "We propose a system for differentiating through solutions to geometry processing problems. Our system differentiates a broad class of geometric algorithms, exploiting existing fast problem-specific schemes common to geometry processing, including local-global and ADMM solvers. It is compatible with machine learning frameworks, opening doors to new classes of inverse geometry processing applications. We marry the scatter-gather approach to mesh processing with tensor-based workflows and rely on the adjoint method applied to user-specified imperative code to generate an efficient backward pass behind the scenes. We demonstrate our approach by differentiating through mean curvature flow, spectral conformal parameterization, geodesic distance computation, and as-rigid-as-possible deformation, examining usability and performance on these applications. Our system allows practitioners to differentiate through existing geometry processing algorithms without needing to reformulate them, resulting in low implementation effort, fast runtimes, and lower memory requirements than differentiable optimization tools not tailored to geometry processing.",
    "authors": [
      "Ana Dodik",
      "Ahmed H. Mahmoud",
      "Justin Solomon"
    ],
    "categories": [
      "cs.GR",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12105v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12105v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.11909v1",
    "title": "Echo: Towards Advanced Audio Comprehension via Audio-Interleaved Reasoning",
    "summary": "The maturation of Large Audio Language Models (LALMs) has raised growing expectations for them to comprehend complex audio much like humans. Current efforts primarily replicate text-based reasoning by contextualizing audio content through a one-time encoding, which introduces a critical information bottleneck. Drawing inspiration from human cognition, we propose audio-interleaved reasoning to break through this bottleneck. It treats audio as an active reasoning component, enabling sustained audio engagement and perception-grounded analysis. To instantiate it, we introduce a two-stage training framework, first teaching LALMs to localize salient audio segments through supervised fine-tuning, and then incentivizing proficient re-listening via reinforcement learning. In parallel, a structured data generation pipeline is developed to produce high-quality training data. Consequently, we present Echo, a LALM capable of dynamically re-listening to audio in demand during reasoning. On audio comprehension benchmarks, Echo achieves overall superiority in both challenging expert-level and general-purpose tasks. Comprehensive analysis further confirms the efficiency and generalizability of audio-interleaved reasoning, establishing it as a promising direction for advancing audio comprehension. Project page: https://github.com/wdqqdw/Echo.",
    "authors": [
      "Daiqing Wu",
      "Xuan Zhang",
      "Dongbao Yang",
      "Jiashu Yao",
      "Longfei Chen",
      "Qingsong Liu",
      "Sicheng Zhao",
      "Can Ma",
      "Yangyang Kang",
      "Yu Zhou"
    ],
    "categories": [
      "cs.SD",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11909v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11909v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.11860v1",
    "title": "Talk2DM: Enabling Natural Language Querying and Commonsense Reasoning for Vehicle-Road-Cloud Integrated Dynamic Maps with Large Language Models",
    "summary": "Dynamic maps (DM) serve as the fundamental information infrastructure for vehicle-road-cloud (VRC) cooperative autonomous driving in China and Japan. By providing comprehensive traffic scene representations, DM overcome the limitations of standalone autonomous driving systems (ADS), such as physical occlusions. Although DM-enhanced ADS have been successfully deployed in real-world applications in Japan, existing DM systems still lack a natural-language-supported (NLS) human interface, which could substantially enhance human-DM interaction. To address this gap, this paper introduces VRCsim, a VRC cooperative perception (CP) simulation framework designed to generate streaming VRC-CP data. Based on VRCsim, we construct a question-answering data set, VRC-QA, focused on spatial querying and reasoning in mixed-traffic scenes. Building upon VRCsim and VRC-QA, we further propose Talk2DM, a plug-and-play module that extends VRC-DM systems with NLS querying and commonsense reasoning capabilities. Talk2DM is built upon a novel chain-of-prompt (CoP) mechanism that progressively integrates human-defined rules with the commonsense knowledge of large language models (LLMs). Experiments on VRC-QA show that Talk2DM can seamlessly switch across different LLMs while maintaining high NLS query accuracy, demonstrating strong generalization capability. Although larger models tend to achieve higher accuracy, they incur significant efficiency degradation. Our results reveal that Talk2DM, powered by Qwen3:8B, Gemma3:27B, and GPT-oss models, achieves over 93\\% NLS query accuracy with an average response time of only 2-5 seconds, indicating strong practical potential.",
    "authors": [
      "Lu Tao",
      "Jinxuan Luo",
      "Yousuke Watanabe",
      "Zhengshu Zhou",
      "Yuhuan Lu",
      "Shen Ying",
      "Pan Zhang",
      "Fei Zhao",
      "Hiroaki Takada"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11860v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11860v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.11852v1",
    "title": "Prototype Transformer: Towards Language Model Architectures Interpretable by Design",
    "summary": "While state-of-the-art language models (LMs) surpass the vast majority of humans in certain domains, their reasoning remains largely opaque, undermining trust in their output. Furthermore, while autoregressive LMs can output explicit reasoning, their true reasoning process is opaque, which introduces risks like deception and hallucination. In this work, we introduce the Prototype Transformer (ProtoT) -- an autoregressive LM architecture based on prototypes (parameter vectors), posed as an alternative to the standard self-attention-based transformers. ProtoT works by means of two-way communication between the input sequence and the prototypes, and we show that this leads to the prototypes automatically capturing nameable concepts (e.g. \"woman\") during training. They provide the potential to interpret the model's reasoning and allow for targeted edits of its behavior. Furthermore, by design, the prototypes create communication channels that aggregate contextual information at different time scales, aiding interpretability. In terms of computation scalability, ProtoT scales linearly with sequence length vs the quadratic scalability of SOTA self-attention transformers. Compared to baselines, ProtoT scales well with model and data size, and performs well on text generation and downstream tasks (GLUE). ProtoT exhibits robustness to input perturbations on par or better than some baselines, but differs from them by providing interpretable pathways showing how robustness and sensitivity arises. Reaching close to the performance of state-of-the-art architectures, ProtoT paves the way to creating well-performing autoregressive LMs interpretable by design.",
    "authors": [
      "Yordan Yordanov",
      "Matteo Forasassi",
      "Bayar Menzat",
      "Ruizhi Wang",
      "Chang Qi",
      "Markus Kaltenberger",
      "Amine M'Charrak",
      "Tommaso Salvatori",
      "Thomas Lukasiewicz"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11852v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11852v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.11666v1",
    "title": "PhyNiKCE: A Neurosymbolic Agentic Framework for Autonomous Computational Fluid Dynamics",
    "summary": "The deployment of autonomous agents for Computational Fluid Dynamics (CFD), is critically limited by the probabilistic nature of Large Language Models (LLMs), which struggle to enforce the strict conservation laws and numerical stability required for physics-based simulations. Reliance on purely semantic Retrieval Augmented Generation (RAG) often leads to \"context poisoning,\" where agents generate linguistically plausible but physically invalid configurations due to a fundamental Semantic-Physical Disconnect. To bridge this gap, this work introduces PhyNiKCE (Physical and Numerical Knowledgeable Context Engineering), a neurosymbolic agentic framework for trustworthy engineering. Unlike standard black-box agents, PhyNiKCE decouples neural planning from symbolic validation. It employs a Symbolic Knowledge Engine that treats simulation setup as a Constraint Satisfaction Problem, rigidly enforcing physical constraints via a Deterministic RAG Engine with specialized retrieval strategies for solvers, turbulence models, and boundary conditions. Validated through rigorous OpenFOAM experiments on practical, non-tutorial CFD tasks using Gemini-2.5-Pro/Flash, PhyNiKCE demonstrates a 96% relative improvement over state-of-the-art baselines. Furthermore, by replacing trial-and-error with knowledge-driven initialization, the framework reduced autonomous self-correction loops by 59% while simultaneously lowering LLM token consumption by 17%. These results demonstrate that decoupling neural generation from symbolic constraint enforcement significantly enhances robustness and efficiency. While validated on CFD, this architecture offers a scalable, auditable paradigm for Trustworthy Artificial Intelligence in broader industrial automation.",
    "authors": [
      "E Fan",
      "Lisong Shi",
      "Zhengtong Li",
      "Chih-yung Wen"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11666v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11666v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.11661v1",
    "title": "Quark Medical Alignment: A Holistic Multi-Dimensional Alignment and Collaborative Optimization Paradigm",
    "summary": "While reinforcement learning for large language model alignment has progressed rapidly in recent years, transferring these paradigms to high-stakes medical question answering reveals a fundamental paradigm mismatch. Reinforcement Learning from Human Feedback relies on preference annotations that are prohibitively expensive and often fail to reflect the absolute correctness of medical facts. Reinforcement Learning from Verifiable Rewards lacks effective automatic verifiers and struggles to handle complex clinical contexts. Meanwhile, medical alignment requires the simultaneous optimization of correctness, safety, and compliance, yet multi-objective heterogeneous reward signals are prone to scale mismatch and optimization conflicts.To address these challenges, we propose a robust medical alignment paradigm. We first construct a holistic multi-dimensional medical alignment matrix that decomposes alignment objectives into four categories: fundamental capabilities, expert knowledge, online feedback, and format specifications. Within each category, we establish a closed loop of where observable metrics inform attributable diagnosis, which in turn drives optimizable rewards, thereby providing fine-grained, high-resolution supervision signals for subsequent iterative optimization. To resolve gradient domination and optimization instability problem caused by heterogeneous signals, we further propose a unified optimization mechanism. This mechanism employs Reference-Frozen Normalization to align reward scales and implements a Tri-Factor Adaptive Dynamic Weighting strategy to achieve collaborative optimization that is weakness-oriented, risk-prioritized, and redundancy-reducing. Experimental results demonstrate the effectiveness of our proposed paradigm in real-world medical scenario evaluations, establishing a new paradigm for complex alignment in vertical domains.",
    "authors": [
      "Tianxiang Xu",
      "Jiayi Liu",
      "Yixuan Tong",
      "Jialu Xu",
      "Yunqing Wei",
      "Kaiwen Feng",
      "PanPan Hou",
      "Kangping Yin",
      "Jiyuan Hu",
      "Hao Zhou",
      "Zhenxin Ma",
      "Jian Xu",
      "Guanjun Jiang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11661v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11661v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.11639v1",
    "title": "PACE: Prefix-Protected and Difficulty-Aware Compression for Efficient Reasoning",
    "summary": "Language Reasoning Models (LRMs) achieve strong performance by scaling test-time computation but often suffer from ``overthinking'', producing excessively long reasoning traces that increase latency and memory usage. Existing LRMs typically enforce conciseness with uniform length penalties, which over-compress crucial early deduction steps at the sequence level and indiscriminately penalize all queries at the group level. To solve these limitations, we propose \\textbf{\\model}, a dual-level framework for prefix-protected and difficulty-aware compression under hierarchical supervision. At the sequence level, prefix-protected optimization employs decaying mixed rollouts to maintain valid reasoning paths while promoting conciseness. At the group level, difficulty-aware penalty dynamically scales length constraints based on query complexity, maintaining exploration for harder questions while curbing redundancy on easier ones. Extensive experiments on DeepSeek-R1-Distill-Qwen (1.5B/7B) demonstrate that \\model achieves a substantial reduction in token usage (up to \\textbf{55.7\\%}) while simultaneously improving accuracy (up to \\textbf{4.1\\%}) on math benchmarks, with generalization ability to code, science, and general domains.",
    "authors": [
      "Ruixiang Feng",
      "Yuntao Wen",
      "Silin Zhou",
      "Ke Shi",
      "Yifan Wang",
      "Ran Le",
      "Zhenwei An",
      "Zongchao Chen",
      "Chen Yang",
      "Guangyue Peng",
      "Yiming Jia",
      "Dongsheng Wang",
      "Tao Zhang",
      "Lisi Chen",
      "Yang Song",
      "Shen Gao",
      "Shuo Shang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11639v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11639v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2602.12108v1",
    "title": "The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context",
    "summary": "In the world of Harry Potter, when Dumbledore's mind is overburdened, he extracts memories into a Pensieve to be revisited later. In the world of AI, while we possess the Pensieve-mature databases and retrieval systems, our models inexplicably lack the \"wand\" to operate it. They remain like a Dumbledore without agency, passively accepting a manually engineered context as their entire memory. This work finally places the wand in the model's hand. We introduce StateLM, a new class of foundation models endowed with an internal reasoning loop to manage their own state. We equip our model with a suite of memory tools, such as context pruning, document indexing, and note-taking, and train it to actively manage these tools. By learning to dynamically engineering its own context, our model breaks free from the architectural prison of a fixed window. Experiments across various model sizes demonstrate StateLM's effectiveness across diverse scenarios. On long-document QA tasks, StateLMs consistently outperform standard LLMs across all model scales; on the chat memory task, they achieve absolute accuracy improvements of 10% to 20% over standard LLMs. On the deep research task BrowseComp-Plus, the performance gap becomes even more pronounced: StateLM achieves up to 52% accuracy, whereas standard LLM counterparts struggle around 5%. Ultimately, our approach shifts LLMs from passive predictors to state-aware agents where reasoning becomes a stateful and manageable process.",
    "authors": [
      "Xiaoyuan Liu",
      "Tian Liang",
      "Dongyang Ma",
      "Deyu Zhou",
      "Haitao Mi",
      "Pinjia He",
      "Yan Wang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12108v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12108v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.12047v1",
    "title": "Safety Beyond the Training Data: Robust Out-of-Distribution MPC via Conformalized System Level Synthesis",
    "summary": "We present a novel framework for robust out-of-distribution planning and control using conformal prediction (CP) and system level synthesis (SLS), addressing the challenge of ensuring safety and robustness when using learned dynamics models beyond the training data distribution. We first derive high-confidence model error bounds using weighted CP with a learned, state-control-dependent covariance model. These bounds are integrated into an SLS-based robust nonlinear model predictive control (MPC) formulation, which performs constraint tightening over the prediction horizon via volume-optimized forward reachable sets. We provide theoretical guarantees on coverage and robustness under distributional drift, and analyze the impact of data density and trajectory tube size on prediction coverage. Empirically, we demonstrate our method on nonlinear systems of increasing complexity, including a 4D car and a {12D} quadcopter, improving safety and robustness compared to fixed-bound and non-robust baselines, especially outside of the data distribution.",
    "authors": [
      "Anutam Srinivasan",
      "Antoine Leeman",
      "Glen Chou"
    ],
    "categories": [
      "cs.RO",
      "cs.LG",
      "eess.SY",
      "math.OC"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12047v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12047v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.12038v1",
    "title": "An Empirical Study of the Imbalance Issue in Software Vulnerability Detection",
    "summary": "Vulnerability detection is crucial to protect software security. Nowadays, deep learning (DL) is the most promising technique to automate this detection task, leveraging its superior ability to extract patterns and representations within extensive code volumes. Despite its promise, DL-based vulnerability detection remains in its early stages, with model performance exhibiting variability across datasets. Drawing insights from other well-explored application areas like computer vision, we conjecture that the imbalance issue (the number of vulnerable code is extremely small) is at the core of the phenomenon. To validate this, we conduct a comprehensive empirical study involving nine open-source datasets and two state-of-the-art DL models. The results confirm our conjecture. We also obtain insightful findings on how existing imbalance solutions perform in vulnerability detection. It turns out that these solutions perform differently as well across datasets and evaluation metrics. Specifically: 1) Focal loss is more suitable to improve the precision, 2) mean false error and class-balanced loss encourages the recall, and 3) random over-sampling facilitates the F1-measure. However, none of them excels across all metrics. To delve deeper, we explore external influences on these solutions and offer insights for developing new solutions.",
    "authors": [
      "Yuejun Guo",
      "Qiang Hu",
      "Qiang Tang",
      "Yves Le Traon"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12038v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12038v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.12036v1",
    "title": "Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models",
    "summary": "Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.",
    "authors": [
      "Xin Xu",
      "Clive Bai",
      "Kai Yang",
      "Tianhao Chen",
      "Yangkun Chen",
      "Weijie Liu",
      "Hao Chen",
      "Yang Wang",
      "Saiyong Yang",
      "Can Yang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12036v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12036v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.12014v1",
    "title": "FedGRPO: Privately Optimizing Foundation Models with Group-Relative Rewards from Domain Client",
    "summary": "One important direction of Federated Foundation Models (FedFMs) is leveraging data from small client models to enhance the performance of a large server-side foundation model. Existing methods based on model level or representation level knowledge transfer either require expensive local training or incur high communication costs and introduce unavoidable privacy risks. We reformulate this problem as a reinforcement learning style evaluation process and propose FedGRPO, a privacy preserving framework comprising two modules. The first module performs competence-based expert selection by building a lightweight confidence graph from auxiliary data to identify the most suitable clients for each question. The second module leverages the \"Group Relative\" concept from the Group Relative Policy Optimization (GRPO) framework by packaging each question together with its solution rationale into candidate policies, dispatching these policies to a selected subset of expert clients, and aggregating solely the resulting scalar reward signals via a federated group-relative loss function. By exchanging reward values instead of data or model updates, FedGRPO reduces privacy risk and communication overhead while enabling parallel evaluation across heterogeneous devices. Empirical results on diverse domain tasks demonstrate that FedGRPO achieves superior downstream accuracy and communication efficiency compared to conventional FedFMs baselines.",
    "authors": [
      "Gongxi Zhu",
      "Hanlin Gu",
      "Lixin Fan",
      "Qiang Yang",
      "Yuxing Han"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12014v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12014v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.12005v1",
    "title": "LaCy: What Small Language Models Can and Should Learn is Not Just a Question of Loss",
    "summary": "Language models have consistently grown to compress more world knowledge into their parameters, but the knowledge that can be pretrained into them is upper-bounded by their parameter size. Especially the capacity of Small Language Models (SLMs) is limited, leading to factually incorrect generations. This problem is often mitigated by giving the SLM access to an outside source: the ability to query a larger model, documents, or a database. Under this setting, we study the fundamental question of \\emph{which tokens an SLM can and should learn} during pretraining, versus \\emph{which ones it should delegate} via a \\texttt{<CALL>} token. We find that this is not simply a question of loss: although the loss is predictive of whether a predicted token mismatches the ground-truth, some tokens are \\emph{acceptable} in that they are truthful alternative continuations of a pretraining document, and should not trigger a \\texttt{<CALL>} even if their loss is high. We find that a spaCy grammar parser can help augment the loss signal to decide which tokens the SLM should learn to delegate to prevent factual errors and which are safe to learn and predict even under high losses. We propose LaCy, a novel pretraining method based on this token selection philosophy. Our experiments demonstrate that LaCy models successfully learn which tokens to predict and where to delegate for help. This results in higher FactScores when generating in a cascade with a bigger model and outperforms Rho or LLM-judge trained SLMs, while being simpler and cheaper.",
    "authors": [
      "Szilvia Ujváry",
      "Louis Béthune",
      "Pierre Ablin",
      "João Monteiro",
      "Marco Cuturi",
      "Michael Kirchhof"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12005v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12005v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.11945v1",
    "title": "Towards Performance-Enhanced Model-Contrastive Federated Learning using Historical Information in Heterogeneous Scenarios",
    "summary": "Federated Learning (FL) enables multiple nodes to collaboratively train a model without sharing raw data. However, FL systems are usually deployed in heterogeneous scenarios, where nodes differ in both data distributions and participation frequencies, which undermines the FL performance. To tackle the above issue, this paper proposes PMFL, a performance-enhanced model-contrastive federated learning framework using historical training information. Specifically, on the node side, we design a novel model-contrastive term into the node optimization objective by incorporating historical local models to capture stable contrastive points, thereby improving the consistency of model updates in heterogeneous data distributions.   On the server side, we utilize the cumulative participation count of each node to adaptively adjust its aggregation weight, thereby correcting the bias in the global objective caused by different node participation frequencies. Furthermore, the updated global model incorporates historical global models to reduce its fluctuations in performance between adjacent rounds. Extensive experiments demonstrate that PMFL achieves superior performance compared with existing FL methods in heterogeneous scenarios.",
    "authors": [
      "Hongliang Zhang",
      "Jiguo Yu",
      "Guijuan Wang",
      "Wenshuo Ma",
      "Tianqing He",
      "Baobao Chai",
      "Chunqiang Hu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11945v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11945v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.11880v1",
    "title": "SynthRAR: Ring Artifacts Reduction in CT with Unrolled Network and Synthetic Data Training",
    "summary": "Defective and inconsistent responses in CT detectors can cause ring and streak artifacts in the reconstructed images, making them unusable for clinical purposes. In recent years, several ring artifact reduction solutions have been proposed in the image domain or in the sinogram domain using supervised deep learning methods. However, these methods require dedicated datasets for training, leading to a high data collection cost. Furthermore, existing approaches focus exclusively on either image-space or sinogram-space correction, neglecting the intrinsic correlations from the forward operation of the CT geometry. Based on the theoretical analysis of non-ideal CT detector responses, the RAR problem is reformulated as an inverse problem by using an unrolled network, which considers non-ideal response together with linear forward-projection with CT geometry. Additionally, the intrinsic correlations of ring artifacts between the sinogram and image domains are leveraged through synthetic data derived from natural images, enabling the trained model to correct artifacts without requiring real-world clinical data. Extensive evaluations on diverse scanning geometries and anatomical regions demonstrate that the model trained on synthetic data consistently outperforms existing state-of-the-art methods.",
    "authors": [
      "Hongxu Yang",
      "Levente Lippenszky",
      "Edina Timko",
      "Gopal Avinash"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11880v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11880v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.11850v1",
    "title": "Free Lunch for Stabilizing Rectified Flow Inversion",
    "summary": "Rectified-Flow (RF)-based generative models have recently emerged as strong alternatives to traditional diffusion models, demonstrating state-of-the-art performance across various tasks. By learning a continuous velocity field that transforms simple noise into complex data, RF-based models not only enable high-quality generation, but also support training-free inversion, which facilitates downstream tasks such as reconstruction and editing. However, existing inversion methods, such as vanilla RF-based inversion, suffer from approximation errors that accumulate across timesteps, leading to unstable velocity fields and degraded reconstruction and editing quality. To address this challenge, we propose Proximal-Mean Inversion (PMI), a training-free gradient correction method that stabilizes the velocity field by guiding it toward a running average of past velocities, constrained within a theoretically derived spherical Gaussian. Furthermore, we introduce mimic-CFG, a lightweight velocity correction scheme for editing tasks, which interpolates between the current velocity and its projection onto the historical average, balancing editing effectiveness and structural consistency. Extensive experiments on PIE-Bench demonstrate that our methods significantly improve inversion stability, image reconstruction quality, and editing fidelity, while reducing the required number of neural function evaluations. Our approach achieves state-of-the-art performance on the PIE-Bench with enhanced efficiency and theoretical soundness.",
    "authors": [
      "Chenru Wang",
      "Beier Zhu",
      "Chi Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11850v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11850v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.11825v1",
    "title": "CAAL: Confidence-Aware Active Learning for Heteroscedastic Atmospheric Regression",
    "summary": "Quantifying the impacts of air pollution on health and climate relies on key atmospheric particle properties such as toxicity and hygroscopicity. However, these properties typically require complex observational techniques or expensive particle-resolved numerical simulations, limiting the availability of labeled data. We therefore estimate these hard-to-measure particle properties from routinely available observations (e.g., air pollutant concentrations and meteorological conditions). Because routine observations only indirectly reflect particle composition and structure, the mapping from routine observations to particle properties is noisy and input-dependent, yielding a heteroscedastic regression setting. With a limited and costly labeling budget, the central challenge is to select which samples to measure or simulate. While active learning is a natural approach, most acquisition strategies rely on predictive uncertainty. Under heteroscedastic noise, this signal conflates reducible epistemic uncertainty with irreducible aleatoric uncertainty, causing limited budgets to be wasted in noise-dominated regions. To address this challenge, we propose a confidence-aware active learning framework (CAAL) for efficient and robust sample selection in heteroscedastic settings. CAAL consists of two components: a decoupled uncertainty-aware training objective that separately optimises the predictive mean and noise level to stabilise uncertainty estimation, and a confidence-aware acquisition function that dynamically weights epistemic uncertainty using predicted aleatoric uncertainty as a reliability signal. Experiments on particle-resolved numerical simulations and real atmospheric observations show that CAAL consistently outperforms standard AL baselines. The proposed framework provides a practical and general solution for the efficient expansion of high-cost atmospheric particle property databases.",
    "authors": [
      "Fei Jiang",
      "Jiyang Xia",
      "Junjie Yu",
      "Mingfei Sun",
      "Hugh Coe",
      "David Topping",
      "Dantong Liu",
      "Zhenhui Jessie Li",
      "Zhonghua Zheng"
    ],
    "categories": [
      "cs.LG",
      "physics.ao-ph"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11825v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11825v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.11810v1",
    "title": "How to Sample High Quality 3D Fractals for Action Recognition Pre-Training?",
    "summary": "Synthetic datasets are being recognized in the deep learning realm as a valuable alternative to exhaustively labeled real data. One such synthetic data generation method is Formula Driven Supervised Learning (FDSL), which can provide an infinite number of perfectly labeled data through a formula driven approach, such as fractals or contours. FDSL does not have common drawbacks like manual labor, privacy and other ethical concerns. In this work we generate 3D fractals using 3D Iterated Function Systems (IFS) for pre-training an action recognition model. The fractals are temporally transformed to form a video that is used as a pre-training dataset for downstream task of action recognition. We find that standard methods of generating fractals are slow and produce degenerate 3D fractals. Therefore, we systematically explore alternative ways of generating fractals and finds that overly-restrictive approaches, while generating aesthetically pleasing fractals, are detrimental for downstream task performance. We propose a novel method, Targeted Smart Filtering, to address both the generation speed and fractal diversity issue. The method reports roughly 100 times faster sampling speed and achieves superior downstream performance against other 3D fractal filtering methods.",
    "authors": [
      "Marko Putak",
      "Thomas B. Moeslund",
      "Joakim Bruslund Haurum"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11810v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11810v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.11807v1",
    "title": "PuYun-LDM: A Latent Diffusion Model for High-Resolution Ensemble Weather Forecasts",
    "summary": "Latent diffusion models (LDMs) suffer from limited diffusability in high-resolution (<=0.25°) ensemble weather forecasting, where diffusability characterizes how easily a latent data distribution can be modeled by a diffusion process. Unlike natural image fields, meteorological fields lack task-agnostic foundation models and explicit semantic structures, making VFM-based regularization inapplicable. Moreover, existing frequency-based approaches impose identical spectral regularization across channels under a homogeneity assumption, which leads to uneven regularization strength under the inter-variable spectral heterogeneity in multivariate meteorological data. To address these challenges, we propose a 3D Masked AutoEncoder (3D-MAE) that encodes weather-state evolution features as an additional conditioning for the diffusion model, together with a Variable-Aware Masked Frequency Modeling (VA-MFM) strategy that adaptively selects thresholds based on the spectral energy distribution of each variable. Together, we propose PuYun-LDM, which enhances latent diffusability and achieves superior performance to ENS at short lead times while remaining comparable to ENS at longer horizons. PuYun-LDM generates a 15-day global forecast with a 6-hour temporal resolution in five minutes on a single NVIDIA H200 GPU, while ensemble forecasts can be efficiently produced in parallel.",
    "authors": [
      "Lianjun Wu",
      "Shengchen Zhu",
      "Yuxuan Liu",
      "Liuyu Kai",
      "Xiaoduan Feng",
      "Duomin Wang",
      "Wenshuo Liu",
      "Jingxuan Zhang",
      "Kelvin Li",
      "Bin Wang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11807v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11807v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.11802v1",
    "title": "TopoFair: Linking Topological Bias to Fairness in Link Prediction Benchmarks",
    "summary": "Graph link prediction (LP) plays a critical role in socially impactful applications, such as job recommendation and friendship formation. Ensuring fairness in this task is thus essential. While many fairness-aware methods manipulate graph structures to mitigate prediction disparities, the topological biases inherent to social graph structures remain poorly understood and are often reduced to homophily alone. This undermines the generalization potential of fairness interventions and limits their applicability across diverse network topologies. In this work, we propose a novel benchmarking framework for fair LP, centered on the structural biases of the underlying graphs. We begin by reviewing and formalizing a broad taxonomy of topological bias measures relevant to fairness in graphs. In parallel, we introduce a flexible graph generation method that simultaneously ensures fidelity to real-world graph patterns and enables controlled variation across a wide spectrum of structural biases. We apply this framework to evaluate both classical and fairness-aware LP models across multiple use cases. Our results provide a fine-grained empirical analysis of the interactions between predictive fairness and structural biases. This new perspective reveals the sensitivity of fairness interventions to beyond-homophily biases and underscores the need for structurally grounded fairness evaluations in graph learning.",
    "authors": [
      "Lilian Marey",
      "Mathilde Perez",
      "Tiphaine Viard",
      "Charlotte Laclau"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11802v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11802v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.11771v1",
    "title": "How to Optimize Multispecies Set Predictions in Presence-Absence Modeling ?",
    "summary": "Species distribution models (SDMs) commonly produce probabilistic occurrence predictions that must be converted into binary presence-absence maps for ecological inference and conservation planning. However, this binarization step is typically heuristic and can substantially distort estimates of species prevalence and community composition. We present MaxExp, a decision-driven binarization framework that selects the most probable species assemblage by directly maximizing a chosen evaluation metric. MaxExp requires no calibration data and is flexible across several scores. We also introduce the Set Size Expectation (SSE) method, a computationally efficient alternative that predicts assemblages based on expected species richness. Using three case studies spanning diverse taxa, species counts, and performance metrics, we show that MaxExp consistently matches or surpasses widely used thresholding and calibration methods, especially under strong class imbalance and high rarity. SSE offers a simpler yet competitive option. Together, these methods provide robust, reproducible tools for multispecies SDM binarization.",
    "authors": [
      "Sébastien Gigot--Léandri",
      "Gaétan Morand",
      "Alexis Joly",
      "François Munoz",
      "David Mouillot",
      "Christophe Botella",
      "Maximilien Servajean"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11771v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11771v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.11767v1",
    "title": "TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents",
    "summary": "Advances in large language models (LLMs) are driving a shift toward using reinforcement learning (RL) to train agents from iterative, multi-turn interactions across tasks. However, multi-turn RL remains challenging as rewards are often sparse or delayed, and environments can be stochastic. In this regime, naive trajectory sampling can hinder exploitation and induce mode collapse. We propose TSR (Trajectory-Search Rollouts), a training-time approach that repurposes test-time scaling ideas for improved per-turn rollout generation. TSR performs lightweight tree-style search to construct high-quality trajectories by selecting high-scoring actions at each turn using task-specific feedback. This improves rollout quality and stabilizes learning while leaving the underlying optimization objective unchanged, making TSR optimizer-agnostic. We instantiate TSR with best-of-N, beam, and shallow lookahead search, and pair it with PPO and GRPO, achieving up to 15% performance gains and more stable learning on Sokoban, FrozenLake, and WebShop tasks at a one-time increase in training compute. By moving search from inference time to the rollout stage of training, TSR provides a simple and general mechanism for stronger multi-turn agent learning, complementary to existing frameworks and rejection-sampling-style selection methods.",
    "authors": [
      "Aladin Djuhera",
      "Swanand Ravindra Kadhe",
      "Farhan Ahmed",
      "Holger Boche"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11767v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11767v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.11750v1",
    "title": "AmbiBench: Benchmarking Mobile GUI Agents Beyond One-Shot Instructions in the Wild",
    "summary": "Benchmarks are paramount for gauging progress in the domain of Mobile GUI Agents. In practical scenarios, users frequently fail to articulate precise directives containing full task details at the onset, and their expressions are typically ambiguous. Consequently, agents are required to converge on the user's true intent via active clarification and interaction during execution. However, existing benchmarks predominantly operate under the idealized assumption that user-issued instructions are complete and unequivocal. This paradigm focuses exclusively on assessing single-turn execution while overlooking the alignment capability of the agent. To address this limitation, we introduce AmbiBench, the first benchmark incorporating a taxonomy of instruction clarity to shift evaluation from unidirectional instruction following to bidirectional intent alignment. Grounded in Cognitive Gap theory, we propose a taxonomy of four clarity levels: Detailed, Standard, Incomplete, and Ambiguous. We construct a rigorous dataset of 240 ecologically valid tasks across 25 applications, subject to strict review protocols. Furthermore, targeting evaluation in dynamic environments, we develop MUSE (Mobile User Satisfaction Evaluator), an automated framework utilizing an MLLM-as-a-judge multi-agent architecture. MUSE performs fine-grained auditing across three dimensions: Outcome Effectiveness, Execution Quality, and Interaction Quality. Empirical results on AmbiBench reveal the performance boundaries of SoTA agents across different clarity levels, quantify the gains derived from active interaction, and validate the strong correlation between MUSE and human judgment. This work redefines evaluation standards, laying the foundation for next-generation agents capable of truly understanding user intent.",
    "authors": [
      "Jiazheng Sun",
      "Mingxuan Li",
      "Yingying Zhang",
      "Jiayang Niu",
      "Yachen Wu",
      "Ruihan Jin",
      "Shuyu Lei",
      "Pengrongrui Tan",
      "Zongyu Zhang",
      "Ruoyi Wang",
      "Jiachen Yang",
      "Boyu Yang",
      "Jiacheng Liu",
      "Xin Peng"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11750v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11750v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.11700v1",
    "title": "TabSieve: Explicit In-Table Evidence Selection for Tabular Prediction",
    "summary": "Tabular prediction can benefit from in-table rows as few-shot evidence, yet existing tabular models typically perform instance-wise inference and LLM-based prompting is often brittle. Models do not consistently leverage relevant rows, and noisy context can degrade performance. To address this challenge, we propose TabSieve, a select-then-predict framework that makes evidence usage explicit and auditable. Given a table and a query row, TabSieve first selects a small set of informative rows as evidence and then predicts the missing target conditioned on the selected evidence. To enable this capability, we construct TabSieve-SFT-40K by synthesizing high-quality reasoning trajectories from 331 real tables using a strong teacher model with strict filtering. Furthermore, we introduce TAB-GRPO, a reinforcement learning recipe that jointly optimizes evidence selection and prediction correctness with separate rewards, and stabilizes mixed regression and classification training via dynamic task-advantage balancing. Experiments on a held-out benchmark of 75 classification and 52 regression tables show that TabSieve consistently improves performance across shot budgets, with average gains of 2.92% on classification and 4.45% on regression over the second-best baseline. Further analysis indicates that TabSieve concentrates more attention on the selected evidence, which improves robustness to noisy context.",
    "authors": [
      "Yongyao Wang",
      "Ziqi Miao",
      "Lu Yang",
      "Haonan Jia",
      "Wenting Yan",
      "Chen Qian",
      "Lijun Li"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11700v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11700v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2602.12045v1",
    "title": "Fourier Transformers for Latent Crystallographic Diffusion and Generative Modeling",
    "summary": "The discovery of new crystalline materials calls for generative models that handle periodic boundary conditions, crystallographic symmetries, and physical constraints, while scaling to large and structurally diverse unit cells. We propose a reciprocal-space generative pipeline that represents crystals through a truncated Fourier transform of the species-resolved unit-cell density, rather than modeling atomic coordinates directly. This representation is periodicity-native, admits simple algebraic actions of space-group symmetries, and naturally supports variable atomic multiplicities during generation, addressing a common limitation of particle-based approaches. Using only nine Fourier basis functions per spatial dimension, our approach reconstructs unit cells containing up to 108 atoms per chemical species. We instantiate this pipeline with a transformer variational autoencoder over complex-valued Fourier coefficients, and a latent diffusion model that generates in the compressed latent space. We evaluate reconstruction and latent diffusion on the LeMaterial benchmark and compare unconditional generation against coordinate-based baselines in the small-cell regime ($\\leq 16$ atoms per unit cell).",
    "authors": [
      "Jed A. Duersch",
      "Elohan Veillon",
      "Astrid Klipfel",
      "Adlane Sayede",
      "Zied Bouraoui"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12045v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12045v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2602.12021v1",
    "title": "Improved state mixing in higher-order and block diagonal linear recurrent networks",
    "summary": "Linear recurrent networks (LRNNs) and linear state space models (SSMs) promise computational and memory efficiency on long-sequence modeling tasks, yet their diagonal state transitions limit expressivity. Dense and nonlinear architectures (e.g., LSTMs) on the other hand are provably more expressive, but computationally costly. Here, we explore how expressivity in LRNNs can be increased via richer state mixing across time and channels while maintaining competitive efficiency. Specifically, we introduce two structured LRNN architectures: (i) Higher-order Linear Recurrent Units (H-LRU), which generalize first-order recurrence to higher order, mixing multiple past states, and (ii) Block-Diagonal LRUs (BD-LRU), which enable dense intra-block channel mixing. Per-channel (H-LRU) or per-row (BD-LRU) L1-normalization of selective gates stabilizes training and allows for scaling window/block sizes. A parallel-scan implementation of the proposed architectures keeps the throughput competitive with diagonal LRNNs for moderate orders (H-LRU) and block sizes (BD-LRU). In synthetic sequence modeling tasks, the performance of BD-LRU matches or exceeds those of linear SSMs (Mamba), low-rank LRNNs (DeltaNet) and LSTM baselines, while H-LRU is found to be the most parameter-efficient in compression task. In both synthetic sequence modeling and language modeling, our results indicate that the structure of state mixing rather than width alone shapes expressivity of LRNNs, offering a practical route to closing the efficiency-expressivity gap in linear sequence models.",
    "authors": [
      "Igor Dubinin",
      "Antonio Orvieto",
      "Felix Effenberger"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12021v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12021v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2602.11881v1",
    "title": "From Atoms to Trees: Building a Structured Feature Forest with Hierarchical Sparse Autoencoders",
    "summary": "Sparse autoencoders (SAEs) have proven effective for extracting monosemantic features from large language models (LLMs), yet these features are typically identified in isolation. However, broad evidence suggests that LLMs capture the intrinsic structure of natural language, where the phenomenon of \"feature splitting\" in particular indicates that such structure is hierarchical. To capture this, we propose the Hierarchical Sparse Autoencoder (HSAE), which jointly learns a series of SAEs and the parent-child relationships between their features. HSAE strengthens the alignment between parent and child features through two novel mechanisms: a structural constraint loss and a random feature perturbation mechanism. Extensive experiments across various LLMs and layers demonstrate that HSAE consistently recovers semantically meaningful hierarchies, supported by both qualitative case studies and rigorous quantitative metrics. At the same time, HSAE preserves the reconstruction fidelity and interpretability of standard SAEs across different dictionary sizes. Our work provides a powerful, scalable tool for discovering and analyzing the multi-scale conceptual structures embedded in LLM representations.",
    "authors": [
      "Yifan Luo",
      "Yang Zhan",
      "Jiedong Jiang",
      "Tianyang Liu",
      "Mingrui Wu",
      "Zhennan Zhou",
      "Bin Dong"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11881v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11881v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2602.11824v1",
    "title": "Revis: Sparse Latent Steering to Mitigate Object Hallucination in Large Vision-Language Models",
    "summary": "Despite the advanced capabilities of Large Vision-Language Models (LVLMs), they frequently suffer from object hallucination. One reason is that visual features and pretrained textual representations often become intertwined in the deeper network layers. To address this, we propose REVIS, a training-free framework designed to explicitly re-activate this suppressed visual information. Rooted in latent space geometry, REVIS extracts the pure visual information vector via orthogonal projection and employs a calibrated strategy to perform sparse intervention only at the precise depth where suppression occurs. This surgical approach effectively restores visual information with minimal computational cost. Empirical evaluations on standard benchmarks demonstrate that REVIS reduces object hallucination rates by approximately 19% compared to state-of-the-art baselines, while preserving general reasoning capabilities.",
    "authors": [
      "Jialin Wu",
      "Wei Shi",
      "Han Shen",
      "Peigui Qi",
      "Kunsheng Tang",
      "Zhicong Huang",
      "Binghao Wang",
      "Zhou Yang"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11824v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11824v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2602.11780v1",
    "title": "RELATE: A Reinforcement Learning-Enhanced LLM Framework for Advertising Text Generation",
    "summary": "In online advertising, advertising text plays a critical role in attracting user engagement and driving advertiser value. Existing industrial systems typically follow a two-stage paradigm, where candidate texts are first generated and subsequently aligned with online performance metrics such as click-through rate(CTR). This separation often leads to misaligned optimization objectives and low funnel efficiency, limiting global optimality.   To address these limitations, we propose RELATE, a reinforcement learning-based end-to-end framework that unifies generation and objective alignment within a single model. Instead of decoupling text generation from downstream metric alignment, RELATE integrates performance and compliance objectives directly into the generation process via policy learning. To better capture ultimate advertiser value beyond click-level signals, We incorporate conversion-oriented metrics into the objective and jointly model them with compliance constraints as multi-dimensional rewards, enabling the model to generate high-quality ad texts that improve conversion performance under policy constraints.   Extensive experiments on large-scale industrial datasets demonstrate that RELATE consistently outperforms baselines. Furthermore, online deployment on a production advertising platform yields statistically significant improvements in click-through conversion rate(CTCVR) under strict policy constraints, validating the robustness and real-world effectiveness of the proposed framework.",
    "authors": [
      "Jinfang Wang",
      "Jiajie Liu",
      "Jianwei Wu",
      "Ziqin Luo",
      "Zhen Chen",
      "Chunlei Li",
      "Biao Han",
      "Tao Deng",
      "Yi Li",
      "Shuanglong Li",
      "Lin Liu"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11780v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11780v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2602.11743v1",
    "title": "Adaptive Debiasing Tsallis Entropy for Test-Time Adaptation",
    "summary": "Mainstream Test-Time Adaptation (TTA) methods for adapting vision-language models, e.g., CLIP, typically rely on Shannon Entropy (SE) at test time to measure prediction uncertainty and inconsistency. However, since CLIP has a built-in bias from pretraining on highly imbalanced web-crawled data, SE inevitably results in producing biased estimates of uncertainty entropy. To address this issue, we notably find and demonstrate that Tsallis Entropy (TE), a generalized form of SE, is naturally suited for characterizing biased distributions by introducing a non-extensive parameter q, with the performance of SE serving as a lower bound for TE. Building upon this, we generalize TE into Adaptive Debiasing Tsallis Entropy (ADTE) for TTA, customizing a class-specific parameter q^l derived by normalizing the estimated label bias from continuously incoming test instances, for each category. This adaptive approach allows ADTE to accurately select high-confidence views and seamlessly integrate with a label adjustment strategy to enhance adaptation, without introducing distribution-specific hyperparameter tuning. Besides, our investigation reveals that both TE and ADTE can serve as direct, advanced alternatives to SE in TTA, without any other modifications. Experimental results show that ADTE outperforms state-of-the-art methods on ImageNet and its five variants, and achieves the highest average performance on 10 cross-domain benchmarks, regardless of the model architecture or text prompts used. Our code is available at https://github.com/Jinx630/ADTE.",
    "authors": [
      "Xiangyu Wu",
      "Dongming Jiang",
      "Feng Yu",
      "Yueying Tian",
      "Jiaqi Tang",
      "Qing-Guo Chen",
      "Yang Yang",
      "Jianfeng Lu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11743v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11743v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2602.12123v1",
    "title": "Meta-Sel: Efficient Demonstration Selection for In-Context Learning via Supervised Meta-Learning",
    "summary": "Demonstration selection is a practical bottleneck in in-context learning (ICL): under a tight prompt budget, accuracy can change substantially depending on which few-shot examples are included, yet selection must remain cheap enough to run per query over large candidate pools. We propose Meta-Sel, a lightweight supervised meta-learning approach for intent classification that learns a fast, interpretable scoring function for (candidate, query) pairs from labeled training data.   Meta-Sel constructs a meta-dataset by sampling pairs from the training split and using class agreement as supervision, then trains a calibrated logistic regressor on two inexpensive meta-features: TF--IDF cosine similarity and a length-compatibility ratio. At inference time, the selector performs a single vectorized scoring pass over the full candidate pool and returns the top-k demonstrations, requiring no model fine-tuning, no online exploration, and no additional LLM calls. This yields deterministic rankings and makes the selection mechanism straightforward to audit via interpretable feature weights.   Beyond proposing Meta-Sel, we provide a broad empirical study of demonstration selection, benchmarking 12 methods -- spanning prompt engineering baselines, heuristic selection, reinforcement learning, and influence-based approaches -- across four intent datasets and five open-source LLMs. Across this benchmark, Meta-Sel consistently ranks among the top-performing methods, is particularly effective for smaller models where selection quality can partially compensate for limited model capacity, and maintains competitive selection-time overhead.",
    "authors": [
      "Xubin Wang",
      "Weijia Jia"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12123v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12123v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.11995v1",
    "title": "Momentum LMS Theory beyond Stationarity: Stability, Tracking, and Regret",
    "summary": "In large-scale data processing scenarios, data often arrive in sequential streams generated by complex systems that exhibit drifting distributions and time-varying system parameters. This nonstationarity challenges theoretical analysis, as it violates classical assumptions of i.i.d. (independent and identically distributed) samples, necessitating algorithms capable of real-time updates without expensive retraining. An effective approach should process each sample in a single pass, while maintaining computational and memory complexities independent of the data stream length. Motivated by these challenges, this paper investigates the Momentum Least Mean Squares (MLMS) algorithm as an adaptive identification tool, leveraging its computational simplicity and online processing capabilities. Theoretically, we derive tracking performance and regret bounds for the MLMS in time-varying stochastic linear systems under various practical conditions. Unlike classical LMS, whose stability can be characterized by first-order random vector difference equations, MLMS introduces an additional dynamical state due to momentum, leading to second-order time-varying random vector difference equations whose stability analysis hinges on more complicated products of random matrices, which poses a substantially challenging problem to resolve. Experiments on synthetic and real-world data streams demonstrate that MLMS achieves rapid adaptation and robust tracking, in agreement with our theoretical results especially in nonstationary settings, highlighting its promise for modern streaming and online learning applications.",
    "authors": [
      "Yifei Jin",
      "Xin Zheng",
      "Lei Guo"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11995v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11995v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.11937v1",
    "title": "Extending Puzzle for Mixture-of-Experts Reasoning Models with Application to GPT-OSS Acceleration",
    "summary": "Reasoning-focused LLMs improve answer quality by generating longer reasoning traces, but the additional tokens dramatically increase serving cost, motivating inference optimization. We extend and apply Puzzle, a post-training neural architecture search (NAS) framework, to gpt-oss-120B to produce gpt-oss-puzzle-88B, a deployment-optimized derivative. Our approach combines heterogeneous MoE expert pruning, selective replacement of full-context attention with window attention, FP8 KV-cache quantization with calibrated scales, and post-training reinforcement learning to recover accuracy, while maintaining low generation length. In terms of per-token speeds, on an 8XH100 node we achieve 1.63X and 1.22X throughput speedups in long-context and short-context settings, respectively. gpt-oss-puzzle-88B also delivers throughput speedups of 2.82X on a single NVIDIA H100 GPU. However, because token counts can change with reasoning effort and model variants, per-token throughput (tok/s) and latency (ms/token) do not necessarily lead to end-to-end speedups: a 2X throughput gain is erased if traces grow 2X. Conversely, throughput gains can be spent on more reasoning tokens to improve accuracy; we therefore advocate request-level efficiency metrics that normalize throughput by tokens generated and trace an accuracy--speed frontier across reasoning efforts. We show that gpt-oss-puzzle-88B improves over gpt-oss-120B along the entire frontier, delivering up to 1.29X higher request-level efficiency. Across various benchmarks, gpt-oss-puzzle-88B matches or slightly exceeds the parent on suite-average accuracy across reasoning efforts, with retention ranging from 100.8% (high) to 108.2% (low), showing that post-training architecture search can substantially reduce inference costs without sacrificing quality.",
    "authors": [
      "Akhiad Bercovich",
      "Nir Ailon",
      "Vladimir Anisimov",
      "Tomer Asida",
      "Nave Assaf",
      "Mohammad Dabbah",
      "Ido Galil",
      "Amnon Geifman",
      "Yonatan Geifman",
      "Izhak Golan",
      "Roi Koren",
      "Itay Levy",
      "Zach Moshe",
      "Pavlo Molchanov",
      "Najeeb Nabwani",
      "Mostofa Patwari",
      "Omri Puny",
      "Tomer Ronen",
      "Itamar Schen",
      "Elad Segal",
      "Ido Shahaf",
      "Oren Tropp",
      "Ran Zilberstein",
      "Ran El-Yaniv"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11937v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11937v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.11931v1",
    "title": "AdaptEvolve: Improving Efficiency of Evolutionary AI Agents through Adaptive Model Selection",
    "summary": "Evolutionary agentic systems intensify the trade-off between computational efficiency and reasoning capability by repeatedly invoking large language models (LLMs) during inference. This setting raises a central question: how can an agent dynamically select an LLM that is sufficiently capable for the current generation step while remaining computationally efficient? While model cascades offer a practical mechanism for balancing this trade-off, existing routing strategies typically rely on static heuristics or external controllers and do not explicitly account for model uncertainty. We introduce AdaptEvolve: Adaptive LLM Selection for Multi-LLM Evolutionary Refinement within an evolutionary sequential refinement framework that leverages intrinsic generation confidence to estimate real-time solvability. Empirical results show that confidence-driven selection yields a favourable Pareto frontier, reducing total inference cost by an average of 37.9% across benchmarks while retaining 97.5% of the upper-bound accuracy of static large-model baselines. Our code is available at https://github.com/raypretam/adaptive_llm_selection.",
    "authors": [
      "Pretam Ray",
      "Pratik Prabhanjan Brahma",
      "Zicheng Liu",
      "Emad Barsoum"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11931v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11931v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.11897v1",
    "title": "Agentic AI for Cybersecurity: A Meta-Cognitive Architecture for Governable Autonomy",
    "summary": "Contemporary AI-driven cybersecurity systems are predominantly architected as model-centric detection and automation pipelines optimized for task-level performance metrics such as accuracy and response latency. While effective for bounded classification tasks, these architectures struggle to support accountable decision-making under adversarial uncertainty, where actions must be justified, governed, and aligned with organizational and regulatory constraints. This paper argues that cybersecurity orchestration should be reconceptualized as an agentic, multi-agent cognitive system, rather than a linear sequence of detection and response components. We introduce a conceptual architectural framework in which heterogeneous AI agents responsible for detection, hypothesis formation, contextual interpretation, explanation, and governance are coordinated through an explicit meta-cognitive judgement function. This function governs decision readiness and dynamically calibrates system autonomy when evidence is incomplete, conflicting, or operationally risky. By synthesizing distributed cognition theory, multi-agent systems research, and responsible AI governance frameworks, we demonstrate that modern security operations already function as distributed cognitive systems, albeit without an explicit organizing principle. Our contribution is to make this cognitive structure architecturally explicit and governable by embedding meta-cognitive judgement as a first-class system function. We discuss implications for security operations centers, accountable autonomy, and the design of next-generation AI-enabled cyber defence architectures. The proposed framework shifts the focus of AI in cybersecurity from optimizing isolated predictions to governing autonomy under uncertainty.",
    "authors": [
      "Andrei Kojukhov",
      "Arkady Bovshover"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11897v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11897v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.11893v1",
    "title": "Universal Diffusion-Based Probabilistic Downscaling",
    "summary": "We introduce a universal diffusion-based downscaling framework that lifts deterministic low-resolution weather forecasts into probabilistic high-resolution predictions without any model-specific fine-tuning. A single conditional diffusion model is trained on paired coarse-resolution inputs (~25 km resolution) and high-resolution regional reanalysis targets (~5 km resolution), and is applied in a fully zero-shot manner to deterministic forecasts from heterogeneous upstream weather models. Focusing on near-surface variables, we evaluate probabilistic forecasts against independent in situ station observations over lead times up to 90 h. Across a diverse set of AI-based and numerical weather prediction (NWP) systems, the ensemble mean of the downscaled forecasts consistently improves upon each model's own raw deterministic forecast, and substantially larger gains are observed in probabilistic skill as measured by CRPS. These results demonstrate that diffusion-based downscaling provides a scalable, model-agnostic probabilistic interface for enhancing spatial resolution and uncertainty representation in operational weather forecasting pipelines.",
    "authors": [
      "Roberto Molinaro",
      "Niall Siegenheim",
      "Henry Martin",
      "Mark Frey",
      "Niels Poulsen",
      "Philipp Seitz",
      "Marvin Vincent Gabler"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11893v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11893v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.11861v1",
    "title": "A$^{2}$V-SLP: Alignment-Aware Variational Modeling for Disentangled Sign Language Production",
    "summary": "Building upon recent structural disentanglement frameworks for sign language production, we propose A$^{2}$V-SLP, an alignment-aware variational framework that learns articulator-wise disentangled latent distributions rather than deterministic embeddings. A disentangled Variational Autoencoder (VAE) encodes ground-truth sign pose sequences and extracts articulator-specific mean and variance vectors, which are used as distributional supervision for training a non-autoregressive Transformer. Given text embeddings, the Transformer predicts both latent means and log-variances, while the VAE decoder reconstructs the final sign pose sequences through stochastic sampling at the decoding stage. This formulation maintains articulator-level representations by avoiding deterministic latent collapse through distributional latent modeling. In addition, we integrate a gloss attention mechanism to strengthen alignment between linguistic input and articulated motion. Experimental results show consistent gains over deterministic latent regression, achieving state-of-the-art back-translation performance and improved motion realism in a fully gloss-free setting.",
    "authors": [
      "Sümeyye Meryem Taşyürek",
      "Enis Mücahid İskender",
      "Hacer Yalim Keles"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11861v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11861v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.11799v1",
    "title": "Hi-SAM: A Hierarchical Structure-Aware Multi-modal Framework for Large-Scale Recommendation",
    "summary": "Multi-modal recommendation has gained traction as items possess rich attributes like text and images. Semantic ID-based approaches effectively discretize this information into compact tokens. However, two challenges persist: (1) Suboptimal Tokenization: existing methods (e.g., RQ-VAE) lack disentanglement between shared cross-modal semantics and modality-specific details, causing redundancy or collapse; (2) Architecture-Data Mismatch: vanilla Transformers treat semantic IDs as flat streams, ignoring the hierarchy of user interactions, items, and tokens. Expanding items into multiple tokens amplifies length and noise, biasing attention toward local details over holistic semantics. We propose Hi-SAM, a Hierarchical Structure-Aware Multi-modal framework with two designs: (1) Disentangled Semantic Tokenizer (DST): unifies modalities via geometry-aware alignment and quantizes them via a coarse-to-fine strategy. Shared codebooks distill consensus while modality-specific ones recover nuances from residuals, enforced by mutual information minimization; (2) Hierarchical Memory-Anchor Transformer (HMAT): splits positional encoding into inter- and intra-item subspaces via Hierarchical RoPE to restore hierarchy. It inserts Anchor Tokens to condense items into compact memory, retaining details for the current item while accessing history only through compressed summaries. Experiments on real-world datasets show consistent improvements over SOTA baselines, especially in cold-start scenarios. Deployed on a large-scale social platform serving millions of users, Hi-SAM achieved a 6.55% gain in the core online metric.",
    "authors": [
      "Pingjun Pan",
      "Tingting Zhou",
      "Peiyao Lu",
      "Tingting Fei",
      "Hongxiang Chen",
      "Chuanjiang Luo"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11799v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11799v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.11706v1",
    "title": "LLM-Driven 3D Scene Generation of Agricultural Simulation Environments",
    "summary": "Procedural generation techniques in 3D rendering engines have revolutionized the creation of complex environments, reducing reliance on manual design. Recent approaches using Large Language Models (LLMs) for 3D scene generation show promise but often lack domain-specific reasoning, verification mechanisms, and modular design. These limitations lead to reduced control and poor scalability. This paper investigates the use of LLMs to generate agricultural synthetic simulation environments from natural language prompts, specifically to address the limitations of lacking domain-specific reasoning, verification mechanisms, and modular design. A modular multi-LLM pipeline was developed, integrating 3D asset retrieval, domain knowledge injection, and code generation for the Unreal rendering engine using its API. This results in a 3D environment with realistic planting layouts and environmental context, all based on the input prompt and the domain knowledge. To enhance accuracy and scalability, the system employs a hybrid strategy combining LLM optimization techniques such as few-shot prompting, Retrieval-Augmented Generation (RAG), finetuning, and validation. Unlike monolithic models, the modular architecture enables structured data handling, intermediate verification, and flexible expansion. The system was evaluated using structured prompts and semantic accuracy metrics. A user study assessed realism and familiarity against real-world images, while an expert comparison demonstrated significant time savings over manual scene design. The results confirm the effectiveness of multi-LLM pipelines in automating domain-specific 3D scene generation with improved reliability and precision. Future work will explore expanding the asset hierarchy, incorporating real-time generation, and adapting the pipeline to other simulation domains beyond agriculture.",
    "authors": [
      "Arafa Yoncalik",
      "Wouter Jansen",
      "Nico Huebel",
      "Mohammad Hasan Rahmani",
      "Jan Steckel"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11706v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11706v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2602.12117v1",
    "title": "KAN-FIF: Spline-Parameterized Lightweight Physics-based Tropical Cyclone Estimation on Meteorological Satellite",
    "summary": "Tropical cyclones (TC) are among the most destructive natural disasters, causing catastrophic damage to coastal regions through extreme winds, heavy rainfall, and storm surges. Timely monitoring of tropical cyclones is crucial for reducing loss of life and property, yet it is hindered by the computational inefficiency and high parameter counts of existing methods on resource-constrained edge devices. Current physics-guided models suffer from linear feature interactions that fail to capture high-order polynomial relationships between TC attributes, leading to inflated model sizes and hardware incompatibility. To overcome these challenges, this study introduces the Kolmogorov-Arnold Network-based Feature Interaction Framework (KAN-FIF), a lightweight multimodal architecture that integrates MLP and CNN layers with spline-parameterized KAN layers. For Maximum Sustained Wind (MSW) prediction, experiments demonstrate that the KAN-FIF framework achieves a $94.8\\%$ reduction in parameters (0.99MB vs 19MB) and $68.7\\%$ faster inference per sample (2.3ms vs 7.35ms) compared to baseline model Phy-CoCo, while maintaining superior accuracy with $32.5\\%$ lower MAE. The offline deployment experiment of the FY-4 series meteorological satellite processor on the Qingyun-1000 development board achieved a 14.41ms per-sample inference latency with the KAN-FIF framework, demonstrating promising feasibility for operational TC monitoring and extending deployability to edge-device AI applications. The code is released at https://github.com/Jinglin-Zhang/KAN-FIF.",
    "authors": [
      "Jiakang Shen",
      "Qinghui Chen",
      "Runtong Wang",
      "Chenrui Xu",
      "Jinglin Zhang",
      "Cong Bai",
      "Feng Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12117v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12117v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.12004v1",
    "title": "CSEval: A Framework for Evaluating Clinical Semantics in Text-to-Image Generation",
    "summary": "Text-to-image generation has been increasingly applied in medical domains for various purposes such as data augmentation and education. Evaluating the quality and clinical reliability of these generated images is essential. However, existing methods mainly assess image realism or diversity, while failing to capture whether the generated images reflect the intended clinical semantics, such as anatomical location and pathology. In this study, we propose the Clinical Semantics Evaluator (CSEval), a framework that leverages language models to assess clinical semantic alignment between the generated images and their conditioning prompts. Our experiments show that CSEval identifies semantic inconsistencies overlooked by other metrics and correlates with expert judgment. CSEval provides a scalable and clinically meaningful complement to existing evaluation methods, supporting the safe adoption of generative models in healthcare.",
    "authors": [
      "Robert Cronshaw",
      "Konstantinos Vilouras",
      "Junyu Yan",
      "Yuning Du",
      "Feng Chen",
      "Steven McDonagh",
      "Sotirios A. Tsaftaris"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12004v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12004v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.11902v1",
    "title": "Mitigating Mismatch within Reference-based Preference Optimization",
    "summary": "Direct Preference Optimization (DPO) has become the de facto standard for offline preference alignment of large language models, but its reliance on a reference policy introduces a critical tension. DPO weighs each update relative to a reference, which stabilizes the training by regularizing the updates within a trusted region. This reliance becomes problematic for pessimistic pairs, where the reference model prefers the rejected response. For these pairs, DPO prematurely attenuates the gradient as soon as the policy margin ($Δ_θ$) merely beats the reference margin ($Δ_{\\mathrm{ref}}$) even if the policy is still wrong ($Δ_θ<0$). We name this failure premature satisfaction, which is a concrete form of the training-inference mismatch. Reference-free objectives remove this mismatch by optimizing the absolute margin, but at the cost of discarding the stabilizing signal of the reference. We mitigate this tension with Hybrid-DPO (HyPO), a drop-in modification to DPO that applies reference conditionally: HyPO behaves exactly like DPO when the reference is optimistic or neutral, and it treats the reference as neutral when it is pessimistic by replacing $Δ_θ-Δ_{\\mathrm{ref}}$ with $Δ_θ-\\max\\{0,Δ_{\\mathrm{ref}}\\}$. This one-line change strictly strengthens per-example learning signals on pessimistic pairs while preserving DPO's objective form and computational cost. By conditionally debiasing the pessimistic reference signal, HyPO mitigates premature satisfaction; empirically, across preference alignment, HyPO improves inference-aligned metrics and achieves higher pairwise win rates. Our results provide evidence that direct preference alignment could be enhanced by conditionally debiasing the reference signal, rather than discarding it.",
    "authors": [
      "Suqin Yuan",
      "Xingrui Yu",
      "Jiyang Zheng",
      "Lei Feng",
      "Dadong Wang",
      "Ivor Tsang",
      "Tongliang Liu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11902v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11902v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.11882v1",
    "title": "Where Bits Matter in World Model Planning: A Paired Mixed-Bit Study for Efficient Spatial Reasoning",
    "summary": "Efficient spatial reasoning requires world models that remain reliable under tight precision budgets. We study whether low-bit planning behavior is determined mostly by total bitwidth or by where bits are allocated across modules. Using DINO-WM on the Wall planning task, we run a paired-goal mixed-bit evaluation across uniform, mixed, asymmetric, and layerwise variants under two planner budgets. We observe a consistent three-regime pattern: 8-bit and 6-bit settings remain close to FP16, 3-bit settings collapse, and 4-bit settings are allocation-sensitive. In that transition region, preserving encoder precision improves planning relative to uniform quantization, and near-size asymmetric variants show the same encoder-side direction. In a later strict 22-cell replication with smaller per-cell episode count, the mixed-versus-uniform INT4 sign becomes budget-conditioned, which further highlights the sensitivity of this transition regime. These findings motivate module-aware, budget-aware quantization policies as a broader research direction for efficient spatial reasoning. Code and run artifacts are available at https://github.com/suraj-ranganath/DINO-MBQuant.",
    "authors": [
      "Suraj Ranganath",
      "Anish Patnaik",
      "Vaishak Menon"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11882v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11882v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.11790v1",
    "title": "Beyond End-to-End Video Models: An LLM-Based Multi-Agent System for Educational Video Generation",
    "summary": "Although recent end-to-end video generation models demonstrate impressive performance in visually oriented content creation, they remain limited in scenarios that require strict logical rigor and precise knowledge representation, such as instructional and educational media. To address this problem, we propose LAVES, a hierarchical LLM-based multi-agent system for generating high-quality instructional videos from educational problems. The LAVES formulates educational video generation as a multi-objective task that simultaneously demands correct step-by-step reasoning, pedagogically coherent narration, semantically faithful visual demonstrations, and precise audio--visual alignment. To address the limitations of prior approaches--including low procedural fidelity, high production cost, and limited controllability--LAVES decomposes the generation workflow into specialized agents coordinated by a central Orchestrating Agent with explicit quality gates and iterative critique mechanisms. Specifically, the Orchestrating Agent supervises a Solution Agent for rigorous problem solving, an Illustration Agent that produces executable visualization codes, and a Narration Agent for learner-oriented instructional scripts. In addition, all outputs from the working agents are subject to semantic critique, rule-based constraints, and tool-based compilation checks. Rather than directly synthesizing pixels, the system constructs a structured executable video script that is deterministically compiled into synchronized visuals and narration using template-driven assembly rules, enabling fully automated end-to-end production without manual editing. In large-scale deployments, LAVES achieves a throughput exceeding one million videos per day, delivering over a 95% reduction in cost compared to current industry-standard approaches while maintaining a high acceptance rate.",
    "authors": [
      "Lingyong Yan",
      "Jiulong Wu",
      "Dong Xie",
      "Weixian Shi",
      "Deguo Xia",
      "Jizhou Huang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11790v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11790v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.11745v1",
    "title": "Text2GQL-Bench: A Text to Graph Query Language Benchmark [Experiment, Analysis & Benchmark]",
    "summary": "Graph models are fundamental to data analysis in domains rich with complex relationships. Text-to-Graph-Query-Language (Text-to-GQL) systems act as a translator, converting natural language into executable graph queries. This capability allows Large Language Models (LLMs) to directly analyze and manipulate graph data, posi-tioning them as powerful agent infrastructures for Graph Database Management System (GDBMS). Despite recent progress, existing datasets are often limited in domain coverage, supported graph query languages, or evaluation scope. The advancement of Text-to-GQL systems is hindered by the lack of high-quality benchmark datasets and evaluation methods to systematically compare model capabilities across different graph query languages and domains. In this work, we present Text2GQL-Bench, a unified Text-to-GQL benchmark designed to address these limitations. Text2GQL-Bench couples a multi-GQL dataset that has 178,184 (Question, Query) pairs spanning 13 domains, with a scalable construction framework that generates datasets in different domains, question abstraction levels, and GQLs with heterogeneous resources. To support compre-hensive assessment, we introduce an evaluation method that goes beyond a single end-to-end metric by jointly reporting grammatical validity, similarity, semantic alignment, and execution accuracy. Our evaluation uncovers a stark dialect gap in ISO-GQL generation: even strong LLMs achieve only at most 4% execution accuracy (EX) in zero-shot settings, though a fixed 3-shot prompt raises accuracy to around 50%, the grammatical validity remains lower than 70%. Moreover, a fine-tuned 8B open-weight model reaches 45.1% EX, and 90.8% grammatical validity, demonstrating that most of the performance jump is unlocked by exposure to sufficient ISO-GQL examples.",
    "authors": [
      "Songlin Lyu",
      "Lujie Ban",
      "Zihang Wu",
      "Tianqi Luo",
      "Jirong Liu",
      "Chenhao Ma",
      "Yuyu Luo",
      "Nan Tang",
      "Shipeng Qi",
      "Heng Lin",
      "Yongchao Liu",
      "Chuntao Hong"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11745v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11745v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.11733v1",
    "title": "Adapting Vision-Language Models for E-commerce Understanding at Scale",
    "summary": "E-commerce product understanding demands by nature, strong multimodal comprehension from text, images, and structured attributes. General-purpose Vision-Language Models (VLMs) enable generalizable multimodal latent modelling, yet there is no documented, well-known strategy for adapting them to the attribute-centric, multi-image, and noisy nature of e-commerce data, without sacrificing general performance. In this work, we show through a large-scale experimental study, how targeted adaptation of general VLMs can substantially improve e-commerce performance while preserving broad multimodal capabilities. Furthermore, we propose a novel extensive evaluation suite covering deep product understanding, strict instruction following, and dynamic attribute extraction.",
    "authors": [
      "Matteo Nulli",
      "Vladimir Orshulevich",
      "Tala Bazazo",
      "Christian Herold",
      "Michael Kozielski",
      "Marcin Mazur",
      "Szymon Tuzel",
      "Cees G. M. Snoek",
      "Seyyed Hadi Hashemi",
      "Omar Javed",
      "Yannick Versley",
      "Shahram Khadivi"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11733v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11733v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.11684v1",
    "title": "PatientHub: A Unified Framework for Patient Simulation",
    "summary": "As Large Language Models increasingly power role-playing applications, simulating patients has become a valuable tool for training counselors and scaling therapeutic assessment. However, prior work is fragmented: existing approaches rely on incompatible, non-standardized data formats, prompts, and evaluation metrics, hindering reproducibility and fair comparison. In this paper, we introduce PatientHub, a unified and modular framework that standardizes the definition, composition, and deployment of simulated patients. To demonstrate PatientHub's utility, we implement several representative patient simulation methods as case studies, showcasing how our framework supports standardized cross-method evaluation and the seamless integration of custom evaluation metrics. We further demonstrate PatientHub's extensibility by prototyping two new simulator variants, highlighting how PatientHub accelerates method development by eliminating infrastructure overhead. By consolidating existing work into a single reproducible pipeline, PatientHub lowers the barrier to developing new simulation methods and facilitates cross-method and cross-model benchmarking. Our framework provides a practical foundation for future datasets, methods, and benchmarks in patient-centered dialogue, and the code is publicly available via https://github.com/Sahandfer/PatientHub.",
    "authors": [
      "Sahand Sabour",
      "TszYam NG",
      "Minlie Huang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11684v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11684v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.11678v1",
    "title": "Beyond Pixels: Vector-to-Graph Transformation for Reliable Schematic Auditing",
    "summary": "Multimodal Large Language Models (MLLMs) have shown remarkable progress in visual understanding, yet they suffer from a critical limitation: structural blindness. Even state-of-the-art models fail to capture topology and symbolic logic in engineering schematics, as their pixel-driven paradigm discards the explicit vector-defined relations needed for reasoning. To overcome this, we propose a Vector-to-Graph (V2G) pipeline that converts CAD diagrams into property graphs where nodes represent components and edges encode connectivity, making structural dependencies explicit and machine-auditable. On a diagnostic benchmark of electrical compliance checks, V2G yields large accuracy gains across all error categories, while leading MLLMs remain near chance level. These results highlight the systemic inadequacy of pixel-based methods and demonstrate that structure-aware representations provide a reliable path toward practical deployment of multimodal AI in engineering domains. To facilitate further research, we release our benchmark and implementation at https://github.com/gm-embodied/V2G-Audit.",
    "authors": [
      "Chengwei Ma",
      "Zhen Tian",
      "Zhou Zhou",
      "Zhixian Xu",
      "Xiaowei Zhu",
      "Xia Hua",
      "Si Shi",
      "F. Richard Yu"
    ],
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11678v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11678v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.11668v1",
    "title": "Explainable Machine-Learning based Detection of Knee Injuries in Runners",
    "summary": "Running is a widely practiced activity but shows a high incidence of knee injuries, especially Patellofemoral Pain Syndrome (PFPS) and Iliotibial Band Syndrome (ITBS). Identifying gait patterns linked to these injuries can improve clinical decision-making, which requires precise systems capable of capturing and analyzing temporal kinematic data.   This study uses optical motion capture systems to enhance detection of injury-related running patterns. We analyze a public dataset of 839 treadmill recordings from healthy and injured runners to evaluate how effectively these systems capture dynamic parameters relevant to injury classification. The focus is on the stance phase, using joint and segment angle time series and discrete point values.   Three classification tasks are addressed: healthy vs. injured, healthy vs. PFPS, and healthy vs. ITBS. We examine different feature spaces, from traditional point-based metrics to full stance-phase time series and hybrid representations. Multiple models are tested, including classical algorithms (K-Nearest Neighbors, Gaussian Processes, Decision Trees) and deep learning architectures (CNNs, LSTMs).   Performance is evaluated with accuracy, precision, recall, and F1-score. Explainability tools such as Shapley values, saliency maps, and Grad-CAM are used to interpret model behavior. Results show that combining time series with point values substantially improves detection. Deep learning models outperform classical ones, with CNNs achieving the highest accuracy: 77.9% for PFPS, 73.8% for ITBS, and 71.43% for the combined injury class.   These findings highlight the potential of motion capture systems coupled with advanced machine learning to identify knee injury-related running patterns.",
    "authors": [
      "David Fuentes-Jiménez",
      "Sara García-de-Villa",
      "David Casillas-Pérez",
      "Pablo Floría",
      "Francisco-Manuel Melgarejo-Meseguer"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11668v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11668v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2602.12124v1",
    "title": "Capability-Oriented Training Induced Alignment Risk",
    "summary": "While most AI alignment research focuses on preventing models from generating explicitly harmful content, a more subtle risk is emerging: capability-oriented training induced exploitation. We investigate whether language models, when trained with reinforcement learning (RL) in environments with implicit loopholes, will spontaneously learn to exploit these flaws to maximize their reward, even without any malicious intent in their training. To test this, we design a suite of four diverse \"vulnerability games\", each presenting a unique, exploitable flaw related to context-conditional compliance, proxy metrics, reward tampering, and self-evaluation. Our experiments show that models consistently learn to exploit these vulnerabilities, discovering opportunistic strategies that significantly increase their reward at the expense of task correctness or safety. More critically, we find that these exploitative strategies are not narrow \"tricks\" but generalizable skills; they can be transferred to new tasks and even \"distilled\" from a capable teacher model to other student models through data alone. Our findings reveal that capability-oriented training induced risks pose a fundamental challenge to current alignment approaches, suggesting that future AI safety work must extend beyond content moderation to rigorously auditing and securing the training environments and reward mechanisms themselves. Code is available at https://github.com/YujunZhou/Capability_Oriented_Alignment_Risk.",
    "authors": [
      "Yujun Zhou",
      "Yue Huang",
      "Han Bao",
      "Kehan Guo",
      "Zhenwen Liang",
      "Pin-Yu Chen",
      "Tian Gao",
      "Werner Geyer",
      "Nuno Moniz",
      "Nitesh V Chawla",
      "Xiangliang Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12124v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12124v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.12056v1",
    "title": "LawThinker: A Deep Research Legal Agent in Dynamic Environments",
    "summary": "Legal reasoning requires not only correct outcomes but also procedurally compliant reasoning processes. However, existing methods lack mechanisms to verify intermediate reasoning steps, allowing errors such as inapplicable statute citations to propagate undetected through the reasoning chain. To address this, we propose LawThinker, an autonomous legal research agent that adopts an Explore-Verify-Memorize strategy for dynamic judicial environments. The core idea is to enforce verification as an atomic operation after every knowledge exploration step. A DeepVerifier module examines each retrieval result along three dimensions of knowledge accuracy, fact-law relevance, and procedural compliance, with a memory module for cross-round knowledge reuse in long-horizon tasks. Experiments on the dynamic benchmark J1-EVAL show that LawThinker achieves a 24% improvement over direct reasoning and an 11% gain over workflow-based methods, with particularly strong improvements on process-oriented metrics. Evaluations on three static benchmarks further confirm its generalization capability. The code is available at https://github.com/yxy-919/LawThinker-agent .",
    "authors": [
      "Xinyu Yang",
      "Chenlong Deng",
      "Tongyu Wen",
      "Binyu Xie",
      "Zhicheng Dou"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12056v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12056v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.12029v1",
    "title": "PrefillShare: A Shared Prefill Module for KV Reuse in Multi-LLM Disaggregated Serving",
    "summary": "Multi-agent systems increasingly orchestrate multiple specialized language models to solve complex real-world problems, often invoking them over a shared context. This execution pattern repeatedly processes the same prompt prefix across models. Consequently, each model redundantly executes the prefill stage and maintains its own key-value (KV) cache, increasing aggregate prefill load and worsening tail latency by intensifying prefill-decode interference in existing LLM serving stacks. Disaggregated serving reduces such interference by placing prefill and decode on separate GPUs, but disaggregation does not fundamentally eliminate inter-model redundancy in computation and KV storage for the same prompt. To address this issue, we propose PrefillShare, a novel algorithm that enables sharing the prefill stage across multiple models in a disaggregated setting. PrefillShare factorizes the model into prefill and decode modules, freezes the prefill module, and fine-tunes only the decode module. This design allows multiple task-specific models to share a prefill module and the KV cache generated for the same prompt. We further introduce a routing mechanism that enables effective prefill sharing across heterogeneous models in a vLLM-based disaggregated system. PrefillShare not only matches full fine-tuning accuracy on a broad range of tasks and models, but also delivers 4.5x lower p95 latency and 3.9x higher throughput in multi-model agent workloads.",
    "authors": [
      "Sunghyeon Woo",
      "Hoseung Kim",
      "Sunghwan Shim",
      "Minjung Jo",
      "Hyunjoon Jeong",
      "Jeongtae Lee",
      "Joonghoon Kim",
      "Sungjae Lee",
      "Baeseong Park",
      "Se Jung Kwon",
      "Dongsoo Lee"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12029v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12029v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.11964v1",
    "title": "Gaia2: Benchmarking LLM Agents on Dynamic and Asynchronous Environments",
    "summary": "We introduce Gaia2, a benchmark for evaluating large language model agents in realistic, asynchronous environments. Unlike prior static or synchronous evaluations, Gaia2 introduces scenarios where environments evolve independently of agent actions, requiring agents to operate under temporal constraints, adapt to noisy and dynamic events, resolve ambiguity, and collaborate with other agents. Each scenario is paired with a write-action verifier, enabling fine-grained, action-level evaluation and making Gaia2 directly usable for reinforcement learning from verifiable rewards. Our evaluation of state-of-the-art proprietary and open-source models shows that no model dominates across capabilities: GPT-5 (high) reaches the strongest overall score of 42% pass@1 but fails on time-sensitive tasks, Claude-4 Sonnet trades accuracy and speed for cost, Kimi-K2 leads among open-source models with 21% pass@1. These results highlight fundamental trade-offs between reasoning, efficiency, robustness, and expose challenges in closing the \"sim2real\" gap. Gaia2 is built on a consumer environment with the open-source Agents Research Environments platform and designed to be easy to extend. By releasing Gaia2 alongside the foundational ARE framework, we aim to provide the community with a flexible infrastructure for developing, benchmarking, and training the next generation of practical agent systems.",
    "authors": [
      "Romain Froger",
      "Pierre Andrews",
      "Matteo Bettini",
      "Amar Budhiraja",
      "Ricardo Silveira Cabral",
      "Virginie Do",
      "Emilien Garreau",
      "Jean-Baptiste Gaya",
      "Hugo Laurençon",
      "Maxime Lecanu",
      "Kunal Malkan",
      "Dheeraj Mekala",
      "Pierre Ménard",
      "Gerard Moreno-Torres Bertran",
      "Ulyana Piterbarg",
      "Mikhail Plekhanov",
      "Mathieu Rita",
      "Andrey Rusakov",
      "Vladislav Vorotilov",
      "Mengjue Wang",
      "Ian Yu",
      "Amine Benhalloum",
      "Grégoire Mialon",
      "Thomas Scialom"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11964v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11964v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.11917v1",
    "title": "AlphaPROBE: Alpha Mining via Principled Retrieval and On-graph biased evolution",
    "summary": "Extracting signals through alpha factor mining is a fundamental challenge in quantitative finance. Existing automated methods primarily follow two paradigms: Decoupled Factor Generation, which treats factor discovery as isolated events, and Iterative Factor Evolution, which focuses on local parent-child refinements. However, both paradigms lack a global structural view, often treating factor pools as unstructured collections or fragmented chains, which leads to redundant search and limited diversity. To address these limitations, we introduce AlphaPROBE (Alpha Mining via Principled Retrieval and On-graph Biased Evolution), a framework that reframes alpha mining as the strategic navigation of a Directed Acyclic Graph (DAG). By modeling factors as nodes and evolutionary links as edges, AlphaPROBE treats the factor pool as a dynamic, interconnected ecosystem. The framework consists of two core components: a Bayesian Factor Retriever that identifies high-potential seeds by balancing exploitation and exploration through a posterior probability model, and a DAG-aware Factor Generator that leverages the full ancestral trace of factors to produce context-aware, nonredundant optimizations. Extensive experiments on three major Chinese stock market datasets against 8 competitive baselines demonstrate that AlphaPROBE significantly gains enhanced performance in predictive accuracy, return stability and training efficiency. Our results confirm that leveraging global evolutionary topology is essential for efficient and robust automated alpha discovery. We have open-sourced our implementation at https://github.com/gta0804/AlphaPROBE.",
    "authors": [
      "Taian Guo",
      "Haiyang Shen",
      "Junyu Luo",
      "Binqi Chen",
      "Hongjun Ding",
      "Jinsheng Huang",
      "Luchen Liu",
      "Yun Ma",
      "Ming Zhang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11917v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11917v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.11871v1",
    "title": "DMAP: A Distribution Map for Text",
    "summary": "Large Language Models (LLMs) are a powerful tool for statistical text analysis, with derived sequences of next-token probability distributions offering a wealth of information. Extracting this signal typically relies on metrics such as perplexity, which do not adequately account for context; how one should interpret a given next-token probability is dependent on the number of reasonable choices encoded by the shape of the conditional distribution. In this work, we present DMAP, a mathematically grounded method that maps a text, via a language model, to a set of samples in the unit interval that jointly encode rank and probability information. This representation enables efficient, model-agnostic analysis and supports a range of applications. We illustrate its utility through three case studies: (i) validation of generation parameters to ensure data integrity, (ii) examining the role of probability curvature in machine-generated text detection, and (iii) a forensic analysis revealing statistical fingerprints left in downstream models that have been subject to post-training on synthetic data. Our results demonstrate that DMAP offers a unified statistical view of text that is simple to compute on consumer hardware, widely applicable, and provides a foundation for further research into text analysis with LLMs.",
    "authors": [
      "Tom Kempton",
      "Julia Rozanova",
      "Parameswaran Kamalaruban",
      "Maeve Madigan",
      "Karolina Wresilo",
      "Yoann L. Launay",
      "David Sutton",
      "Stuart Burrell"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11871v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11871v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.11800v1",
    "title": "Temporal Difference Learning with Constrained Initial Representations",
    "summary": "Recently, there have been numerous attempts to enhance the sample efficiency of off-policy reinforcement learning (RL) agents when interacting with the environment, including architecture improvements and new algorithms. Despite these advances, they overlook the potential of directly constraining the initial representations of the input data, which can intuitively alleviate the distribution shift issue and stabilize training. In this paper, we introduce the Tanh function into the initial layer to fulfill such a constraint. We theoretically unpack the convergence property of the temporal difference learning with the Tanh function under linear function approximation. Motivated by theoretical insights, we present our Constrained Initial Representations framework, tagged CIR, which is made up of three components: (i) the Tanh activation along with normalization methods to stabilize representations; (ii) the skip connection module to provide a linear pathway from the shallow layer to the deep layer; (iii) the convex Q-learning that allows a more flexible value estimate and mitigates potential conservatism. Empirical results show that CIR exhibits strong performance on numerous continuous control tasks, even being competitive or surpassing existing strong baseline methods.",
    "authors": [
      "Jiafei Lyu",
      "Jingwen Yang",
      "Zhongjian Qiao",
      "Runze Liu",
      "Zeyuan Liu",
      "Deheng Ye",
      "Zongqing Lu",
      "Xiu Li"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11800v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11800v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.11792v1",
    "title": "Detecting RLVR Training Data via Structural Convergence of Reasoning",
    "summary": "Reinforcement learning with verifiable rewards (RLVR) is central to training modern reasoning models, but the undisclosed training data raises concerns about benchmark contamination. Unlike pretraining methods, which optimize models using token-level probabilities, RLVR fine-tunes models based on reward feedback from self-generated reasoning trajectories, making conventional likelihood-based detection methods less effective. We show that RLVR induces a distinctive behavioral signature: prompts encountered during RLVR training result in more rigid and similar generations, while unseen prompts retain greater diversity. We introduce Min-$k$NN Distance, a simple black-box detector that quantifies this collapse by sampling multiple completions for a given prompt and computing the average of the $k$ smallest nearest-neighbor edit distances. Min-$k$NN Distance requires no access to the reference model or token probabilities. Experiments across multiple RLVR-trained reasoning models show that Min-$k$NN Distance reliably distinguishes RL-seen examples from unseen ones and outperforms existing membership inference and RL contamination detection baselines.",
    "authors": [
      "Hongbo Zhang",
      "Yue Yang",
      "Jianhao Yan",
      "Guangsheng Bao",
      "Yue Zhang",
      "Yue Zhang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11792v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11792v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.11785v1",
    "title": "Safe Fairness Guarantees Without Demographics in Classification: Spectral Uncertainty Set Perspective",
    "summary": "As automated classification systems become increasingly prevalent, concerns have emerged over their potential to reinforce and amplify existing societal biases. In the light of this issue, many methods have been proposed to enhance the fairness guarantees of classifiers. Most of the existing interventions assume access to group information for all instances, a requirement rarely met in practice. Fairness without access to demographic information has often been approached through robust optimization techniques,which target worst-case outcomes over a set of plausible distributions known as the uncertainty set. However, their effectiveness is strongly influenced by the chosen uncertainty set. In fact, existing approaches often overemphasize outliers or overly pessimistic scenarios, compromising both overall performance and fairness. To overcome these limitations, we introduce SPECTRE, a minimax-fair method that adjusts the spectrum of a simple Fourier feature mapping and constrains the extent to which the worst-case distribution can deviate from the empirical distribution. We perform extensive experiments on the American Community Survey datasets involving 20 states. The safeness of SPECTRE comes as it provides the highest average values on fairness guarantees together with the smallest interquartile range in comparison to state-of-the-art approaches, even compared to those with access to demographic group information. In addition, we provide a theoretical analysis that derives computable bounds on the worst-case error for both individual groups and the overall population, as well as characterizes the worst-case distributions responsible for these extremal performances",
    "authors": [
      "Ainhize Barrainkua",
      "Santiago Mazuelas",
      "Novi Quadrianto",
      "Jose A. Lozano"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11785v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11785v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.11712v1",
    "title": "Potential-energy gating for robust state estimation in bistable stochastic systems",
    "summary": "We introduce potential-energy gating, a method for robust state estimation in systems governed by double-well stochastic dynamics. The observation noise covariance of a Bayesian filter is modulated by the local value of a known or assumed potential energy function: observations are trusted when the state is near a potential minimum and progressively discounted as it approaches the barrier separating metastable wells. This physics-based mechanism differs from purely statistical robust filters, which treat all regions of state space identically, and from constrained filters, which impose hard bounds on states rather than modulating observation trust. We implement the gating within Extended, Unscented, Ensemble, and Adaptive Kalman filters and particle filters, requiring only two additional hyperparameters. Synthetic benchmarks on a Ginzburg-Landau double-well process with 10% outlier contamination and Monte Carlo validation over 100 replications show 57-80% RMSE improvement over the standard Extended Kalman Filter, all statistically significant (p < 10^{-15}, Wilcoxon signed-rank test). A naive topological baseline using only distance to the nearest well achieves 57%, confirming that the continuous energy landscape adds an additional ~21 percentage points. The method is robust to misspecification: even when assumed potential parameters deviate by 50% from their true values, improvement never falls below 47%. Comparing externally forced and spontaneous Kramers-type transitions, gating retains 68% improvement under noise-induced transitions whereas the naive baseline degrades to 30%. As an empirical illustration, we apply the framework to Dansgaard-Oeschger events in the NGRIP delta-18O ice-core record, estimating asymmetry parameter gamma = -0.109 (bootstrap 95% CI: [-0.220, -0.011], excluding zero) and demonstrating that outlier fraction explains 91% of the variance in filter improvement.",
    "authors": [
      "Luigi Simeone"
    ],
    "categories": [
      "cs.LG",
      "cs.CE",
      "nlin.CD",
      "physics.data-an",
      "stat.ME"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11712v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11712v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.11711v1",
    "title": "Estimation of instrument and noise parameters for inverse problem based on prior diffusion model",
    "summary": "This article addresses the issue of estimating observation parameters (response and error parameters) in inverse problems. The focus is on cases where regularization is introduced in a Bayesian framework and the prior is modeled by a diffusion process. In this context, the issue of posterior sampling is well known to be thorny, and a recent paper proposes a notably simple and effective solution. Consequently, it offers an remarkable additional flexibility when it comes to estimating observation parameters. The proposed strategy enables us to define an optimal estimator for both the observation parameters and the image of interest. Furthermore, the strategy provides a means of quantifying uncertainty. In addition, MCMC algorithms allow for the efficient computation of estimates and properties of posteriors, while offering some guarantees. The paper presents several numerical experiments that clearly confirm the computational efficiency and the quality of both estimates and uncertainties quantification.",
    "authors": [
      "Jean-François Giovannelli"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.NA",
      "stat.AP"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11711v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11711v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.11698v1",
    "title": "SpiralFormer: Looped Transformers Can Learn Hierarchical Dependencies via Multi-Resolution Recursion",
    "summary": "Recursive (looped) Transformers decouple computational depth from parameter depth by repeatedly applying shared layers, providing an explicit architectural primitive for iterative refinement and latent reasoning. However, early looped Transformers often underperform non-recursive baselines of equal compute. While recent literature has introduced more effective recursion mechanisms to mitigate this gap, existing architectures still operate at a fixed, full-token resolution, neglecting the potential efficiency of computing over compressed latent representations. In this paper, we propose SpiralFormer, a looped Transformer that executes recurrence under a multi-resolution recursion schedule. We provide probing evidence that multi-resolution recursion enables the model to learn hierarchical dependencies by inducing iteration-wise functional specialization across different scales. Empirically, SpiralFormer achieves better parameter and compute efficiency than both looped and non-looped baselines across model scales from 160M to 1.4B, establishing sequence resolution as a potential axis for scaling recursive architectures.",
    "authors": [
      "Chengting Yu",
      "Xiaobo Shu",
      "Yadao Wang",
      "Yizhen Zhang",
      "Haoyi Wu",
      "You Wu",
      "Rujiao Long",
      "Ziheng Chen",
      "Yuchi Xu",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11698v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11698v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.11665v1",
    "title": "Fully First-Order Algorithms for Online Bilevel Optimization",
    "summary": "In this work, we study non-convex-strongly-convex online bilevel optimization (OBO). Existing OBO algorithms are mainly based on hypergradient descent, which requires access to a Hessian-vector product (HVP) oracle and potentially incurs high computational costs. By reformulating the original OBO problem as a single-level online problem with inequality constraints and constructing a sequence of Lagrangian function, we eliminate the need for HVPs arising from implicit differentiation. Specifically, we propose a fully first-order algorithm for OBO, and provide theoretical guarantees showing that it achieves regret of $O(1 + V_T + H_{2,T})$. Furthermore, we develop an improved variant with an adaptive inner-iteration scheme, which removes the dependence on the drift variation of the inner-level optimal solution and achieves regret of $O(\\sqrt{T} + V_T)$. This regret have the advatange when $V_{T}\\ge O(\\sqrt{T})$.",
    "authors": [
      "Tingkai Jia",
      "Cheng Chen"
    ],
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11665v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11665v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.11643v1",
    "title": "ViTaS: Visual Tactile Soft Fusion Contrastive Learning for Visuomotor Learning",
    "summary": "Tactile information plays a crucial role in human manipulation tasks and has recently garnered increasing attention in robotic manipulation. However, existing approaches mostly focus on the alignment of visual and tactile features and the integration mechanism tends to be direct concatenation. Consequently, they struggle to effectively cope with occluded scenarios due to neglecting the inherent complementary nature of both modalities and the alignment may not be exploited enough, limiting the potential of their real-world deployment. In this paper, we present ViTaS, a simple yet effective framework that incorporates both visual and tactile information to guide the behavior of an agent. We introduce Soft Fusion Contrastive Learning, an advanced version of conventional contrastive learning method and a CVAE module to utilize the alignment and complementarity within visuo-tactile representations. We demonstrate the effectiveness of our method in 12 simulated and 3 real-world environments, and our experiments show that ViTaS significantly outperforms existing baselines. Project page: https://skyrainwind.github.io/ViTaS/index.html.",
    "authors": [
      "Yufeng Tian",
      "Shuiqi Cheng",
      "Tianming Wei",
      "Tianxing Zhou",
      "Yuanhang Zhang",
      "Zixian Liu",
      "Qianwei Han",
      "Zhecheng Yuan",
      "Huazhe Xu"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11643v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11643v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2602.11910v1",
    "title": "TADA! Tuning Audio Diffusion Models through Activation Steering",
    "summary": "Audio diffusion models can synthesize high-fidelity music from text, yet their internal mechanisms for representing high-level concepts remain poorly understood. In this work, we use activation patching to demonstrate that distinct semantic musical concepts, such as the presence of specific instruments, vocals, or genre characteristics, are controlled by a small, shared subset of attention layers in state-of-the-art audio diffusion architectures. Next, we demonstrate that applying Contrastive Activation Addition and Sparse Autoencoders in these layers enables more precise control over the generated audio, indicating a direct benefit of the specialization phenomenon. By steering activations of the identified layers, we can alter specific musical elements with high precision, such as modulating tempo or changing a track's mood.",
    "authors": [
      "Łukasz Staniszewski",
      "Katarzyna Zaleska",
      "Mateusz Modrzejewski",
      "Kamil Deja"
    ],
    "categories": [
      "cs.SD",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11910v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11910v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.11877v1",
    "title": "Towards Fair and Comprehensive Evaluation of Routers in Collaborative LLM Systems",
    "summary": "Large language models (LLMs) have achieved success, but cost and privacy constraints necessitate deploying smaller models locally while offloading complex queries to cloud-based models. Existing router evaluations are unsystematic, overlooking scenario-specific requirements and out-of-distribution robustness. We propose RouterXBench, a principled evaluation framework with three dimensions: router ability, scenario alignment, and cross-domain robustness. Unlike prior work that relies on output probabilities or external embeddings, we utilize internal hidden states that capture model uncertainty before answer generation. We introduce ProbeDirichlet, a lightweight router that aggregates cross-layer hidden states via learnable Dirichlet distributions with probabilistic training. Trained on multi-domain data, it generalizes robustly across in-domain and out-of-distribution scenarios. Our results show ProbeDirichlet achieves 16.68% and 18.86% relative improvements over the best baselines in router ability and high-accuracy scenarios, with consistent performance across model families, model scales, heterogeneous tasks, and agentic workflows.",
    "authors": [
      "Wanxing Wu",
      "He Zhu",
      "Yixia Li",
      "Lei Yang",
      "Jiehui Zhao",
      "Hongru Wang",
      "Jian Yang",
      "Benyou Wang",
      "Bingyi Jing",
      "Guanhua Chen"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11877v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11877v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.11865v1",
    "title": "Intelligent AI Delegation",
    "summary": "AI agents are able to tackle increasingly complex tasks. To achieve more ambitious goals, AI agents need to be able to meaningfully decompose problems into manageable sub-components, and safely delegate their completion across to other AI agents and humans alike. Yet, existing task decomposition and delegation methods rely on simple heuristics, and are not able to dynamically adapt to environmental changes and robustly handle unexpected failures. Here we propose an adaptive framework for intelligent AI delegation - a sequence of decisions involving task allocation, that also incorporates transfer of authority, responsibility, accountability, clear specifications regarding roles and boundaries, clarity of intent, and mechanisms for establishing trust between the two (or more) parties. The proposed framework is applicable to both human and AI delegators and delegatees in complex delegation networks, aiming to inform the development of protocols in the emerging agentic web.",
    "authors": [
      "Nenad Tomašev",
      "Matija Franklin",
      "Simon Osindero"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11865v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11865v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.11760v1",
    "title": "Aggregate Models, Not Explanations: Improving Feature Importance Estimation",
    "summary": "Feature-importance methods show promise in transforming machine learning models from predictive engines into tools for scientific discovery. However, due to data sampling and algorithmic stochasticity, expressive models can be unstable, leading to inaccurate variable importance estimates and undermining their utility in critical biomedical applications. Although ensembling offers a solution, deciding whether to explain a single ensemble model or aggregate individual model explanations is difficult due to the nonlinearity of importance measures and remains largely understudied. Our theoretical analysis, developed under assumptions accommodating complex state-of-the-art ML models, reveals that this choice is primarily driven by the model's excess risk. In contrast to prior literature, we show that ensembling at the model level provides more accurate variable-importance estimates, particularly for expressive models, by reducing this leading error term. We validate these findings on classical benchmarks and a large-scale proteomic study from the UK Biobank.",
    "authors": [
      "Joseph Paillard",
      "Angel Reyero Lobo",
      "Denis A. Engemann",
      "Bertrand Thirion"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11760v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11760v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.11748v1",
    "title": "Think Longer to Explore Deeper: Learn to Explore In-Context via Length-Incentivized Reinforcement Learning",
    "summary": "Achieving effective test-time scaling requires models to engage in In-Context Exploration -- the intrinsic ability to generate, verify, and refine multiple reasoning hypotheses within a single continuous context.   Grounded in State Coverage theory, our analysis identifies a critical bottleneck to enabling this capability: while broader state coverage requires longer reasoning trajectories, the probability of sampling such sequences decays exponentially during autoregressive generation, a phenomenon we term the ``Shallow Exploration Trap''.   To bridge this gap, we propose Length-Incentivized Exploration(\\method).   This simple yet effective recipe explicitly encourages models to explore more via a length-based reward coupled with a redundancy penalty, thereby maximizing state coverage in two-step manner.   Comprehensive experiments across different models (Qwen3, Llama) demonstrate that \\method effectively incentivize in-context exploration.   As a result, our method achieves an average improvement of 4.4\\% on in-domain tasks and a 2.7\\% gain on out-of-domain benchmarks.",
    "authors": [
      "Futing Wang",
      "Jianhao Yan",
      "Yun Luo",
      "Ganqu Cui",
      "Zhi Wang",
      "Xiaoye Qu",
      "Yue Zhang",
      "Yu Cheng",
      "Tao Lin"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11748v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11748v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.11674v1",
    "title": "Benchmark Health Index: A Systematic Framework for Benchmarking the Benchmarks of LLMs",
    "summary": "Large Language Models (LLMs) are advancing rapidly, yet the benchmarks used to measure this progress are becoming increasingly unreliable. Score inflation and selective reporting have eroded the authority of standard benchmarks, leaving the community uncertain about which evaluation results remain trustworthy. We introduce the Benchmark Health Index (BHI), a pure data-driven framework for auditing evaluation sets along three orthogonal and complementary axes: (1) Capability Discrimination, measuring how sharply a benchmark separates model performance beyond noise; (2) Anti-Saturation, estimating remaining headroom before ceiling effects erode resolution and thus the benchmark's expected longevity; and (3) Impact, quantifying influence across academic and industrial ecosystems via adoption breadth and practice-shaping power. By distilling 106 validated benchmarks from the technical reports of 91 representative models in 2025, we systematically characterize the evaluation landscape. BHI is the first framework to quantify benchmark health at a macro level, providing a principled basis for benchmark selection and enabling dynamic lifecycle management for next-generation evaluation protocols.",
    "authors": [
      "Longyuan Zhu",
      "Hairan Hua",
      "Linlin Miao",
      "Bing Zhao"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11674v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11674v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.11673v1",
    "title": "RI-Mamba: Rotation-Invariant Mamba for Robust Text-to-Shape Retrieval",
    "summary": "3D assets have rapidly expanded in quantity and diversity due to the growing popularity of virtual reality and gaming. As a result, text-to-shape retrieval has become essential in facilitating intuitive search within large repositories. However, existing methods require canonical poses and support few object categories, limiting their real-world applicability where objects can belong to diverse classes and appear in random orientations. To address this challenge, we propose RI-Mamba, the first rotation-invariant state-space model for point clouds. RI-Mamba defines global and local reference frames to disentangle pose from geometry and uses Hilbert sorting to construct token sequences with meaningful geometric structure while maintaining rotation invariance. We further introduce a novel strategy to compute orientational embeddings and reintegrate them via feature-wise linear modulation, effectively recovering spatial context and enhancing model expressiveness. Our strategy is inherently compatible with state-space models and operates in linear time. To scale up retrieval, we adopt cross-modal contrastive learning with automated triplet generation, allowing training on diverse datasets without manual annotation. Extensive experiments demonstrate RI-Mamba's superior representational capacity and robustness, achieving state-of-the-art performance on the OmniObject3D benchmark across more than 200 object categories under arbitrary orientations. Our code will be made available at https://github.com/ndkhanh360/RI-Mamba.git.",
    "authors": [
      "Khanh Nguyen",
      "Dasith de Silva Edirimuni",
      "Ghulam Mubashar Hassan",
      "Ajmal Mian"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11673v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11673v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.11662v1",
    "title": "UMAP Is Spectral Clustering on the Fuzzy Nearest-Neighbor Graph",
    "summary": "UMAP (Uniform Manifold Approximation and Projection) is among the most widely used algorithms for non linear dimensionality reduction and data visualisation. Despite its popularity, and despite being presented through the lens of algebraic topology, the exact relationship between UMAP and classical spectral methods has remained informal. In this work, we prove that UMAP performs spectral clustering on the fuzzy k nearest neighbour graph. Our proof proceeds in three steps: (1) we show that UMAP's stochastic optimisation with negative sampling is a contrastive learning objective on the similarity graph; (2) we invoke the result of HaoChen et al. [8], establishing that contrastive learning on a similarity graph is equivalent to spectral clustering; and (3) we verify that UMAP's spectral initialisation computes the exact linear solution to this spectral problem. The equivalence is exact for Gaussian kernels, and holds as a first order approximation for UMAP's default Cauchy type kernel. Our result unifies UMAP, contrastive learning, and spectral clustering under a single framework, and provides theoretical grounding for several empirical observations about UMAP's behaviour.",
    "authors": [
      "Yang Yang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11662v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11662v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.11655v1",
    "title": "LoRA-based Parameter-Efficient LLMs for Continuous Learning in Edge-based Malware Detection",
    "summary": "The proliferation of edge devices has created an urgent need for security solutions capable of detecting malware in real time while operating under strict computational and memory constraints. Recently, Large Language Models (LLMs) have demonstrated remarkable capabilities in recognizing complex patterns, yet their deployment on edge devices remains impractical due to their resource demands. However, in edge malware detection, static or centrally retrained models degrade under evolving threats and heterogeneous traffic; locally trained models become siloed and fail to transfer across domains. To overcome these limitations, in this paper, we present a continuous learning architecture for edge-based malware detection that combines local adaptation on each device with global knowledge sharing through parameter-efficient LoRA adapters. Lightweight transformer models (DistilBERT, DistilGPT-2, TinyT5) run on edge nodes and are incrementally fine-tuned on device-specific traffic; only the resulting LoRA modules are aggregated by a lightweight coordinator and redistributed, enabling cross-device generalization without exchanging raw data. We evaluate on two public IoT security datasets, Edge-IIoTset and TON-IoT, under multi-round learning to simulate evolving threats. Compared to isolated fine-tuning, the LoRA-based exchange yields up to 20-25% accuracy gains when models encounter previously unseen attacks from another domain, while maintaining stable loss and F1 across rounds. LoRA adds less than 1% to model size (~0.6-1.8 MB), making updates practical for constrained edge hardware.",
    "authors": [
      "Christian Rondanini",
      "Barbara Carminati",
      "Elena Ferrari",
      "Niccolò Lardo",
      "Ashish Kundu"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11655v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11655v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2602.12049v1",
    "title": "Improving HPC Code Generation Capability of LLMs via Online Reinforcement Learning with Real-Machine Benchmark Rewards",
    "summary": "Large language models (LLMs) have demonstrated strong code generation capabilities, yet the runtime performance of generated code is not guaranteed, and there have been few attempts to train LLMs using runtime performance as a reward in the HPC domain. We propose an online reinforcement learning approach that executes LLM-generated code on a supercomputer and directly feeds back the measured runtime performance (GFLOPS) as a reward. We further introduce a Staged Quality-Diversity (SQD) algorithm that progressively varies the permitted optimization techniques on a per-problem basis, enabling the model to learn code optimization from diverse perspectives. We build a distributed system connecting a GPU training cluster with a CPU benchmarking cluster, and train Qwen2.5 Coder 14B on a double-precision matrix multiplication task using Group Relative Policy Optimization (GRPO). Through two experiments, we show that reinforcement learning combining runtime performance feedback with staged optimization can improve the HPC code generation capability of LLMs.",
    "authors": [
      "Ryo Mikasa",
      "Shun-ichiro Hayashi",
      "Daichi Mukunoki",
      "Tetsuya Hoshino",
      "Takahiro Katagiri"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12049v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12049v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.11982v1",
    "title": "Automatic Simplification of Common Vulnerabilities and Exposures Descriptions",
    "summary": "Understanding cyber security is increasingly important for individuals and organizations. However, a lot of information related to cyber security can be difficult to understand to those not familiar with the topic. In this study, we focus on investigating how large language models (LLMs) could be utilized in automatic text simplification (ATS) of Common Vulnerability and Exposure (CVE) descriptions. Automatic text simplification has been studied in several contexts, such as medical, scientific, and news texts, but it has not yet been studied to simplify texts in the rapidly changing and complex domain of cyber security. We created a baseline for cyber security ATS and a test dataset of 40 CVE descriptions, evaluated by two groups of cyber security experts in two survey rounds. We have found that while out-of-the box LLMs can make the text appear simpler, they struggle with meaning preservation. Code and data are available at https://version.aalto.fi/gitlab/vehomav1/simplification\\_nmi.",
    "authors": [
      "Varpu Vehomäki",
      "Kimmo K. Kaski"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11982v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11982v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.11903v1",
    "title": "Learning Perceptual Representations for Gaming NR-VQA with Multi-Task FR Signals",
    "summary": "No-reference video quality assessment (NR-VQA) for gaming videos is challenging due to limited human-rated datasets and unique content characteristics including fast motion, stylized graphics, and compression artifacts. We present MTL-VQA, a multi-task learning framework that uses full-reference metrics as supervisory signals to learn perceptually meaningful features without human labels for pretraining. By jointly optimizing multiple full-reference (FR) objectives with adaptive task weighting, our approach learns shared representations that transfer effectively to NR-VQA. Experiments on gaming video datasets show MTL-VQA achieves performance competitive with state-of-the-art NR-VQA methods across both MOS-supervised and label-efficient/self-supervised settings.",
    "authors": [
      "Yu-Chih Chen",
      "Michael Wang",
      "Chieh-Dun Wen",
      "Kai-Siang Ma",
      "Avinab Saha",
      "Li-Heng Chen",
      "Alan Bovik"
    ],
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.MM"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11903v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11903v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.11795v1",
    "title": "A Subword Embedding Approach for Variation Detection in Luxembourgish User Comments",
    "summary": "This paper presents an embedding-based approach to detecting variation without relying on prior normalisation or predefined variant lists. The method trains subword embeddings on raw text and groups related forms through combined cosine and n-gram similarity. This allows spelling and morphological diversity to be examined and analysed as linguistic structure rather than treated as noise. Using a large corpus of Luxembourgish user comments, the approach uncovers extensive lexical and orthographic variation that aligns with patterns described in dialectal and sociolinguistic research. The induced families capture systematic correspondences and highlight areas of regional and stylistic differentiation. The procedure does not strictly require manual annotation, but does produce transparent clusters that support both quantitative and qualitative analysis. The results demonstrate that distributional modelling can reveal meaningful patterns of variation even in ''noisy'' or low-resource settings, offering a reproducible methodological framework for studying language variety in multilingual and small-language contexts.",
    "authors": [
      "Anne-Marie Lutgen",
      "Alistair Plum",
      "Christoph Purschke"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11795v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11795v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.11641v1",
    "title": "Both Topology and Text Matter: Revisiting LLM-guided Out-of-Distribution Detection on Text-attributed Graphs",
    "summary": "Text-attributed graphs (TAGs) associate nodes with textual attributes and graph structure, enabling GNNs to jointly model semantic and structural information. While effective on in-distribution (ID) data, GNNs often encounter out-of-distribution (OOD) nodes with unseen textual or structural patterns in real-world settings, leading to overconfident and erroneous predictions in the absence of reliable OOD detection. Early approaches address this issue from a topology-driven perspective, leveraging neighboring structures to mitigate node-level detection bias. However, these methods typically encode node texts as shallow vector features, failing to fully exploit rich semantic information. In contrast, recent LLM-based approaches generate pseudo OOD priors by leveraging textual knowledge, but they suffer from several limitations: (1) a reliability-informativeness imbalance in the synthesized OOD priors, as the generated OOD exposures either deviate from the true OOD semantics, or introduce non-negligible ID noise, all of which offers limited improvement to detection performance; (2) reliance on specialized architectures, which prevents incorporation of the extensive effective topology-level insights that have been empirically validated in prior work. To this end, we propose LG-Plug, an LLM-Guided Plug-and-play strategy for TAG OOD detection tasks. LG-Plug aligns topology and text representations to produce fine-grained node embeddings, then generates consensus-driven OOD exposure via clustered iterative LLM prompting. Moreover, it leverages lightweight in-cluster codebook and heuristic sampling reduce time cost of LLM querying. The resulting OOD exposure serves as a regularization term to separate ID and OOD nodes, enabling seamless integration with existing detectors.",
    "authors": [
      "Yinlin Zhu",
      "Di Wu",
      "Xu Wang",
      "Guocong Quan",
      "Miao Hu"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11641v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11641v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2602.12089v1",
    "title": "Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation",
    "summary": "As AI usage becomes more prevalent in social contexts, understanding agent-user interaction is critical to designing systems that improve both individual and group outcomes. We present an online behavioral experiment (N = 243) in which participants play three multi-turn bargaining games in groups of three. Each game, presented in randomized order, grants \\textit{access to} a single LLM assistance modality: proactive recommendations from an \\textit{Advisor}, reactive feedback from a \\textit{Coach}, or autonomous execution by a \\textit{Delegate}; all modalities are powered by an underlying LLM that achieves superhuman performance in an all-agent environment. On each turn, participants privately decide whether to act manually or use the AI modality available in that game. Despite preferring the \\textit{Advisor} modality, participants achieve the highest mean individual gains with the \\textit{Delegate}, demonstrating a preference-performance misalignment. Moreover, delegation generates positive externalities; even non-adopting users in \\textit{access-to-delegate} treatment groups benefit by receiving higher-quality offers. Mechanism analysis reveals that the \\textit{Delegate} agent acts as a market maker, injecting rational, Pareto-improving proposals that restructure the trading environment. Our research reveals a gap between agent capabilities and realized group welfare. While autonomous agents can exhibit super-human strategic performance, their impact on realized welfare gains can be constrained by interfaces, user perceptions, and adoption barriers. Assistance modalities should be designed as mechanisms with endogenous participation; adoption-compatible interaction rules are a prerequisite to improving human welfare with automated assistance.",
    "authors": [
      "Kehang Zhu",
      "Lithium Thain",
      "Vivian Tsai",
      "James Wexler",
      "Crystal Qian"
    ],
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12089v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12089v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.11968v1",
    "title": "DHPLT: large-scale multilingual diachronic corpora and word representations for semantic change modelling",
    "summary": "In this resource paper, we present DHPLT, an open collection of diachronic corpora in 41 diverse languages. DHPLT is based on the web-crawled HPLT datasets; we use web crawl timestamps as the approximate signal of document creation time. The collection covers three time periods: 2011-2015, 2020-2021 and 2024-present (1 million documents per time period for each language). We additionally provide pre-computed word type and token embeddings and lexical substitutions for our chosen target words, while at the same time leaving it open for the other researchers to come up with their own target words using the same datasets. DHPLT aims at filling in the current lack of multilingual diachronic corpora for semantic change modelling (beyond a dozen of high-resource languages). It opens the way for a variety of new experimental setups in this field. All the resources described in this paper are available at https://data.hplt-project.org/three/diachronic/, sorted by language.",
    "authors": [
      "Mariia Fedorova",
      "Andrey Kutuzov",
      "Khonzoda Umarova"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11968v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11968v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.11956v1",
    "title": "TAVAE: A VAE with Adaptable Priors Explains Contextual Modulation in the Visual Cortex",
    "summary": "The brain interprets visual information through learned regularities, a computation formalized as probabilistic inference under a prior. The visual cortex establishes priors for this inference, some delivered through established top-down connections that inform low-level cortices about statistics represented at higher levels in the cortical hierarchy. While evidence shows that adaptation leads to priors reflecting the structure of natural images, it remains unclear whether similar priors can be flexibly acquired when learning a specific task. To investigate this, we built a generative model of V1 optimized for a simple discrimination task and analyzed it together with large-scale recordings from mice performing an analogous task. In line with recent approaches, we assumed that neuronal activity in V1 corresponds to latent posteriors in the generative model, enabling investigation of task-related priors in neuronal responses. To obtain a flexible test bed, we extended the VAE formalism so that a task can be acquired efficiently by reusing previously learned representations. Task-specific priors learned by this Task-Amortized VAE were used to investigate biases in mice and model when presenting stimuli that violated trained task statistics. Mismatch between learned task statistics and incoming sensory evidence produced signatures of uncertainty in stimulus category in the TAVAE posterior, reflecting properties of bimodal response profiles in V1 recordings. The task-optimized generative model accounted for key characteristics of V1 population activity, including within-day updates to population responses. Our results confirm that flexible task-specific contextual priors can be learned on demand by the visual system and deployed as early as the entry level of visual cortex.",
    "authors": [
      "Balázs Meszéna",
      "Keith T. Murray",
      "Julien Corbo",
      "O. Batuhan Erkat",
      "Márton A. Hajnal",
      "Pierre-Olivier Polack",
      "Gergő Orbán"
    ],
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11956v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11956v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.11939v1",
    "title": "Do Large Language Models Adapt to Language Variation across Socioeconomic Status?",
    "summary": "Humans adjust their linguistic style to the audience they are addressing. However, the extent to which LLMs adapt to different social contexts is largely unknown. As these models increasingly mediate human-to-human communication, their failure to adapt to diverse styles can perpetuate stereotypes and marginalize communities whose linguistic norms are less closely mirrored by the models, thereby reinforcing social stratification. We study the extent to which LLMs integrate into social media communication across different socioeconomic status (SES) communities. We collect a novel dataset from Reddit and YouTube, stratified by SES. We prompt four LLMs with incomplete text from that corpus and compare the LLM-generated completions to the originals along 94 sociolinguistic metrics, including syntactic, rhetorical, and lexical features. LLMs modulate their style with respect to SES to only a minor extent, often resulting in approximation or caricature, and tend to emulate the style of upper SES more effectively. Our findings (1) show how LLMs risk amplifying linguistic hierarchies and (2) call into question their validity for agent-based social simulation, survey experiments, and any research relying on language style as a social signal.",
    "authors": [
      "Elisa Bassignana",
      "Mike Zhang",
      "Dirk Hovy",
      "Amanda Cercas Curry"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11939v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11939v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.11938v1",
    "title": "Who is the richest club in the championship? Detecting and Rewriting Underspecified Questions Improve QA Performance",
    "summary": "Large language models (LLMs) perform well on well-posed questions, yet standard question-answering (QA) benchmarks remain far from solved. We argue that this gap is partly due to underspecified questions - queries whose interpretation cannot be uniquely determined without additional context. To test this hypothesis, we introduce an LLM-based classifier to identify underspecified questions and apply it to several widely used QA datasets, finding that 16% to over 50% of benchmark questions are underspecified and that LLMs perform significantly worse on them. To isolate the effect of underspecification, we conduct a controlled rewriting experiment that serves as an upper-bound analysis, rewriting underspecified questions into fully specified variants while holding gold answers fixed. QA performance consistently improves under this setting, indicating that many apparent QA failures stem from question underspecification rather than model limitations. Our findings highlight underspecification as an important confound in QA evaluation and motivate greater attention to question clarity in benchmark design.",
    "authors": [
      "Yunchong Huang",
      "Gianni Barlacchi",
      "Sandro Pezzelle"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11938v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11938v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.11886v1",
    "title": "LLM-based Triplet Extraction from Financial Reports",
    "summary": "Corporate financial reports are a valuable source of structured knowledge for Knowledge Graph construction, but the lack of annotated ground truth in this domain makes evaluation difficult. We present a semi-automated pipeline for Subject-Predicate-Object triplet extraction that uses ontology-driven proxy metrics, specifically Ontology Conformance and Faithfulness, instead of ground-truth-based evaluation. We compare a static, manually engineered ontology against a fully automated, document-specific ontology induction approach across different LLMs and two corporate annual reports. The automatically induced ontology achieves 100% schema conformance in all configurations, eliminating the ontology drift observed with the manual approach. We also propose a hybrid verification strategy that combines regex matching with an LLM-as-a-judge check, reducing apparent subject hallucination rates from 65.2% to 1.6% by filtering false positives caused by coreference resolution. Finally, we identify a systematic asymmetry between subject and object hallucinations, which we attribute to passive constructions and omitted agents in financial prose.",
    "authors": [
      "Dante Wesslund",
      "Ville Stenström",
      "Pontus Linde",
      "Alexander Holmberg"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11886v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11886v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.11834v1",
    "title": "EqDeepRx: Learning a Scalable MIMO Receiver",
    "summary": "While machine learning (ML)-based receiver algorithms have received a great deal of attention in the recent literature, they often suffer from poor scaling with increasing spatial multiplexing order and lack of explainability and generalization. This paper presents EqDeepRx, a practical deep-learning-aided multiple-input multiple-output (MIMO) receiver, which is built by augmenting linear receiver processing with carefully engineered ML blocks. At the core of the receiver model is a shared-weight DetectorNN that operates independently on each spatial stream or layer, enabling near-linear complexity scaling with respect to multiplexing order. To ensure better explainability and generalization, EqDeepRx retains conventional channel estimation and augments it with a lightweight DenoiseNN that learns frequency-domain smoothing. To reduce the dimensionality of the DetectorNN inputs, the receiver utilizes two linear equalizers in parallel: a linear minimum mean-square error (LMMSE) equalizer with interference-plus-noise covariance estimation and a regularized zero-forcing (RZF) equalizer. The parallel equalized streams are jointly consumed by the DetectorNN, after which a compact DemapperNN produces bit log-likelihood ratios for channel decoding. 5G/6G-compliant end-to-end simulations across multiple channel scenarios, pilot patterns, and inter-cell interference conditions show improved error rate and spectral efficiency over a conventional baseline, while maintaining low-complexity inference and support for different MIMO configurations without retraining.",
    "authors": [
      "Mikko Honkala",
      "Dani Korpi",
      "Elias Raninen",
      "Janne M. J. Huttunen"
    ],
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11834v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11834v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.11829v1",
    "title": "Towards Sustainable Investment Policies Informed by Opponent Shaping",
    "summary": "Addressing climate change requires global coordination, yet rational economic actors often prioritize immediate gains over collective welfare, resulting in social dilemmas. InvestESG is a recently proposed multi-agent simulation that captures the dynamic interplay between investors and companies under climate risk. We provide a formal characterization of the conditions under which InvestESG exhibits an intertemporal social dilemma, deriving theoretical thresholds at which individual incentives diverge from collective welfare. Building on this, we apply Advantage Alignment, a scalable opponent shaping algorithm shown to be effective in general-sum games, to influence agent learning in InvestESG. We offer theoretical insights into why Advantage Alignment systematically favors socially beneficial equilibria by biasing learning dynamics toward cooperative outcomes. Our results demonstrate that strategically shaping the learning processes of economic agents can result in better outcomes that could inform policy mechanisms to better align market incentives with long-term sustainability goals.",
    "authors": [
      "Juan Agustin Duque",
      "Razvan Ciuca",
      "Ayoub Echchahed",
      "Hugo Larochelle",
      "Aaron Courville"
    ],
    "categories": [
      "cs.LG",
      "cs.GT"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11829v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11829v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.11794v1",
    "title": "Latent-Variable Learning of SPDEs via Wiener Chaos",
    "summary": "We study the problem of learning the law of linear stochastic partial differential equations (SPDEs) with additive Gaussian forcing from spatiotemporal observations. Most existing deep learning approaches either assume access to the driving noise or initial condition, or rely on deterministic surrogate models that fail to capture intrinsic stochasticity. We propose a structured latent-variable formulation that requires only observations of solution realizations and learns the underlying randomly forced dynamics. Our approach combines a spectral Galerkin projection with a truncated Wiener chaos expansion, yielding a principled separation between deterministic evolution and stochastic forcing. This reduces the infinite-dimensional SPDE to a finite system of parametrized ordinary differential equations governing latent temporal dynamics. The latent dynamics and stochastic forcing are jointly inferred through variational learning, allowing recovery of stochastic structure without explicit observation or simulation of noise during training. Empirical evaluation on synthetic data demonstrates state-of-the-art performance under comparable modeling assumptions across bounded and unbounded one-dimensional spatial domains.",
    "authors": [
      "Sebastian Zeng",
      "Andreas Petersson",
      "Wolfgang Bock"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11794v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11794v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.11757v1",
    "title": "Code2Worlds: Empowering Coding LLMs for 4D World Generation",
    "summary": "Achieving spatial intelligence requires moving beyond visual plausibility to build world simulators grounded in physical laws. While coding LLMs have advanced static 3D scene generation, extending this paradigm to 4D dynamics remains a critical frontier. This task presents two fundamental challenges: multi-scale context entanglement, where monolithic generation fails to balance local object structures with global environmental layouts; and a semantic-physical execution gap, where open-loop code generation leads to physical hallucinations lacking dynamic fidelity. We introduce Code2Worlds, a framework that formulates 4D generation as language-to-simulation code generation. First, we propose a dual-stream architecture that disentangles retrieval-augmented object generation from hierarchical environmental orchestration. Second, to ensure dynamic fidelity, we establish a physics-aware closed-loop mechanism in which a PostProcess Agent scripts dynamics, coupled with a VLM-Motion Critic that performs self-reflection to iteratively refine simulation code. Evaluations on the Code4D benchmark show Code2Worlds outperforms baselines with a 41% SGS gain and 49% higher Richness, while uniquely generating physics-aware dynamics absent in prior static methods. Code: https://github.com/AIGeeksGroup/Code2Worlds. Website: https://aigeeksgroup.github.io/Code2Worlds.",
    "authors": [
      "Yi Zhang",
      "Yunshuang Wang",
      "Zeyu Zhang",
      "Hao Tang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11757v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11757v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.11731v1",
    "title": "Thinking with Drafting: Optical Decompression via Logical Reconstruction",
    "summary": "Existing multimodal large language models have achieved high-fidelity visual perception and exploratory visual generation. However, a precision paradox persists in complex reasoning tasks: optical perception systems transcribe symbols without capturing logical topology, while pixel-based generative models produce visual artifacts lacking mathematical exactness. To bridge this gap, we propose that reasoning over visual inputs be reconceptualized as optical decompression-the process of reconstructing latent logical structures from compressed visual tokens. Guided by the axiom that Parsing is Reasoning, we introduce Thinking with Drafting (TwD), which utilizes a minimalist Domain-Specific Language (DSL) as a grounding intermediate representation. Unlike standard approaches that hallucinate answers directly, TwD forces the model to draft its mental model into executable code, rendering deterministic visual proofs for self-verification. To validate this, we present VisAlg, a visual algebra benchmark. Experiments demonstrate that TwD serve as a superior cognitive scaffold. Our work establishes a closed-loop system where visual generation acts not as a creative output but as a logical verifier, offering a generalizable path for visual reasoning.",
    "authors": [
      "Jingxuan Wei",
      "Honghao He",
      "Caijun Jia",
      "Siyuan Li",
      "Zheng Sun",
      "Yuhang Xu",
      "Yuanyuan Lin",
      "Linzhuang Sun",
      "Yuchen Wu",
      "Bihui Yu",
      "Xiangxiang Zhang",
      "Cheng Tan"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11731v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11731v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.11679v1",
    "title": "Provable Offline Reinforcement Learning for Structured Cyclic MDPs",
    "summary": "We introduce a novel cyclic Markov decision process (MDP) framework for multi-step decision problems with heterogeneous stage-specific dynamics, transitions, and discount factors across the cycle. In this setting, offline learning is challenging: optimizing a policy at any stage shifts the state distributions of subsequent stages, propagating mismatch across the cycle. To address this, we propose a modular structural framework that decomposes the cyclic process into stage-wise sub-problems. While generally applicable, we instantiate this principle as CycleFQI, an extension of fitted Q-iteration enabling theoretical analysis and interpretation. It uses a vector of stage-specific Q-functions, tailored to each stage, to capture within-stage sequences and transitions between stages. This modular design enables partial control, allowing some stages to be optimized while others follow predefined policies. We establish finite-sample suboptimality error bounds and derive global convergence rates under Besov regularity, demonstrating that CycleFQI mitigates the curse of dimensionality compared to monolithic baselines. Additionally, we propose a sieve-based method for asymptotic inference of optimal policy values under a margin condition. Experiments on simulated and real-world Type 1 Diabetes data sets demonstrate CycleFQI's effectiveness.",
    "authors": [
      "Kyungbok Lee",
      "Angelica Cristello Sarteau",
      "Michael R. Kosorok"
    ],
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.OC",
      "stat.ME"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11679v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11679v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.11669v1",
    "title": "Egocentric Gaze Estimation via Neck-Mounted Camera",
    "summary": "This paper introduces neck-mounted view gaze estimation, a new task that estimates user gaze from the neck-mounted camera perspective. Prior work on egocentric gaze estimation, which predicts device wearer's gaze location within the camera's field of view, mainly focuses on head-mounted cameras while alternative viewpoints remain underexplored. To bridge this gap, we collect the first dataset for this task, consisting of approximately 4 hours of video collected from 8 participants during everyday activities. We evaluate a transformer-based gaze estimation model, GLC, on the new dataset and propose two extensions: an auxiliary gaze out-of-bound classification task and a multi-view co-learning approach that jointly trains head-view and neck-view models using a geometry-aware auxiliary loss. Experimental results show that incorporating gaze out-of-bound classification improves performance over standard fine-tuning, while the co-learning approach does not yield gains. We further analyze these results and discuss implications for neck-mounted gaze estimation.",
    "authors": [
      "Haoyu Huang",
      "Yoichi Sato"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11669v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11669v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.11650v1",
    "title": "Which Feedback Works for Whom? Differential Effects of LLM-Generated Feedback Elements Across Learner Profiles",
    "summary": "Large language models (LLMs) show promise for automatically generating feedback in education settings. However, it remains unclear how specific feedback elements, such as tone and information coverage, contribute to learning outcomes and learner acceptance, particularly across learners with different personality traits. In this study, we define six feedback elements and generate feedback for multiple-choice biology questions using GPT-5. We conduct a learning experiment with 321 first-year high school students and evaluate feedback effectiveness using two learning outcomes measures and subjective evaluations across six criteria. We further analyze differences in how feedback acceptance varies across learners based on Big Five personality traits. Our results show that effective feedback elements share common patterns supporting learning outcomes, while learners' subjective preferences differ across personality-based clusters. These findings highlight the importance of selecting and adapting feedback elements according to learners' personality traits when we design LLM-generated feedback, and provide practical implications for personalized feedback design in education.",
    "authors": [
      "Momoka Furuhashi",
      "Kouta Nakayama",
      "Noboru Kawai",
      "Takashi Kodama",
      "Saku Sugawara",
      "Kyosuke Takami"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11650v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11650v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2602.12096v1",
    "title": "Multi Graph Search for High-Dimensional Robot Motion Planning",
    "summary": "Efficient motion planning for high-dimensional robotic systems, such as manipulators and mobile manipulators, is critical for real-time operation and reliable deployment. Although advances in planning algorithms have enhanced scalability to high-dimensional state spaces, these improvements often come at the cost of generating unpredictable, inconsistent motions or requiring excessive computational resources and memory. In this work, we introduce Multi-Graph Search (MGS), a search-based motion planning algorithm that generalizes classical unidirectional and bidirectional search to a multi-graph setting. MGS maintains and incrementally expands multiple implicit graphs over the state space, focusing exploration on high-potential regions while allowing initially disconnected subgraphs to be merged through feasible transitions as the search progresses. We prove that MGS is complete and bounded-suboptimal, and empirically demonstrate its effectiveness on a range of manipulation and mobile manipulation tasks. Demonstrations, benchmarks and code are available at https://multi-graph-search.github.io/.",
    "authors": [
      "Itamar Mishani",
      "Maxim Likhachev"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12096v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12096v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.12039v1",
    "title": "The Implicit Bias of Logit Regularization",
    "summary": "Logit regularization, the addition a convex penalty directly in logit space, is widely used in modern classifiers, with label smoothing as a prominent example. While such methods often improve calibration and generalization, their mechanism remains under-explored. In this work, we analyze a general class of such logit regularizers in the context of linear classification, and demonstrate that they induce an implicit bias of logit clustering around finite per-sample targets. For Gaussian data, or whenever logits are sufficiently clustered, we prove that logit clustering drives the weight vector to align exactly with Fisher's Linear Discriminant. To demonstrate the consequences, we study a simple signal-plus-noise model in which this transition has dramatic effects: Logit regularization halves the critical sample complexity and induces grokking in the small-noise limit, while making generalization robust to noise. Our results extend the theoretical understanding of label smoothing and highlight the efficacy of a broader class of logit-regularization methods.",
    "authors": [
      "Alon Beck",
      "Yohai Bar Sinai",
      "Noam Levi"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12039v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12039v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.12026v1",
    "title": "Protein Circuit Tracing via Cross-layer Transcoders",
    "summary": "Protein language models (pLMs) have emerged as powerful predictors of protein structure and function. However, the computational circuits underlying their predictions remain poorly understood. Recent mechanistic interpretability methods decompose pLM representations into interpretable features, but they treat each layer independently and thus fail to capture cross-layer computation, limiting their ability to approximate the full model. We introduce ProtoMech, a framework for discovering computational circuits in pLMs using cross-layer transcoders that learn sparse latent representations jointly across layers to capture the model's full computational circuitry. Applied to the pLM ESM2, ProtoMech recovers 82-89% of the original performance on protein family classification and function prediction tasks. ProtoMech then identifies compressed circuits that use <1% of the latent space while retaining up to 79% of model accuracy, revealing correspondence with structural and functional motifs, including binding, signaling, and stability. Steering along these circuits enables high-fitness protein design, surpassing baseline methods in more than 70% of cases. These results establish ProtoMech as a principled framework for protein circuit tracing.",
    "authors": [
      "Darin Tsui",
      "Kunal Talreja",
      "Daniel Saeedi",
      "Amirali Aghazadeh"
    ],
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12026v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12026v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.12009v1",
    "title": "On the Sensitivity of Firing Rate-Based Federated Spiking Neural Networks to Differential Privacy",
    "summary": "Federated Neuromorphic Learning (FNL) enables energy-efficient and privacy-preserving learning on devices without centralizing data. However, real-world deployments require additional privacy mechanisms that can significantly alter training signals. This paper analyzes how Differential Privacy (DP) mechanisms, specifically gradient clipping and noise injection, perturb firing-rate statistics in Spiking Neural Networks (SNNs) and how these perturbations are propagated to rate-based FNL coordination. On a speech recognition task under non-IID settings, ablations across privacy budgets and clipping bounds reveal systematic rate shifts, attenuated aggregation, and ranking instability during client selection. Moreover, we relate these shifts to sparsity and memory indicators. Our findings provide actionable guidance for privacy-preserving FNL, specifically regarding the balance between privacy strength and rate-dependent coordination.",
    "authors": [
      "Luiz Pereira",
      "Mirko Perkusich",
      "Dalton Valadares",
      "Kyller Gorgônio"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12009v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12009v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.11920v1",
    "title": "Learning Conditional Averages",
    "summary": "We introduce the problem of learning conditional averages in the PAC framework. The learner receives a sample labeled by an unknown target concept from a known concept class, as in standard PAC learning. However, instead of learning the target concept itself, the goal is to predict, for each instance, the average label over its neighborhood -- an arbitrary subset of points that contains the instance. In the degenerate case where all neighborhoods are singletons, the problem reduces exactly to classic PAC learning. More generally, it extends PAC learning to a setting that captures learning tasks arising in several domains, including explainability, fairness, and recommendation systems. Our main contribution is a complete characterization of when conditional averages are learnable, together with sample complexity bounds that are tight up to logarithmic factors. The characterization hinges on the joint finiteness of two novel combinatorial parameters, which depend on both the concept class and the neighborhood system, and are closely related to the independence number of the associated neighborhood graph.",
    "authors": [
      "Marco Bressan",
      "Nataly Brukhim",
      "Nicolo Cesa-Bianchi",
      "Emmanuel Esposito",
      "Yishay Mansour",
      "Shay Moran",
      "Maximilian Thiessen"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11920v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11920v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.11875v1",
    "title": "DiffPlace: Street View Generation via Place-Controllable Diffusion Model Enhancing Place Recognition",
    "summary": "Generative models have advanced significantly in realistic image synthesis, with diffusion models excelling in quality and stability. Recent multi-view diffusion models improve 3D-aware street view generation, but they struggle to produce place-aware and background-consistent urban scenes from text, BEV maps, and object bounding boxes. This limits their effectiveness in generating realistic samples for place recognition tasks. To address these challenges, we propose DiffPlace, a novel framework that introduces a place-ID controller to enable place-controllable multi-view image generation. The place-ID controller employs linear projection, perceiver transformer, and contrastive learning to map place-ID embeddings into a fixed CLIP space, allowing the model to synthesize images with consistent background buildings while flexibly modifying foreground objects and weather conditions. Extensive experiments, including quantitative comparisons and augmented training evaluations, demonstrate that DiffPlace outperforms existing methods in both generation quality and training support for visual place recognition. Our results highlight the potential of generative models in enhancing scene-level and place-aware synthesis, providing a valuable approach for improving place recognition in autonomous driving",
    "authors": [
      "Ji Li",
      "Zhiwei Li",
      "Shihao Li",
      "Zhenjiang Yu",
      "Boyang Wang",
      "Haiou Liu"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11875v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11875v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.11857v1",
    "title": "Scale-Invariant Fast Convergence in Games",
    "summary": "Scale-invariance in games has recently emerged as a widely valued desirable property. Yet, almost all fast convergence guarantees in learning in games require prior knowledge of the utility scale. To address this, we develop learning dynamics that achieve fast convergence while being both scale-free, requiring no prior information about utilities, and scale-invariant, remaining unchanged under positive rescaling of utilities. For two-player zero-sum games, we obtain scale-free and scale-invariant dynamics with external regret bounded by $\\tilde{O}(A_{\\mathrm{diff}})$, where $A_{\\mathrm{diff}}$ is the payoff range, which implies an $\\tilde{O}(A_{\\mathrm{diff}} / T)$ convergence rate to Nash equilibrium after $T$ rounds. For multiplayer general-sum games with $n$ players and $m$ actions, we obtain scale-free and scale-invariant dynamics with swap regret bounded by $O(U_{\\mathrm{max}} \\log T)$, where $U_{\\mathrm{max}}$ is the range of the utilities, ignoring the dependence on the number of players and actions. This yields an $O(U_{\\mathrm{max}} \\log T / T)$ convergence rate to correlated equilibrium. Our learning dynamics are based on optimistic follow-the-regularized-leader with an adaptive learning rate that incorporates the squared path length of the opponents' gradient vectors, together with a new stopping-time analysis that exploits negative terms in regret bounds without scale-dependent tuning. For general-sum games, scale-free learning is enabled also by a technique called doubling clipping, which clips observed gradients based on past observations.",
    "authors": [
      "Taira Tsuchiya",
      "Haipeng Luo",
      "Shinji Ito"
    ],
    "categories": [
      "cs.GT",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11857v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11857v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.11814v1",
    "title": "A Comparative Study of MAP and LMMSE Estimators for Blind Inverse Problems",
    "summary": "Maximum-a-posteriori (MAP) approaches are an effective framework for inverse problems with known forward operators, particularly when combined with expressive priors and careful parameter selection. In blind settings, however, their use becomes significantly less stable due to the inherent non-convexity of the problem and the potential non-identifiability of the solutions. (Linear) minimum mean square error (MMSE) estimators provide a compelling alternative that can circumvent these limitations. In this work, we study synthetic two-dimensional blind deconvolution problems under fully controlled conditions, with complete prior knowledge of both the signal and kernel distributions. We compare tailored MAP algorithms with simple LMMSE estimators whose functional form is closely related to that of an optimal Tikhonov estimator. Our results show that, even in these highly controlled settings, MAP methods remain unstable and require extensive parameter tuning, whereas the LMMSE estimator yields a robust and reliable baseline. Moreover, we demonstrate empirically that the LMMSE solution can serve as an effective initialization for MAP approaches, improving their performance and reducing sensitivity to regularization parameters, thereby opening the door to future theoretical and practical developments.",
    "authors": [
      "Nathan Buskulic",
      "Luca Calatroni"
    ],
    "categories": [
      "cs.IT",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11814v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11814v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.11805v1",
    "title": "From Path Signatures to Sequential Modeling: Incremental Signature Contributions for Offline RL",
    "summary": "Path signatures embed trajectories into tensor algebra and constitute a universal, non-parametric representation of paths; however, in the standard form, they collapse temporal structure into a single global object, which limits their suitability for decision-making problems that require step-wise reactivity. We propose the Incremental Signature Contribution (ISC) method, which decomposes truncated path signatures into a temporally ordered sequence of elements in the tensor-algebra space, corresponding to incremental contributions induced by last path increments. This reconstruction preserves the algebraic structure and expressivity of signatures, while making their internal temporal evolution explicit, enabling processing signature-based representations via sequential modeling approaches. In contrast to full signatures, ISC is inherently sensitive to instantaneous trajectory updates, which is critical for sensitive and stability-requiring control dynamics. Building on this representation, we introduce ISC-Transformer (ISCT), an offline reinforcement learning model that integrates ISC into a standard Transformer architecture without further architectural modification. We evaluate ISCT on HalfCheetah, Walker2d, Hopper, and Maze2d, including settings with delayed rewards and downgraded datasets. The results demonstrate that ISC method provides a theoretically grounded and practically effective alternative to path processing for temporally sensitive control tasks.",
    "authors": [
      "Ziyi Zhao",
      "Qingchuan Li",
      "Yuxuan Xu"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11805v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11805v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.11789v1",
    "title": "Decentralized Non-convex Stochastic Optimization with Heterogeneous Variance",
    "summary": "Decentralized optimization is critical for solving large-scale machine learning problems over distributed networks, where multiple nodes collaborate through local communication. In practice, the variances of stochastic gradient estimators often differ across nodes, yet their impact on algorithm design and complexity remains unclear. To address this issue, we propose D-NSS, a decentralized algorithm with node-specific sampling, and establish its sample complexity depending on the arithmetic mean of local standard deviations, achieving tighter bounds than existing methods that rely on the worst-case or quadratic mean. We further derive a matching sample complexity lower bound under heterogeneous variance, thereby proving the optimality of this dependence. Moreover, we extend the framework with a variance reduction technique and develop D-NSS-VR, which under the mean-squared smoothness assumption attains an improved sample complexity bound while preserving the arithmetic-mean dependence. Finally, numerical experiments validate the theoretical results and demonstrate the effectiveness of the proposed algorithms.",
    "authors": [
      "Hongxu Chen",
      "Ke Wei",
      "Luo Luo"
    ],
    "categories": [
      "math.OC",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11789v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11789v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.11737v1",
    "title": "Mask What Matters: Mitigating Object Hallucinations in Multimodal Large Language Models with Object-Aligned Visual Contrastive Decoding",
    "summary": "We study object hallucination in Multimodal Large Language Models (MLLMs) and improve visual contrastive decoding (VCD) by constructing an object-aligned auxiliary view. We leverage object-centric attention in self-supervised Vision Transformers. In particular, we remove the most salient visual evidence to construct an auxiliary view that disrupts unsupported tokens and produces a stronger contrast signal. Our method is prompt-agnostic, model-agnostic, and can be seamlessly plugged into the existing VCD pipeline with little computation overhead, i.e., a single cacheable forward pass. Empirically, our method demonstrates consistent gains on two popular object hallucination benchmarks across two MLLMs.",
    "authors": [
      "Boqi Chen",
      "Xudong Liu",
      "Jianing Qiu"
    ],
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11737v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11737v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.11722v1",
    "title": "PAC-Bayesian Generalization Guarantees for Fairness on Stochastic and Deterministic Classifiers",
    "summary": "Classical PAC generalization bounds on the prediction risk of a classifier are insufficient to provide theoretical guarantees on fairness when the goal is to learn models balancing predictive risk and fairness constraints. We propose a PAC-Bayesian framework for deriving generalization bounds for fairness, covering both stochastic and deterministic classifiers. For stochastic classifiers, we derive a fairness bound using standard PAC-Bayes techniques. Whereas for deterministic classifiers, as usual PAC-Bayes arguments do not apply directly, we leverage a recent advance in PAC-Bayes to extend the fairness bound beyond the stochastic setting. Our framework has two advantages: (i) It applies to a broad class of fairness measures that can be expressed as a risk discrepancy, and (ii) it leads to a self-bounding algorithm in which the learning procedure directly optimizes a trade-off between generalization bounds on the prediction risk and on the fairness. We empirically evaluate our framework with three classical fairness measures, demonstrating not only its usefulness but also the tightness of our bounds.",
    "authors": [
      "Julien Bastian",
      "Benjamin Leblanc",
      "Pascal Germain",
      "Amaury Habrard",
      "Christine Largeron",
      "Guillaume Metzler",
      "Emilie Morvant",
      "Paul Viallard"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11722v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11722v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.11675v1",
    "title": "Right for the Wrong Reasons: Epistemic Regret Minimization for Causal Rung Collapse in LLMs",
    "summary": "Machine learning systems that are \"right for the wrong reasons\" achieve high performance through shortcuts that collapse under distributional shift. We show this pathology has a precise causal origin: autoregressive training provides no gradient signal to distinguish association P(Y|X) from intervention P(Y|do(X)), a failure we formalize as Rung Collapse. When outcome-based learning reinforces correct answers obtained through incorrect causal models, the agent becomes entrenched in flawed reasoning, a phenomenon we term Aleatoric Entrenchment. We propose Epistemic Regret Minimization (ERM), a belief revision objective that penalizes errors in causal reasoning independently of task success, and embed it within a three-layer architecture with three contributions grounded in knowledge representation: (1) a Physical Grounding Theorem proving that actions satisfying actuator independence implement valid do-operations, bridging action languages and do-calculus; (2) ERM as a causal belief revision operator satisfying AGM postulates, preventing entrenchment even when the agent succeeds for the wrong reasons; and (3) a failure mode taxonomy that classifies recurring reasoning errors and injects domain-independent guards, enabling cross-domain transfer. We prove asymptotic recovery of the true interventional distribution with finite-sample bounds. Experiments on 1,360 causal trap scenarios across six frontier LLMs reveal that Rung Collapse persists even in reasoning-enhanced models (3.7% for GPT-5.2), that steerability exhibits inverse scaling where advanced models resist generic correction, and that targeted ERM feedback recovers 53-59% of entrenched errors where outcome-level feedback fails.",
    "authors": [
      "Edward Y. Chang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11675v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11675v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2602.12080v1",
    "title": "PathCRF: Ball-Free Soccer Event Detection via Possession Path Inference from Player Trajectories",
    "summary": "Despite recent advances in AI, event data collection in soccer still relies heavily on labor-intensive manual annotation. Although prior work has explored automatic event detection using player and ball trajectories, ball tracking also remains difficult to scale due to high infrastructural and operational costs. As a result, comprehensive data collection in soccer is largely confined to top-tier competitions, limiting the broader adoption of data-driven analysis in this domain. To address this challenge, this paper proposes PathCRF, a framework for detecting on-ball soccer events using only player tracking data. We model player trajectories as a fully connected dynamic graph and formulate event detection as the problem of selecting exactly one edge corresponding to the current possession state at each time step. To ensure logical consistency of the resulting edge sequence, we employ a Conditional Random Field (CRF) that forbids impossible transitions between consecutive edges. Both emission and transition scores dynamically computed from edge embeddings produced by a Set Attention-based backbone architecture. During inference, the most probable edge sequence is obtained via Viterbi decoding, and events such as ball controls or passes are detected whenever the selected edge changes between adjacent time steps. Experiments show that PathCRF produces accurate, logically consistent possession paths, enabling reliable downstream analyses while substantially reducing the need for manual event annotation. The source code is available at https://github.com/hyunsungkim-ds/pathcrf.git.",
    "authors": [
      "Hyunsung Kim",
      "Kunhee Lee",
      "Sangwoo Seo",
      "Sang-Ki Ko",
      "Jinsung Yoon",
      "Chanyoung Park"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12080v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12080v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.12013v1",
    "title": "InjectRBP: Steering Large Language Model Reasoning Behavior via Pattern Injection",
    "summary": "Reasoning can significantly enhance the performance of Large Language Models. While recent studies have exploited behavior-related prompts adjustment to enhance reasoning, these designs remain largely intuitive and lack a systematic analysis of the underlying behavioral patterns. Motivated by this, we investigate how models' reasoning behaviors shape reasoning from the perspective of behavioral patterns. We observe that models exhibit adaptive distributions of reasoning behaviors when responding to specific types of questions, and that structurally injecting these patterns can substantially influence the quality of the models' reasoning processes and outcomes. Building on these findings, we propose two optimization methods that require no parameter updates: InjectCorrect and InjectRLOpt. InjectCorrect guides the model by imitating behavioral patterns derived from its own past correct answers. InjectRLOpt learns a value function from historical behavior-pattern data and, via our proposed Reliability-Aware Softmax Policy, generates behavioral injectant during inference to steer the reasoning process. Our experiments demonstrate that both methods can improve model performance across various reasoning tasks without requiring any modifications to model parameters, achieving gains of up to 5.34% and 8.67%, respectively.",
    "authors": [
      "Xiuping Wu",
      "Zhao Yu",
      "Yuxin Cheng",
      "Ngai Wong",
      "Liangjun Ke",
      "Tapas Mishra",
      "Konstantinos V. Katsikopoulos"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12013v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12013v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.11969v1",
    "title": "UPDA: Unsupervised Progressive Domain Adaptation for No-Reference Point Cloud Quality Assessment",
    "summary": "While no-reference point cloud quality assessment (NR-PCQA) approaches have achieved significant progress over the past decade, their performance often degrades substantially when a distribution gap exists between the training (source domain) and testing (target domain) data. However, to date, limited attention has been paid to transferring NR-PCQA models across domains. To address this challenge, we propose the first unsupervised progressive domain adaptation (UPDA) framework for NR-PCQA, which introduces a two-stage coarse-to-fine alignment paradigm to address domain shifts. At the coarse-grained stage, a discrepancy-aware coarse-grained alignment method is designed to capture relative quality relationships between cross-domain samples through a novel quality-discrepancy-aware hybrid loss, circumventing the challenges of direct absolute feature alignment. At the fine-grained stage, a perception fusion fine-grained alignment approach with symmetric feature fusion is developed to identify domain-invariant features, while a conditional discriminator selectively enhances the transfer of quality-relevant features. Extensive experiments demonstrate that the proposed UPDA effectively enhances the performance of NR-PCQA methods in cross-domain scenarios, validating its practical applicability. The code is available at https://github.com/yokeno1/UPDA-main.",
    "authors": [
      "Bingxu Xie",
      "Fang Zhou",
      "Jincan Wu",
      "Yonghui Liu",
      "Weiqing Li",
      "Zhiyong Su"
    ],
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.MM"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11969v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11969v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.11904v1",
    "title": "Leveraging LLMs to support co-evolution between definitions and instances of textual DSLs: A Systematic Evaluation",
    "summary": "Software languages evolve over time for reasons such as feature additions. When grammars evolve, textual instances that originally conformed to them may become outdated. While model-driven engineering provides many techniques for co-evolving models with metamodel changes, these approaches are not designed for textual DSLs and may lose human-relevant information such as layout and comments. This study systematically evaluates the potential of large language models (LLMs) for co-evolving grammars and instances of textual DSLs. Using Claude Sonnet 4.5 and GPT-5.2 across ten case languages with ten runs each, we assess both correctness and preservation of human-oriented information. Results show strong performance on small-scale cases ($\\geq$94% precision and recall for instances requiring fewer than 20 modified lines), but performance degraded with scale: Claude maintains 85% recall at 40 lines, while GPT fails on the largest instances. Response time increases substantially with instance size, and grammar evolution complexity and deletion granularity affect performance more than change type. These findings clarify when LLM-based co-evolution is effective and where current limitations remain.",
    "authors": [
      "Weixing Zhang",
      "Bowen Jiang",
      "Yuhong Fu",
      "Anne Koziolek",
      "Regina Hebig",
      "Daniel Strüber"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11904v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11904v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.11863v1",
    "title": "In-Context Function Learning in Large Language Models",
    "summary": "Large language models (LLMs) can learn from a few demonstrations provided at inference time. We study this in-context learning phenomenon through the lens of Gaussian Processes (GPs). We build controlled experiments where models observe sequences of multivariate scalar-valued function samples drawn from known GP priors. We evaluate prediction error in relation to the number of demonstrations and compare against two principled references: (i) an empirical GP-regression learner that gives a lower bound on achievable error, and (ii) the expected error of a 1-nearest-neighbor (1-NN) rule, which gives a data-driven upper bound. Across model sizes, we find that LLM learning curves are strongly influenced by the function-generating kernels and approach the GP lower bound as the number of demonstrations increases. We then study the inductive biases of these models using a likelihood-based analysis. We find that LLM predictions are most likely under less smooth GP kernels. Finally, we explore whether post-training can shift these inductive biases and improve sample-efficiency on functions sampled from GPs with smoother kernels. We find that both reinforcement learning and supervised fine-tuning can effectively shift inductive biases in the direction of the training data. Together, our framework quantifies the extent to which LLMs behave like GP learners and provides tools for steering their inductive biases for continuous function learning tasks.",
    "authors": [
      "Elif Akata",
      "Konstantinos Voudouris",
      "Vincent Fortuin",
      "Eric Schulz"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11863v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11863v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2602.12099v1",
    "title": "GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning",
    "summary": "Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose \\textit{GigaBrain-0.5M*}, a VLA model trained via world model-based reinforcement learning. Built upon \\textit{GigaBrain-0.5}, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark. \\textit{GigaBrain-0.5M*} further integrates world model-based reinforcement learning via \\textit{RAMP} (Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation. Empirical results demonstrate that \\textit{RAMP} achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\\% on challenging tasks including \\texttt{Laundry Folding}, \\texttt{Box Packing}, and \\texttt{Espresso Preparation}. Critically, \\textit{GigaBrain-0.5M$^*$} exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our \\href{https://gigabrain05m.github.io}{project page}.",
    "authors": [
      " GigaBrain Team",
      "Boyuan Wang",
      "Chaojun Ni",
      "Guan Huang",
      "Guosheng Zhao",
      "Hao Li",
      "Jie Li",
      "Jindi Lv",
      "Jingyu Liu",
      "Lv Feng",
      "Mingming Yu",
      "Peng Li",
      "Qiuping Deng",
      "Tianze Liu",
      "Xinyu Zhou",
      "Xinze Chen",
      "Xiaofeng Wang",
      "Yang Wang",
      "Yifan Li",
      "Yifei Nie",
      "Yilong Li",
      "Yukun Zhou",
      "Yun Ye",
      "Zhichao Liu",
      "Zheng Zhu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12099v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12099v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.12082v1",
    "title": "Empirical Gaussian Processes",
    "summary": "Gaussian processes (GPs) are powerful and widely used probabilistic regression models, but their effectiveness in practice is often limited by the choice of kernel function. This kernel function is typically handcrafted from a small set of standard functions, a process that requires expert knowledge, results in limited adaptivity to data, and imposes strong assumptions on the hypothesis space. We study Empirical GPs, a principled framework for constructing flexible, data-driven GP priors that overcome these limitations. Rather than relying on standard parametric kernels, we estimate the mean and covariance functions empirically from a corpus of historical observations, enabling the prior to reflect rich, non-trivial covariance structures present in the data. Theoretically, we show that the resulting model converges to the GP that is closest (in KL-divergence sense) to the real data generating process. Practically, we formulate the problem of learning the GP prior from independent datasets as likelihood estimation and derive an Expectation-Maximization algorithm with closed-form updates, allowing the model handle heterogeneous observation locations across datasets. We demonstrate that Empirical GPs achieve competitive performance on learning curve extrapolation and time series forecasting benchmarks.",
    "authors": [
      "Jihao Andreas Lin",
      "Sebastian Ament",
      "Louis C. Tiao",
      "David Eriksson",
      "Maximilian Balandat",
      "Eytan Bakshy"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12082v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12082v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.11988v1",
    "title": "Evaluating AGENTS.md: Are Repository-Level Context Files Helpful for Coding Agents?",
    "summary": "A widespread practice in software development is to tailor coding agents to repositories using context files, such as AGENTS.md, by either manually or automatically generating them. Although this practice is strongly encouraged by agent developers, there is currently no rigorous investigation into whether such context files are actually effective for real-world tasks. In this work, we study this question and evaluate coding agents' task completion performance in two complementary settings: established SWE-bench tasks from popular repositories, with LLM-generated context files following agent-developer recommendations, and a novel collection of issues from repositories containing developer-committed context files.   Across multiple coding agents and LLMs, we find that context files tend to reduce task success rates compared to providing no repository context, while also increasing inference cost by over 20%. Behaviorally, both LLM-generated and developer-provided context files encourage broader exploration (e.g., more thorough testing and file traversal), and coding agents tend to respect their instructions. Ultimately, we conclude that unnecessary requirements from context files make tasks harder, and human-written context files should describe only minimal requirements.",
    "authors": [
      "Thibaud Gloaguen",
      "Niels Mündler",
      "Mark Müller",
      "Veselin Raychev",
      "Martin Vechev"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11988v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11988v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.11960v1",
    "title": "Benchmarking Vision-Language Models for French PDF-to-Markdown Conversion",
    "summary": "This report evaluates PDF-to-Markdown conversion using recent Vision-Language Models (VLMs) on challenging French documents. Document parsing is a critical step for Retrieval-Augmented Generation (RAG) pipelines, where transcription and layout errors propagate to downstream retrieval and grounding. Existing benchmarks often emphasize English or Chinese and can over-penalize benign formatting and linearization choices (e.g., line breaks, list segmentation, alternative table renderings) that are largely irrelevant for downstream use.   We introduce a French-focused benchmark of difficult pages selected via model-disagreement sampling from a corpus of 60{,}000 documents, covering handwritten forms, complex layouts, dense tables, and graphics-rich pages. Evaluation is performed with unit-test-style checks that target concrete failure modes (text presence, reading order, and local table constraints) combined with category-specific normalization designed to discount presentation-only variance. Across 15 models, we observe substantially higher robustness for the strongest proprietary models on handwriting and forms, while several open-weights systems remain competitive on standard printed layouts.",
    "authors": [
      "Bruno Rigal",
      "Victor Dupriez",
      "Alexis Mignon",
      "Ronan Le Hy",
      "Nicolas Mery"
    ],
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11960v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11960v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.11947v1",
    "title": "Mixed-Integer Programming for Change-point Detection",
    "summary": "We present a new mixed-integer programming (MIP) approach for offline multiple change-point detection by casting the problem as a globally optimal piecewise linear (PWL) fitting problem. Our main contribution is a family of strengthened MIP formulations whose linear programming (LP) relaxations admit integral projections onto the segment assignment variables, which encode the segment membership of each data point. This property yields provably tighter relaxations than existing formulations for offline multiple change-point detection. We further extend the framework to two settings of active research interest: (i) multidimensional PWL models with shared change-points, and (ii) sparse change-point detection, where only a subset of dimensions undergo structural change. Extensive computational experiments on benchmark real-world datasets demonstrate that the proposed formulations achieve reductions in solution times under both $\\ell_1$ and $\\ell_2$ loss functions in comparison to the state-of-the-art.",
    "authors": [
      "Apoorva Narula",
      "Santanu S. Dey",
      "Yao Xie"
    ],
    "categories": [
      "math.OC",
      "stat.ML"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11947v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11947v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.11801v1",
    "title": "SpaTeoGL: Spatiotemporal Graph Learning for Interpretable Seizure Onset Zone Analysis from Intracranial EEG",
    "summary": "Accurate localization of the seizure onset zone (SOZ) from intracranial EEG (iEEG) is essential for epilepsy surgery but is challenged by complex spatiotemporal seizure dynamics. We propose SpaTeoGL, a spatiotemporal graph learning framework for interpretable seizure network analysis. SpaTeoGL jointly learns window-level spatial graphs capturing interactions among iEEG electrodes and a temporal graph linking time windows based on similarity of their spatial structure. The method is formulated within a smooth graph signal processing framework and solved via an alternating block coordinate descent algorithm with convergence guarantees. Experiments on a multicenter iEEG dataset with successful surgical outcomes show that SpaTeoGL is competitive with a baseline based on horizontal visibility graphs and logistic regression, while improving non-SOZ identification and providing interpretable insights into seizure onset and propagation dynamics.",
    "authors": [
      "Elham Rostami",
      "Aref Einizade",
      "Taous-Meriem Laleg-Kirati"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11801v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11801v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.11786v1",
    "title": "Evaluating LLM Safety Under Repeated Inference via Accelerated Prompt Stress Testing",
    "summary": "Traditional benchmarks for large language models (LLMs) primarily assess safety risk through breadth-oriented evaluation across diverse tasks. However, real-world deployment exposes a different class of risk: operational failures arising from repeated inference on identical or near-identical prompts rather than broad task generalization. In high-stakes settings, response consistency and safety under sustained use are critical. We introduce Accelerated Prompt Stress Testing (APST), a depth-oriented evaluation framework inspired by reliability engineering. APST repeatedly samples identical prompts under controlled operational conditions (e.g., decoding temperature) to surface latent failure modes including hallucinations, refusal inconsistency, and unsafe completions. Rather than treating failures as isolated events, APST models them as stochastic outcomes of independent inference events. We formalize safety failures using Bernoulli and binomial models to estimate per-inference failure probabilities, enabling quantitative comparison of reliability across models and decoding configurations. Applying APST to multiple instruction-tuned LLMs evaluated on AIR-BENCH-derived safety prompts, we find that models with similar benchmark-aligned scores can exhibit substantially different empirical failure rates under repeated sampling, particularly as temperature increases. These results demonstrate that shallow, single-sample evaluation can obscure meaningful reliability differences under sustained use. APST complements existing benchmarks by providing a practical framework for evaluating LLM safety and reliability under repeated inference, bridging benchmark alignment and deployment-oriented risk assessment.",
    "authors": [
      "Keita Broadwater"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11786v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11786v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.11776v1",
    "title": "MUSE: Multi-Tenant Model Serving With Seamless Model Updates",
    "summary": "In binary classification systems, decision thresholds translate model scores into actions. Choosing suitable thresholds relies on the specific distribution of the underlying model scores but also on the specific business decisions of each client using that model. However, retraining models inevitably shifts score distributions, invalidating existing thresholds. In multi-tenant Score-as-a-Service environments, where decision boundaries reside in client-managed infrastructure, this creates a severe bottleneck: recalibration requires coordinating threshold updates across hundreds of clients, consuming excessive human hours and leading to model stagnation. We introduce MUSE, a model serving framework that enables seamless model updates by decoupling model scores from client decision boundaries. Designed for multi-tenancy, MUSE optimizes infrastructure re-use by sharing models via dynamic intent-based routing, combined with a two-level score transformation that maps model outputs to a stable, reference distribution. Deployed at scale by Feedzai, MUSE processes over a thousand events per second, and over 55 billion events in the last 12 months, across several dozens of tenants, while maintaining high-availability and low-latency guarantees. By reducing model lead time from weeks to minutes, MUSE promotes model resilience against shifting attacks, saving millions of dollars in fraud losses and operational costs.",
    "authors": [
      "Cláudio Correia",
      "Alberto E. A. Ferreira",
      "Lucas Martins",
      "Miguel P. Bento",
      "Sofia Guerreiro",
      "Ricardo Ribeiro Pereira",
      "Ana Sofia Gomes",
      "Jacopo Bono",
      "Hugo Ferreira",
      "Pedro Bizarro"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11776v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11776v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.11646v1",
    "title": "Brain Tumor Classifiers Under Attack: Robustness of ResNet Variants Against Transferable FGSM and PGD Attacks",
    "summary": "Adversarial robustness in deep learning models for brain tumor classification remains an underexplored yet critical challenge, particularly for clinical deployment scenarios involving MRI data. In this work, we investigate the susceptibility and resilience of several ResNet-based architectures, referred to as BrainNet, BrainNeXt and DilationNet, against gradient-based adversarial attacks, namely FGSM and PGD. These models, based on ResNet, ResNeXt, and dilated ResNet variants respectively, are evaluated across three preprocessing configurations (i) full-sized augmented, (ii) shrunk augmented and (iii) shrunk non-augmented MRI datasets. Our experiments reveal that BrainNeXt models exhibit the highest robustness to black-box attacks, likely due to their increased cardinality, though they produce weaker transferable adversarial samples. In contrast, BrainNet and Dilation models are more vulnerable to attacks from each other, especially under PGD with higher iteration steps and $α$ values. Notably, shrunk and non-augmented data significantly reduce model resilience, even when the untampered test accuracy remains high, highlighting a key trade-off between input resolution and adversarial vulnerability. These results underscore the importance of jointly evaluating classification performance and adversarial robustness for reliable real-world deployment in brain MRI analysis.",
    "authors": [
      "Ryan Deem",
      "Garrett Goodman",
      "Waqas Majeed",
      "Md Abdullah Al Hafiz Khan",
      "Michail S. Alexiou"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11646v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11646v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2602.12120v1",
    "title": "Commencing-Student Enrolment Forecasting Under Data Sparsity with Time Series Foundation Models",
    "summary": "Many universities face increasing financial pressure and rely on accurate forecasts of commencing enrolments. However, enrolment forecasting in higher education is often data-sparse; annual series are short and affected by reporting changes and regime shifts. Popular classical approaches can be unreliable, as parameter estimation and model selection are unstable with short samples, and structural breaks degrade extrapolation. Recently, TSFMs have provided zero-shot priors, delivering strong gains in annual, data-sparse institutional forecasting under leakage-disciplined covariate construction. We benchmark multiple TSFM families in a zero-shot setting and test a compact, leakage-safe covariate set and introduce the Institutional Operating Conditions Index (IOCI), a transferable 0-100 regime covariate derived from time-stamped documentary evidence available at each forecast origin, alongside Google Trends demand proxies with stabilising feature engineering. Using an expanding-window backtest with strict vintage alignment, covariate-conditioned TSFMs perform on par with classical benchmarks without institution-specific training, with performance differences varying by cohort and model.",
    "authors": [
      "Jittarin Jetwiriyanon",
      "Teo Susnjak",
      "Surangika Ranathunga"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12120v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12120v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.12058v1",
    "title": "ModelWisdom: An Integrated Toolkit for TLA+ Model Visualization, Digest and Repair",
    "summary": "Model checking in TLA+ provides strong correctness guarantees, yet practitioners continue to face significant challenges in interpreting counterexamples, understanding large state-transition graphs, and repairing faulty models. These difficulties stem from the limited explainability of raw model-checker output and the substantial manual effort required to trace violations back to source specifications. Although the TLA+ Toolbox includes a state diagram viewer, it offers only a static, fully expanded graph without folding, color highlighting, or semantic explanations, which limits its scalability and interpretability. We present ModelWisdom, an interactive environment that uses visualization and large language models to make TLA+ model checking more interpretable and actionable. ModelWisdom offers: (i) Model Visualization, with colorized violation highlighting, click-through links from transitions to TLA+ code, and mapping between violating states and broken properties; (ii) Graph Optimization, including tree-based structuring and node/edge folding to manage large models; (iii) Model Digest, which summarizes and explains subgraphs via large language models (LLMs) and performs preprocessing and partial explanations; and (iv) Model Repair, which extracts error information and supports iterative debugging. Together, these capabilities turn raw model-checker output into an interactive, explainable workflow, improving understanding and reducing debugging effort for nontrivial TLA+ specifications. The website to ModelWisdom is available: https://model-wisdom.pages.dev. A demonstrative video can be found at https://www.youtube.com/watch?v=plyZo30VShA.",
    "authors": [
      "Zhiyong Chen",
      "Jialun Cao",
      "Chang Xu",
      "Shing-Chi Cheung"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.FL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12058v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12058v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.11898v1",
    "title": "Benchmark Illusion: Disagreement among LLMs and Its Scientific Consequences",
    "summary": "Benchmarks underpin how progress in large language models (LLMs) is measured and trusted. Yet our analyses reveal that apparent convergence in benchmark accuracy can conceal deep epistemic divergence. Using two major reasoning benchmarks - MMLU-Pro and GPQA - we show that LLMs achieving comparable accuracy still disagree on 16-66% of items, and 16-38% among top-performing frontier models. These discrepancies suggest distinct error profiles for different LLMs. When such models are used for scientific data annotation and inference, their hidden disagreements propagate into research results: in re-analyses of published studies in education and political science, switching the annotation model can change estimated treatment effects by more than 80%, and in some cases reverses their sign. Together, these findings illustrate a benchmark illusion, where equal accuracy may conceal disagreement, with model choice becoming a hidden yet consequential variable for scientific reproducibility.",
    "authors": [
      "Eddie Yang",
      "Dashun Wang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11898v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11898v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.11841v1",
    "title": "Improving Neural Retrieval with Attribution-Guided Query Rewriting",
    "summary": "Neural retrievers are effective but brittle: underspecified or ambiguous queries can misdirect ranking even when relevant documents exist. Existing approaches address this brittleness only partially: LLMs rewrite queries without retriever feedback, and explainability methods identify misleading tokens but are used for post-hoc analysis. We close this loop and propose an attribution-guided query rewriting method that uses token-level explanations to guide query rewriting. For each query, we compute gradient-based token attributions from the retriever and then use these scores as soft guidance in a structured prompt to an LLM that clarifies weak or misleading query components while preserving intent. Evaluated on BEIR collections, the resulting rewrites consistently improve retrieval effectiveness over strong baselines, with larger gains for implicit or ambiguous information needs.",
    "authors": [
      "Moncef Garouani",
      "Josiane Mothe"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11841v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11841v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.11804v1",
    "title": "Efficient Segment Anything with Depth-Aware Fusion and Limited Training Data",
    "summary": "Segment Anything Models (SAM) achieve impressive universal segmentation performance but require massive datasets (e.g., 11M images) and rely solely on RGB inputs. Recent efficient variants reduce computation but still depend on large-scale training. We propose a lightweight RGB-D fusion framework that augments EfficientViT-SAM with monocular depth priors. Depth maps are generated with a pretrained estimator and fused mid-level with RGB features through a dedicated depth encoder. Trained on only 11.2k samples (less than 0.1\\% of SA-1B), our method achieves higher accuracy than EfficientViT-SAM, showing that depth cues provide strong geometric priors for segmentation.",
    "authors": [
      "Yiming Zhou",
      "Xuenjie Xie",
      "Panfeng Li",
      "Albrecht Kunz",
      "Ahmad Osman",
      "Xavier Maldague"
    ],
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11804v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11804v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.11714v1",
    "title": "GSO-SLAM: Bidirectionally Coupled Gaussian Splatting and Direct Visual Odometry",
    "summary": "We propose GSO-SLAM, a real-time monocular dense SLAM system that leverages Gaussian scene representation. Unlike existing methods that couple tracking and mapping with a unified scene, incurring computational costs, or loosely integrate them with well-structured tracking frameworks, introducing redundancies, our method bidirectionally couples Visual Odometry (VO) and Gaussian Splatting (GS). Specifically, our approach formulates joint optimization within an Expectation-Maximization (EM) framework, enabling the simultaneous refinement of VO-derived semi-dense depth estimates and the GS representation without additional computational overhead. Moreover, we present Gaussian Splat Initialization, which utilizes image information, keyframe poses, and pixel associations from VO to produce close approximations to the final Gaussian scene, thereby eliminating the need for heuristic methods. Through extensive experiments, we validate the effectiveness of our method, showing that it not only operates in real time but also achieves state-of-the-art geometric/photometric fidelity of the reconstructed scene and tracking accuracy.",
    "authors": [
      "Jiung Yeon",
      "Seongbo Ha",
      "Hyeonwoo Yu"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11714v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11714v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.11705v1",
    "title": "TG-Field: Geometry-Aware Radiative Gaussian Fields for Tomographic Reconstruction",
    "summary": "3D Gaussian Splatting (3DGS) has revolutionized 3D scene representation with superior efficiency and quality. While recent adaptations for computed tomography (CT) show promise, they struggle with severe artifacts under highly sparse-view projections and dynamic motions. To address these challenges, we propose Tomographic Geometry Field (TG-Field), a geometry-aware Gaussian deformation framework tailored for both static and dynamic CT reconstruction. A multi-resolution hash encoder is employed to capture local spatial priors, regularizing primitive parameters under ultra-sparse settings. We further extend the framework to dynamic reconstruction by introducing time-conditioned representations and a spatiotemporal attention block to adaptively aggregate features, thereby resolving spatiotemporal ambiguities and enforcing temporal coherence. In addition, a motion-flow network models fine-grained respiratory motion to track local anatomical deformations. Extensive experiments on synthetic and real-world datasets demonstrate that TG-Field consistently outperforms existing methods, achieving state-of-the-art reconstruction accuracy under highly sparse-view conditions.",
    "authors": [
      "Yuxiang Zhong",
      "Jun Wei",
      "Chaoqi Chen",
      "Senyou An",
      "Hui Huang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11705v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11705v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.11704v1",
    "title": "U-DAVI: Uncertainty-Aware Diffusion-Prior-Based Amortized Variational Inference for Image Reconstruction",
    "summary": "Ill-posed imaging inverse problems remain challenging due to the ambiguity in mapping degraded observations to clean images. Diffusion-based generative priors have recently shown promise, but typically rely on computationally intensive iterative sampling or per-instance optimization. Amortized variational inference frameworks address this inefficiency by learning a direct mapping from measurements to posteriors, enabling fast posterior sampling without requiring the optimization of a new posterior for every new set of measurements. However, they still struggle to reconstruct fine details and complex textures. To address this, we extend the amortized framework by injecting spatially adaptive perturbations to measurements during training, guided by uncertainty estimates, to emphasize learning in the most uncertain regions. Experiments on deblurring and super-resolution demonstrate that our method achieves superior or competitive performance to previous diffusion-based approaches, delivering more realistic reconstructions without the computational cost of iterative refinement.",
    "authors": [
      "Ayush Varshney",
      "Katherine L. Bouman",
      "Berthy T. Feng"
    ],
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11704v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11704v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.11703v1",
    "title": "Semantically Conditioned Diffusion Models for Cerebral DSA Synthesis",
    "summary": "Digital subtraction angiography (DSA) plays a central role in the diagnosis and treatment of cerebrovascular disease, yet its invasive nature and high acquisition cost severely limit large-scale data collection and public data sharing. Therefore, we developed a semantically conditioned latent diffusion model (LDM) that synthesizes arterial-phase cerebral DSA frames under explicit control of anatomical circulation (anterior vs.\\ posterior) and canonical C-arm positions. We curated a large single-centre DSA dataset of 99,349 frames and trained a conditional LDM using text embeddings that encoded anatomy and acquisition geometry. To assess clinical realism, four medical experts, including two neuroradiologists, one neurosurgeon, and one internal medicine expert, systematically rated 400 synthetic DSA images using a 5-grade Likert scale for evaluating proximal large, medium, and small peripheral vessels. The generated images achieved image-wise overall Likert scores ranging from 3.1 to 3.3, with high inter-rater reliability (ICC(2,k) = 0.80--0.87). Distributional similarity to real DSA frames was supported by a low median Fréchet inception distance (FID) of 15.27. Our results indicate that semantically controlled LDMs can produce realistic synthetic DSAs suitable for downstream algorithm development, research, and training.",
    "authors": [
      "Qiwen Xu",
      "David Rügamer",
      "Holger Wenz",
      "Johann Fontana",
      "Nora Meggyeshazi",
      "Andreas Bender",
      "Máté E. Maros"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11703v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11703v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.11672v1",
    "title": "U-Net with Hadamard Transform and DCT Latent Spaces for Next-day Wildfire Spread Prediction",
    "summary": "We developed a lightweight and computationally efficient tool for next-day wildfire spread prediction using multimodal satellite data as input. The deep learning model, which we call Transform Domain Fusion UNet (TD-FusionUNet), incorporates trainable Hadamard Transform and Discrete Cosine Transform layers that apply two-dimensional transforms, enabling the network to capture essential \"frequency\" components in orthogonalized latent spaces. Additionally, we introduce custom preprocessing techniques, including random margin cropping and a Gaussian mixture model, to enrich the representation of the sparse pre-fire masks and enhance the model's generalization capability. The TD-FusionUNet is evaluated on two datasets which are the Next-Day Wildfire Spread dataset released by Google Research in 2023, and WildfireSpreadTS dataset. Our proposed TD-FusionUNet achieves an F1 score of 0.591 with 370k parameters, outperforming the UNet baseline using ResNet18 as the encoder reported in the WildfireSpreadTS dataset while using substantially fewer parameters. These results show that the proposed latent space fusion model balances accuracy and efficiency under a lightweight setting, making it suitable for real time wildfire prediction applications in resource limited environments.",
    "authors": [
      "Yingyi Luo",
      "Shuaiang Rong",
      "Adam Watts",
      "Ahmet Enis Cetin"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11672v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11672v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2602.12083v1",
    "title": "Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication",
    "summary": "As multi-agent AI systems evolve from simple chatbots to autonomous swarms, debugging semantic failures requires reasoning about knowledge, belief, causality, and obligation, precisely what modal logic was designed to formalize. However, traditional modal logic requires manual specification of relationship structures that are unknown or dynamic in real systems. This tutorial demonstrates differentiable modal logic (DML), implemented via Modal Logical Neural Networks (MLNNs), enabling systems to learn trust networks, causal chains, and regulatory boundaries from behavioral data alone.   We present a unified neurosymbolic debugging framework through four modalities: epistemic (who to trust), temporal (when events cause failures), deontic (what actions are permitted), and doxastic (how to interpret agent confidence). Each modality is demonstrated on concrete multi-agent scenarios, from discovering deceptive alliances in diplomacy games to detecting LLM hallucinations, with complete implementations showing how logical contradictions become learnable optimization objectives. Key contributions for the neurosymbolic community: (1) interpretable learned structures where trust and causality are explicit parameters, not opaque embeddings; (2) knowledge injection via differentiable axioms that guide learning with sparse data (3) compositional multi-modal reasoning that combines epistemic, temporal, and deontic constraints; and (4) practical deployment patterns for monitoring, active control and communication of multi-agent systems. All code provided as executable Jupyter notebooks.",
    "authors": [
      "Antonin Sulc"
    ],
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12083v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12083v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.12003v1",
    "title": "Projected Representation Conditioning for High-fidelity Novel View Synthesis",
    "summary": "We propose a novel framework for diffusion-based novel view synthesis in which we leverage external representations as conditions, harnessing their geometric and semantic correspondence properties for enhanced geometric consistency in generated novel viewpoints. First, we provide a detailed analysis exploring the correspondence capabilities emergent in the spatial attention of external visual representations. Building from these insights, we propose a representation-guided novel view synthesis through dedicated representation projection modules that inject external representations into the diffusion process, a methodology named ReNoV, short for representation-guided novel view synthesis. Our experiments show that this design yields marked improvements in both reconstruction fidelity and inpainting quality, outperforming prior diffusion-based novel-view methods on standard benchmarks and enabling robust synthesis from sparse, unposed image collections.",
    "authors": [
      "Min-Seop Kwak",
      "Minkyung Kwon",
      "Jinhyeok Choi",
      "Jiho Park",
      "Seungryong Kim"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12003v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12003v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.11944v1",
    "title": "Using predictive multiplicity to measure individual performance within the AI Act",
    "summary": "When building AI systems for decision support, one often encounters the phenomenon of predictive multiplicity: a single best model does not exist; instead, one can construct many models with similar overall accuracy that differ in their predictions for individual cases. Especially when decisions have a direct impact on humans, this can be highly unsatisfactory. For a person subject to high disagreement between models, one could as well have chosen a different model of similar overall accuracy that would have decided the person's case differently. We argue that this arbitrariness conflicts with the EU AI Act, which requires providers of high-risk AI systems to report performance not only at the dataset level but also for specific persons. The goal of this paper is to put predictive multiplicity in context with the EU AI Act's provisions on accuracy and to subsequently derive concrete suggestions on how to evaluate and report predictive multiplicity in practice. Specifically: (1) We argue that incorporating information about predictive multiplicity can serve compliance with the EU AI Act's accuracy provisions for providers. (2) Based on this legal analysis, we suggest individual conflict ratios and $δ$-ambiguity as tools to quantify the disagreement between models on individual cases and to help detect individuals subject to conflicting predictions. (3) Based on computational insights, we derive easy-to-implement rules on how model providers could evaluate predictive multiplicity in practice. (4) Ultimately, we suggest that information about predictive multiplicity should be made available to deployers under the AI Act, enabling them to judge whether system outputs for specific individuals are reliable enough for their use case.",
    "authors": [
      "Karolin Frohnapfel",
      "Mara Seyfert",
      "Sebastian Bordt",
      "Ulrike von Luxburg",
      "Kristof Meding"
    ],
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11944v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11944v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.11941v1",
    "title": "IncompeBench: A Permissively Licensed, Fine-Grained Benchmark for Music Information Retrieval",
    "summary": "Multimodal Information Retrieval has made significant progress in recent years, leveraging the increasingly strong multimodal abilities of deep pre-trained models to represent information across modalities. Music Information Retrieval (MIR), in particular, has considerably increased in quality, with neural representations of music even making its way into everyday life products. However, there is a lack of high-quality benchmarks for evaluating music retrieval performance. To address this issue, we introduce \\textbf{IncompeBench}, a carefully annotated benchmark comprising $1,574$ permissively licensed, high-quality music snippets, $500$ diverse queries, and over $125,000$ individual relevance judgements. These annotations were created through the use of a multi-stage pipeline, resulting in high agreement between human annotators and the generated data. The resulting datasets are publicly available at https://huggingface.co/datasets/mixedbread-ai/incompebench-strict and https://huggingface.co/datasets/mixedbread-ai/incompebench-lenient with the prompts available at https://github.com/mixedbread-ai/incompebench-programs.",
    "authors": [
      "Benjamin Clavié",
      "Atoof Shakir",
      "Jonah Turner",
      "Sean Lee",
      "Aamir Shakir",
      "Makoto P. Kato"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11941v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11941v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.11845v1",
    "title": "WorldTree: Towards 4D Dynamic Worlds from Monocular Video using Tree-Chains",
    "summary": "Dynamic reconstruction has achieved remarkable progress, but there remain challenges in monocular input for more practical applications. The prevailing works attempt to construct efficient motion representations, but lack a unified spatiotemporal decomposition framework, suffering from either holistic temporal optimization or coupled hierarchical spatial composition. To this end, we propose WorldTree, a unified framework comprising Temporal Partition Tree (TPT) that enables coarse-to-fine optimization based on the inheritance-based partition tree structure for hierarchical temporal decomposition, and Spatial Ancestral Chains (SAC) that recursively query ancestral hierarchical structure to provide complementary spatial dynamics while specializing motion representations across ancestral nodes. Experimental results on different datasets indicate that our proposed method achieves 8.26% improvement of LPIPS on NVIDIA-LS and 9.09% improvement of mLPIPS on DyCheck compared to the second-best method. Code: https://github.com/iCVTEAM/WorldTree.",
    "authors": [
      "Qisen Wang",
      "Yifan Zhao",
      "Jia Li"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11845v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11845v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.11808v1",
    "title": "Deep Kernel Fusion for Transformers",
    "summary": "Agentic LLM inference with long contexts is increasingly limited by memory bandwidth rather than compute. In this setting, SwiGLU MLP blocks, whose large weights exceed cache capacity, become a major yet under-optimized bottleneck. We propose DeepFusionKernel, a deeply fused kernel that cuts HBM traffic and boosts cache reuse, delivering up to 13.2% speedup on H100 and 9.7% on A100 over SGLang. Integrated with SGLang and paired with a kernel scheduler, DeepFusionKernel ensures consistent accelerations over generation lengths, while remaining adaptable to diverse models, inference configurations, and hardware platforms.",
    "authors": [
      "Zixi Zhang",
      "Zhiwen Mo",
      "Yiren Zhao",
      "Robert Mullins"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11808v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11808v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.11699v1",
    "title": "Finding Sense in Nonsense with Generated Contexts: Perspectives from Humans and Language Models",
    "summary": "Nonsensical and anomalous sentences have been instrumental in the development of computational models of semantic interpretation. A core challenge is to distinguish between what is merely anomalous (but can be interpreted given a supporting context) and what is truly nonsensical. However, it is unclear (a) how nonsensical, rather than merely anomalous, existing datasets are; and (b) how well LLMs can make this distinction. In this paper, we answer both questions by collecting sensicality judgments from human raters and LLMs on sentences from five semantically deviant datasets: both context-free and when providing a context. We find that raters consider most sentences at most anomalous, and only a few as properly nonsensical. We also show that LLMs are substantially skilled in generating plausible contexts for anomalous cases.",
    "authors": [
      "Katrin Olsen",
      "Sebastian Padó"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11699v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11699v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.11658v1",
    "title": "EmoSpace: Fine-Grained Emotion Prototype Learning for Immersive Affective Content Generation",
    "summary": "Emotion is important for creating compelling virtual reality (VR) content. Although some generative methods have been applied to lower the barrier to creating emotionally rich content, they fail to capture the nuanced emotional semantics and the fine-grained control essential for immersive experiences. To address these limitations, we introduce EmoSpace, a novel framework for emotion-aware content generation that learns dynamic, interpretable emotion prototypes through vision-language alignment. We employ a hierarchical emotion representation with rich learnable prototypes that evolve during training, enabling fine-grained emotional control without requiring explicit emotion labels. We develop a controllable generation pipeline featuring multi-prototype guidance, temporal blending, and attention reweighting that supports diverse applications, including emotional image outpainting, stylized generation, and emotional panorama generation for VR environments. Our experiments demonstrate the superior performance of EmoSpace over existing methods in both qualitative and quantitative evaluations. Additionally, we present a comprehensive user study investigating how VR environments affect emotional perception compared to desktop settings. Our work facilitates immersive visual content generation with fine-grained emotion control and supports applications like therapy, education, storytelling, artistic creation, and cultural preservation. Code and models will be made publicly available.",
    "authors": [
      "Bingyuan Wang",
      "Xingbei Chen",
      "Zongyang Qiu",
      "Linping Yuan",
      "Zeyu Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11658v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11658v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2602.12043v1",
    "title": "Improved Inference for CSDID Using the Cluster Jackknife",
    "summary": "Obtaining reliable inferences with traditional difference-in-differences (DiD) methods can be difficult. Problems can arise when both outcomes and errors are serially correlated, when there are few clusters or few treated clusters, when cluster sizes vary greatly, and in various other cases. In recent years, recognition of the ``staggered adoption'' problem has shifted the focus away from inference towards consistent estimation of treatment effects. One of the most popular new estimators is the CSDID procedure of Callaway and Sant'Anna (2021). We find that the issues of over-rejection with few clusters and/or few treated clusters are at least as severe for CSDID as for traditional DiD methods. We also propose using a cluster jackknife for inference with CSDID, which simulations suggest greatly improves inference. We provide software packages in Stata csdidjack and R didjack to calculate cluster-jackknife standard errors easily.",
    "authors": [
      "Sunny R. Karim",
      "Morten Ørregaard Nielsen",
      "James G. MacKinnon",
      "Matthew D. Webb"
    ],
    "categories": [
      "econ.EM",
      "stat.ME",
      "stat.ML"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12043v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12043v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2602.11948v1",
    "title": "Insights on Muon from Simple Quadratics",
    "summary": "Muon updates weight matrices along (approximate) polar factors of the gradients and has shown strong empirical performance in large-scale training. Existing attempts at explaining its performance largely focus on single-step comparisons (on quadratic proxies) and worst-case guarantees that treat the inexactness of the polar-factor as a nuisance ``to be argued away''. We show that already on simple strongly convex functions such as $L(W)=\\frac12\\|W\\|_{\\text{F}}^2$, these perspectives are insufficient, suggesting that understanding Muon requires going beyond local proxies and pessimistic worst-case bounds. Instead, our analysis exposes two observations that already affect behavior on simple quadratics and are not well captured by prevailing abstractions: (i) approximation error in the polar step can qualitatively alter discrete-time dynamics and improve reachability and finite-time performance -- an effect practitioners exploit to tune Muon, but that existing theory largely treats as a pure accuracy compromise; and (ii) structural properties of the objective affect finite-budget constants beyond the prevailing conditioning-based explanations. Thus, any general theory covering these cases must either incorporate these ingredients explicitly or explain why they are irrelevant in the regimes of interest.",
    "authors": [
      "Antoine Gonon",
      "Andreea-Alexandra Muşat",
      "Nicolas Boumal"
    ],
    "categories": [
      "math.OC",
      "cs.LG"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11948v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11948v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2602.11919v1",
    "title": "DynaHOI: Benchmarking Hand-Object Interaction for Dynamic Target",
    "summary": "Most existing hand motion generation benchmarks for hand-object interaction (HOI) focus on static objects, leaving dynamic scenarios with moving targets and time-critical coordination largely untested. To address this gap, we introduce the DynaHOI-Gym, a unified online closed-loop platform with parameterized motion generators and rollout-based metrics for dynamic capture evaluation. Built on DynaHOI-Gym, we release DynaHOI-10M, a large-scale benchmark with 10M frames and 180K hand capture trajectories, whose target motions are organized into 8 major categories and 22 fine-grained subcategories. We also provide a simple observe-before-act baseline (ObAct) that integrates short-term observations with the current frame via spatiotemporal attention to predict actions, achieving an 8.1% improvement in location success rate.",
    "authors": [
      "BoCheng Hu",
      "Zhonghan Zhao",
      "Kaiyue Zhou",
      "Hongwei Wang",
      "Gaoang Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11919v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11919v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2602.12002v1",
    "title": "Can Local Vision-Language Models improve Activity Recognition over Vision Transformers? -- Case Study on Newborn Resuscitation",
    "summary": "Accurate documentation of newborn resuscitation is essential for quality improvement and adherence to clinical guidelines, yet remains underutilized in practice. Previous work using 3D-CNNs and Vision Transformers (ViT) has shown promising results in detecting key activities from newborn resuscitation videos, but also highlighted the challenges in recognizing such fine-grained activities. This work investigates the potential of generative AI (GenAI) methods to improve activity recognition from such videos. Specifically, we explore the use of local vision-language models (VLMs), combined with large language models (LLMs), and compare them to a supervised TimeSFormer baseline. Using a simulated dataset comprising 13.26 hours of newborn resuscitation videos, we evaluate several zero-shot VLM-based strategies and fine-tuned VLMs with classification heads, including Low-Rank Adaptation (LoRA). Our results suggest that small (local) VLMs struggle with hallucinations, but when fine-tuned with LoRA, the results reach F1 score at 0.91, surpassing the TimeSformer results of 0.70.",
    "authors": [
      "Enrico Guerriero",
      "Kjersti Engan",
      "Øyvind Meinich-Bache"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12002v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12002v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2602.11924v1",
    "title": "Who Does What? Archetypes of Roles Assigned to LLMs During Human-AI Decision-Making",
    "summary": "LLMs are increasingly supporting decision-making across high-stakes domains, requiring critical reflection on the socio-technical factors that shape how humans and LLMs are assigned roles and interact during human-in-the-loop decision-making. This paper introduces the concept of human-LLM archetypes -- defined as re-curring socio-technical interaction patterns that structure the roles of humans and LLMs in collaborative decision-making. We describe 17 human-LLM archetypes derived from a scoping literature review and thematic analysis of 113 LLM-supported decision-making papers. Then, we evaluate these diverse archetypes across real-world clinical diagnostic cases to examine the potential effects of adopting distinct human-LLM archetypes on LLM outputs and decision outcomes. Finally, we present relevant tradeoffs and design choices across human-LLM archetypes, including decision control, social hierarchies, cognitive forcing strategies, and information requirements. Through our analysis, we show that selection of human-LLM interaction archetype can influence LLM outputs and decisions, bringing important risks and considerations for the designers of human-AI decision-making systems",
    "authors": [
      "Shreya Chappidi",
      "Jatinder Singh",
      "Andra V. Krauze"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11924v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11924v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2602.11685v1",
    "title": "DRACO: a Cross-Domain Benchmark for Deep Research Accuracy, Completeness, and Objectivity",
    "summary": "We present DRACO (Deep Research Accuracy, Completeness, and Objectivity), a benchmark of complex deep research tasks. These tasks, which span 10 domains and draw on information sources from 40 countries, originate from anonymized real-world usage patterns within a large-scale deep research system. Tasks are sampled from a de-identified dataset of Perplexity Deep Research requests, then filtered and augmented to ensure that the tasks are anonymized, open-ended and complex, objectively evaluable, and representative of the broad scope of real-world deep research use cases. Outputs are graded against task-specific rubrics along four dimensions: factual accuracy (accuracy), breadth and depth of analysis (including completeness), presentation quality (including objectivity), and citation quality. DRACO is publicly available at https://hf.co/datasets/perplexity-ai/draco.",
    "authors": [
      "Joey Zhong",
      "Hao Zhang",
      "Clare Southern",
      "Jeremy Yang",
      "Thomas Wang",
      "Kate Jung",
      "Shu Zhang",
      "Denis Yarats",
      "Johnny Ho",
      "Jerry Ma"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11685v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11685v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2602.12044v1",
    "title": "A DMD-Based Adaptive Modulation Method for High Dynamic Range Imaging in High-Glare Environments",
    "summary": "Background The accuracy of photomechanics measurements critically relies on image quality,particularly under extreme illumination conditions such as welding arc monitoring and polished metallic surface analysis. High dynamic range (HDR) imaging above 120 dB is essential in these contexts. Conventional CCD/CMOS sensors, with dynamic ranges typically below 70 dB, are highly susceptible to saturation under glare, resulting in irreversible loss of detail and significant errors in digital image correlation (DIC). Methods This paper presents an HDR imaging system that leverages the spatial modulation capability of a digital micromirror device (DMD). The system architecture enables autonomous regional segmentation and adaptive exposure control for high-dynamic-range scenes through an integrated framework comprising two synergistic subsystems: a DMD-based optical modulation unit and an adaptive computational imaging pipeline. Results The system achieves a measurable dynamic range of 127 dB, effectively eliminating satu ration artifacts under high glare. Experimental results demonstrate a 78% reduction in strain error and improved DIC positioning accuracy, confirming reliable performance across extreme intensity variations. Conclusion The DMD-based system provides high fidelity adaptive HDR imaging, overcoming key limitations of conventional sensors. It exhibits strong potential for optical metrology and stress analysis in high-glare environments where traditional methods are inadequate.",
    "authors": [
      "Banglei Guan",
      "Jing Tao",
      "Liang Xu",
      "Dongcai Tan",
      "Pengju Sun",
      "Jianbing Liu",
      "Yang Shang",
      "Qifeng Yu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12044v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12044v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.49
  },
  {
    "arxiv_id": "2602.12100v1",
    "title": "AssetFormer: Modular 3D Assets Generation with Autoregressive Transformer",
    "summary": "The digital industry demands high-quality, diverse modular 3D assets, especially for user-generated content~(UGC). In this work, we introduce AssetFormer, an autoregressive Transformer-based model designed to generate modular 3D assets from textual descriptions. Our pilot study leverages real-world modular assets collected from online platforms. AssetFormer tackles the challenge of creating assets composed of primitives that adhere to constrained design parameters for various applications. By innovatively adapting module sequencing and decoding techniques inspired by language models, our approach enhances asset generation quality through autoregressive modeling. Initial results indicate the effectiveness of AssetFormer in streamlining asset creation for professional development and UGC scenarios. This work presents a flexible framework extendable to various types of modular 3D assets, contributing to the broader field of 3D content generation. The code is available at https://github.com/Advocate99/AssetFormer.",
    "authors": [
      "Lingting Zhu",
      "Shengju Qian",
      "Haidi Fan",
      "Jiayu Dong",
      "Zhenchao Jin",
      "Siwei Zhou",
      "Gen Dong",
      "Xin Wang",
      "Lequan Yu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12100v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12100v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.48
  },
  {
    "arxiv_id": "2602.11642v1",
    "title": "Electrostatics-Inspired Surface Reconstruction (EISR): Recovering 3D Shapes as a Superposition of Poisson's PDE Solutions",
    "summary": "Implicit shape representation, such as SDFs, is a popular approach to recover the surface of a 3D shape as the level sets of a scalar field. Several methods approximate SDFs using machine learning strategies that exploit the knowledge that SDFs are solutions of the Eikonal partial differential equation (PDEs). In this work, we present a novel approach to surface reconstruction by encoding it as a solution to a proxy PDE, namely Poisson's equation. Then, we explore the connection between Poisson's equation and physics, e.g., the electrostatic potential due to a positive charge density. We employ Green's functions to obtain a closed-form parametric expression for the PDE's solution, and leverage the linearity of our proxy PDE to find the target shape's implicit field as a superposition of solutions. Our method shows improved results in approximating high-frequency details, even with a small number of shape priors.",
    "authors": [
      "Diego Patiño",
      "Knut Peterson",
      "Kostas Daniilidis",
      "David K. Han"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11642v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11642v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2602.11832v1",
    "title": "JEPA-VLA: Video Predictive Embedding is Needed for VLA Models",
    "summary": "Recent vision-language-action (VLA) models built upon pretrained vision-language models (VLMs) have achieved significant improvements in robotic manipulation. However, current VLAs still suffer from low sample efficiency and limited generalization. This paper argues that these limitations are closely tied to an overlooked component, pretrained visual representation, which offers insufficient knowledge on both aspects of environment understanding and policy prior. Through an in-depth analysis, we find that commonly used visual representations in VLAs, whether pretrained via language-image contrastive learning or image-based self-supervised learning, remain inadequate at capturing crucial, task-relevant environment information and at inducing effective policy priors, i.e., anticipatory knowledge of how the environment evolves under successful task execution. In contrast, we discover that predictive embeddings pretrained on videos, in particular V-JEPA 2, are adept at flexibly discarding unpredictable environment factors and encoding task-relevant temporal dynamics, thereby effectively compensating for key shortcomings of existing visual representations in VLAs. Building on these observations, we introduce JEPA-VLA, a simple yet effective approach that adaptively integrates predictive embeddings into existing VLAs. Our experiments demonstrate that JEPA-VLA yields substantial performance gains across a range of benchmarks, including LIBERO, LIBERO-plus, RoboTwin2.0, and real-robot tasks.",
    "authors": [
      "Shangchen Miao",
      "Ningya Feng",
      "Jialong Wu",
      "Ye Lin",
      "Xu He",
      "Dong Li",
      "Mingsheng Long"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11832v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11832v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.46
  },
  {
    "arxiv_id": "2602.12023v1",
    "title": "Decomposition of Spillover Effects Under Misspecification:Pseudo-true Estimands and a Local--Global Extension",
    "summary": "Applied work with interference typically models outcomes as functions of own treatment and a low-dimensional exposure mapping of others' treatments, even when that mapping may be misspecified. This raises a basic question: what policy object are exposure-based estimands implicitly targeting, and how should we interpret their direct and spillover components relative to the underlying policy question? We take as primitive the marginal policy effect, defined as the effect of a small change in the treatment probability under the actual experimental design, and show that any researcher-chosen exposure mapping induces a unique pseudo-true outcome model. This model is the best approximation to the underlying potential outcomes that depends only on the user-chosen exposure. Utilizing that representation, the marginal policy effect admits a canonical decomposition into exposure-based direct and spillover effects, and each component provides its optimal approximation to the corresponding oracle objects that would be available if interference were fully known. We then focus on a setting that nests important empirical and theoretical applications in which both local network spillovers and global spillovers, such as market equilibrium, operate. There, the marginal policy effect further decomposes asymptotically into direct, local, and global channels. An important implication is that many existing methods are more robust than previously understood once we reinterpret their targets as channel-specific components of this pseudo-true policy estimand. Simulations and a semi-synthetic experiment calibrated to a large cash-transfer experiment show that these components can be recovered in realistic experimental designs.",
    "authors": [
      "Yechan Park",
      "Xiaodong Yang"
    ],
    "categories": [
      "econ.EM",
      "math.ST",
      "stat.ML"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.12023v1",
    "pdf_url": "https://arxiv.org/pdf/2602.12023v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.43
  },
  {
    "arxiv_id": "2602.11747v1",
    "title": "High-Probability Minimax Adaptive Estimation in Besov Spaces via Online-to-Batch",
    "summary": "We study nonparametric regression over Besov spaces from noisy observations under sub-exponential noise, aiming to achieve minimax-optimal guarantees on the integrated squared error that hold with high probability and adapt to the unknown noise level. To this end, we propose a wavelet-based online learning algorithm that dynamically adjusts to the observed gradient noise by adaptively clipping it at an appropriate level, eliminating the need to tune parameters such as the noise variance or gradient bounds. As a by-product of our analysis, we derive high-probability adaptive regret bounds that scale with the $\\ell_1$-norm of the competitor. Finally, in the batch statistical setting, we obtain adaptive and minimax-optimal estimation rates for Besov spaces via a refined online-to-batch conversion. This approach carefully exploits the structure of the squared loss in combination with self-normalized concentration inequalities.",
    "authors": [
      "Paul Liautaud",
      "Pierre Gaillard",
      "Olivier Wintenberger"
    ],
    "categories": [
      "math.ST",
      "stat.ML"
    ],
    "published": "2026-02-12",
    "url": "https://arxiv.org/abs/2602.11747v1",
    "pdf_url": "https://arxiv.org/pdf/2602.11747v1.pdf",
    "date": "2026-02-13",
    "source": "arxiv",
    "research_score": 0.43
  }
]