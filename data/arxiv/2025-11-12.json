[
  {
    "arxiv_id": "2511.07663v1",
    "title": "Cortex AISQL: A Production SQL Engine for Unstructured Data",
    "summary": "Snowflake's Cortex AISQL is a production SQL engine that integrates native semantic operations directly into SQL. This integration allows users to write declarative queries that combine relational operations with semantic reasoning, enabling them to query both structured and unstructured data effortlessly. However, making semantic operations efficient at production scale poses fundamental challenges. Semantic operations are more expensive than traditional SQL operations, possess distinct latency and throughput characteristics, and their cost and selectivity are unknown during query compilation. Furthermore, existing query engines are not designed to optimize semantic operations. The AISQL query execution engine addresses these challenges through three novel techniques informed by production deployment data from Snowflake customers. First, AI-aware query optimization treats AI inference cost as a first-class optimization objective, reasoning about large language model (LLM) cost directly during query planning to achieve 2-8$\\times$ speedups. Second, adaptive model cascades reduce inference costs by routing most rows through a fast proxy model while escalating uncertain cases to a powerful oracle model, achieving 2-6$\\times$ speedups while maintaining 90-95% of oracle model quality. Third, semantic join query rewriting lowers the quadratic time complexity of join operations to linear through reformulation as multi-label classification tasks, achieving 15-70$\\times$ speedups with often improved prediction quality. AISQL is deployed in production at Snowflake, where it powers diverse customer workloads across analytics, search, and content understanding.",
    "authors": [
      "Paritosh Aggarwal",
      "Bowei Chen",
      "Anupam Datta",
      "Benjamin Han",
      "Boxin Jiang",
      "Nitish Jindal",
      "Zihan Li",
      "Aaron Lin",
      "Pawel Liskowski",
      "Jay Tayade",
      "Dimitris Tsirogiannis",
      "Nathan Wiegand",
      "Weicheng Zhao"
    ],
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07663v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07663v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.94
  },
  {
    "arxiv_id": "2511.08573v1",
    "title": "SENCA-st: Integrating Spatial Transcriptomics and Histopathology with Cross Attention Shared Encoder for Region Identification in Cancer Pathology",
    "summary": "Spatial transcriptomics is an emerging field that enables the identification of functional regions based on the spatial distribution of gene expression. Integrating this functional information present in transcriptomic data with structural data from histopathology images is an active research area with applications in identifying tumor substructures associated with cancer drug resistance. Current histopathology-spatial-transcriptomic region segmentation methods suffer due to either making spatial transcriptomics prominent by using histopathology features just to assist processing spatial transcriptomics data or using vanilla contrastive learning that make histopathology images prominent due to only promoting common features losing functional information. In both extremes, the model gets either lost in the noise of spatial transcriptomics or overly smoothed, losing essential information. Thus, we propose our novel architecture SENCA-st (Shared Encoder with Neighborhood Cross Attention) that preserves the features of both modalities. More importantly, it emphasizes regions that are structurally similar in histopathology but functionally different on spatial transcriptomics using cross-attention. We demonstrate the superior performance of our model that surpasses state-of-the-art methods in detecting tumor heterogeneity and tumor micro-environment regions, a clinically crucial aspect.",
    "authors": [
      "Shanaka Liyanaarachchi",
      "Chathurya Wijethunga",
      "Shihab Aaquil Ahamed",
      "Akthas Absar",
      "Ranga Rodrigo"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08573v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08573v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.92
  },
  {
    "arxiv_id": "2511.07343v1",
    "title": "TNT: Improving Chunkwise Training for Test-Time Memorization",
    "summary": "Recurrent neural networks (RNNs) with deep test-time memorization modules, such as Titans and TTT, represent a promising, linearly-scaling paradigm distinct from Transformers. While these expressive models do not yet match the peak performance of state-of-the-art Transformers, their potential has been largely untapped due to prohibitively slow training and low hardware utilization. Existing parallelization methods force a fundamental conflict governed by the chunksize hyperparameter: large chunks boost speed but degrade performance, necessitating a fixed, suboptimal compromise. To solve this challenge, we introduce TNT, a novel training paradigm that decouples training efficiency from inference performance through a two-stage process. Stage one is an efficiency-focused pre-training phase utilizing a hierarchical memory. A global module processes large, hardware-friendly chunks for long-range context, while multiple parallel local modules handle fine-grained details. Crucially, by periodically resetting local memory states, we break sequential dependencies to enable massive context parallelization. Stage two is a brief fine-tuning phase where only the local memory modules are adapted to a smaller, high-resolution chunksize, maximizing accuracy with minimal overhead. Evaluated on Titans and TTT models, TNT achieves a substantial acceleration in training speed-up to 17 times faster than the most accurate baseline configuration - while simultaneously improving model accuracy. This improvement removes a critical scalability barrier, establishing a practical foundation for developing expressive RNNs and facilitating future work to close the performance gap with Transformers.",
    "authors": [
      "Zeman Li",
      "Ali Behrouz",
      "Yuan Deng",
      "Peilin Zhong",
      "Praneeth Kacham",
      "Mahdi Karami",
      "Meisam Razaviyayn",
      "Vahab Mirrokni"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07343v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07343v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.91
  },
  {
    "arxiv_id": "2511.07329v1",
    "title": "Preparation of Fractal-Inspired Computational Architectures for Advanced Large Language Model Analysis",
    "summary": "It introduces FractalNet, a fractal-inspired computational architectures for advanced large language model analysis that mainly challenges model diversity on a large scale in an efficient manner. The new set-up involves a template-driven generator, runner, and evaluation framework that, through systematic permutations of convolutional, normalization, activation, and dropout layers, can create more than 1,200 variants of neural networks. Fractal templates allow for structural recursion and multi-column pathways, thus, models become deeper and wider in a balanced way. Training utilizes PyTorch, Automatic Mixed Precision (AMP), and gradient checkpointing and is carried out on the CIFAR-10 dataset for five epochs. The outcomes show that fractal-based architectures are capable of strong performance and are computationally efficient. The paper positions fractal design as a feasible and resource-efficient method of automated architecture exploration.",
    "authors": [
      "Yash Mittal",
      "Dmitry Ignatov",
      "Radu Timofte"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07329v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07329v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.9
  },
  {
    "arxiv_id": "2511.08535v1",
    "title": "Large Sign Language Models: Toward 3D American Sign Language Translation",
    "summary": "We present Large Sign Language Models (LSLM), a novel framework for translating 3D American Sign Language (ASL) by leveraging Large Language Models (LLMs) as the backbone, which can benefit hearing-impaired individuals' virtual communication. Unlike existing sign language recognition methods that rely on 2D video, our approach directly utilizes 3D sign language data to capture rich spatial, gestural, and depth information in 3D scenes. This enables more accurate and resilient translation, enhancing digital communication accessibility for the hearing-impaired community. Beyond the task of ASL translation, our work explores the integration of complex, embodied multimodal languages into the processing capabilities of LLMs, moving beyond purely text-based inputs to broaden their understanding of human communication. We investigate both direct translation from 3D gesture features to text and an instruction-guided setting where translations can be modulated by external prompts, offering greater flexibility. This work provides a foundational step toward inclusive, multimodal intelligent systems capable of understanding diverse forms of language.",
    "authors": [
      "Sen Zhang",
      "Xiaoxiao He",
      "Di Liu",
      "Zhaoyang Xia",
      "Mingyu Zhao",
      "Chaowei Tan",
      "Vivian Li",
      "Bo Liu",
      "Dimitris N. Metaxas",
      "Mubbasir Kapadia"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08535v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08535v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.88
  },
  {
    "arxiv_id": "2511.08402v1",
    "title": "Anatomy-VLM: A Fine-grained Vision-Language Model for Medical Interpretation",
    "summary": "Accurate disease interpretation from radiology remains challenging due to imaging heterogeneity. Achieving expert-level diagnostic decisions requires integration of subtle image features with clinical knowledge. Yet major vision-language models (VLMs) treat images as holistic entities and overlook fine-grained image details that are vital for disease diagnosis. Clinicians analyze images by utilizing their prior medical knowledge and identify anatomical structures as important region of interests (ROIs). Inspired from this human-centric workflow, we introduce Anatomy-VLM, a fine-grained, vision-language model that incorporates multi-scale information. First, we design a model encoder to localize key anatomical features from entire medical images. Second, these regions are enriched with structured knowledge for contextually-aware interpretation. Finally, the model encoder aligns multi-scale medical information to generate clinically-interpretable disease prediction. Anatomy-VLM achieves outstanding performance on both in- and out-of-distribution datasets. We also validate the performance of Anatomy-VLM on downstream image segmentation tasks, suggesting that its fine-grained alignment captures anatomical and pathology-related knowledge. Furthermore, the Anatomy-VLM's encoder facilitates zero-shot anatomy-wise interpretation, providing its strong expert-level clinical interpretation capabilities.",
    "authors": [
      "Difei Gu",
      "Yunhe Gao",
      "Mu Zhou",
      "Dimitris Metaxas"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08402v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08402v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.86
  },
  {
    "arxiv_id": "2511.08098v1",
    "title": "PerspAct: Enhancing LLM Situated Collaboration Skills through Perspective Taking and Active Vision",
    "summary": "Recent advances in Large Language Models (LLMs) and multimodal foundation models have significantly broadened their application in robotics and collaborative systems. However, effective multi-agent interaction necessitates robust perspective-taking capabilities, enabling models to interpret both physical and epistemic viewpoints. Current training paradigms often neglect these interactive contexts, resulting in challenges when models must reason about the subjectivity of individual perspectives or navigate environments with multiple observers. This study evaluates whether explicitly incorporating diverse points of view using the ReAct framework, an approach that integrates reasoning and acting, can enhance an LLM's ability to understand and ground the demands of other agents. We extend the classic Director task by introducing active visual exploration across a suite of seven scenarios of increasing perspective-taking complexity. These scenarios are designed to challenge the agent's capacity to resolve referential ambiguity based on visual access and interaction, under varying state representations and prompting strategies, including ReAct-style reasoning. Our results demonstrate that explicit perspective cues, combined with active exploration strategies, significantly improve the model's interpretative accuracy and collaborative effectiveness. These findings highlight the potential of integrating active perception with perspective-taking mechanisms in advancing LLMs' application in robotics and multi-agent systems, setting a foundation for future research into adaptive and context-aware AI systems.",
    "authors": [
      "Sabrina Patania",
      "Luca Annese",
      "Anita Pellegrini",
      "Silvia Serino",
      "Anna Lambiase",
      "Luca Pallonetto",
      "Silvia Rossi",
      "Simone Colombani",
      "Tom Foulsham",
      "Azzurra Ruggeri",
      "Dimitri Ognibene"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08098v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08098v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.84
  },
  {
    "arxiv_id": "2511.07068v1",
    "title": "ClusterMine: Robust Label-Free Visual Out-Of-Distribution Detection via Concept Mining from Text Corpora",
    "summary": "Large-scale visual out-of-distribution (OOD) detection has witnessed remarkable progress by leveraging vision-language models such as CLIP. However, a significant limitation of current methods is their reliance on a pre-defined set of in-distribution (ID) ground-truth label names (positives). These fixed label names can be unavailable, unreliable at scale, or become less relevant due to in-distribution shifts after deployment. Towards truly unsupervised OOD detection, we utilize widely available text corpora for positive label mining, bypassing the need for positives. In this paper, we utilize widely available text corpora for positive label mining under a general concept mining paradigm. Within this framework, we propose ClusterMine, a novel positive label mining method. ClusterMine is the first method to achieve state-of-the-art OOD detection performance without access to positive labels. It extracts positive concepts from a large text corpus by combining visual-only sample consistency (via clustering) and zero-shot image-text consistency. Our experimental study reveals that ClusterMine is scalable across a plethora of CLIP models and achieves state-of-the-art robustness to covariate in-distribution shifts. The code is available at https://github.com/HHU-MMBS/clustermine_wacv_official.",
    "authors": [
      "Nikolas Adaloglou",
      "Diana Petrusheva",
      "Mohamed Asker",
      "Felix Michels",
      "Markus Kollmann"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07068v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07068v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.08349v1",
    "title": "Hybrid Quantum-Classical Selective State Space Artificial Intelligence",
    "summary": "Hybrid Quantum Classical (HQC) algorithms constitute one of the most effective paradigms for exploiting the computational advantages of quantum systems in large-scale numerical tasks. By operating in high-dimensional Hilbert spaces, quantum circuits enable exponential speed-ups and provide access to richer representations of cost landscapes compared to purely classical methods. These capabilities are particularly relevant for machine learning, where state-of-the-art models especially in Natural Language Processing (NLP) suffer from prohibitive time complexity due to massive matrix multiplications and high-dimensional optimization.   In this manuscript, we propose a Hybrid Quantum Classical selection mechanism for the Mamba architecture, designed specifically for temporal sequence classification problems. Our approach leverages Variational Quantum Circuits (VQCs) as quantum gating modules that both enhance feature extraction and improve suppression of irrelevant information. This integration directly addresses the computational bottlenecks of deep learning architectures by exploiting quantum resources for more efficient representation learning.   We analyze how introducing quantum subroutines into large language models (LLMs) impacts their generalization capability, expressivity, and parameter efficiency. The results highlight the potential of quantum-enhanced gating mechanisms as a path toward scalable, resource-efficient NLP models, in a limited simulation step. Within the first four epochs on a reshaped MNIST dataset with input format (batch, 784, d_model), our hybrid model achieved 24.6% accuracy while using one quantum layer and achieve higher expressivity, compared to 21.6% obtained by a purely classical selection mechanism. we state No founding",
    "authors": [
      "Amin Ebrahimi",
      "Farzan Haddadi"
    ],
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08349v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08349v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.79
  },
  {
    "arxiv_id": "2511.07418v1",
    "title": "Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields",
    "summary": "Despite years of research, real-time diverse grasp synthesis for dexterous hands remains an unsolved core challenge in robotics and computer graphics. We present Lightning Grasp, a novel high-performance procedural grasp synthesis algorithm that achieves orders-of-magnitude speedups over state-of-the-art approaches, while enabling unsupervised grasp generation for irregular, tool-like objects. The method avoids many limitations of prior approaches, such as the need for carefully tuned energy functions and sensitive initialization. This breakthrough is driven by a key insight: decoupling complex geometric computation from the search process via a simple, efficient data structure - the Contact Field. This abstraction collapses the problem complexity, enabling a procedural search at unprecedented speeds. We open-source our system to propel further innovation in robotic manipulation.",
    "authors": [
      "Zhao-Heng Yin",
      "Pieter Abbeel"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.DC",
      "cs.GR"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07418v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07418v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2511.06665v1",
    "title": "Sim4Seg: Boosting Multimodal Multi-disease Medical Diagnosis Segmentation with Region-Aware Vision-Language Similarity Masks",
    "summary": "Despite significant progress in pixel-level medical image analysis, existing medical image segmentation models rarely explore medical segmentation and diagnosis tasks jointly. However, it is crucial for patients that models can provide explainable diagnoses along with medical segmentation results. In this paper, we introduce a medical vision-language task named Medical Diagnosis Segmentation (MDS), which aims to understand clinical queries for medical images and generate the corresponding segmentation masks as well as diagnostic results. To facilitate this task, we first present the Multimodal Multi-disease Medical Diagnosis Segmentation (M3DS) dataset, containing diverse multimodal multi-disease medical images paired with their corresponding segmentation masks and diagnosis chain-of-thought, created via an automated diagnosis chain-of-thought generation pipeline. Moreover, we propose Sim4Seg, a novel framework that improves the performance of diagnosis segmentation by taking advantage of the Region-Aware Vision-Language Similarity to Mask (RVLS2M) module. To improve overall performance, we investigate a test-time scaling strategy for MDS tasks. Experimental results demonstrate that our method outperforms the baselines in both segmentation and diagnosis.",
    "authors": [
      "Lingran Song",
      "Yucheng Zhou",
      "Jianbing Shen"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06665v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06665v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2511.08043v1",
    "title": "DynaAct: Large Language Model Reasoning with Dynamic Action Spaces",
    "summary": "In modern sequential decision-making systems, the construction of an optimal candidate action space is critical to efficient inference. However, existing approaches either rely on manually defined action spaces that lack scalability or utilize unstructured spaces that render exhaustive search computationally prohibitive. In this paper, we propose a novel framework named \\textsc{DynaAct} for automatically constructing a compact action space to enhance sequential reasoning in complex problem-solving scenarios. Our method first estimates a proxy for the complete action space by extracting general sketches observed in a corpus covering diverse complex reasoning problems using large language models. We then formulate a submodular function that jointly evaluates candidate actions based on their utility to the current state and their diversity, and employ a greedy algorithm to select an optimal candidate set. Extensive experiments on six diverse standard benchmarks demonstrate that our approach significantly improves overall performance, while maintaining efficient inference without introducing substantial latency. The implementation is available at https://github.com/zhaoxlpku/DynaAct.",
    "authors": [
      "Xueliang Zhao",
      "Wei Wu",
      "Jian Guan",
      "Qintong Li",
      "Lingpeng Kong"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08043v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08043v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.77
  },
  {
    "arxiv_id": "2511.08287v1",
    "title": "Dual-Kernel Graph Community Contrastive Learning",
    "summary": "Graph Contrastive Learning (GCL) has emerged as a powerful paradigm for training Graph Neural Networks (GNNs) in the absence of task-specific labels. However, its scalability on large-scale graphs is hindered by the intensive message passing mechanism of GNN and the quadratic computational complexity of contrastive loss over positive and negative node pairs. To address these issues, we propose an efficient GCL framework that transforms the input graph into a compact network of interconnected node sets while preserving structural information across communities. We firstly introduce a kernelized graph community contrastive loss with linear complexity, enabling effective information transfer among node sets to capture hierarchical structural information of the graph. We then incorporate a knowledge distillation technique into the decoupled GNN architecture to accelerate inference while maintaining strong generalization performance. Extensive experiments on sixteen real-world datasets of varying scales demonstrate that our method outperforms state-of-the-art GCL baselines in both effectiveness and scalability.",
    "authors": [
      "Xiang Chen",
      "Kun Yue",
      "Wenjie Liu",
      "Zhenyu Zhang",
      "Liang Duan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08287v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08287v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2511.06785v1",
    "title": "Resource Efficient Sleep Staging via Multi-Level Masking and Prompt Learning",
    "summary": "Automatic sleep staging plays a vital role in assessing sleep quality and diagnosing sleep disorders. Most existing methods rely heavily on long and continuous EEG recordings, which poses significant challenges for data acquisition in resource-constrained systems, such as wearable or home-based monitoring systems. In this paper, we propose the task of resource-efficient sleep staging, which aims to reduce the amount of signal collected per sleep epoch while maintaining reliable classification performance. To solve this task, we adopt the masking and prompt learning strategy and propose a novel framework called Mask-Aware Sleep Staging (MASS). Specifically, we design a multi-level masking strategy to promote effective feature modeling under partial and irregular observations. To mitigate the loss of contextual information introduced by masking, we further propose a hierarchical prompt learning mechanism that aggregates unmasked data into a global prompt, serving as a semantic anchor for guiding both patch-level and epoch-level feature modeling. MASS is evaluated on four datasets, demonstrating state-of-the-art performance, especially when the amount of data is very limited. This result highlights its potential for efficient and scalable deployment in real-world low-resource sleep monitoring environments.",
    "authors": [
      "Lejun Ai",
      "Yulong Li",
      "Haodong Yi",
      "Jixuan Xie",
      "Yue Wang",
      "Jia Liu",
      "Min Chen",
      "Rui Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06785v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06785v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2511.06658v2",
    "title": "Active Learning for Animal Re-Identification with Ambiguity-Aware Sampling",
    "summary": "Animal Re-ID has recently gained substantial attention in the AI research community due to its high impact on biodiversity monitoring and unique research challenges arising from environmental factors. The subtle distinguishing patterns, handling new species and the inherent open-set nature make the problem even harder. To address these complexities, foundation models trained on labeled, large-scale and multi-species animal Re-ID datasets have recently been introduced to enable zero-shot Re-ID. However, our benchmarking reveals significant gaps in their zero-shot Re-ID performance for both known and unknown species. While this highlights the need for collecting labeled data in new domains, exhaustive annotation for Re-ID is laborious and requires domain expertise. Our analyses show that existing unsupervised (USL) and AL Re-ID methods underperform for animal Re-ID. To address these limitations, we introduce a novel AL Re-ID framework that leverages complementary clustering methods to uncover and target structurally ambiguous regions in the embedding space for mining pairs of samples that are both informative and broadly representative. Oracle feedback on these pairs, in the form of must-link and cannot-link constraints, facilitates a simple annotation interface, which naturally integrates with existing USL methods through our proposed constrained clustering refinement algorithm. Through extensive experiments, we demonstrate that, by utilizing only 0.033% of all annotations, our approach consistently outperforms existing foundational, USL and AL baselines. Specifically, we report an average improvement of 10.49%, 11.19% and 3.99% (mAP) on 13 wildlife datasets over foundational, USL and AL methods, respectively, while attaining state-of-the-art performance on each dataset. Furthermore, we also show an improvement of 11.09%, 8.2% and 2.06% for unknown individuals in an open-world setting.",
    "authors": [
      "Depanshu Sani",
      "Mehar Khurana",
      "Saket Anand"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06658v2",
    "pdf_url": "https://arxiv.org/pdf/2511.06658v2.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2511.07233v1",
    "title": "Noise & pattern: identity-anchored Tikhonov regularization for robust structural anomaly detection",
    "summary": "Anomaly detection plays a pivotal role in automated industrial inspection, aiming to identify subtle or rare defects in otherwise uniform visual patterns. As collecting representative examples of all possible anomalies is infeasible, we tackle structural anomaly detection using a self-supervised autoencoder that learns to repair corrupted inputs. To this end, we introduce a corruption model that injects artificial disruptions into training images to mimic structural defects. While reminiscent of denoising autoencoders, our approach differs in two key aspects. First, instead of unstructured i.i.d.\\ noise, we apply structured, spatially coherent perturbations that make the task a hybrid of segmentation and inpainting. Second, and counterintuitively, we add and preserve Gaussian noise on top of the occlusions, which acts as a Tikhonov regularizer anchoring the Jacobian of the reconstruction function toward identity. This identity-anchored regularization stabilizes reconstruction and further improves both detection and segmentation accuracy. On the MVTec AD benchmark, our method achieves state-of-the-art results (I/P-AUROC: 99.9/99.4), supporting our theoretical framework and demonstrating its practical relevance for automatic inspection.",
    "authors": [
      "Alexander Bauer",
      "Klaus-Robert Müller"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07233v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07233v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2511.06898v1",
    "title": "A Hybrid Autoencoder-Transformer Model for Robust Day-Ahead Electricity Price Forecasting under Extreme Conditions",
    "summary": "Accurate day-ahead electricity price forecasting (DAEPF) is critical for the efficient operation of power systems, but extreme condition and market anomalies pose significant challenges to existing forecasting methods. To overcome these challenges, this paper proposes a novel hybrid deep learning framework that integrates a Distilled Attention Transformer (DAT) model and an Autoencoder Self-regression Model (ASM). The DAT leverages a self-attention mechanism to dynamically assign higher weights to critical segments of historical data, effectively capturing both long-term trends and short-term fluctuations. Concurrently, the ASM employs unsupervised learning to detect and isolate anomalous patterns induced by extreme conditions, such as heavy rain, heat waves, or human festivals. Experiments on datasets sampled from California and Shandong Province demonstrate that our framework significantly outperforms state-of-the-art methods in prediction accuracy, robustness, and computational efficiency. Our framework thus holds promise for enhancing grid resilience and optimizing market operations in future power systems.",
    "authors": [
      "Boyan Tang",
      "Xuanhao Ren",
      "Peng Xiao",
      "Shunbo Lei",
      "Xiaorong Sun",
      "Jianghua Wu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06898v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06898v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2511.06776v1",
    "title": "Data Trajectory Alignment for LLM Domain Adaptation: A Two-Phase Synthesis Framework for Telecommunications Mathematics",
    "summary": "General-purpose large language models (LLMs) are increasingly deployed in verticals such as telecommunications, where adaptation is hindered by scarce, low-information-density corpora and tight mobile/edge constraints. We propose Data Trajectory Alignment (DTA), a two-phase, model-agnostic data curation framework that treats solution processes - not only final answers - as first-class supervision. Phase I (Initializing) synthesizes diverse, high-coverage candidates using an ensemble of strong teachers. Phase II (DTA) rewrites teacher solutions to align intermediate steps and presentation style with the target student's inductive biases and then performs signal-aware exemplar selection via agreement checks and reflection-based judging. Instantiated on telecommunications mathematics (e.g., link budgets, SNR/AMC selection, and power-control feasibility), DTA yields state-of-the-art (SOTA) accuracy on TELEMATH without enabling explicit \"thinking\" modes: 72.45% pass@1, surpassing distilled-only training by +17.65 points and outperforming a strong baseline (Qwen3-32B with thinking enabled) by +2.94 points. Token-shift analyses indicate that DTA concentrates gains on logical-structural discourse markers rather than merely amplifying domain nouns, indicating improved reasoning scaffolding. Under edge-like inference settings, DTA improves efficiency by reducing reliance on multi-sample voting and disabling expensive reasoning heuristics, cutting energy per output token by ~42% versus Qwen3-32B (thinking mode enabled) and end-to-end latency by ~60% versus Qwen3-32B (thinking mode disabled). These results demonstrate that aligning how solutions are produced enables compact, high-yield supervision that is effective for both accuracy and efficiency, offering a practical recipe for domain adaptation in low-resource verticals beyond telecom.",
    "authors": [
      "Zhicheng Zhou",
      "Jing Li",
      "Suming Qiu",
      "Junjie Huang",
      "Linyuan Qiu",
      "Zhijie Sun"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06776v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06776v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2511.07171v1",
    "title": "Federated Learning for Video Violence Detection: Complementary Roles of Lightweight CNNs and Vision-Language Models for Energy-Efficient Use",
    "summary": "Deep learning-based video surveillance increasingly demands privacy-preserving architectures with low computational and environmental overhead. Federated learning preserves privacy but deploying large vision-language models (VLMs) introduces major energy and sustainability challenges. We compare three strategies for federated violence detection under realistic non-IID splits on the RWF-2000 and RLVS datasets: zero-shot inference with pretrained VLMs, LoRA-based fine-tuning of LLaVA-NeXT-Video-7B, and personalized federated learning of a 65.8M-parameter 3D CNN. All methods exceed 90% accuracy in binary violence detection. The 3D CNN achieves superior calibration (ROC AUC 92.59%) at roughly half the energy cost (240 Wh vs. 570 Wh) of federated LoRA, while VLMs provide richer multimodal reasoning. Hierarchical category grouping (based on semantic similarity and class exclusion) boosts VLM multiclass accuracy from 65.31% to 81% on the UCF-Crime dataset. To our knowledge, this is the first comparative simulation study of LoRA-tuned VLMs and personalized CNNs for federated violence detection, with explicit energy and CO2e quantification. Our results inform hybrid deployment strategies that default to efficient CNNs for routine inference and selectively engage VLMs for complex contextual reasoning.",
    "authors": [
      "Sébastien Thuau",
      "Siba Haidar",
      "Rachid Chelouah"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07171v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07171v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.08360v1",
    "title": "Extreme Model Compression with Structured Sparsity at Low Precision",
    "summary": "Deep neural networks (DNNs) are used in many applications, but their large size and high computational cost make them hard to run on devices with limited resources. Two widely used techniques to address this challenge are weight quantization, which lowers the precision of all weights, and structured sparsity, which removes unimportant weights while retaining the important ones at full precision. Although both are effective individually, they are typically studied in isolation due to their compounded negative impact on model accuracy when combined. In this work, we introduce SLOPE Structured Sparsity at Low Precision), a unified framework, to effectively combine structured sparsity and low-bit quantization in a principled way. We show that naively combining sparsity and quantization severely harms performance due to the compounded impact of both techniques. To address this, we propose a training-time regularization strategy that minimizes the discrepancy between full-precision weights and their sparse, quantized counterparts by promoting angular alignment rather than direct matching. On ResNet-18, SLOPE achieves $\\sim20\\times$ model size reduction while retaining $\\sim$99% of the original accuracy. It consistently outperforms state-of-the-art quantization and structured sparsity methods across classification, detection, and segmentation tasks on models such as ResNet-18, ViT-Small, and Mask R-CNN.",
    "authors": [
      "Dan Liu",
      "Nikita Dvornik",
      "Xue Liu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08360v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08360v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.08339v1",
    "title": "LPPG-RL: Lexicographically Projected Policy Gradient Reinforcement Learning with Subproblem Exploration",
    "summary": "Lexicographic multi-objective problems, which consist of multiple conflicting subtasks with explicit priorities, are common in real-world applications. Despite the advantages of Reinforcement Learning (RL) in single tasks, extending conventional RL methods to prioritized multiple objectives remains challenging. In particular, traditional Safe RL and Multi-Objective RL (MORL) methods have difficulty enforcing priority orderings efficiently. Therefore, Lexicographic Multi-Objective RL (LMORL) methods have been developed to address these challenges. However, existing LMORL methods either rely on heuristic threshold tuning with prior knowledge or are restricted to discrete domains. To overcome these limitations, we propose Lexicographically Projected Policy Gradient RL (LPPG-RL), a novel LMORL framework which leverages sequential gradient projections to identify feasible policy update directions, thereby enabling LPPG-RL broadly compatible with all policy gradient algorithms in continuous spaces. LPPG-RL reformulates the projection step as an optimization problem, and utilizes Dykstra's projection rather than generic solvers to deliver great speedups, especially for small- to medium-scale instances. In addition, LPPG-RL introduces Subproblem Exploration (SE) to prevent gradient vanishing, accelerate convergence and enhance stability. We provide theoretical guarantees for convergence and establish a lower bound on policy improvement. Finally, through extensive experiments in a 2D navigation environment, we demonstrate the effectiveness of LPPG-RL, showing that it outperforms existing state-of-the-art continuous LMORL methods.",
    "authors": [
      "Ruiyu Qiu",
      "Rui Wang",
      "Guanghui Yang",
      "Xiang Li",
      "Zhijiang Shao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08339v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08339v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.06682v1",
    "title": "Textual Self-attention Network: Test-Time Preference Optimization through Textual Gradient-based Attention",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable generalization capabilities, but aligning their outputs with human preferences typically requires expensive supervised fine-tuning. Recent test-time methods leverage textual feedback to overcome this, but they often critique and revise a single candidate response, lacking a principled mechanism to systematically analyze, weigh, and synthesize the strengths of multiple promising candidates. Such a mechanism is crucial because different responses may excel in distinct aspects (e.g., clarity, factual accuracy, or tone), and combining their best elements may produce a far superior outcome. This paper proposes the Textual Self-Attention Network (TSAN), a new paradigm for test-time preference optimization that requires no parameter updates. TSAN emulates self-attention entirely in natural language to overcome this gap: it analyzes multiple candidates by formatting them into textual keys and values, weighs their relevance using an LLM-based attention module, and synthesizes their strengths into a new, preference-aligned response under the guidance of the learned textual attention. This entire process operates in a textual gradient space, enabling iterative and interpretable optimization. Empirical evaluations demonstrate that with just three test-time iterations on a base SFT model, TSAN outperforms supervised models like Llama-3.1-70B-Instruct and surpasses the current state-of-the-art test-time alignment method by effectively leveraging multiple candidate solutions.",
    "authors": [
      "Shibing Mo",
      "Haoyang Ruan",
      "Kai Wu",
      "Jing Liu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06682v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06682v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.08340v1",
    "title": "HN-MVTS: HyperNetwork-based Multivariate Time Series Forecasting",
    "summary": "Accurate forecasting of multivariate time series data remains a formidable challenge, particularly due to the growing complexity of temporal dependencies in real-world scenarios. While neural network-based models have achieved notable success in this domain, complex channel-dependent models often suffer from performance degradation compared to channel-independent models that do not consider the relationship between components but provide high robustness due to small capacity. In this work, we propose HN-MVTS, a novel architecture that integrates a hypernetwork-based generative prior with an arbitrary neural network forecasting model. The input of this hypernetwork is a learnable embedding matrix of time series components. To restrict the number of new parameters, the hypernetwork learns to generate the weights of the last layer of the target forecasting networks, serving as a data-adaptive regularizer that improves generalization and long-range predictive accuracy. The hypernetwork is used only during the training, so it does not increase the inference time compared to the base forecasting model. Extensive experiments on eight benchmark datasets demonstrate that application of HN-MVTS to the state-of-the-art models (DLinear, PatchTST, TSMixer, etc.) typically improves their performance. Our findings suggest that hypernetwork-driven parameterization offers a promising direction for enhancing existing forecasting techniques in complex scenarios.",
    "authors": [
      "Andrey Savchenko",
      "Oleg Kachan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08340v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08340v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.08379v1",
    "title": "SOM Directions are Better than One: Multi-Directional Refusal Suppression in Language Models",
    "summary": "Refusal refers to the functional behavior enabling safety-aligned language models to reject harmful or unethical prompts. Following the growing scientific interest in mechanistic interpretability, recent work encoded refusal behavior as a single direction in the model's latent space; e.g., computed as the difference between the centroids of harmful and harmless prompt representations. However, emerging evidence suggests that concepts in LLMs often appear to be encoded as a low-dimensional manifold embedded in the high-dimensional latent space. Motivated by these findings, we propose a novel method leveraging Self-Organizing Maps (SOMs) to extract multiple refusal directions. To this end, we first prove that SOMs generalize the prior work's difference-in-means technique. We then train SOMs on harmful prompt representations to identify multiple neurons. By subtracting the centroid of harmless representations from each neuron, we derive a set of multiple directions expressing the refusal concept. We validate our method on an extensive experimental setup, demonstrating that ablating multiple directions from models' internals outperforms not only the single-direction baseline but also specialized jailbreak algorithms, leading to an effective suppression of refusal. Finally, we conclude by analyzing the mechanistic implications of our approach.",
    "authors": [
      "Giorgio Piras",
      "Raffaele Mura",
      "Fabio Brau",
      "Luca Oneto",
      "Fabio Roli",
      "Battista Biggio"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08379v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08379v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2511.08344v1",
    "title": "Towards Open-Set Myoelectric Gesture Recognition via Dual-Perspective Inconsistency Learning",
    "summary": "Surface electromyography (sEMG)-based gesture recognition plays a critical role in human-machine interaction (HMI), particularly for rehabilitation and prosthetic control. However, sEMG-based systems often suffer from the scarcity of informative training data, leading to overfitting and poor generalization in deep learning models. Data augmentation offers a promising approach to increasing the size and diversity of training data, where faithfulness and diversity are two critical factors to effectiveness. However, promoting untargeted diversity can result in redundant samples with limited utility. To address these challenges, we propose a novel diffusion-based data augmentation approach, Sparse-Aware Semantic-Guided Diffusion Augmentation (SASG-DA). To enhance generation faithfulness, we introduce the Semantic Representation Guidance (SRG) mechanism by leveraging fine-grained, task-aware semantic representations as generation conditions. To enable flexible and diverse sample generation, we propose a Gaussian Modeling Semantic Modeling (GMSS) strategy, which models the semantic representation distribution and allows stochastic sampling to produce both faithful and diverse samples. To enhance targeted diversity, we further introduce a Sparse-Aware Semantic Sampling strategy to explicitly explore underrepresented regions, improving distribution coverage and sample utility. Extensive experiments on benchmark sEMG datasets, Ninapro DB2, DB4, and DB7, demonstrate that SASG-DA significantly outperforms existing augmentation methods. Overall, our proposed data augmentation approach effectively mitigates overfitting and improves recognition performance and generalization by offering both faithful and diverse samples.",
    "authors": [
      "Chen Liu",
      "Can Han",
      "Weishi Xu",
      "Yaqi Wang",
      "Dahong Qian"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08344v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08344v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2511.08567v1",
    "title": "The Path Not Taken: RLVR Provably Learns Off the Principals",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) reliably improves the reasoning performance of large language models, yet it appears to modify only a small fraction of parameters. We revisit this paradox and show that sparsity is a surface artifact of a model-conditioned optimization bias: for a fixed pretrained model, updates consistently localize to preferred parameter regions, highly consistent across runs and largely invariant to datasets and RL recipes. We mechanistically explain these dynamics with a Three-Gate Theory: Gate I (KL Anchor) imposes a KL-constrained update; Gate II (Model Geometry) steers the step off principal directions into low-curvature, spectrum-preserving subspaces; and Gate III (Precision) hides micro-updates in non-preferred regions, making the off-principal bias appear as sparsity. We then validate this theory and, for the first time, provide a parameter-level characterization of RLVR's learning dynamics: RLVR learns off principal directions in weight space, achieving gains via minimal spectral drift, reduced principal-subspace rotation, and off-principal update alignment. In contrast, SFT targets principal weights, distorts the spectrum, and even lags RLVR.   Together, these results provide the first parameter-space account of RLVR's training dynamics, revealing clear regularities in how parameters evolve. Crucially, we show that RL operates in a distinct optimization regime from SFT, so directly adapting SFT-era parameter-efficient fine-tuning (PEFT) methods can be flawed, as evidenced by our case studies on advanced sparse fine-tuning and LoRA variants. We hope this work charts a path toward a white-box understanding of RLVR and the design of geometry-aware, RLVR-native learning algorithms, rather than repurposed SFT-era heuristics.",
    "authors": [
      "Hanqing Zhu",
      "Zhenyu Zhang",
      "Hanxian Huang",
      "DiJia Su",
      "Zechun Liu",
      "Jiawei Zhao",
      "Igor Fedorov",
      "Hamed Pirsiavash",
      "Zhizhou Sha",
      "Jinwon Lee",
      "David Z. Pan",
      "Zhangyang Wang",
      "Yuandong Tian",
      "Kai Sheng Tai"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08567v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08567v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.07006v1",
    "title": "S$^2$Drug: Bridging Protein Sequence and 3D Structure in Contrastive Representation Learning for Virtual Screening",
    "summary": "Virtual screening (VS) is an essential task in drug discovery, focusing on the identification of small-molecule ligands that bind to specific protein pockets. Existing deep learning methods, from early regression models to recent contrastive learning approaches, primarily rely on structural data while overlooking protein sequences, which are more accessible and can enhance generalizability. However, directly integrating protein sequences poses challenges due to the redundancy and noise in large-scale protein-ligand datasets. To address these limitations, we propose \\textbf{S$^2$Drug}, a two-stage framework that explicitly incorporates protein \\textbf{S}equence information and 3D \\textbf{S}tructure context in protein-ligand contrastive representation learning. In the first stage, we perform protein sequence pretraining on ChemBL using an ESM2-based backbone, combined with a tailored data sampling strategy to reduce redundancy and noise on both protein and ligand sides. In the second stage, we fine-tune on PDBBind by fusing sequence and structure information through a residue-level gating module, while introducing an auxiliary binding site prediction task. This auxiliary task guides the model to accurately localize binding residues within the protein sequence and capture their 3D spatial arrangement, thereby refining protein-ligand matching. Across multiple benchmarks, S$^2$Drug consistently improves virtual screening performance and achieves strong results on binding site prediction, demonstrating the value of bridging sequence and structure in contrastive learning.",
    "authors": [
      "Bowei He",
      "Bowen Gao",
      "Yankai Chen",
      "Yanyan Lan",
      "Chen Ma",
      "Philip S. Yu",
      "Ya-Qin Zhang",
      "Wei-Ying Ma"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07006v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07006v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.06893v1",
    "title": "DeepBooTS: Dual-Stream Residual Boosting for Drift-Resilient Time-Series Forecasting",
    "summary": "Time-Series (TS) exhibits pronounced non-stationarity. Consequently, most forecasting methods display compromised robustness to concept drift, despite the prevalent application of instance normalization. We tackle this challenge by first analysing concept drift through a bias-variance lens and proving that weighted ensemble reduces variance without increasing bias. These insights motivate DeepBooTS, a novel end-to-end dual-stream residual-decreasing boosting method that progressively reconstructs the intrinsic signal. In our design, each block of a deep model becomes an ensemble of learners with an auxiliary output branch forming a highway to the final prediction. The block-wise outputs correct the residuals of previous blocks, leading to a learning-driven decomposition of both inputs and targets. This method enhances versatility and interpretability while substantially improving robustness to concept drift. Extensive experiments, including those on large-scale datasets, show that the proposed method outperforms existing methods by a large margin, yielding an average performance improvement of 15.8% across various datasets, establishing a new benchmark for TS forecasting.",
    "authors": [
      "Daojun Liang",
      "Jing Chen",
      "Xiao Wang",
      "Yinglong Wang",
      "Suo Li"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06893v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06893v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.06757v1",
    "title": "Implicit Federated In-context Learning For Task-Specific LLM Fine-Tuning",
    "summary": "As large language models continue to develop and expand, the extensive public data they rely on faces the risk of depletion. Consequently, leveraging private data within organizations to enhance the performance of large models has emerged as a key challenge. The federated learning paradigm, combined with model fine-tuning techniques, effectively reduces the number of trainable parameters. However,the necessity to process high-dimensional feature spaces results in substantial overall computational overhead. To address this issue, we propose the Implicit Federated In-Context Learning (IFed-ICL) framework. IFed-ICL draws inspiration from federated learning to establish a novel distributed collaborative paradigm, by converting client local context examples into implicit vector representations, it enables distributed collaborative computation during the inference phase and injects model residual streams to enhance model performance. Experiments demonstrate that our proposed method achieves outstanding performance across multiple text classification tasks. Compared to traditional methods, IFed-ICL avoids the extensive parameter updates required by conventional fine-tuning methods while reducing data transmission and local computation at the client level in federated learning. This enables efficient distributed context learning using local private-domain data, significantly improving model performance on specific tasks.",
    "authors": [
      "Dongcheng Li",
      "Junhan Chen",
      "Aoxiang Zhou",
      "Chunpei Li",
      "Youquan Xian",
      "Peng Liu",
      "Xianxian Li"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06757v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06757v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.07377v1",
    "title": "Real-Time LiDAR Super-Resolution via Frequency-Aware Multi-Scale Fusion",
    "summary": "LiDAR super-resolution addresses the challenge of achieving high-quality 3D perception from cost-effective, low-resolution sensors. While recent transformer-based approaches like TULIP show promise, they remain limited to spatial-domain processing with restricted receptive fields. We introduce FLASH (Frequency-aware LiDAR Adaptive Super-resolution with Hierarchical fusion), a novel framework that overcomes these limitations through dual-domain processing. FLASH integrates two key innovations: (i) Frequency-Aware Window Attention that combines local spatial attention with global frequency-domain analysis via FFT, capturing both fine-grained geometry and periodic scanning patterns at log-linear complexity. (ii) Adaptive Multi-Scale Fusion that replaces conventional skip connections with learned position-specific feature aggregation, enhanced by CBAM attention for dynamic feature selection. Extensive experiments on KITTI demonstrate that FLASH achieves state-of-the-art performance across all evaluation metrics, surpassing even uncertainty-enhanced baselines that require multiple forward passes. Notably, FLASH outperforms TULIP with Monte Carlo Dropout while maintaining single-pass efficiency, which enables real-time deployment. The consistent superiority across all distance ranges validates that our dual-domain approach effectively handles uncertainty through architectural design rather than computationally expensive stochastic inference, making it practical for autonomous systems.",
    "authors": [
      "June Moh Goo",
      "Zichao Zeng",
      "Jan Boehm"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07377v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07377v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.07831v1",
    "title": "Distributionally Robust Online Markov Game with Linear Function Approximation",
    "summary": "The sim-to-real gap, where agents trained in a simulator face significant performance degradation during testing, is a fundamental challenge in reinforcement learning. Extansive works adopt the framework of distributionally robust RL, to learn a policy that acts robustly under worst case environment shift. Within this framework, our objective is to devise algorithms that are sample efficient with interactive data collection and large state spaces. By assuming d-rectangularity of environment dynamic shift, we identify a fundamental hardness result for learning in online Markov game, and address it by adopting minimum value assumption. Then, a novel least square value iteration type algorithm, DR-CCE-LSI, with exploration bonus devised specifically for multiple agents, is proposed to find an \\episilon-approximate robust Coarse Correlated Equilibrium(CCE). To obtain sample efficient learning, we find that: when the feature mapping function satisfies certain properties, our algorithm, DR-CCE-LSI, is able to achieve ε-approximate CCE with a regret bound of O{dHmin{H,1/min{σ_i}}\\sqrt{K}}, where K is the number of interacting episodes, H is the horizon length, d is the feature dimension, and \\simga_i represents the uncertainty level of player i. Our work introduces the first sample-efficient algorithm for this setting, matches the best result so far in single agent setting, and achieves minimax optimalsample complexity in terms of the feature dimension d. Meanwhile, we also conduct simulation study to validate the efficacy of our algorithm in learning a robust equilibrium.",
    "authors": [
      "Zewu Zheng",
      "Yuanyuan Lin"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07831v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07831v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.08394v1",
    "title": "Interaction Dynamics as a Reward Signal for LLMs",
    "summary": "The alignment of Large Language Models (LLMs) for multi-turn conversations typically relies on reward signals derived from the content of the text. This approach, however, overlooks a rich, complementary source of signal: the dynamics of the interaction itself. This paper introduces TRACE (Trajectory-based Reward for Agent Collaboration Estimation), a novel reward signal derived from the geometric properties of a dialogue's embedding trajectory--a concept we term 'conversational geometry'. Our central finding is that a reward model trained only on these structural signals achieves a pairwise accuracy (68.20%) comparable to a powerful LLM baseline that analyzes the full transcript (70.04%). Furthermore, a hybrid model combining interaction dynamics with textual analysis achieves the highest performance (80.17%), demonstrating their complementary nature. This work provides strong evidence that for interactive settings, how an agent communicates is as powerful a predictor of success as what it says, offering a new, privacy-preserving framework that not only aligns agents but also serves as a diagnostic tool for understanding the distinct interaction patterns that drive successful collaboration.",
    "authors": [
      "Sian Gooding",
      "Edward Grefenstette"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08394v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08394v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.06625v1",
    "title": "Explainable Cross-Disease Reasoning for Cardiovascular Risk Assessment from LDCT",
    "summary": "Low-dose chest computed tomography (LDCT) inherently captures both pulmonary and cardiac structures, offering a unique opportunity for joint assessment of lung and cardiovascular health. However, most existing approaches treat these domains as independent tasks, overlooking their physiological interplay and shared imaging biomarkers. We propose an Explainable Cross-Disease Reasoning Framework that enables interpretable cardiopulmonary risk assessment from a single LDCT scan. The framework introduces an agentic reasoning process that emulates clinical diagnostic thinking-first perceiving pulmonary findings, then reasoning through established medical knowledge, and finally deriving a cardiovascular judgment with explanatory rationale. It integrates three synergistic components: a pulmonary perception module that summarizes lung abnormalities, a knowledge-guided reasoning module that infers their cardiovascular implications, and a cardiac representation module that encodes structural biomarkers. Their outputs are fused to produce a holistic cardiovascular risk prediction that is both accurate and physiologically grounded. Experiments on the NLST cohort demonstrate that the proposed framework achieves state-of-the-art performance for CVD screening and mortality prediction, outperforming single-disease and purely image-based baselines. Beyond quantitative gains, the framework provides human-verifiable reasoning that aligns with cardiological understanding, revealing coherent links between pulmonary abnormalities and cardiac stress mechanisms. Overall, this work establishes a unified and explainable paradigm for cardiovascular analysis from LDCT, bridging the gap between image-based prediction and mechanism-based medical interpretation.",
    "authors": [
      "Yifei Zhang",
      "Jiashuo Zhang",
      "Xiaofeng Yang",
      "Liang Zhao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06625v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06625v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07399v1",
    "title": "StreamDiffusionV2: A Streaming System for Dynamic and Interactive Video Generation",
    "summary": "Generative models are reshaping the live-streaming industry by redefining how content is created, styled, and delivered. Previous image-based streaming diffusion models have powered efficient and creative live streaming products but have hit limits on temporal consistency due to the foundation of image-based designs. Recent advances in video diffusion have markedly improved temporal consistency and sampling efficiency for offline generation. However, offline generation systems primarily optimize throughput by batching large workloads. In contrast, live online streaming operates under strict service-level objectives (SLOs): time-to-first-frame must be minimal, and every frame must meet a per-frame deadline with low jitter. Besides, scalable multi-GPU serving for real-time streams remains largely unresolved so far. To address this, we present StreamDiffusionV2, a training-free pipeline for interactive live streaming with video diffusion models. StreamDiffusionV2 integrates an SLO-aware batching scheduler and a block scheduler, together with a sink-token--guided rolling KV cache, a motion-aware noise controller, and other system-level optimizations. Moreover, we introduce a scalable pipeline orchestration that parallelizes the diffusion process across denoising steps and network layers, achieving near-linear FPS scaling without violating latency guarantees. The system scales seamlessly across heterogeneous GPU environments and supports flexible denoising steps (e.g., 1--4), enabling both ultra-low-latency and higher-quality modes. Without TensorRT or quantization, StreamDiffusionV2 renders the first frame within 0.5s and attains 58.28 FPS with a 14B-parameter model and 64.52 FPS with a 1.3B-parameter model on four H100 GPUs, making state-of-the-art generative live streaming practical and accessible--from individual creators to enterprise-scale platforms.",
    "authors": [
      "Tianrui Feng",
      "Zhi Li",
      "Shuo Yang",
      "Haocheng Xi",
      "Muyang Li",
      "Xiuyu Li",
      "Lvmin Zhang",
      "Keting Yang",
      "Kelly Peng",
      "Song Han",
      "Maneesh Agrawala",
      "Kurt Keutzer",
      "Akio Kodaira",
      "Chenfeng Xu"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07399v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07399v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.06794v1",
    "title": "Beyond Uniform Deletion: A Data Value-Weighted Framework for Certified Machine Unlearning",
    "summary": "As the right to be forgotten becomes legislated worldwide, machine unlearning mechanisms have emerged to efficiently update models for data deletion and enhance user privacy protection. However, existing machine unlearning algorithms frequently neglect the fact that different data points may contribute unequally to model performance (i.e., heterogeneous data values). Treat them equally in machine unlearning procedure can potentially degrading the performance of updated models. To address this limitation, we propose Data Value-Weighted Unlearning (DVWU), a general unlearning framework that accounts for data value heterogeneity into the unlearning process. Specifically, we design a weighting strategy based on data values, which are then integrated into the unlearning procedure to enable differentiated unlearning for data points with varying utility to the model. The DVWU framework can be broadly adapted to various existing machine unlearning methods. We use the one-step Newton update as an example for implementation, developing both output and objective perturbation algorithms to achieve certified unlearning. Experiments on both synthetic and real-world datasets demonstrate that our methods achieve superior predictive performance and robustness compared to conventional unlearning approaches. We further show the extensibility of our framework on gradient ascent method by incorporating the proposed weighting strategy into the gradient terms, highlighting the adaptability of DVWU for broader gradient-based deep unlearning methods.",
    "authors": [
      "Lisong He",
      "Yi Yang",
      "Xiangyu Chang"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06794v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06794v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07923v1",
    "title": "Exploring the Underwater World Segmentation without Extra Training",
    "summary": "Accurate segmentation of marine organisms is vital for biodiversity monitoring and ecological assessment, yet existing datasets and models remain largely limited to terrestrial scenes. To bridge this gap, we introduce \\textbf{AquaOV255}, the first large-scale and fine-grained underwater segmentation dataset containing 255 categories and over 20K images, covering diverse categories for open-vocabulary (OV) evaluation. Furthermore, we establish the first underwater OV segmentation benchmark, \\textbf{UOVSBench}, by integrating AquaOV255 with five additional underwater datasets to enable comprehensive evaluation. Alongside, we present \\textbf{Earth2Ocean}, a training-free OV segmentation framework that transfers terrestrial vision--language models (VLMs) to underwater domains without any additional underwater training. Earth2Ocean consists of two core components: a Geometric-guided Visual Mask Generator (\\textbf{GMG}) that refines visual features via self-similarity geometric priors for local structure perception, and a Category-visual Semantic Alignment (\\textbf{CSA}) module that enhances text embeddings through multimodal large language model reasoning and scene-aware template construction. Extensive experiments on the UOVSBench benchmark demonstrate that Earth2Ocean achieves significant performance improvement on average while maintaining efficient inference.",
    "authors": [
      "Bingyu Li",
      "Tao Huo",
      "Da Zhang",
      "Zhiyuan Zhao",
      "Junyu Gao",
      "Xuelong Li"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07923v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07923v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.08061v1",
    "title": "Taming Identity Consistency and Prompt Diversity in Diffusion Models via Latent Concatenation and Masked Conditional Flow Matching",
    "summary": "Subject-driven image generation aims to synthesize novel depictions of a specific subject across diverse contexts while preserving its core identity features. Achieving both strong identity consistency and high prompt diversity presents a fundamental trade-off. We propose a LoRA fine-tuned diffusion model employing a latent concatenation strategy, which jointly processes reference and target images, combined with a masked Conditional Flow Matching (CFM) objective. This approach enables robust identity preservation without architectural modifications. To facilitate large-scale training, we introduce a two-stage Distilled Data Curation Framework: the first stage leverages data restoration and VLM-based filtering to create a compact, high-quality seed dataset from diverse sources; the second stage utilizes these curated examples for parameter-efficient fine-tuning, thus scaling the generation capability across various subjects and contexts. Finally, for filtering and quality assessment, we present CHARIS, a fine-grained evaluation framework that performs attribute-level comparisons along five key axes: identity consistency, prompt adherence, region-wise color fidelity, visual quality, and transformation diversity.",
    "authors": [
      "Aditi Singhania",
      "Arushi Jain",
      "Krutik Malani",
      "Riddhi Dhawan",
      "Souymodip Chakraborty",
      "Vineet Batra",
      "Ankit Phogat"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08061v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08061v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.08224v1",
    "title": "2D Representation for Unguided Single-View 3D Super-Resolution in Real-Time",
    "summary": "We introduce 2Dto3D-SR, a versatile framework for real-time single-view 3D super-resolution that eliminates the need for high-resolution RGB guidance. Our framework encodes 3D data from a single viewpoint into a structured 2D representation, enabling the direct application of existing 2D image super-resolution architectures. We utilize the Projected Normalized Coordinate Code (PNCC) to represent 3D geometry from a visible surface as a regular image, thereby circumventing the complexities of 3D point-based or RGB-guided methods. This design supports lightweight and fast models adaptable to various deployment environments. We evaluate 2Dto3D-SR with two implementations: one using Swin Transformers for high accuracy, and another using Vision Mamba for high efficiency. Experiments show the Swin Transformer model achieves state-of-the-art accuracy on standard benchmarks, while the Vision Mamba model delivers competitive results at real-time speeds. This establishes our geometry-guided pipeline as a surprisingly simple yet viable and practical solution for real-world scenarios, especially where high-resolution RGB data is inaccessible.",
    "authors": [
      "Ignasi Mas",
      "Ivan Huerta",
      "Ramon Morros",
      "Javier Ruiz-Hidalgo"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08224v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08224v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07293v1",
    "title": "Verifying rich robustness properties for neural networks",
    "summary": "Robustness is a important problem in AI alignment and safety, with models such as neural networks being increasingly used in safety-critical systems. In the last decade, a large body of work has emerged on local robustness, i.e., checking if the decision of a neural network remains unchanged when the input is slightly perturbed. However, many of these approaches require specialized encoding and often ignore the confidence of a neural network on its output. In this paper, our goal is to build a generalized framework to specify and verify variants of robustness in neural network verification. We propose a specification framework using a simple grammar, which is flexible enough to capture most existing variants. This allows us to introduce new variants of robustness that take into account the confidence of the neural network in its outputs. Next, we develop a novel and powerful unified technique to verify all such variants in a homogeneous way, viz., by adding a few additional layers to the neural network. This enables us to use any state-of-the-art neural network verification tool, without having to tinker with the encoding within, while incurring an approximation error that we show is bounded. We perform an extensive experimental evaluation over a large suite of 8870 benchmarks having 138M parameters in a largest network, and show that we are able to capture a wide set of robustness variants and outperform direct encoding approaches by a significant margin.",
    "authors": [
      "Mohammad Afzal",
      "S. Akshay",
      "Ashutosh Gupta"
    ],
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07293v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07293v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07904v1",
    "title": "Test-driven Reinforcement Learning",
    "summary": "Reinforcement learning (RL) has been recognized as a powerful tool for robot control tasks. RL typically employs reward functions to define task objectives and guide agent learning. However, since the reward function serves the dual purpose of defining the optimal goal and guiding learning, it is challenging to design the reward function manually, which often results in a suboptimal task representation. To tackle the reward design challenge in RL, inspired by the satisficing theory, we propose a Test-driven Reinforcement Learning (TdRL) framework. In the TdRL framework, multiple test functions are used to represent the task objective rather than a single reward function. Test functions can be categorized as pass-fail tests and indicative tests, each dedicated to defining the optimal objective and guiding the learning process, respectively, thereby making defining tasks easier. Building upon such a task definition, we first prove that if a trajectory return function assigns higher returns to trajectories closer to the optimal trajectory set, maximum entropy policy optimization based on this return function will yield a policy that is closer to the optimal policy set. Then, we introduce a lexicographic heuristic approach to compare the relative distance relationship between trajectories and the optimal trajectory set for learning the trajectory return function. Furthermore, we develop an algorithm implementation of TdRL. Experimental results on the DeepMind Control Suite benchmark demonstrate that TdRL matches or outperforms handcrafted reward methods in policy training, with greater design simplicity and inherent support for multi-objective optimization. We argue that TdRL offers a novel perspective for representing task objectives, which could be helpful in addressing the reward design challenges in RL applications.",
    "authors": [
      "Zhao Yu",
      "Xiuping Wu",
      "Liangjun Ke"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07904v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07904v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.08242v1",
    "title": "Towards Outcome-Oriented, Task-Agnostic Evaluation of AI Agents",
    "summary": "As AI agents proliferate across industries and applications, evaluating their performance based solely on infrastructural metrics such as latency, time-to-first-token, or token throughput is proving insufficient. These metrics fail to capture the quality of an agent's decisions, its operational autonomy, or its ultimate business value. This white paper proposes a novel, comprehensive framework of eleven outcome-based, task-agnostic performance metrics for AI agents that transcend domain boundaries. These metrics are designed to enable organizations to evaluate agents based on the quality of their decisions, their degree of autonomy, their adaptability to new challenges, and the tangible business value they deliver, regardless of the underlying model architecture or specific use case. We introduce metrics such as Goal Completion Rate (GCR), Autonomy Index (AIx), Multi-Step Task Resilience (MTR), and Business Impact Efficiency (BIE). Through a large-scale simulated experiment involving four distinct agent architectures (ReAct, Chain-of-Thought, Tool-Augmented, Hybrid) across five diverse domains (Healthcare, Finance, Marketing, Legal, and Customer Service), we demonstrate the framework's efficacy. Our results reveal significant performance trade-offs between different agent designs, highlighting the Hybrid Agent as the most consistently high-performing model across the majority of our proposed metrics, achieving an average Goal Completion Rate of 88.8\\% and the highest Return on Investment (ROI). This work provides a robust, standardized methodology for the holistic evaluation of AI agents, paving the way for more effective development, deployment, and governance.",
    "authors": [
      "Waseem AlShikh",
      "Muayad Sayed Ali",
      "Brian Kennedy",
      "Dmytro Mozolevskyi"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08242v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08242v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.06944v1",
    "title": "From Attribution to Action: Jointly ALIGNing Predictions and Explanations",
    "summary": "Explanation-guided learning (EGL) has shown promise in aligning model predictions with interpretable reasoning, particularly in computer vision tasks. However, most approaches rely on external annotations or heuristic-based segmentation to supervise model explanations, which can be noisy, imprecise and difficult to scale. In this work, we provide both empirical and theoretical evidence that low-quality supervision signals can degrade model performance rather than improve it. In response, we propose ALIGN, a novel framework that jointly trains a classifier and a masker in an iterative manner. The masker learns to produce soft, task-relevant masks that highlight informative regions, while the classifier is optimized for both prediction accuracy and alignment between its saliency maps and the learned masks. By leveraging high-quality masks as guidance, ALIGN improves both interpretability and generalizability, showing its superiority across various settings. Experiments on the two domain generalization benchmarks, VLCS and Terra Incognita, show that ALIGN consistently outperforms six strong baselines in both in-distribution and out-of-distribution settings. Besides, ALIGN also yields superior explanation quality concerning sufficiency and comprehensiveness, highlighting its effectiveness in producing accurate and interpretable models.",
    "authors": [
      "Dongsheng Hong",
      "Chao Chen",
      "Yanhui Chen",
      "Shanshan Lin",
      "Zhihao Chen",
      "Xiangwen Liao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06944v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06944v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.08152v1",
    "title": "Boomda: Balanced Multi-objective Optimization for Multimodal Domain Adaptation",
    "summary": "Multimodal learning, while contributing to numerous success stories across various fields, faces the challenge of prohibitively expensive manual annotation. To address the scarcity of annotated data, a popular solution is unsupervised domain adaptation, which has been extensively studied in unimodal settings yet remains less explored in multimodal settings. In this paper, we investigate heterogeneous multimodal domain adaptation, where the primary challenge is the varying domain shifts of different modalities from the source to the target domain. We first introduce the information bottleneck method to learn representations for each modality independently, and then match the source and target domains in the representation space with correlation alignment. To balance the domain alignment of all modalities, we formulate the problem as a multi-objective task, aiming for a Pareto optimal solution. By exploiting the properties specific to our model, the problem can be simplified to a quadratic programming problem. Further approximation yields a closed-form solution, leading to an efficient modality-balanced multimodal domain adaptation algorithm. The proposed method features \\textbf{B}alanced multi-\\textbf{o}bjective \\textbf{o}ptimization for \\textbf{m}ultimodal \\textbf{d}omain \\textbf{a}daptation, termed \\textbf{Boomda}. Extensive empirical results showcase the effectiveness of the proposed approach and demonstrate that Boomda outperforms the competing schemes. The code is is available at: https://github.com/sunjunaimer/Boomda.git.",
    "authors": [
      "Jun Sun",
      "Xinxin Zhang",
      "Simin Hong",
      "Jian Zhu",
      "Xiang Gao"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08152v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08152v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07685v1",
    "title": "ResearchRubrics: A Benchmark of Prompts and Rubrics For Evaluating Deep Research Agents",
    "summary": "Deep Research (DR) is an emerging agent application that leverages large language models (LLMs) to address open-ended queries. It requires the integration of several capabilities, including multi-step reasoning, cross-document synthesis, and the generation of evidence-backed, long-form answers. Evaluating DR remains challenging because responses are lengthy and diverse, admit many valid solutions, and often depend on dynamic information sources. We introduce ResearchRubrics, a standardized benchmark for DR built with over 2,800+ hours of human labor that pairs realistic, domain-diverse prompts with 2,500+ expert-written, fine-grained rubrics to assess factual grounding, reasoning soundness, and clarity. We also propose a new complexity framework for categorizing DR tasks along three axes: conceptual breadth, logical nesting, and exploration. In addition, we develop human and model-based evaluation protocols that measure rubric adherence for DR agents. We evaluate several state-of-the-art DR systems and find that even leading agents like Gemini's DR and OpenAI's DR achieve under 68% average compliance with our rubrics, primarily due to missed implicit context and inadequate reasoning about retrieved information. Our results highlight the need for robust, scalable assessment of deep research capabilities, to which end we release ResearchRubrics(including all prompts, rubrics, and evaluation code) to facilitate progress toward well-justified research assistants.",
    "authors": [
      "Manasi Sharma",
      "Chen Bo Calvin Zhang",
      "Chaithanya Bandi",
      "Clinton Wang",
      "Ankit Aich",
      "Huy Nghiem",
      "Tahseen Rabbani",
      "Ye Htet",
      "Brian Jang",
      "Sumana Basu",
      "Aishwarya Balwani",
      "Denis Peskoff",
      "Marcos Ayestaran",
      "Sean M. Hendryx",
      "Brad Kenstler",
      "Bing Liu"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07685v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07685v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.08238v1",
    "title": "Remodeling Semantic Relationships in Vision-Language Fine-Tuning",
    "summary": "Vision-language fine-tuning has emerged as an efficient paradigm for constructing multimodal foundation models. While textual context often highlights semantic relationships within an image, existing fine-tuning methods typically overlook this information when aligning vision and language, thus leading to suboptimal performance. Toward solving this problem, we propose a method that can improve multimodal alignment and fusion based on both semantics and relationships.Specifically, we first extract multilevel semantic features from different vision encoder to capture more visual cues of the relationships. Then, we learn to project the vision features to group related semantics, among which are more likely to have relationships. Finally, we fuse the visual features with the textual by using inheritable cross-attention, where we globally remove the redundant visual relationships by discarding visual-language feature pairs with low correlation. We evaluate our proposed method on eight foundation models and two downstream tasks, visual question answering and image captioning, and show that it outperforms all existing methods.",
    "authors": [
      "Xiangyang Wu",
      "Liu Liu",
      "Baosheng Yu",
      "Jiayan Qiu",
      "Zhenwei Shi"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08238v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08238v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.07338v2",
    "title": "DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas",
    "summary": "Simulating human profiles by instilling personas into large language models (LLMs) is rapidly transforming research in agentic behavioral simulation, LLM personalization, and human-AI alignment. However, most existing synthetic personas remain shallow and simplistic, capturing minimal attributes and failing to reflect the rich complexity and diversity of real human identities. We introduce DEEPPERSONA, a scalable generative engine for synthesizing narrative-complete synthetic personas through a two-stage, taxonomy-guided method. First, we algorithmically construct the largest-ever human-attribute taxonomy, comprising over hundreds of hierarchically organized attributes, by mining thousands of real user-ChatGPT conversations. Second, we progressively sample attributes from this taxonomy, conditionally generating coherent and realistic personas that average hundreds of structured attributes and roughly 1 MB of narrative text, two orders of magnitude deeper than prior works. Intrinsic evaluations confirm significant improvements in attribute diversity (32 percent higher coverage) and profile uniqueness (44 percent greater) compared to state-of-the-art baselines. Extrinsically, our personas enhance GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on average across ten metrics and substantially narrow (by 31.7 percent) the gap between simulated LLM citizens and authentic human responses in social surveys. Our generated national citizens reduced the performance gap on the Big Five personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA thus provides a rigorous, scalable, and privacy-free platform for high-fidelity human simulation and personalized AI research.",
    "authors": [
      "Zhen Wang",
      "Yufan Zhou",
      "Zhongyan Luo",
      "Lyumanshan Ye",
      "Adam Wood",
      "Man Yao",
      "Luoshang Pan"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07338v2",
    "pdf_url": "https://arxiv.org/pdf/2511.07338v2.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.07166v1",
    "title": "AdaRec: Adaptive Recommendation with LLMs via Narrative Profiling and Dual-Channel Reasoning",
    "summary": "We propose AdaRec, a few-shot in-context learning framework that leverages large language models for an adaptive personalized recommendation. AdaRec introduces narrative profiling, transforming user-item interactions into natural language representations to enable unified task handling and enhance human readability. Centered on a bivariate reasoning paradigm, AdaRec employs a dual-channel architecture that integrates horizontal behavioral alignment, discovering peer-driven patterns, with vertical causal attribution, highlighting decisive factors behind user preferences. Unlike existing LLM-based approaches, AdaRec eliminates manual feature engineering through semantic representations and supports rapid cross-task adaptation with minimal supervision. Experiments on real ecommerce datasets demonstrate that AdaRec outperforms both machine learning models and LLM-based baselines by up to eight percent in few-shot settings. In zero-shot scenarios, it achieves up to a nineteen percent improvement over expert-crafted profiling, showing effectiveness for long-tail personalization with minimal interaction data. Furthermore, lightweight fine-tuning on synthetic data generated by AdaRec matches the performance of fully fine-tuned models, highlighting its efficiency and generalization across diverse tasks.",
    "authors": [
      "Meiyun Wang",
      "Charin Polpanumas"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07166v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07166v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07755v1",
    "title": "Filtered-ViT: A Robust Defense Against Multiple Adversarial Patch Attacks",
    "summary": "Deep learning vision systems are increasingly deployed in safety-critical domains such as healthcare, yet they remain vulnerable to small adversarial patches that can trigger misclassifications. Most existing defenses assume a single patch and fail when multiple localized disruptions occur, the type of scenario adversaries and real-world artifacts often exploit. We propose Filtered-ViT, a new vision transformer architecture that integrates SMART Vector Median Filtering (SMART-VMF), a spatially adaptive, multi-scale, robustness-aware mechanism that enables selective suppression of corrupted regions while preserving semantic detail. On ImageNet with LaVAN multi-patch attacks, Filtered-ViT achieves 79.8% clean accuracy and 46.3% robust accuracy under four simultaneous 1\\% patches, outperforming existing defenses. Beyond synthetic benchmarks, a real-world case study on radiographic medical imagery shows that Filtered-ViT mitigates natural artifacts such as occlusions and scanner noise without degrading diagnostic content. This establishes Filtered-ViT as the first transformer to demonstrate unified robustness against both adversarial and naturally occurring patch-like disruptions, charting a path toward reliable vision systems in truly high-stakes environments.",
    "authors": [
      "Aja Khanal",
      "Ahmed Faid",
      "Apurva Narayan"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07755v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07755v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07748v1",
    "title": "Auto-US: An Ultrasound Video Diagnosis Agent Using Video Classification Framework and LLMs",
    "summary": "AI-assisted ultrasound video diagnosis presents new opportunities to enhance the efficiency and accuracy of medical imaging analysis. However, existing research remains limited in terms of dataset diversity, diagnostic performance, and clinical applicability. In this study, we propose \\textbf{Auto-US}, an intelligent diagnosis agent that integrates ultrasound video data with clinical diagnostic text. To support this, we constructed \\textbf{CUV Dataset} of 495 ultrasound videos spanning five categories and three organs, aggregated from multiple open-access sources. We developed \\textbf{CTU-Net}, which achieves state-of-the-art performance in ultrasound video classification, reaching an accuracy of 86.73\\% Furthermore, by incorporating large language models, Auto-US is capable of generating clinically meaningful diagnostic suggestions. The final diagnostic scores for each case exceeded 3 out of 5 and were validated by professional clinicians. These results demonstrate the effectiveness and clinical potential of Auto-US in real-world ultrasound applications. Code and data are available at: https://github.com/Bean-Young/Auto-US.",
    "authors": [
      "Yuezhe Yang",
      "Yiyue Guo",
      "Wenjie Cai",
      "Qingqing Ruan",
      "Siying Wang",
      "Xingbo Dong",
      "Zhe Jin",
      "Yong Dai"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07748v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07748v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07743v1",
    "title": "UltraGS: Gaussian Splatting for Ultrasound Novel View Synthesis",
    "summary": "Ultrasound imaging is a cornerstone of non-invasive clinical diagnostics, yet its limited field of view complicates novel view synthesis. We propose \\textbf{UltraGS}, a Gaussian Splatting framework optimized for ultrasound imaging. First, we introduce a depth-aware Gaussian splatting strategy, where each Gaussian is assigned a learnable field of view, enabling accurate depth prediction and precise structural representation. Second, we design SH-DARS, a lightweight rendering function combining low-order spherical harmonics with ultrasound-specific wave physics, including depth attenuation, reflection, and scattering, to model tissue intensity accurately. Third, we contribute the Clinical Ultrasound Examination Dataset, a benchmark capturing diverse anatomical scans under real-world clinical protocols. Extensive experiments on three datasets demonstrate UltraGS's superiority, achieving state-of-the-art results in PSNR (up to 29.55), SSIM (up to 0.89), and MSE (as low as 0.002) while enabling real-time synthesis at 64.69 fps. The code and dataset are open-sourced at: https://github.com/Bean-Young/UltraGS.",
    "authors": [
      "Yuezhe Yang",
      "Wenjie Cai",
      "Dexin Yang",
      "Yufang Dong",
      "Xingbo Dong",
      "Zhe Jin"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07743v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07743v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.08090v1",
    "title": "StableMorph: High-Quality Face Morph Generation with Stable Diffusion",
    "summary": "Face morphing attacks threaten the integrity of biometric identity systems by enabling multiple individuals to share a single identity. To develop and evaluate effective morphing attack detection (MAD) systems, we need access to high-quality, realistic morphed images that reflect the challenges posed in real-world scenarios. However, existing morph generation methods often produce images that are blurry, riddled with artifacts, or poorly constructed making them easy to detect and not representative of the most dangerous attacks. In this work, we introduce StableMorph, a novel approach that generates highly realistic, artifact-free morphed face images using modern diffusion-based image synthesis. Unlike prior methods, StableMorph produces full-head images with sharp details, avoids common visual flaws, and offers unmatched control over visual attributes. Through extensive evaluation, we show that StableMorph images not only rival or exceed the quality of genuine face images but also maintain a strong ability to fool face recognition systems posing a greater challenge to existing MAD solutions and setting a new standard for morph quality in research and operational testing. StableMorph improves the evaluation of biometric security by creating more realistic and effective attacks and supports the development of more robust detection systems.",
    "authors": [
      "Wassim Kabbani",
      "Kiran Raja",
      "Raghavendra Ramachandra",
      "Christoph Busch"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08090v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08090v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.06817v2",
    "title": "TiS-TSL: Image-Label Supervised Surgical Video Stereo Matching via Time-Switchable Teacher-Student Learning",
    "summary": "Stereo matching in minimally invasive surgery (MIS) is essential for next-generation navigation and augmented reality. Yet, dense disparity supervision is nearly impossible due to anatomical constraints, typically limiting annotations to only a few image-level labels acquired before the endoscope enters deep body cavities. Teacher-Student Learning (TSL) offers a promising solution by leveraging a teacher trained on sparse labels to generate pseudo labels and associated confidence maps from abundant unlabeled surgical videos. However, existing TSL methods are confined to image-level supervision, providing only spatial confidence and lacking temporal consistency estimation. This absence of spatio-temporal reliability results in unstable disparity predictions and severe flickering artifacts across video frames. To overcome these challenges, we propose TiS-TSL, a novel time-switchable teacher-student learning framework for video stereo matching under minimal supervision. At its core is a unified model that operates in three distinct modes: Image-Prediction (IP), Forward Video-Prediction (FVP), and Backward Video-Prediction (BVP), enabling flexible temporal modeling within a single architecture. Enabled by this unified model, TiS-TSL adopts a two-stage learning strategy. The Image-to-Video (I2V) stage transfers sparse image-level knowledge to initialize temporal modeling. The subsequent Video-to-Video (V2V) stage refines temporal disparity predictions by comparing forward and backward predictions to calculate bidirectional spatio-temporal consistency. This consistency identifies unreliable regions across frames, filters noisy video-level pseudo labels, and enforces temporal coherence. Experimental results on two public datasets demonstrate that TiS-TSL exceeds other image-based state-of-the-arts by improving TEPE and EPE by at least 2.11% and 4.54%, respectively.",
    "authors": [
      "Rui Wang",
      "Ying Zhou",
      "Hao Wang",
      "Wenwei Zhang",
      "Qiang Li",
      "Zhiwei Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06817v2",
    "pdf_url": "https://arxiv.org/pdf/2511.06817v2.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.06678v1",
    "title": "Flexible Concept Bottleneck Model",
    "summary": "Concept bottleneck models (CBMs) improve neural network interpretability by introducing an intermediate layer that maps human-understandable concepts to predictions. Recent work has explored the use of vision-language models (VLMs) to automate concept selection and annotation. However, existing VLM-based CBMs typically require full model retraining when new concepts are involved, which limits their adaptability and flexibility in real-world scenarios, especially considering the rapid evolution of vision-language foundation models. To address these issues, we propose Flexible Concept Bottleneck Model (FCBM), which supports dynamic concept adaptation, including complete replacement of the original concept set. Specifically, we design a hypernetwork that generates prediction weights based on concept embeddings, allowing seamless integration of new concepts without retraining the entire model. In addition, we introduce a modified sparsemax module with a learnable temperature parameter that dynamically selects the most relevant concepts, enabling the model to focus on the most informative features. Extensive experiments on five public benchmarks demonstrate that our method achieves accuracy comparable to state-of-the-art baselines with a similar number of effective concepts. Moreover, the model generalizes well to unseen concepts with just a single epoch of fine-tuning, demonstrating its strong adaptability and flexibility.",
    "authors": [
      "Xingbo Du",
      "Qiantong Dou",
      "Lei Fan",
      "Rui Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06678v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06678v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07813v1",
    "title": "Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views",
    "summary": "Recently, large language models (LLMs) have been explored widely for 3D scene understanding. Among them, training-free approaches are gaining attention for their flexibility and generalization over training-based methods. However, they typically struggle with accuracy and efficiency in practical deployment. To address the problems, we propose Sparse3DPR, a novel training-free framework for open-ended scene understanding, which leverages the reasoning capabilities of pre-trained LLMs and requires only sparse-view RGB inputs. Specifically, we introduce a hierarchical plane-enhanced scene graph that supports open vocabulary and adopts dominant planar structures as spatial anchors, which enables clearer reasoning chains and more reliable high-level inferences. Furthermore, we design a task-adaptive subgraph extraction method to filter query-irrelevant information dynamically, reducing contextual noise and improving 3D scene reasoning efficiency and accuracy. Experimental results demonstrate the superiority of Sparse3DPR, which achieves a 28.7% EM@1 improvement and a 78.2% speedup compared with ConceptGraphs on the Space3D-Bench. Moreover, Sparse3DPR obtains comparable performance to training-based methods on ScanQA, with additional real-world experiments confirming its robustness and generalization capability.",
    "authors": [
      "Haida Feng",
      "Hao Wei",
      "Zewen Xu",
      "Haolin Wang",
      "Chade Li",
      "Yihong Wu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07813v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07813v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.08143v1",
    "title": "Relation as a Prior: A Novel Paradigm for LLM-based Document-level Relation Extraction",
    "summary": "Large Language Models (LLMs) have demonstrated their remarkable capabilities in document understanding. However, recent research reveals that LLMs still exhibit performance gaps in Document-level Relation Extraction (DocRE) as requiring fine-grained comprehension. The commonly adopted \"extract entities then predict relations\" paradigm in LLM-based methods leads to these gaps due to two main reasons: (1) Numerous unrelated entity pairs introduce noise and interfere with the relation prediction for truly related entity pairs. (2) Although LLMs have identified semantic associations between entities, relation labels beyond the predefined set are still treated as prediction errors. To address these challenges, we propose a novel Relation as a Prior (RelPrior) paradigm for LLM-based DocRE. For challenge (1), RelPrior utilizes binary relation as a prior to extract and determine whether two entities are correlated, thereby filtering out irrelevant entity pairs and reducing prediction noise. For challenge (2), RelPrior utilizes predefined relation as a prior to match entities for triples extraction instead of directly predicting relation. Thus, it avoids misjudgment caused by strict predefined relation labeling. Extensive experiments on two benchmarks demonstrate that RelPrior achieves state-of-the-art performance, surpassing existing LLM-based methods.",
    "authors": [
      "Qiankun Pi",
      "Yepeng Sun",
      "Jicang Lu",
      "Qinlong Fan",
      "Ningbo Huang",
      "Shiyu Wang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08143v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08143v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07156v1",
    "title": "Conditional Diffusion as Latent Constraints for Controllable Symbolic Music Generation",
    "summary": "Recent advances in latent diffusion models have demonstrated state-of-the-art performance in high-dimensional time-series data synthesis while providing flexible control through conditioning and guidance. However, existing methodologies primarily rely on musical context or natural language as the main modality of interacting with the generative process, which may not be ideal for expert users who seek precise fader-like control over specific musical attributes. In this work, we explore the application of denoising diffusion processes as plug-and-play latent constraints for unconditional symbolic music generation models. We focus on a framework that leverages a library of small conditional diffusion models operating as implicit probabilistic priors on the latents of a frozen unconditional backbone. While previous studies have explored domain-specific use cases, this work, to the best of our knowledge, is the first to demonstrate the versatility of such an approach across a diverse array of musical attributes, such as note density, pitch range, contour, and rhythm complexity. Our experiments show that diffusion-driven constraints outperform traditional attribute regularization and other latent constraints architectures, achieving significantly stronger correlations between target and generated attributes while maintaining high perceptual quality and diversity.",
    "authors": [
      "Matteo Pettenó",
      "Alessandro Ilic Mezza",
      "Alberto Bernardini"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.AS"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07156v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07156v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07486v1",
    "title": "Provably Efficient Sample Complexity for Robust CMDP",
    "summary": "We study the problem of learning policies that maximize cumulative reward while satisfying safety constraints, even when the real environment differs from a simulator or nominal model. We focus on robust constrained Markov decision processes (RCMDPs), where the agent must maximize reward while ensuring cumulative utility exceeds a threshold under the worst-case dynamics within an uncertainty set. While recent works have established finite-time iteration complexity guarantees for RCMDPs using policy optimization, their sample complexity guarantees remain largely unexplored. In this paper, we first show that Markovian policies may fail to be optimal even under rectangular uncertainty sets unlike the {\\em unconstrained} robust MDP. To address this, we introduce an augmented state space that incorporates the remaining utility budget into the state representation. Building on this formulation, we propose a novel Robust constrained Value iteration (RCVI) algorithm with a sample complexity of $\\mathcal{\\tilde{O}}(|S||A|H^5/ε^2)$ achieving at most $ε$ violation using a generative model where $|S|$ and $|A|$ denote the sizes of the state and action spaces, respectively, and $H$ is the episode length. To the best of our knowledge, this is the {\\em first sample complexity guarantee} for RCMDP. Empirical results further validate the effectiveness of our approach.",
    "authors": [
      "Sourav Ganguly",
      "Arnob Ghosh"
    ],
    "categories": [
      "cs.LG",
      "eess.SY",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07486v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07486v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07738v1",
    "title": "From Exploration to Exploitation: A Two-Stage Entropy RLVR Approach for Noise-Tolerant MLLM Training",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) for Multimodal Large Language Models (MLLMs) is highly dependent on high-quality labeled data, which is often scarce and prone to substantial annotation noise in real-world scenarios. Existing unsupervised RLVR methods, including pure entropy minimization, can overfit to incorrect labels and limit the crucial reward ranking signal for Group-Relative Policy Optimization (GRPO). To address these challenges and enhance noise tolerance, we propose a novel two-stage, token-level entropy optimization method for RLVR. This approach dynamically guides the model from exploration to exploitation during training. In the initial exploration phase, token-level entropy maximization promotes diverse and stochastic output generation, serving as a strong regularizer that prevents premature convergence to noisy labels and ensures sufficient intra-group variation, which enables more reliable reward gradient estimation in GRPO. As training progresses, the method transitions into the exploitation phase, where token-level entropy minimization encourages the model to produce confident and deterministic outputs, thereby consolidating acquired knowledge and refining prediction accuracy. Empirically, across three MLLM backbones - Qwen2-VL-2B, Qwen2-VL-7B, and Qwen2.5-VL-3B - spanning diverse noise settings and multiple tasks, our phased strategy consistently outperforms prior approaches by unifying and enhancing external, internal, and entropy-based methods, delivering robust and superior performance across the board.",
    "authors": [
      "Donglai Xu",
      "Hongzheng Yang",
      "Yuzhi Zhao",
      "Pingping Zhang",
      "Jinpeng Chen",
      "Wenao Ma",
      "Zhijian Hou",
      "Mengyang Wu",
      "Xiaolei Li",
      "Senkang Hu",
      "Ziyi Guan",
      "Jason Chun Lok Li",
      "Lai Man Po"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07738v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07738v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07103v1",
    "title": "GEWDiff: Geometric Enhanced Wavelet-based Diffusion Model for Hyperspectral Image Super-resolution",
    "summary": "Improving the quality of hyperspectral images (HSIs), such as through super-resolution, is a crucial research area. However, generative modeling for HSIs presents several challenges. Due to their high spectral dimensionality, HSIs are too memory-intensive for direct input into conventional diffusion models. Furthermore, general generative models lack an understanding of the topological and geometric structures of ground objects in remote sensing imagery. In addition, most diffusion models optimize loss functions at the noise level, leading to a non-intuitive convergence behavior and suboptimal generation quality for complex data. To address these challenges, we propose a Geometric Enhanced Wavelet-based Diffusion Model (GEWDiff), a novel framework for reconstructing hyperspectral images at 4-times super-resolution. A wavelet-based encoder-decoder is introduced that efficiently compresses HSIs into a latent space while preserving spectral-spatial information. To avoid distortion during generation, we incorporate a geometry-enhanced diffusion process that preserves the geometric features. Furthermore, a multi-level loss function was designed to guide the diffusion process, promoting stable convergence and improved reconstruction fidelity. Our model demonstrated state-of-the-art results across multiple dimensions, including fidelity, spectral accuracy, visual realism, and clarity.",
    "authors": [
      "Sirui Wang",
      "Jiang He",
      "Natàlia Blasco Andreo",
      "Xiao Xiang Zhu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07103v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07103v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.08071v1",
    "title": "Radar-APLANC: Unsupervised Radar-based Heartbeat Sensing via Augmented Pseudo-Label and Noise Contrast",
    "summary": "Frequency Modulated Continuous Wave (FMCW) radars can measure subtle chest wall oscillations to enable non-contact heartbeat sensing. However, traditional radar-based heartbeat sensing methods face performance degradation due to noise. Learning-based radar methods achieve better noise robustness but require costly labeled signals for supervised training. To overcome these limitations, we propose the first unsupervised framework for radar-based heartbeat sensing via Augmented Pseudo-Label and Noise Contrast (Radar-APLANC). We propose to use both the heartbeat range and noise range within the radar range matrix to construct the positive and negative samples, respectively, for improved noise robustness. Our Noise-Contrastive Triplet (NCT) loss only utilizes positive samples, negative samples, and pseudo-label signals generated by the traditional radar method, thereby avoiding dependence on expensive ground-truth physiological signals. We further design a pseudo-label augmentation approach featuring adaptive noise-aware label selection to improve pseudo-label signal quality. Extensive experiments on the Equipleth dataset and our collected radar dataset demonstrate that our unsupervised method achieves performance comparable to state-of-the-art supervised methods. Our code, dataset, and supplementary materials can be accessed from https://github.com/RadarHRSensing/Radar-APLANC.",
    "authors": [
      "Ying Wang",
      "Zhaodong Sun",
      "Xu Cheng",
      "Zuxian He",
      "Xiaobai Li"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "eess.SP"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08071v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08071v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07318v1",
    "title": "When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs",
    "summary": "Despite substantial advances, large language models (LLMs) continue to exhibit hallucinations, generating plausible yet incorrect responses. In this paper, we highlight a critical yet previously underexplored class of hallucinations driven by spurious correlations -- superficial but statistically prominent associations between features (e.g., surnames) and attributes (e.g., nationality) present in the training data. We demonstrate that these spurious correlations induce hallucinations that are confidently generated, immune to model scaling, evade current detection methods, and persist even after refusal fine-tuning. Through systematically controlled synthetic experiments and empirical evaluations on state-of-the-art open-source and proprietary LLMs (including GPT-5), we show that existing hallucination detection methods, such as confidence-based filtering and inner-state probing, fundamentally fail in the presence of spurious correlations. Our theoretical analysis further elucidates why these statistical biases intrinsically undermine confidence-based detection techniques. Our findings thus emphasize the urgent need for new approaches explicitly designed to address hallucinations caused by spurious correlations.",
    "authors": [
      "Shaowen Wang",
      "Yiqi Dong",
      "Ruinian Chang",
      "Tansheng Zhu",
      "Yuebo Sun",
      "Kaifeng Lyu",
      "Jian Li"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07318v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07318v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.07362v1",
    "title": "Inference-Time Scaling of Diffusion Models for Infrared Data Generation",
    "summary": "Infrared imagery enables temperature-based scene understanding using passive sensors, particularly under conditions of low visibility where traditional RGB imaging fails. Yet, developing downstream vision models for infrared applications is hindered by the scarcity of high-quality annotated data, due to the specialized expertise required for infrared annotation. While synthetic infrared image generation has the potential to accelerate model development by providing large-scale, diverse training data, training foundation-level generative diffusion models in the infrared domain has remained elusive due to limited datasets. In light of such data constraints, we explore an inference-time scaling approach using a domain-adapted CLIP-based verifier for enhanced infrared image generation quality. We adapt FLUX.1-dev, a state-of-the-art text-to-image diffusion model, to the infrared domain by finetuning it on a small sample of infrared images using parameter-efficient techniques. The trained verifier is then employed during inference to guide the diffusion sampling process toward higher quality infrared generations that better align with input text prompts. Empirically, we find that our approach leads to consistent improvements in generation quality, reducing FID scores on the KAIST Multispectral Pedestrian Detection Benchmark dataset by 10% compared to unguided baseline samples. Our results suggest that inference-time guidance offers a promising direction for bridging the domain gap in low-data infrared settings.",
    "authors": [
      "Kai A. Horstmann",
      "Maxim Clouser",
      "Kia Khezeli"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07362v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07362v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.07885v1",
    "title": "Intelligence per Watt: Measuring Intelligence Efficiency of Local AI",
    "summary": "Large language model (LLM) queries are predominantly processed by frontier models in centralized cloud infrastructure. Rapidly growing demand strains this paradigm, and cloud providers struggle to scale infrastructure at pace. Two advances enable us to rethink this paradigm: small LMs (<=20B active parameters) now achieve competitive performance to frontier models on many tasks, and local accelerators (e.g., Apple M4 Max) run these models at interactive latencies. This raises the question: can local inference viably redistribute demand from centralized infrastructure? Answering this requires measuring whether local LMs can accurately answer real-world queries and whether they can do so efficiently enough to be practical on power-constrained devices (i.e., laptops). We propose intelligence per watt (IPW), task accuracy divided by unit of power, as a metric for assessing capability and efficiency of local inference across model-accelerator pairs. We conduct a large-scale empirical study across 20+ state-of-the-art local LMs, 8 accelerators, and a representative subset of LLM traffic: 1M real-world single-turn chat and reasoning queries. For each query, we measure accuracy, energy, latency, and power. Our analysis reveals $3$ findings. First, local LMs can accurately answer 88.7% of single-turn chat and reasoning queries with accuracy varying by domain. Second, from 2023-2025, IPW improved 5.3x and local query coverage rose from 23.2% to 71.3%. Third, local accelerators achieve at least 1.4x lower IPW than cloud accelerators running identical models, revealing significant headroom for optimization. These findings demonstrate that local inference can meaningfully redistribute demand from centralized infrastructure, with IPW serving as the critical metric for tracking this transition. We release our IPW profiling harness for systematic intelligence-per-watt benchmarking.",
    "authors": [
      "Jon Saad-Falcon",
      "Avanika Narayan",
      "Hakki Orhun Akengin",
      "J. Wes Griffin",
      "Herumb Shandilya",
      "Adrian Gamarra Lafuente",
      "Medhya Goel",
      "Rebecca Joseph",
      "Shlok Natarajan",
      "Etash Kumar Guha",
      "Shang Zhu",
      "Ben Athiwaratkun",
      "John Hennessy",
      "Azalia Mirhoseini",
      "Christopher Ré"
    ],
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07885v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07885v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.08500v1",
    "title": "SPEAR-MM: Selective Parameter Evaluation and Restoration via Model Merging for Efficient Financial LLM Adaptation",
    "summary": "Large language models (LLMs) adapted to financial domains often suffer from catastrophic forgetting of general reasoning capabilities essential for customer interactions and complex financial analysis. We introduce Selective Parameter Evaluation and Restoration via Model Merging (SPEAR-MM), a practical framework that preserves critical capabilities while enabling domain adaptation. Our method approximates layer-wise impact on external benchmarks through post-hoc analysis, then selectively freezes or restores transformer layers via spherical interpolation merging. Applied to LLaMA-3.1-8B for financial tasks, SPEAR-MM achieves 91.2% retention of general capabilities versus 69.7% for standard continual pretraining, while maintaining 94% of domain adaptation gains. The approach provides interpretable trade-off control and reduces computational costs by 90% crucial for resource-constrained financial institutions.",
    "authors": [
      "Berkcan Kapusuzoglu",
      "Supriyo Chakraborty",
      "Renkun Ni",
      "Stephen Rawls",
      "Sambit Sahu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "math.SP"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08500v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08500v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.08319v1",
    "title": "Adaptive Multi-Agent Response Refinement in Conversational Systems",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable success in conversational systems by generating human-like responses. However, they can fall short, especially when required to account for personalization or specific knowledge. In real-life settings, it is impractical to rely on users to detect these errors and request a new response. One way to address this problem is to refine the response before returning it to the user. While existing approaches focus on refining responses within a single LLM, this method struggles to consider diverse aspects needed for effective conversations. In this work, we propose refining responses through a multi-agent framework, where each agent is assigned a specific role for each aspect. We focus on three key aspects crucial to conversational quality: factuality, personalization, and coherence. Each agent is responsible for reviewing and refining one of these aspects, and their feedback is then merged to improve the overall response. To enhance collaboration among them, we introduce a dynamic communication strategy. Instead of following a fixed sequence of agents, our approach adaptively selects and coordinates the most relevant agents based on the specific requirements of each query. We validate our framework on challenging conversational datasets, demonstrating that ours significantly outperforms relevant baselines, particularly in tasks involving knowledge or user's persona, or both.",
    "authors": [
      "Soyeong Jeong",
      "Aparna Elangovan",
      "Emine Yilmaz",
      "Oleg Rokhlenko"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08319v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08319v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.07504v1",
    "title": "Tractable Instances of Bilinear Maximization: Implementing LinUCB on Ellipsoids",
    "summary": "We consider the maximization of $x^\\top θ$ over $(x,θ) \\in \\mathcal{X} \\times Θ$, with $\\mathcal{X} \\subset \\mathbb{R}^d$ convex and $Θ\\subset \\mathbb{R}^d$ an ellipsoid. This problem is fundamental in linear bandits, as the learner must solve it at every time step using optimistic algorithms. We first show that for some sets $\\mathcal{X}$ e.g. $\\ell_p$ balls with $p>2$, no efficient algorithms exist unless $\\mathcal{P} = \\mathcal{NP}$. We then provide two novel algorithms solving this problem efficiently when $\\mathcal{X}$ is a centered ellipsoid. Our findings provide the first known method to implement optimistic algorithms for linear bandits in high dimensions.",
    "authors": [
      "Raymond Zhang",
      "Hédi Hadiji",
      "Richard Combes"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07504v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07504v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06854v1",
    "title": "Beyond Observations: Reconstruction Error-Guided Irregularly Sampled Time Series Representation Learning",
    "summary": "Irregularly sampled time series (ISTS), characterized by non-uniform time intervals with natural missingness, are prevalent in real-world applications. Existing approaches for ISTS modeling primarily rely on observed values to impute unobserved ones or infer latent dynamics. However, these methods overlook a critical source of learning signal: the reconstruction error inherently produced during model training. Such error implicitly reflects how well a model captures the underlying data structure and can serve as an informative proxy for unobserved values. To exploit this insight, we propose iTimER, a simple yet effective self-supervised pre-training framework for ISTS representation learning. iTimER models the distribution of reconstruction errors over observed values and generates pseudo-observations for unobserved timestamps through a mixup strategy between sampled errors and the last available observations. This transforms unobserved timestamps into noise-aware training targets, enabling meaningful reconstruction signals. A Wasserstein metric aligns reconstruction error distributions between observed and pseudo-observed regions, while a contrastive learning objective enhances the discriminability of learned representations. Extensive experiments on classification, interpolation, and forecasting tasks demonstrate that iTimER consistently outperforms state-of-the-art methods under the ISTS setting.",
    "authors": [
      "Jiexi Liu",
      "Meng Cao",
      "Songcan Chen"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06854v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06854v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.07857v1",
    "title": "A General Method for Proving Networks Universal Approximation Property",
    "summary": "Deep learning architectures are highly diverse. To prove their universal approximation properties, existing works typically rely on model-specific proofs. Generally, they construct a dedicated mathematical formulation for each architecture (e.g., fully connected networks, CNNs, or Transformers) and then prove their universal approximability. However, this approach suffers from two major limitations: first, every newly proposed architecture often requires a completely new proof from scratch; second, these proofs are largely isolated from one another, lacking a common analytical foundation. This not only incurs significant redundancy but also hinders unified theoretical understanding across different network families. To address these issues, this paper proposes a general and modular framework for proving universal approximation. We define a basic building block (comprising one or multiple layers) that possesses the universal approximation property as a Universal Approximation Module (UAM). Under this condition, we show that any deep network composed of such modules inherently retains the universal approximation property. Moreover, the overall approximation process can be interpreted as a progressive refinement across modules. This perspective not only unifies the analysis of diverse architectures but also enables a step-by-step understanding of how expressive power evolves through the network.",
    "authors": [
      "Wei Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07857v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07857v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.08465v1",
    "title": "Generalizable Blood Cell Detection via Unified Dataset and Faster R-CNN",
    "summary": "This paper presents a comprehensive methodology and comparative performance analysis for the automated classification and object detection of peripheral blood cells (PBCs) in microscopic images. Addressing the critical challenge of data scarcity and heterogeneity, robust data pipeline was first developed to standardize and merge four public datasets (PBC, BCCD, Chula, Sickle Cell) into a unified resource. Then employed a state-of-the-art Faster R-CNN object detection framework, leveraging a ResNet-50-FPN backbone. Comparative training rigorously evaluated a randomly initialized baseline model (Regimen 1) against a Transfer Learning Regimen (Regimen 2), initialized with weights pre-trained on the Microsoft COCO dataset. The results demonstrate that the Transfer Learning approach achieved significantly faster convergence and superior stability, culminating in a final validation loss of 0.08666, a substantial improvement over the baseline. This validated methodology establishes a robust foundation for building high-accuracy, deployable systems for automated hematological diagnosis.",
    "authors": [
      "Siddharth Sahay"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08465v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08465v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06715v1",
    "title": "Sensor Calibration Model Balancing Accuracy, Real-time, and Efficiency",
    "summary": "Most on-device sensor calibration studies benchmark models only against three macroscopic requirements (i.e., accuracy, real-time, and resource efficiency), thereby hiding deployment bottlenecks such as instantaneous error and worst-case latency. We therefore decompose this triad into eight microscopic requirements and introduce Scare (Sensor Calibration model balancing Accuracy, Real-time, and Efficiency), an ultra-compressed transformer that fulfills them all. SCARE comprises three core components: (1) Sequence Lens Projector (SLP) that logarithmically compresses time-series data while preserving boundary information across bins, (2) Efficient Bitwise Attention (EBA) module that replaces costly multiplications with bitwise operations via binary hash codes, and (3) Hash optimization strategy that ensures stable training without auxiliary loss terms. Together, these components minimize computational overhead while maintaining high accuracy and compatibility with microcontroller units (MCUs). Extensive experiments on large-scale air-quality datasets and real microcontroller deployments demonstrate that Scare outperforms existing linear, hybrid, and deep-learning baselines, making Scare, to the best of our knowledge, the first model to meet all eight microscopic requirements simultaneously.",
    "authors": [
      "Jinyong Yun",
      "Hyungjin Kim",
      "Seokho Ahn",
      "Euijong Lee",
      "Young-Duk Seo"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06715v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06715v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.07092v1",
    "title": "Sample-efficient quantum error mitigation via classical learning surrogates",
    "summary": "The pursuit of practical quantum utility on near-term quantum processors is critically challenged by their inherent noise. Quantum error mitigation (QEM) techniques are leading solutions to improve computation fidelity with relatively low qubit-overhead, while full-scale quantum error correction remains a distant goal. However, QEM techniques incur substantial measurement overheads, especially when applied to families of quantum circuits parameterized by classical inputs. Focusing on zero-noise extrapolation (ZNE), a widely adopted QEM technique, here we devise the surrogate-enabled ZNE (S-ZNE), which leverages classical learning surrogates to perform ZNE entirely on the classical side. Unlike conventional ZNE, whose measurement cost scales linearly with the number of circuits, S-ZNE requires only constant measurement overhead for an entire family of quantum circuits, offering superior scalability. Theoretical analysis indicates that S-ZNE achieves accuracy comparable to conventional ZNE in many practical scenarios, and numerical experiments on up to 100-qubit ground-state energy and quantum metrology tasks confirm its effectiveness. Our approach provides a template that can be effectively extended to other quantum error mitigation protocols, opening a promising path toward scalable error mitigation.",
    "authors": [
      "Wei-You Liao",
      "Ge Yan",
      "Yujin Song",
      "Tian-Ci Tian",
      "Wei-Ming Zhu",
      "De-Tao Jiang",
      "Yuxuan Du",
      "He-Liang Huang"
    ],
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07092v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07092v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06634v1",
    "title": "CaberNet: Causal Representation Learning for Cross-Domain HVAC Energy Prediction",
    "summary": "Cross-domain HVAC energy prediction is essential for scalable building energy management, particularly because collecting extensive labeled data for every new building is both costly and impractical. Yet, this task remains highly challenging due to the scarcity and heterogeneity of data across different buildings, climate zones, and seasonal patterns. In particular, buildings situated in distinct climatic regions introduce variability that often leads existing methods to overfit to spurious correlations, rely heavily on expert intervention, or compromise on data diversity. To address these limitations, we propose CaberNet, a causal and interpretable deep sequence model that learns invariant (Markov blanket) representations for robust cross-domain prediction. In a purely data-driven fashion and without requiring any prior knowledge, CaberNet integrates i) a global feature gate trained with a self-supervised Bernoulli regularization to distinguish superior causal features from inferior ones, and ii) a domain-wise training scheme that balances domain contributions, minimizes cross-domain loss variance, and promotes latent factor independence. We evaluate CaberNet on real-world datasets collected from three buildings located in three climatically diverse cities, and it consistently outperforms all baselines, achieving a 22.9\\% reduction in normalized mean squared error (NMSE) compared to the best benchmark. Our code is available at https://github.com/rickzky1001/CaberNet-CRL.",
    "authors": [
      "Kaiyuan Zhai",
      "Jiacheng Cui",
      "Zhehao Zhang",
      "Junyu Xue",
      "Yang Deng",
      "Kui Wu",
      "Guoming Tang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06634v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06634v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.06946v1",
    "title": "Learning to Focus: Prioritizing Informative Histories with Structured Attention Mechanisms in Partially Observable Reinforcement Learning",
    "summary": "Transformers have shown strong ability to model long-term dependencies and are increasingly adopted as world models in model-based reinforcement learning (RL) under partial observability. However, unlike natural language corpora, RL trajectories are sparse and reward-driven, making standard self-attention inefficient because it distributes weight uniformly across all past tokens rather than emphasizing the few transitions critical for control. To address this, we introduce structured inductive priors into the self-attention mechanism of the dynamics head: (i) per-head memory-length priors that constrain attention to task-specific windows, and (ii) distributional priors that learn smooth Gaussian weightings over past state-action pairs. We integrate these mechanisms into UniZero, a model-based RL agent with a Transformer-based world model that supports planning under partial observability. Experiments on the Atari 100k benchmark show that most efficiency gains arise from the Gaussian prior, which smoothly allocates attention to informative transitions, while memory-length priors often truncate useful signals with overly restrictive cut-offs. In particular, Gaussian Attention achieves a 77% relative improvement in mean human-normalized scores over UniZero. These findings suggest that in partially observable RL domains with non-stationary temporal dependencies, discrete memory windows are difficult to learn reliably, whereas smooth distributional priors flexibly adapt across horizons and yield more robust data efficiency. Overall, our results demonstrate that encoding structured temporal priors directly into self-attention improves the prioritization of informative histories for dynamics modeling under partial observability.",
    "authors": [
      "Daniel De Dios Allegue",
      "Jinke He",
      "Frans A. Oliehoek"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06946v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06946v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.07943v1",
    "title": "Thinker: Training LLMs in Hierarchical Thinking for Deep Search via Multi-Turn Interaction",
    "summary": "Efficient retrieval of external knowledge bases and web pages is crucial for enhancing the reasoning abilities of LLMs. Previous works on training LLMs to leverage external retrievers for solving complex problems have predominantly employed end-to-end reinforcement learning. However, these approaches neglect supervision over the reasoning process, making it difficult to guarantee logical coherence and rigor. To address these limitations, we propose Thinker, a hierarchical thinking model for deep search through multi-turn interaction, making the reasoning process supervisable and verifiable. It decomposes complex problems into independently solvable sub-problems, each dually represented in both natural language and an equivalent logical function to support knowledge base and web searches. Concurrently, dependencies between sub-problems are passed as parameters via these logical functions, enhancing the logical coherence of the problem-solving process. To avoid unnecessary external searches, we perform knowledge boundary determination to check if a sub-problem is within the LLM's intrinsic knowledge, allowing it to answer directly. Experimental results indicate that with as few as several hundred training samples, the performance of Thinker is competitive with established baselines. Furthermore, when scaled to the full training set, Thinker significantly outperforms these methods across various datasets and model sizes. The source code is available at https://github.com/OpenSPG/KAG-Thinker.",
    "authors": [
      "Jun Xu",
      "Xinkai Du",
      "Yu Ao",
      "Peilong Zhao",
      "Yang Li",
      "Ling Zhong",
      "Lin Yuan",
      "Zhongpu Bo",
      "Xiaorui Wang",
      "Mengshu Sun",
      "Zhengke Gui",
      "Dalong Zhang",
      "Zhaoyang Wang",
      "Qiwei Wang",
      "Yangyang Hou",
      "Zhiying Yin",
      "Haofen Wang",
      "Huajun Chen",
      "Lei Liang",
      "Jun Zhou"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07943v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07943v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.08215v1",
    "title": "Evaluating Gemini LLM in Food Image-Based Recipe and Nutrition Description with EfficientNet-B4 Visual Backbone",
    "summary": "The proliferation of digital food applications necessitates robust methods for automated nutritional analysis and culinary guidance. This paper presents a comprehensive comparative evaluation of a decoupled, multimodal pipeline for food recognition. We evaluate a system integrating a specialized visual backbone (EfficientNet-B4) with a powerful generative large language model (Google's Gemini LLM). The core objective is to evaluate the trade-offs between visual classification accuracy, model efficiency, and the quality of generative output (nutritional data and recipes). We benchmark this pipeline against alternative vision backbones (VGG-16, ResNet-50, YOLOv8) and a lightweight LLM (Gemma). We introduce a formalization for \"Semantic Error Propagation\" (SEP) to analyze how classification inaccuracies from the visual module cascade into the generative output. Our analysis is grounded in a new Custom Chinese Food Dataset (CCFD) developed to address cultural bias in public datasets. Experimental results demonstrate that while EfficientNet-B4 (89.0\\% Top-1 Acc.) provides the best balance of accuracy and efficiency, and Gemini (9.2/10 Factual Accuracy) provides superior generative quality, the system's overall utility is fundamentally bottlenecked by the visual front-end's perceptive accuracy. We conduct a detailed per-class analysis, identifying high semantic similarity as the most critical failure mode.",
    "authors": [
      "Rizal Khoirul Anam"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08215v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08215v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.07099v1",
    "title": "E2E-VGuard: Adversarial Prevention for Production LLM-based End-To-End Speech Synthesis",
    "summary": "Recent advancements in speech synthesis technology have enriched our daily lives, with high-quality and human-like audio widely adopted across real-world applications. However, malicious exploitation like voice-cloning fraud poses severe security risks. Existing defense techniques struggle to address the production large language model (LLM)-based speech synthesis. While previous studies have considered the protection for fine-tuning synthesizers, they assume manually annotated transcripts. Given the labor intensity of manual annotation, end-to-end (E2E) systems leveraging automatic speech recognition (ASR) to generate transcripts are becoming increasingly prevalent, e.g., voice cloning via commercial APIs. Therefore, this E2E speech synthesis also requires new security mechanisms. To tackle these challenges, we propose E2E-VGuard, a proactive defense framework for two emerging threats: (1) production LLM-based speech synthesis, and (2) the novel attack arising from ASR-driven E2E scenarios. Specifically, we employ the encoder ensemble with a feature extractor to protect timbre, while ASR-targeted adversarial examples disrupt pronunciation. Moreover, we incorporate the psychoacoustic model to ensure perturbative imperceptibility. For a comprehensive evaluation, we test 16 open-source synthesizers and 3 commercial APIs across Chinese and English datasets, confirming E2E-VGuard's effectiveness in timbre and pronunciation protection. Real-world deployment validation is also conducted. Our code and demo page are available at https://wxzyd123.github.io/e2e-vguard/.",
    "authors": [
      "Zhisheng Zhang",
      "Derui Wang",
      "Yifan Mi",
      "Zhiyong Wu",
      "Jie Gao",
      "Yuxin Cao",
      "Kai Ye",
      "Minhui Xue",
      "Jie Hao"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07099v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07099v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.07935v1",
    "title": "DiffRegCD: Integrated Registration and Change Detection with Diffusion Features",
    "summary": "Change detection (CD) is fundamental to computer vision and remote sensing, supporting applications in environmental monitoring, disaster response, and urban development. Most CD models assume co-registered inputs, yet real-world imagery often exhibits parallax, viewpoint shifts, and long temporal gaps that cause severe misalignment. Traditional two stage methods that first register and then detect, as well as recent joint frameworks (e.g., BiFA, ChangeRD), still struggle under large displacements, relying on regression only flow, global homographies, or synthetic perturbations. We present DiffRegCD, an integrated framework that unifies dense registration and change detection in a single model. DiffRegCD reformulates correspondence estimation as a Gaussian smoothed classification task, achieving sub-pixel accuracy and stable training. It leverages frozen multi-scale features from a pretrained denoising diffusion model, ensuring robustness to illumination and viewpoint variation. Supervision is provided through controlled affine perturbations applied to standard CD datasets, yielding paired ground truth for both flow and change detection without pseudo labels. Extensive experiments on aerial (LEVIR-CD, DSIFN-CD, WHU-CD, SYSU-CD) and ground level (VL-CMU-CD) datasets show that DiffRegCD consistently surpasses recent baselines and remains reliable under wide temporal and geometric variation, establishing diffusion features and classification based correspondence as a strong foundation for unified change detection.",
    "authors": [
      "Seyedehnanita Madani",
      "Rama Chellappa",
      "Vishal M. Patel"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07935v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07935v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.07896v1",
    "title": "SparseRM: A Lightweight Preference Modeling with Sparse Autoencoder",
    "summary": "Reward models (RMs) are a core component in the post-training of large language models (LLMs), serving as proxies for human preference evaluation and guiding model alignment. However, training reliable RMs under limited resources remains challenging due to the reliance on large-scale preference annotations and the high cost of fine-tuning LLMs. To address this, we propose SparseRM, which leverages Sparse Autoencoder (SAE) to extract preference-relevant information encoded in model representations, enabling the construction of a lightweight and interpretable reward model. SparseRM first employs SAE to decompose LLM representations into interpretable directions that capture preference-relevant features. The representations are then projected onto these directions to compute alignment scores, which quantify the strength of each preference feature in the representations. A simple reward head aggregates these scores to predict preference scores. Experiments on three preference modeling tasks show that SparseRM achieves superior performance over most mainstream RMs while using less than 1% of trainable parameters. Moreover, it integrates seamlessly into downstream alignment pipelines, highlighting its potential for efficient alignment.",
    "authors": [
      "Dengcan Liu",
      "Jiahao Li",
      "Zheren Fu",
      "Yi Tu",
      "Jiajun Li",
      "Zhendong Mao",
      "Yongdong Zhang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07896v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07896v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.07332v1",
    "title": "Grounding Computer Use Agents on Human Demonstrations",
    "summary": "Building reliable computer-use agents requires grounding: accurately connecting natural language instructions to the correct on-screen elements. While large datasets exist for web and mobile interactions, high-quality resources for desktop environments are limited. To address this gap, we introduce GroundCUA, a large-scale desktop grounding dataset built from expert human demonstrations. It covers 87 applications across 12 categories and includes 56K screenshots, with every on-screen element carefully annotated for a total of over 3.56M human-verified annotations. From these demonstrations, we generate diverse instructions that capture a wide range of real-world tasks, providing high-quality data for model training. Using GroundCUA, we develop the GroundNext family of models that map instructions to their target UI elements. At both 3B and 7B scales, GroundNext achieves state-of-the-art results across five benchmarks using supervised fine-tuning, while requiring less than one-tenth the training data of prior work. Reinforcement learning post-training further improves performance, and when evaluated in an agentic setting on the OSWorld benchmark using o3 as planner, GroundNext attains comparable or superior results to models trained with substantially more data,. These results demonstrate the critical role of high-quality, expert-driven datasets in advancing general-purpose computer-use agents.",
    "authors": [
      "Aarash Feizi",
      "Shravan Nayak",
      "Xiangru Jian",
      "Kevin Qinghong Lin",
      "Kaixin Li",
      "Rabiul Awal",
      "Xing Han Lù",
      "Johan Obando-Ceron",
      "Juan A. Rodriguez",
      "Nicolas Chapados",
      "David Vazquez",
      "Adriana Romero-Soriano",
      "Reihaneh Rabbany",
      "Perouz Taslakian",
      "Christopher Pal",
      "Spandana Gella",
      "Sai Rajeswar"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07332v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07332v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.08544v1",
    "title": "LeJEPA: Provable and Scalable Self-Supervised Learning Without the Heuristics",
    "summary": "Learning manipulable representations of the world and its dynamics is central to AI. Joint-Embedding Predictive Architectures (JEPAs) offer a promising blueprint, but lack of practical guidance and theory has led to ad-hoc R&D. We present a comprehensive theory of JEPAs and instantiate it in {\\bf LeJEPA}, a lean, scalable, and theoretically grounded training objective. First, we identify the isotropic Gaussian as the optimal distribution that JEPAs' embeddings should follow to minimize downstream prediction risk. Second, we introduce a novel objective--{\\bf Sketched Isotropic Gaussian Regularization} (SIGReg)--to constrain embeddings to reach that ideal distribution. Combining the JEPA predictive loss with SIGReg yields LeJEPA with numerous theoretical and practical benefits: (i) single trade-off hyperparameter, (ii) linear time and memory complexity, (iii) stability across hyper-parameters, architectures (ResNets, ViTs, ConvNets) and domains, (iv) heuristics-free, e.g., no stop-gradient, no teacher-student, no hyper-parameter schedulers, and (v) distributed training-friendly implementation requiring only $\\approx$50 lines of code. Our empirical validation covers 10+ datasets, 60+ architectures, all with varying scales and domains. As an example, using imagenet-1k for pretraining and linear evaluation with frozen backbone, LeJEPA reaches 79\\% with a ViT-H/14. We hope that the simplicity and theory-friendly ecosystem offered by LeJEPA will reestablish self-supervised pre-training as a core pillar of AI research (\\href{git@github.com:rbalestr-lab/lejepa.git}{GitHub repo}).",
    "authors": [
      "Randall Balestriero",
      "Yann LeCun"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08544v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08544v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.06645v1",
    "title": "Adaptive Testing for Segmenting Watermarked Texts From Language Models",
    "summary": "The rapid adoption of large language models (LLMs), such as GPT-4 and Claude 3.5, underscores the need to distinguish LLM-generated text from human-written content to mitigate the spread of misinformation and misuse in education. One promising approach to address this issue is the watermark technique, which embeds subtle statistical signals into LLM-generated text to enable reliable identification. In this paper, we first generalize the likelihood-based LLM detection method of a previous study by introducing a flexible weighted formulation, and further adapt this approach to the inverse transform sampling method. Moving beyond watermark detection, we extend this adaptive detection strategy to tackle the more challenging problem of segmenting a given text into watermarked and non-watermarked substrings. In contrast to the approach in a previous study, which relies on accurate estimation of next-token probabilities that are highly sensitive to prompt estimation, our proposed framework removes the need for precise prompt estimation. Extensive numerical experiments demonstrate that the proposed methodology is both effective and robust in accurately segmenting texts containing a mixture of watermarked and non-watermarked content.",
    "authors": [
      "Xingchi Li",
      "Xiaochi Liu",
      "Guanxun Li"
    ],
    "categories": [
      "stat.ML",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06645v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06645v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07364v1",
    "title": "Self-Evaluating LLMs for Multi-Step Tasks: Stepwise Confidence Estimation for Failure Detection",
    "summary": "Reliability and failure detection of large language models (LLMs) is critical for their deployment in high-stakes, multi-step reasoning tasks. Prior work explores confidence estimation for self-evaluating LLM-scorer systems, with confidence scorers estimating the likelihood of errors in LLM responses. However, most methods focus on single-step outputs and overlook the challenges of multi-step reasoning. In this work, we extend self-evaluation techniques to multi-step tasks, testing two intuitive approaches: holistic scoring and step-by-step scoring. Using two multi-step benchmark datasets, we show that stepwise evaluation generally outperforms holistic scoring in detecting potential errors, with up to 15% relative increase in AUC-ROC. Our findings demonstrate that self-evaluating LLM systems provide meaningful confidence estimates in complex reasoning, improving their trustworthiness and providing a practical framework for failure detection.",
    "authors": [
      "Vaibhav Mavi",
      "Shubh Jaroria",
      "Weiqi Sun"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07364v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07364v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07942v1",
    "title": "Balance Equation-based Distributionally Robust Offline Imitation Learning",
    "summary": "Imitation Learning (IL) has proven highly effective for robotic and control tasks where manually designing reward functions or explicit controllers is infeasible. However, standard IL methods implicitly assume that the environment dynamics remain fixed between training and deployment. In practice, this assumption rarely holds where modeling inaccuracies, real-world parameter variations, and adversarial perturbations can all induce shifts in transition dynamics, leading to severe performance degradation. We address this challenge through Balance Equation-based Distributionally Robust Offline Imitation Learning, a framework that learns robust policies solely from expert demonstrations collected under nominal dynamics, without requiring further environment interaction. We formulate the problem as a distributionally robust optimization over an uncertainty set of transition models, seeking a policy that minimizes the imitation loss under the worst-case transition distribution. Importantly, we show that this robust objective can be reformulated entirely in terms of the nominal data distribution, enabling tractable offline learning. Empirical evaluations on continuous-control benchmarks demonstrate that our approach achieves superior robustness and generalization compared to state-of-the-art offline IL baselines, particularly under perturbed or shifted environments.",
    "authors": [
      "Rishabh Agrawal",
      "Yusuf Alvi",
      "Rahul Jain",
      "Ashutosh Nayyar"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07942v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07942v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.08505v1",
    "title": "Structured RAG for Answering Aggregative Questions",
    "summary": "Retrieval-Augmented Generation (RAG) has become the dominant approach for answering questions over large corpora. However, current datasets and methods are highly focused on cases where only a small part of the corpus (usually a few paragraphs) is relevant per query, and fail to capture the rich world of aggregative queries. These require gathering information from a large set of documents and reasoning over them. To address this gap, we propose S-RAG, an approach specifically designed for such queries. At ingestion time, S-RAG constructs a structured representation of the corpus; at inference time, it translates natural-language queries into formal queries over said representation. To validate our approach and promote further research in this area, we introduce two new datasets of aggregative queries: HOTELS and WORLD CUP. Experiments with S-RAG on the newly introduced datasets, as well as on a public benchmark, demonstrate that it substantially outperforms both common RAG systems and long-context LLMs.",
    "authors": [
      "Omri Koshorek",
      "Niv Granot",
      "Aviv Alloni",
      "Shahar Admati",
      "Roee Hendel",
      "Ido Weiss",
      "Alan Arazi",
      "Shay-Nitzan Cohen",
      "Yonatan Belinkov"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08505v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08505v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07210v2",
    "title": "Breaking the Stealth-Potency Trade-off in Clean-Image Backdoors with Generative Trigger Optimization",
    "summary": "Clean-image backdoor attacks, which use only label manipulation in training datasets to compromise deep neural networks, pose a significant threat to security-critical applications. A critical flaw in existing methods is that the poison rate required for a successful attack induces a proportional, and thus noticeable, drop in Clean Accuracy (CA), undermining their stealthiness. This paper presents a new paradigm for clean-image attacks that minimizes this accuracy degradation by optimizing the trigger itself. We introduce Generative Clean-Image Backdoors (GCB), a framework that uses a conditional InfoGAN to identify naturally occurring image features that can serve as potent and stealthy triggers. By ensuring these triggers are easily separable from benign task-related features, GCB enables a victim model to learn the backdoor from an extremely small set of poisoned examples, resulting in a CA drop of less than 1%. Our experiments demonstrate GCB's remarkable versatility, successfully adapting to six datasets, five architectures, and four tasks, including the first demonstration of clean-image backdoors in regression and segmentation. GCB also exhibits resilience against most of the existing backdoor defenses.",
    "authors": [
      "Binyan Xu",
      "Fan Yang",
      "Di Tang",
      "Xilin Dai",
      "Kehuan Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07210v2",
    "pdf_url": "https://arxiv.org/pdf/2511.07210v2.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.08231v1",
    "title": "Real-Time Performance Analysis of Multi-Fidelity Residual Physics-Informed Neural Process-Based State Estimation for Robotic Systems",
    "summary": "Various neural network architectures are used in many of the state-of-the-art approaches for real-time nonlinear state estimation. With the ever-increasing incorporation of these data-driven models into the estimation domain, model predictions with reliable margins of error are a requirement -- especially for safety-critical applications. This paper discusses the application of a novel real-time, data-driven estimation approach based on the multi-fidelity residual physics-informed neural process (MFR-PINP) toward the real-time state estimation of a robotic system. Specifically, we address the model-mismatch issue of selecting an accurate kinematic model by tasking the MFR-PINP to also learn the residuals between simple, low-fidelity predictions and complex, high-fidelity ground-truth dynamics. To account for model uncertainty present in a physical implementation, robust uncertainty guarantees from the split conformal (SC) prediction framework are modeled in the training and inference paradigms. We provide implementation details of our MFR-PINP-based estimator for a hybrid online learning setting to validate our model's usage in real-time applications. Experimental results of our approach's performance in comparison to the state-of-the-art variants of the Kalman filter (i.e. unscented Kalman filter and deep Kalman filter) in estimation scenarios showed promising results for the MFR-PINP model as a viable option in real-time estimation tasks.",
    "authors": [
      "Devin Hunter",
      "Chinwendu Enyioha"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08231v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08231v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.08226v1",
    "title": "The Online Patch Redundancy Eliminator (OPRE): A novel approach to online agnostic continual learning using dataset compression",
    "summary": "In order to achieve Continual Learning (CL), the problem of catastrophic forgetting, one that has plagued neural networks since their inception, must be overcome. The evaluation of continual learning methods relies on splitting a known homogeneous dataset and learning the associated tasks one after the other. We argue that most CL methods introduce a priori information about the data to come and cannot be considered agnostic. We exemplify this point with the case of methods relying on pretrained feature extractors, which are still used in CL. After showing that pretrained feature extractors imply a loss of generality with respect to the data that can be learned by the model, we then discuss other kinds of a priori information introduced in other CL methods. We then present the Online Patch Redundancy Eliminator (OPRE), an online dataset compression algorithm, which, along with the training of a classifier at test time, yields performance on CIFAR-10 and CIFAR-100 superior to a number of other state-of-the-art online continual learning methods. Additionally, OPRE requires only minimal and interpretable hypothesis on the data to come. We suggest that online dataset compression could well be necessary to achieve fully agnostic CL.",
    "authors": [
      "Raphaël Bayle",
      "Martial Mermillod",
      "Robert M. French"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08226v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08226v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07637v1",
    "title": "Private-RAG: Answering Multiple Queries with LLMs while Keeping Your Data Private",
    "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by retrieving documents from an external corpus at inference time. When this corpus contains sensitive information, however, unprotected RAG systems are at risk of leaking private information. Prior work has introduced differential privacy (DP) guarantees for RAG, but only in single-query settings, which fall short of realistic usage. In this paper, we study the more practical multi-query setting and propose two DP-RAG algorithms. The first, MURAG, leverages an individual privacy filter so that the accumulated privacy loss only depends on how frequently each document is retrieved rather than the total number of queries. The second, MURAG-ADA, further improves utility by privately releasing query-specific thresholds, enabling more precise selection of relevant documents. Our experiments across multiple LLMs and datasets demonstrate that the proposed methods scale to hundreds of queries within a practical DP budget ($\\varepsilon\\approx10$), while preserving meaningful utility.",
    "authors": [
      "Ruihan Wu",
      "Erchi Wang",
      "Zhiyuan Zhang",
      "Yu-Xiang Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07637v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07637v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07032v1",
    "title": "Fair Bayesian Data Selection via Generalized Discrepancy Measures",
    "summary": "Fairness concerns are increasingly critical as machine learning models are deployed in high-stakes applications. While existing fairness-aware methods typically intervene at the model level, they often suffer from high computational costs, limited scalability, and poor generalization. To address these challenges, we propose a Bayesian data selection framework that ensures fairness by aligning group-specific posterior distributions of model parameters and sample weights with a shared central distribution. Our framework supports flexible alignment via various distributional discrepancy measures, including Wasserstein distance, maximum mean discrepancy, and $f$-divergence, allowing geometry-aware control without imposing explicit fairness constraints. This data-centric approach mitigates group-specific biases in training data and improves fairness in downstream tasks, with theoretical guarantees. Experiments on benchmark datasets show that our method consistently outperforms existing data selection and model-based fairness methods in both fairness and accuracy.",
    "authors": [
      "Yixuan Zhang",
      "Jiabin Luo",
      "Zhenggang Wang",
      "Feng Zhou",
      "Quyu Kong"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07032v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07032v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.06826v1",
    "title": "Beyond Plain Demos: A Demo-centric Anchoring Paradigm for In-Context Learning in Alzheimer's Disease Detection",
    "summary": "Detecting Alzheimer's disease (AD) from narrative transcripts challenges large language models (LLMs): pre-training rarely covers this out-of-distribution task, and all transcript demos describe the same scene, producing highly homogeneous contexts. These factors cripple both the model's built-in task knowledge (\\textbf{task cognition}) and its ability to surface subtle, class-discriminative cues (\\textbf{contextual perception}). Because cognition is fixed after pre-training, improving in-context learning (ICL) for AD detection hinges on enriching perception through better demonstration (demo) sets. We demonstrate that standard ICL quickly saturates, its demos lack diversity (context width) and fail to convey fine-grained signals (context depth), and that recent task vector (TV) approaches improve broad task adaptation by injecting TV into the LLMs' hidden states (HSs), they are ill-suited for AD detection due to the mismatch of injection granularity, strength and position. To address these bottlenecks, we introduce \\textbf{DA4ICL}, a demo-centric anchoring framework that jointly expands context width via \\emph{\\textbf{Diverse and Contrastive Retrieval}} (DCR) and deepens each demo's signal via \\emph{\\textbf{Projected Vector Anchoring}} (PVA) at every Transformer layer. Across three AD benchmarks, DA4ICL achieves large, stable gains over both ICL and TV baselines, charting a new paradigm for fine-grained, OOD and low-resource LLM adaptation.",
    "authors": [
      "Puzhen Su",
      "Haoran Yin",
      "Yongzhu Miao",
      "Jintao Tang",
      "Shasha Li",
      "Ting Wang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06826v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06826v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07836v1",
    "title": "Hyperellipsoid Density Sampling: Exploitative Sequences to Accelerate High-Dimensional Optimization",
    "summary": "The curse of dimensionality presents a pervasive challenge in optimization problems, with exponential expansion of the search space rapidly causing traditional algorithms to become inefficient or infeasible. An adaptive sampling strategy is presented to accelerate optimization in this domain as an alternative to uniform quasi-Monte Carlo (QMC) methods.   This method, referred to as Hyperellipsoid Density Sampling (HDS), generates its sequences by defining multiple hyperellipsoids throughout the search space. HDS uses three types of unsupervised learning algorithms to circumvent high-dimensional geometric calculations, producing an intelligent, non-uniform sample sequence that exploits statistically promising regions of the parameter space and improves final solution quality in high-dimensional optimization problems.   A key feature of the method is optional Gaussian weights, which may be provided to influence the sample distribution towards known locations of interest. This capability makes HDS versatile for applications beyond optimization, providing a focused, denser sample distribution where models need to concentrate their efforts on specific, non-uniform regions of the parameter space.   The method was evaluated against Sobol, a standard QMC method, using differential evolution (DE) on the 29 CEC2017 benchmark test functions. The results show statistically significant improvements in solution geometric mean error (p < 0.05), with average performance gains ranging from 3% in 30D to 37% in 10D. This paper demonstrates the efficacy of HDS as a robust alternative to QMC sampling for high-dimensional optimization.",
    "authors": [
      "Julian Soltes"
    ],
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NE"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07836v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07836v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.08464v1",
    "title": "Contrastive Integrated Gradients: A Feature Attribution-Based Method for Explaining Whole Slide Image Classification",
    "summary": "Interpretability is essential in Whole Slide Image (WSI) analysis for computational pathology, where understanding model predictions helps build trust in AI-assisted diagnostics. While Integrated Gradients (IG) and related attribution methods have shown promise, applying them directly to WSIs introduces challenges due to their high-resolution nature. These methods capture model decision patterns but may overlook class-discriminative signals that are crucial for distinguishing between tumor subtypes. In this work, we introduce Contrastive Integrated Gradients (CIG), a novel attribution method that enhances interpretability by computing contrastive gradients in logit space. First, CIG highlights class-discriminative regions by comparing feature importance relative to a reference class, offering sharper differentiation between tumor and non-tumor areas. Second, CIG satisfies the axioms of integrated attribution, ensuring consistency and theoretical soundness. Third, we propose two attribution quality metrics, MIL-AIC and MIL-SIC, which measure how predictive information and model confidence evolve with access to salient regions, particularly under weak supervision. We validate CIG across three datasets spanning distinct cancer types: CAMELYON16 (breast cancer metastasis in lymph nodes), TCGA-RCC (renal cell carcinoma), and TCGA-Lung (lung cancer). Experimental results demonstrate that CIG yields more informative attributions both quantitatively, using MIL-AIC and MIL-SIC, and qualitatively, through visualizations that align closely with ground truth tumor regions, underscoring its potential for interpretable and trustworthy WSI-based diagnostics",
    "authors": [
      "Anh Mai Vu",
      "Tuan L. Vo",
      "Ngoc Lam Quang Bui",
      "Nam Nguyen Le Binh",
      "Akash Awasthi",
      "Huy Quoc Vo",
      "Thanh-Huy Nguyen",
      "Zhu Han",
      "Chandra Mohan",
      "Hien Van Nguyen"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08464v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08464v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07417v1",
    "title": "Language Generation with Infinite Contamination",
    "summary": "We study language generation in the limit, where an algorithm observes an adversarial enumeration of strings from an unknown target language $K$ and must eventually generate new, unseen strings from $K$. Kleinberg and Mullainathan [KM24] proved that generation is achievable in surprisingly general settings. But their generator suffers from ``mode collapse,'' producing from an ever-smaller subset of the target. To address this, Kleinberg and Wei [KW25] require the generator's output to be ``dense'' in the target language. They showed that generation with density, surprisingly, remains achievable at the same generality.   Both results assume perfect data: no noisy insertions and no omissions. This raises a central question: how much contamination can generation tolerate? Recent works made partial progress on this question by studying (non-dense) generation with either finite amounts of noise (but no omissions) or omissions (but no noise).   We characterize robustness under contaminated enumerations: 1. Generation under Contamination: Language generation in the limit is achievable for all countable collections iff the fraction of contaminated examples converges to zero. When this fails, we characterize which collections are generable. 2. Dense Generation under Contamination: Dense generation is strictly less robust to contamination than generation. As a byproduct, we resolve an open question of Raman and Raman [ICML25] by showing that generation is possible with only membership oracle access under finitely many contaminated examples.   Finally, we introduce a beyond-worst-case model inspired by curriculum learning and prove that dense generation is achievable even with infinite contamination provided the fraction of contaminated examples converges to zero. This suggests curriculum learning may be crucial for learning from noisy web data.",
    "authors": [
      "Anay Mehrotra",
      "Grigoris Velegkas",
      "Xifan Yu",
      "Felix Zhou"
    ],
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.DS",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07417v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07417v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07129v1",
    "title": "LoRA on the Go: Instance-level Dynamic LoRA Selection and Merging",
    "summary": "Low-Rank Adaptation (LoRA) has emerged as a parameter-efficient approach for fine-tuning large language models.However, conventional LoRA adapters are typically trained for a single task, limiting their applicability in real-world settings where inputs may span diverse and unpredictable domains. At inference time, existing approaches combine multiple LoRAs for improving performance on diverse tasks, while usually requiring labeled data or additional task-specific training, which is expensive at scale. In this work, we introduce LoRA on the Go (LoGo), a training-free framework that dynamically selects and merges adapters at the instance level without any additional requirements. LoGo leverages signals extracted from a single forward pass through LoRA adapters, to identify the most relevant adapters and determine their contributions on-the-fly. Across 5 NLP benchmarks, 27 datasets, and 3 model families, LoGo outperforms training-based baselines on some tasks upto a margin of 3.6% while remaining competitive on other tasks and maintaining inference throughput, highlighting its effectiveness and practicality.",
    "authors": [
      "Seungeon Lee",
      "Soumi Das",
      "Manish Gupta",
      "Krishna P. Gummadi"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07129v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07129v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08579v1",
    "title": "Training Language Models to Explain Their Own Computations",
    "summary": "Can language models (LMs) learn to faithfully describe their internal computations? Are they better able to describe themselves than other models? We study the extent to which LMs' privileged access to their own internals can be leveraged to produce new techniques for explaining their behavior. Using existing interpretability techniques as a source of ground truth, we fine-tune LMs to generate natural language descriptions of (1) the information encoded by LM features, (2) the causal structure of LMs' internal activations, and (3) the influence of specific input tokens on LM outputs. When trained with only tens of thousands of example explanations, explainer models exhibit non-trivial generalization to new queries. This generalization appears partly attributable to explainer models' privileged access to their own internals: using a model to explain its own computations generally works better than using a *different* model to explain its computations (even if the other model is significantly more capable). Our results suggest not only that LMs can learn to reliably explain their internal computations, but that such explanations offer a scalable complement to existing interpretability methods.",
    "authors": [
      "Belinda Z. Li",
      "Zifan Carl Guo",
      "Vincent Huang",
      "Jacob Steinhardt",
      "Jacob Andreas"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08579v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08579v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07124v1",
    "title": "Think Consistently, Reason Efficiently: Energy-Based Calibration for Implicit Chain-of-Thought",
    "summary": "Large Language Models (LLMs) have demonstrated strong reasoning capabilities through \\emph{Chain-of-Thought} (CoT) prompting, which enables step-by-step intermediate reasoning. However, explicit CoT methods rely on discrete token-level reasoning processes that are prone to error propagation and limited by vocabulary expressiveness, often resulting in rigid and inconsistent reasoning trajectories. Recent research has explored implicit or continuous reasoning in latent spaces, allowing models to perform internal reasoning before generating explicit output. Although such approaches alleviate some limitations of discrete CoT, they generally lack explicit mechanisms to enforce consistency among reasoning steps, leading to divergent reasoning paths and unstable outcomes. To address this issue, we propose EBM-CoT, an Energy-Based Chain-of-Thought Calibration framework that refines latent thought representations through an energy-based model (EBM). Our method dynamically adjusts latent reasoning trajectories toward lower-energy, high-consistency regions in the embedding space, improving both reasoning accuracy and consistency without modifying the base language model. Extensive experiments across mathematical, commonsense, and symbolic reasoning benchmarks demonstrate that the proposed framework significantly enhances the consistency and efficiency of multi-step reasoning in LLMs.",
    "authors": [
      "Zhikang Chen",
      "Sen Cui",
      "Deheng Ye",
      "Yu Zhang",
      "Yatao Bian",
      "Tingting Zhu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07124v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07124v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07084v1",
    "title": "Pandar128 dataset for lane line detection",
    "summary": "We present Pandar128, the largest public dataset for lane line detection using a 128-beam LiDAR. It contains over 52,000 camera frames and 34,000 LiDAR scans, captured in diverse real-world conditions in Germany. The dataset includes full sensor calibration (intrinsics, extrinsics) and synchronized odometry, supporting tasks such as projection, fusion, and temporal modeling.   To complement the dataset, we also introduce SimpleLidarLane, a light-weight baseline method for lane line reconstruction that combines BEV segmentation, clustering, and polyline fitting. Despite its simplicity, our method achieves strong performance under challenging various conditions (e.g., rain, sparse returns), showing that modular pipelines paired with high-quality data and principled evaluation can compete with more complex approaches.   Furthermore, to address the lack of standardized evaluation, we propose a novel polyline-based metric - Interpolation-Aware Matching F1 (IAM-F1) - that employs interpolation-aware lateral matching in BEV space.   All data and code are publicly released to support reproducibility in LiDAR-based lane detection.",
    "authors": [
      "Filip Beránek",
      "Václav Diviš",
      "Ivan Gruber"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07084v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07084v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07820v1",
    "title": "SONIC: Supersizing Motion Tracking for Natural Humanoid Whole-Body Control",
    "summary": "Despite the rise of billion-parameter foundation models trained across thousands of GPUs, similar scaling gains have not been shown for humanoid control. Current neural controllers for humanoids remain modest in size, target a limited behavior set, and are trained on a handful of GPUs over several days. We show that scaling up model capacity, data, and compute yields a generalist humanoid controller capable of creating natural and robust whole-body movements. Specifically, we posit motion tracking as a natural and scalable task for humanoid control, leverageing dense supervision from diverse motion-capture data to acquire human motion priors without manual reward engineering. We build a foundation model for motion tracking by scaling along three axes: network size (from 1.2M to 42M parameters), dataset volume (over 100M frames, 700 hours of high-quality motion data), and compute (9k GPU hours). Beyond demonstrating the benefits of scale, we show the practical utility of our model through two mechanisms: (1) a real-time universal kinematic planner that bridges motion tracking to downstream task execution, enabling natural and interactive control, and (2) a unified token space that supports various motion input interfaces, such as VR teleoperation devices, human videos, and vision-language-action (VLA) models, all using the same policy. Scaling motion tracking exhibits favorable properties: performance improves steadily with increased compute and data diversity, and learned representations generalize to unseen motions, establishing motion tracking at scale as a practical foundation for humanoid control.",
    "authors": [
      "Zhengyi Luo",
      "Ye Yuan",
      "Tingwu Wang",
      "Chenran Li",
      "Sirui Chen",
      "Fernando Castañeda",
      "Zi-Ang Cao",
      "Jiefeng Li",
      "David Minor",
      "Qingwei Ben",
      "Xingye Da",
      "Runyu Ding",
      "Cyrus Hogg",
      "Lina Song",
      "Edy Lim",
      "Eugene Jeong",
      "Tairan He",
      "Haoru Xue",
      "Wenli Xiao",
      "Zi Wang",
      "Simon Yuen",
      "Jan Kautz",
      "Yan Chang",
      "Umar Iqbal",
      "Linxi \"Jim\" Fan",
      "Yuke Zhu"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.GR",
      "eess.SY"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07820v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07820v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08087v1",
    "title": "Beyond the Pixels: VLM-based Evaluation of Identity Preservation in Reference-Guided Synthesis",
    "summary": "Evaluating identity preservation in generative models remains a critical yet unresolved challenge. Existing metrics rely on global embeddings or coarse VLM prompting, failing to capture fine-grained identity changes and providing limited diagnostic insight. We introduce Beyond the Pixels, a hierarchical evaluation framework that decomposes identity assessment into feature-level transformations. Our approach guides VLMs through structured reasoning by (1) hierarchically decomposing subjects into (type, style) -> attribute -> feature decision tree, and (2) prompting for concrete transformations rather than abstract similarity scores. This decomposition grounds VLM analysis in verifiable visual evidence, reducing hallucinations and improving consistency. We validate our framework across four state-of-the-art generative models, demonstrating strong alignment with human judgments in measuring identity consistency. Additionally, we introduce a new benchmark specifically designed to stress-test generative models. It comprises 1,078 image-prompt pairs spanning diverse subject types, including underrepresented categories such as anthropomorphic and animated characters, and captures an average of six to seven transformation axes per prompt.",
    "authors": [
      "Aditi Singhania",
      "Krutik Malani",
      "Riddhi Dhawan",
      "Arushi Jain",
      "Garv Tandon",
      "Nippun Sharma",
      "Souymodip Chakraborty",
      "Vineet Batra",
      "Ankit Phogat"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08087v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08087v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08240v1",
    "title": "Hierarchical Direction Perception via Atomic Dot-Product Operators for Rotation-Invariant Point Clouds Learning",
    "summary": "Point cloud processing has become a cornerstone technology in many 3D vision tasks. However, arbitrary rotations introduce variations in point cloud orientations, posing a long-standing challenge for effective representation learning. The core of this issue is the disruption of the point cloud's intrinsic directional characteristics caused by rotational perturbations. Recent methods attempt to implicitly model rotational equivariance and invariance, preserving directional information and propagating it into deep semantic spaces. Yet, they often fall short of fully exploiting the multiscale directional nature of point clouds to enhance feature representations. To address this, we propose the Direction-Perceptive Vector Network (DiPVNet). At its core is an atomic dot-product operator that simultaneously encodes directional selectivity and rotation invariance--endowing the network with both rotational symmetry modeling and adaptive directional perception. At the local level, we introduce a Learnable Local Dot-Product (L2DP) Operator, which enables interactions between a center point and its neighbors to adaptively capture the non-uniform local structures of point clouds. At the global level, we leverage generalized harmonic analysis to prove that the dot-product between point clouds and spherical sampling vectors is equivalent to a direction-aware spherical Fourier transform (DASFT). This leads to the construction of a global directional response spectrum for modeling holistic directional structures. We rigorously prove the rotation invariance of both operators. Extensive experiments on challenging scenarios involving noise and large-angle rotations demonstrate that DiPVNet achieves state-of-the-art performance on point cloud classification and segmentation tasks. Our code is available at https://github.com/wxszreal0/DiPVNet.",
    "authors": [
      "Chenyu Hu",
      "Xiaotong Li",
      "Hao Zhu",
      "Biao Hou"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08240v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08240v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07941v1",
    "title": "Libra-MIL: Multimodal Prototypes Stereoscopic Infused with Task-specific Language Priors for Few-shot Whole Slide Image Classification",
    "summary": "While Large Language Models (LLMs) are emerging as a promising direction in computational pathology, the substantial computational cost of giga-pixel Whole Slide Images (WSIs) necessitates the use of Multi-Instance Learning (MIL) to enable effective modeling. A key challenge is that pathological tasks typically provide only bag-level labels, while instance-level descriptions generated by LLMs often suffer from bias due to a lack of fine-grained medical knowledge. To address this, we propose that constructing task-specific pathological entity prototypes is crucial for learning generalizable features and enhancing model interpretability. Furthermore, existing vision-language MIL methods often employ unidirectional guidance, limiting cross-modal synergy. In this paper, we introduce a novel approach, Multimodal Prototype-based Multi-Instance Learning, that promotes bidirectional interaction through a balanced information compression scheme. Specifically, we leverage a frozen LLM to generate task-specific pathological entity descriptions, which are learned as text prototypes. Concurrently, the vision branch learns instance-level prototypes to mitigate the model's reliance on redundant data. For the fusion stage, we employ the Stereoscopic Optimal Transport (SOT) algorithm, which is based on a similarity metric, thereby facilitating broader semantic alignment in a higher-dimensional space. We conduct few-shot classification and explainability experiments on three distinct cancer datasets, and the results demonstrate the superior generalization capabilities of our proposed method.",
    "authors": [
      "Zhenfeng Zhuang",
      "Fangyu Zhou",
      "Liansheng Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07941v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07941v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08225v1",
    "title": "Benchmarking Educational LLMs with Analytics: A Case Study on Gender Bias in Feedback",
    "summary": "As teachers increasingly turn to GenAI in their educational practice, we need robust methods to benchmark large language models (LLMs) for pedagogical purposes. This article presents an embedding-based benchmarking framework to detect bias in LLMs in the context of formative feedback. Using 600 authentic student essays from the AES 2.0 corpus, we constructed controlled counterfactuals along two dimensions: (i) implicit cues via lexicon-based swaps of gendered terms within essays, and (ii) explicit cues via gendered author background in the prompt. We investigated six representative LLMs (i.e. GPT-5 mini, GPT-4o mini, DeepSeek-R1, DeepSeek-R1-Qwen, Gemini 2.5 Pro, Llama-3-8B). We first quantified the response divergence with cosine and Euclidean distances over sentence embeddings, then assessed significance via permutation tests, and finally, visualised structure using dimensionality reduction. In all models, implicit manipulations reliably induced larger semantic shifts for male-female counterfactuals than for female-male. Only the GPT and Llama models showed sensitivity to explicit gender cues. These findings show that even state-of-the-art LLMs exhibit asymmetric semantic responses to gender substitutions, suggesting persistent gender biases in feedback they provide learners. Qualitative analyses further revealed consistent linguistic differences (e.g., more autonomy-supportive feedback under male cues vs. more controlling feedback under female cues). We discuss implications for fairness auditing of pedagogical GenAI, propose reporting standards for counterfactual evaluation in learning analytics, and outline practical guidance for prompt design and deployment to safeguard equitable feedback.",
    "authors": [
      "Yishan Du",
      "Conrad Borchers",
      "Mutlu Cukurova"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08225v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08225v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08470v1",
    "title": "Binary Split Categorical feature with Mean Absolute Error Criteria in CART",
    "summary": "In the context of the Classification and Regression Trees (CART) algorithm, the efficient splitting of categorical features using standard criteria like GINI and Entropy is well-established. However, using the Mean Absolute Error (MAE) criterion for categorical features has traditionally relied on various numerical encoding methods. This paper demonstrates that unsupervised numerical encoding methods are not viable for the MAE criteria. Furthermore, we present a novel and efficient splitting algorithm that addresses the challenges of handling categorical features with the MAE criterion. Our findings underscore the limitations of existing approaches and offer a promising solution to enhance the handling of categorical data in CART algorithms.",
    "authors": [
      "Peng Yu",
      "Yike Chen",
      "Chao Xu",
      "Albert Bifet",
      "Jesse Read"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08470v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08470v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06793v1",
    "title": "Cross-Modal Unlearning via Influential Neuron Path Editing in Multimodal Large Language Models",
    "summary": "Multimodal Large Language Models (MLLMs) extend foundation models to real-world applications by integrating inputs such as text and vision. However, their broad knowledge capacity raises growing concerns about privacy leakage, toxicity mitigation, and intellectual property violations. Machine Unlearning (MU) offers a practical solution by selectively forgetting targeted knowledge while preserving overall model utility. When applied to MLLMs, existing neuron-editing-based MU approaches face two fundamental challenges: (1) forgetting becomes inconsistent across modalities because existing point-wise attribution methods fail to capture the structured, layer-by-layer information flow that connects different modalities; and (2) general knowledge performance declines when sensitive neurons that also support important reasoning paths are pruned, as this disrupts the model's ability to generalize. To alleviate these limitations, we propose a multimodal influential neuron path editor (MIP-Editor) for MU. Our approach introduces modality-specific attribution scores to identify influential neuron paths responsible for encoding forget-set knowledge and applies influential-path-aware neuron-editing via representation misdirection. This strategy also enables effective and coordinated forgetting across modalities while preserving the model's general capabilities. Experimental results demonstrate that MIP-Editor achieves a superior unlearning performance on multimodal tasks, with a maximum forgetting rate of 87.75% and up to 54.26% improvement in general knowledge retention. On textual tasks, MIP-Editor achieves up to 80.65% forgetting and preserves 77.9% of general performance. Codes are available at https://github.com/PreckLi/MIP-Editor.",
    "authors": [
      "Kunhao Li",
      "Wenhao Li",
      "Di Wu",
      "Lei Yang",
      "Jun Bai",
      "Ju Jia",
      "Jason Xue"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06793v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06793v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06947v1",
    "title": "FoCLIP: A Feature-Space Misalignment Framework for CLIP-Based Image Manipulation and Detection",
    "summary": "The well-aligned attribute of CLIP-based models enables its effective application like CLIPscore as a widely adopted image quality assessment metric. However, such a CLIP-based metric is vulnerable for its delicate multimodal alignment. In this work, we propose \\textbf{FoCLIP}, a feature-space misalignment framework for fooling CLIP-based image quality metric. Based on the stochastic gradient descent technique, FoCLIP integrates three key components to construct fooling examples: feature alignment as the core module to reduce image-text modality gaps, the score distribution balance module and pixel-guard regularization, which collectively optimize multimodal output equilibrium between CLIPscore performance and image quality. Such a design can be engineered to maximize the CLIPscore predictions across diverse input prompts, despite exhibiting either visual unrecognizability or semantic incongruence with the corresponding adversarial prompts from human perceptual perspectives. Experiments on ten artistic masterpiece prompts and ImageNet subsets demonstrate that optimized images can achieve significant improvement in CLIPscore while preserving high visual fidelity. In addition, we found that grayscale conversion induces significant feature degradation in fooling images, exhibiting noticeable CLIPscore reduction while preserving statistical consistency with original images. Inspired by this phenomenon, we propose a color channel sensitivity-driven tampering detection mechanism that achieves 91% accuracy on standard benchmarks. In conclusion, this work establishes a practical pathway for feature misalignment in CLIP-based multimodal systems and the corresponding defense method.",
    "authors": [
      "Yulin Chen",
      "Zeyuan Wang",
      "Tianyuan Yu",
      "Yingmei Wei",
      "Liang Bai"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06947v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06947v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07250v1",
    "title": "MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal LLMs",
    "summary": "The advent of Multimodal Large Language Models (MLLMs) has expanded AI capabilities to visual modalities, yet existing evaluation benchmarks remain limited to single-video understanding, overlooking the critical need for multi-video understanding in real-world scenarios (e.g., sports analytics and autonomous driving). To address this significant gap, we introduce MVU-Eval, the first comprehensive benchmark for evaluating Multi-Video Understanding for MLLMs. Specifically, our MVU-Eval mainly assesses eight core competencies through 1,824 meticulously curated question-answer pairs spanning 4,959 videos from diverse domains, addressing both fundamental perception tasks and high-order reasoning tasks. These capabilities are rigorously aligned with real-world applications such as multi-sensor synthesis in autonomous systems and cross-angle sports analytics. Through extensive evaluation of state-of-the-art open-source and closed-source models, we reveal significant performance discrepancies and limitations in current MLLMs' ability to perform understanding across multiple videos. The benchmark will be made publicly available to foster future research.",
    "authors": [
      "Tianhao Peng",
      "Haochen Wang",
      "Yuanxing Zhang",
      "Zekun Wang",
      "Zili Wang",
      "Ge Zhang",
      "Jian Yang",
      "Shihao Li",
      "Yanghai Wang",
      "Xintao Wang",
      "Houyi Li",
      "Wei Ji",
      "Pengfei Wan",
      "Wenhao Huang",
      "Zhaoxiang Zhang",
      "Jiaheng Liu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07250v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07250v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07671v1",
    "title": "Robust Experimental Design via Generalised Bayesian Inference",
    "summary": "Bayesian optimal experimental design is a principled framework for conducting experiments that leverages Bayesian inference to quantify how much information one can expect to gain from selecting a certain design. However, accurate Bayesian inference relies on the assumption that one's statistical model of the data-generating process is correctly specified. If this assumption is violated, Bayesian methods can lead to poor inference and estimates of information gain. Generalised Bayesian (or Gibbs) inference is a more robust probabilistic inference framework that replaces the likelihood in the Bayesian update by a suitable loss function. In this work, we present Generalised Bayesian Optimal Experimental Design (GBOED), an extension of Gibbs inference to the experimental design setting which achieves robustness in both design and inference. Using an extended information-theoretic framework, we derive a new acquisition function, the Gibbs expected information gain (Gibbs EIG). Our empirical results demonstrate that GBOED enhances robustness to outliers and incorrect assumptions about the outcome noise distribution.",
    "authors": [
      "Yasir Zubayr Barlas",
      "Sabina J. Sloman",
      "Samuel Kaski"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07671v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07671v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06608v1",
    "title": "Beyond Fixed Depth: Adaptive Graph Neural Networks for Node Classification Under Varying Homophily",
    "summary": "Graph Neural Networks (GNNs) have achieved significant success in addressing node classification tasks. However, the effectiveness of traditional GNNs degrades on heterophilic graphs, where connected nodes often belong to different labels or properties. While recent work has introduced mechanisms to improve GNN performance under heterophily, certain key limitations still exist. Most existing models apply a fixed aggregation depth across all nodes, overlooking the fact that nodes may require different propagation depths based on their local homophily levels and neighborhood structures. Moreover, many methods are tailored to either homophilic or heterophilic settings, lacking the flexibility to generalize across both regimes. To address these challenges, we develop a theoretical framework that links local structural and label characteristics to information propagation dynamics at the node level. Our analysis shows that optimal aggregation depth varies across nodes and is critical for preserving class-discriminative information. Guided by this insight, we propose a novel adaptive-depth GNN architecture that dynamically selects node-specific aggregation depths using theoretically grounded metrics. Our method seamlessly adapts to both homophilic and heterophilic patterns within a unified model. Extensive experiments demonstrate that our approach consistently enhances the performance of standard GNN backbones across diverse benchmarks.",
    "authors": [
      "Asela Hevapathige",
      "Asiri Wijesinghe",
      "Ahad N. Zehmakan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06608v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06608v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07107v1",
    "title": "MENTOR: A Metacognition-Driven Self-Evolution Framework for Uncovering and Mitigating Implicit Risks in LLMs on Domain Tasks",
    "summary": "Ensuring the safety and value alignment of large language models (LLMs) is critical for their deployment. Current alignment efforts primarily target explicit risks such as bias, hate speech, and violence. However, they often fail to address deeper, domain-specific implicit risks and lack a flexible, generalizable framework applicable across diverse specialized fields. Hence, we proposed MENTOR: A MEtacognition-driveN self-evoluTion framework for uncOvering and mitigating implicit Risks in LLMs on Domain Tasks. To address the limitations of labor-intensive human evaluation, we introduce a novel metacognitive self-assessment tool. This enables LLMs to reflect on potential value misalignments in their responses using strategies like perspective-taking and consequential thinking. We also release a supporting dataset of 9,000 risk queries spanning education, finance, and management to enhance domain-specific risk identification. Subsequently, based on the outcomes of metacognitive reflection, the framework dynamically generates supplementary rule knowledge graphs that extend predefined static rule trees. This enables models to actively apply validated rules to future similar challenges, establishing a continuous self-evolution cycle that enhances generalization by reducing maintenance costs and inflexibility of static systems. Finally, we employ activation steering during inference to guide LLMs in following the rules, a cost-effective method to robustly enhance enforcement across diverse contexts. Experimental results show MENTOR's effectiveness: In defensive testing across three vertical domains, the framework substantially reduces semantic attack success rates, enabling a new level of implicit risk mitigation for LLMs. Furthermore, metacognitive assessment not only aligns closely with baseline human evaluators but also delivers more thorough and insightful analysis of LLMs value alignment.",
    "authors": [
      "Liang Shan",
      "Kaicheng Shen",
      "Wen Wu",
      "Zhenyu Ying",
      "Chaochao Lu",
      "Guangze Ye",
      "Liang He"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07107v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07107v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07010v1",
    "title": "A Picture is Worth a Thousand (Correct) Captions: A Vision-Guided Judge-Corrector System for Multimodal Machine Translation",
    "summary": "In this paper, we describe our system under the team name BLEU Monday for the English-to-Indic Multimodal Translation Task at WAT 2025. We participate in the text-only translation tasks for English-Hindi, English-Bengali, English-Malayalam, and English-Odia language pairs. We present a two-stage approach that addresses quality issues in the training data through automated error detection and correction, followed by parameter-efficient model fine-tuning.   Our methodology introduces a vision-augmented judge-corrector pipeline that leverages multimodal language models to systematically identify and correct translation errors in the training data. The judge component classifies translations into three categories: correct, visually ambiguous (requiring image context), or mistranslated (poor translation quality). Identified errors are routed to specialized correctors: GPT-4o-mini regenerates captions requiring visual disambiguation, while IndicTrans2 retranslates cases with pure translation quality issues. This automated pipeline processes 28,928 training examples across four languages, correcting an average of 17.1% of captions per language.   We then apply Low-Rank Adaptation (LoRA) to fine-tune the IndicTrans2 en-indic 200M distilled model on both original and corrected datasets. Training on corrected data yields consistent improvements, with BLEU score gains of +1.30 for English-Bengali on the evaluation set (42.00 -> 43.30) and +0.70 on the challenge set (44.90 -> 45.60), +0.60 for English-Odia on the evaluation set (41.00 -> 41.60), and +0.10 for English-Hindi on the challenge set (53.90 -> 54.00).",
    "authors": [
      "Siddharth Betala",
      "Kushan Raj",
      "Vipul Betala",
      "Rohan Saswade"
    ],
    "categories": [
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07010v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07010v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06937v1",
    "title": "Fine-Tuning Diffusion-Based Recommender Systems via Reinforcement Learning with Reward Function Optimization",
    "summary": "Diffusion models recently emerged as a powerful paradigm for recommender systems, offering state-of-the-art performance by modeling the generative process of user-item interactions. However, training such models from scratch is both computationally expensive and yields diminishing returns once convergence is reached. To remedy these challenges, we propose ReFiT, a new framework that integrates Reinforcement learning (RL)-based Fine-Tuning into diffusion-based recommender systems. In contrast to prior RL approaches for diffusion models depending on external reward models, ReFiT adopts a task-aligned design: it formulates the denoising trajectory as a Markov decision process (MDP) and incorporates a collaborative signal-aware reward function that directly reflects recommendation quality. By tightly coupling the MDP structure with this reward signal, ReFiT empowers the RL agent to exploit high-order connectivity for fine-grained optimization, while avoiding the noisy or uninformative feedback common in naive reward designs. Leveraging policy gradient optimization, ReFiT maximizes exact log-likelihood of observed interactions, thereby enabling effective post hoc fine-tuning of diffusion recommenders. Comprehensive experiments on wide-ranging real-world datasets demonstrate that the proposed ReFiT framework (a) exhibits substantial performance gains over strong competitors (up to 36.3% on sequential recommendation), (b) demonstrates strong efficiency with linear complexity in the number of users or items, and (c) generalizes well across multiple diffusion-based recommendation scenarios. The source code and datasets are publicly available at https://anonymous.4open.science/r/ReFiT-4C60.",
    "authors": [
      "Yu Hou",
      "Hua Li",
      "Ha Young Kim",
      "Won-Yong Shin"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "cs.NI",
      "cs.SI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06937v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06937v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.06805v1",
    "title": "MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning",
    "summary": "Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in vision-language answering tasks. Despite their strengths, these models often encounter challenges in achieving complex reasoning tasks such as mathematical problem-solving. Previous works have focused on fine-tuning on specialized mathematical datasets. However, these datasets are typically distilled directly from teacher models, which capture only static reasoning patterns and leaving substantial gaps compared to student models. This reliance on fixed teacher-derived datasets not only restricts the model's ability to adapt to novel or more intricate questions that extend beyond the confines of the training data, but also lacks the iterative depth needed for robust generalization. To overcome these limitations, we propose \\textbf{\\method}, a \\textbf{Math}ematical \\textbf{S}elf-\\textbf{E}volving framework for MLLMs. In contrast to traditional one-shot fine-tuning paradigms, \\method iteratively refines the model through cycles of inference, reflection, and reward-based feedback. Specifically, we leverage iterative fine-tuning by incorporating correct reasoning paths derived from previous-stage inference and integrating reflections from a specialized Outcome Reward Model (ORM). To verify the effectiveness of \\method, we evaluate it on a suite of challenging benchmarks, demonstrating significant performance gains over backbone models. Notably, our experimental results on MathVL-test surpass the leading open-source multimodal mathematical reasoning model QVQ. Our code and models are available at \\texttt{https://zheny2751\\allowbreak-dotcom.github.io/\\allowbreak MathSE.github.io/}.",
    "authors": [
      "Jinhao Chen",
      "Zhen Yang",
      "Jianxin Shi",
      "Tianyu Wo",
      "Jie Tang"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06805v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06805v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.08031v1",
    "title": "Multi-modal Deepfake Detection and Localization with FPN-Transformer",
    "summary": "The rapid advancement of generative adversarial networks (GANs) and diffusion models has enabled the creation of highly realistic deepfake content, posing significant threats to digital trust across audio-visual domains. While unimodal detection methods have shown progress in identifying synthetic media, their inability to leverage cross-modal correlations and precisely localize forged segments limits their practicality against sophisticated, fine-grained manipulations. To address this, we introduce a multi-modal deepfake detection and localization framework based on a Feature Pyramid-Transformer (FPN-Transformer), addressing critical gaps in cross-modal generalization and temporal boundary regression. The proposed approach utilizes pre-trained self-supervised models (WavLM for audio, CLIP for video) to extract hierarchical temporal features. A multi-scale feature pyramid is constructed through R-TLM blocks with localized attention mechanisms, enabling joint analysis of cross-context temporal dependencies. The dual-branch prediction head simultaneously predicts forgery probabilities and refines temporal offsets of manipulated segments, achieving frame-level localization precision. We evaluate our approach on the test set of the IJCAI'25 DDL-AV benchmark, showing a good performance with a final score of 0.7535 for cross-modal deepfake detection and localization in challenging environments. Experimental results confirm the effectiveness of our approach and provide a novel way for generalized deepfake detection. Our code is available at https://github.com/Zig-HS/MM-DDL",
    "authors": [
      "Chende Zheng",
      "Ruiqi Suo",
      "Zhoulin Ji",
      "Jingyi Deng",
      "Fangbin Yi",
      "Chenhao Lin",
      "Chao Shen"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08031v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08031v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.06899v1",
    "title": "RPTS: Tree-Structured Reasoning Process Scoring for Faithful Multimodal Evaluation",
    "summary": "Large Vision-Language Models (LVLMs) excel in multimodal reasoning and have shown impressive performance on various multimodal benchmarks. However, most of these benchmarks evaluate models primarily through multiple-choice or short-answer formats, which do not take the reasoning process into account. Although some benchmarks assess the reasoning process, their methods are often overly simplistic and only examine reasoning when answers are incorrect. This approach overlooks scenarios where flawed reasoning leads to correct answers. In addition, these benchmarks do not consider the impact of intermodal relationships on reasoning. To address this issue, we propose the Reasoning Process Tree Score (RPTS), a tree structure-based metric to assess reasoning processes. Specifically, we organize the reasoning steps into a reasoning tree and leverage its hierarchical information to assign weighted faithfulness scores to each reasoning step. By dynamically adjusting these weights, RPTS not only evaluates the overall correctness of the reasoning, but also pinpoints where the model fails in the reasoning. To validate RPTS in real-world multimodal scenarios, we construct a new benchmark, RPTS-Eval, comprising 374 images and 390 reasoning instances. Each instance includes reliable visual-textual clues that serve as leaf nodes of the reasoning tree. Furthermore, we define three types of intermodal relationships to investigate how intermodal interactions influence the reasoning process. We evaluated representative LVLMs (e.g., GPT4o, Llava-Next), uncovering their limitations in multimodal reasoning and highlighting the differences between open-source and closed-source commercial LVLMs. We believe that this benchmark will contribute to the advancement of research in the field of multimodal reasoning.",
    "authors": [
      "Haofeng Wang",
      "Yu Zhang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06899v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06899v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.08387v1",
    "title": "RAPTR: Radar-based 3D Pose Estimation using Transformer",
    "summary": "Radar-based indoor 3D human pose estimation typically relied on fine-grained 3D keypoint labels, which are costly to obtain especially in complex indoor settings involving clutter, occlusions, or multiple people. In this paper, we propose \\textbf{RAPTR} (RAdar Pose esTimation using tRansformer) under weak supervision, using only 3D BBox and 2D keypoint labels which are considerably easier and more scalable to collect. Our RAPTR is characterized by a two-stage pose decoder architecture with a pseudo-3D deformable attention to enhance (pose/joint) queries with multi-view radar features: a pose decoder estimates initial 3D poses with a 3D template loss designed to utilize the 3D BBox labels and mitigate depth ambiguities; and a joint decoder refines the initial poses with 2D keypoint labels and a 3D gravity loss. Evaluated on two indoor radar datasets, RAPTR outperforms existing methods, reducing joint position error by $34.3\\%$ on HIBER and $76.9\\%$ on MMVR. Our implementation is available at https://github.com/merlresearch/radar-pose-transformer.",
    "authors": [
      "Sorachi Kato",
      "Ryoma Yataka",
      "Pu Perry Wang",
      "Pedro Miraldo",
      "Takuya Fujihashi",
      "Petros Boufounos"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.SP"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08387v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08387v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.07403v1",
    "title": "SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards",
    "summary": "Multimodal large language models (MLLMs) have achieved remarkable progress in vision-language tasks, but they continue to struggle with spatial understanding. Existing spatial MLLMs often rely on explicit 3D inputs or architecture-specific modifications, and remain constrained by large-scale datasets or sparse supervision. To address these limitations, we introduce SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial grounding with multi-step reasoning. The model simulates human-like spatial perception by constructing a scene graph of task-relevant objects and spatial relations, and reasoning towards an answer via dense spatial rewards. SpatialThinker consists of two key contributions: (1) a data synthesis pipeline that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL with a multi-objective dense spatial reward enforcing spatial grounding. SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline on spatial understanding and real-world VQA benchmarks, nearly doubling the base-model gain compared to sparse RL, and surpassing GPT-4o. These results showcase the effectiveness of combining spatial supervision with reward-aligned reasoning in enabling robust 3D spatial understanding with limited data and advancing MLLMs towards human-level visual reasoning.",
    "authors": [
      "Hunar Batra",
      "Haoqin Tu",
      "Hardy Chen",
      "Yuanze Lin",
      "Cihang Xie",
      "Ronald Clark"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07403v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07403v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.07007v1",
    "title": "TrueCity: Real and Simulated Urban Data for Cross-Domain 3D Scene Understanding",
    "summary": "3D semantic scene understanding remains a long-standing challenge in the 3D computer vision community. One of the key issues pertains to limited real-world annotated data to facilitate generalizable models. The common practice to tackle this issue is to simulate new data. Although synthetic datasets offer scalability and perfect labels, their designer-crafted scenes fail to capture real-world complexity and sensor noise, resulting in a synthetic-to-real domain gap. Moreover, no benchmark provides synchronized real and simulated point clouds for segmentation-oriented domain shift analysis. We introduce TrueCity, the first urban semantic segmentation benchmark with cm-accurate annotated real-world point clouds, semantic 3D city models, and annotated simulated point clouds representing the same city. TrueCity proposes segmentation classes aligned with international 3D city modeling standards, enabling consistent evaluation of synthetic-to-real gap. Our extensive experiments on common baselines quantify domain shift and highlight strategies for exploiting synthetic data to enhance real-world 3D scene understanding. We are convinced that the TrueCity dataset will foster further development of sim-to-real gap quantification and enable generalizable data-driven models. The data, code, and 3D models are available online: https://tum-gis.github.io/TrueCity/",
    "authors": [
      "Duc Nguyen",
      "Yan-Ling Lai",
      "Qilin Zhang",
      "Prabin Gyawali",
      "Benedikt Schwab",
      "Olaf Wysocki",
      "Thomas H. Kolbe"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07007v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07007v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.08577v1",
    "title": "Think-at-Hard: Selective Latent Iterations to Improve Reasoning Language Models",
    "summary": "Improving reasoning capabilities of Large Language Models (LLMs), especially under parameter constraints, is crucial for real-world applications. Prior work proposes recurrent transformers, which allocate a fixed number of extra iterations per token to improve generation quality. After the first, standard forward pass, instead of verbalization, last-layer hidden states are fed back as inputs for additional iterations to refine token predictions. Yet we identify a latent overthinking phenomenon: easy token predictions that are already correct after the first pass are sometimes revised into errors in additional iterations. To address this, we propose Think-at-Hard (TaH), a dynamic latent thinking method that iterates deeper only at hard tokens. It employs a lightweight neural decider to trigger latent iterations only at tokens that are likely incorrect after the standard forward pass. During latent iterations, Low-Rank Adaptation (LoRA) modules shift the LLM objective from general next-token prediction to focused hard-token refinement. We further introduce a duo-causal attention mechanism that extends attention from the token sequence dimension to an additional iteration depth dimension. This enables cross-iteration information flow while maintaining full sequential parallelism. Experiments show that TaH boosts LLM reasoning performance across five challenging benchmarks while maintaining the same parameter count. Compared with baselines that iterate twice for all output tokens, TaH delivers 8.1-11.3% accuracy gains while exempting 94% of tokens from the second iteration. Against strong single-iteration Qwen3 models finetuned with the same data, it also delivers 4.0-5.0% accuracy gains. When allowing less than 3% additional parameters from LoRA and the iteration decider, the gains increase to 8.5-12.6% and 5.3-5.4%, respectively. Our code is available at https://github.com/thu-nics/TaH.",
    "authors": [
      "Tianyu Fu",
      "Yichen You",
      "Zekai Chen",
      "Guohao Dai",
      "Huazhong Yang",
      "Yu Wang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08577v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08577v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.06803v1",
    "title": "Learning to Fast Unrank in Collaborative Filtering Recommendation",
    "summary": "Modern data-driven recommendation systems risk memorizing sensitive user behavioral patterns, raising privacy concerns. Existing recommendation unlearning methods, while capable of removing target data influence, suffer from inefficient unlearning speed and degraded performance, failing to meet real-time unlearning demands. Considering the ranking-oriented nature of recommendation systems, we present unranking, the process of reducing the ranking positions of target items while ensuring the formal guarantees of recommendation unlearning. To achieve efficient unranking, we propose Learning to Fast Unrank in Collaborative Filtering Recommendation (L2UnRank), which operates through three key stages: (a) identifying the influenced scope via interaction-based p-hop propagation, (b) computing structural and semantic influences for entities within this scope, and (c) performing efficient, ranking-aware parameter updates guided by influence information. Extensive experiments across multiple datasets and backbone models demonstrate L2UnRank's model-agnostic nature, achieving state-of-the-art unranking effectiveness and maintaining recommendation quality comparable to retraining, while also delivering a 50x speedup over existing methods. Codes are available at https://github.com/Juniper42/L2UnRank.",
    "authors": [
      "Junpeng Zhao",
      "Lin Li",
      "Ming Li",
      "Amran Bhuiyan",
      "Jimmy Huang"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06803v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06803v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.08274v1",
    "title": "Multi-Agent GraphRAG: A Text-to-Cypher Framework for Labeled Property Graphs",
    "summary": "While Retrieval-Augmented Generation (RAG) methods commonly draw information from unstructured documents, the emerging paradigm of GraphRAG aims to leverage structured data such as knowledge graphs. Most existing GraphRAG efforts focus on Resource Description Framework (RDF) knowledge graphs, relying on triple representations and SPARQL queries. However, the potential of Cypher and Labeled Property Graph (LPG) databases to serve as scalable and effective reasoning engines within GraphRAG pipelines remains underexplored in current research literature. To fill this gap, we propose Multi-Agent GraphRAG, a modular LLM agentic system for text-to-Cypher query generation serving as a natural language interface to LPG-based graph data. Our proof-of-concept system features an LLM-based workflow for automated Cypher queries generation and execution, using Memgraph as the graph database backend. Iterative content-aware correction and normalization, reinforced by an aggregated feedback loop, ensures both semantic and syntactic refinement of generated queries. We evaluate our system on the CypherBench graph dataset covering several general domains with diverse types of queries. In addition, we demonstrate performance of the proposed workflow on a property graph derived from the IFC (Industry Foundation Classes) data, representing a digital twin of a building. This highlights how such an approach can bridge AI with real-world applications at scale, enabling industrial digital automation use cases.",
    "authors": [
      "Anton Gusarov",
      "Anastasia Volkova",
      "Valentin Khrulkov",
      "Andrey Kuznetsov",
      "Evgenii Maslov",
      "Ivan Oseledets"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08274v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08274v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.07931v1",
    "title": "SpeechJudge: Towards Human-Level Judgment for Speech Naturalness",
    "summary": "Aligning large generative models with human feedback is a critical challenge. In speech synthesis, this is particularly pronounced due to the lack of a large-scale human preference dataset, which hinders the development of models that truly align with human perception. To address this, we introduce SpeechJudge, a comprehensive suite comprising a dataset, a benchmark, and a reward model centered on naturalness--one of the most fundamental subjective metrics for speech synthesis. First, we present SpeechJudge-Data, a large-scale human feedback corpus of 99K speech pairs. The dataset is constructed using a diverse set of advanced zero-shot text-to-speech (TTS) models across diverse speech styles and multiple languages, with human annotations for both intelligibility and naturalness preference. From this, we establish SpeechJudge-Eval, a challenging benchmark for speech naturalness judgment. Our evaluation reveals that existing metrics and AudioLLMs struggle with this task; the leading model, Gemini-2.5-Flash, achieves less than 70% agreement with human judgment, highlighting a significant gap for improvement. To bridge this gap, we develop SpeechJudge-GRM, a generative reward model (GRM) based on Qwen2.5-Omni-7B. It is trained on SpeechJudge-Data via a two-stage post-training process: Supervised Fine-Tuning (SFT) with Chain-of-Thought rationales followed by Reinforcement Learning (RL) with GRPO on challenging cases. On the SpeechJudge-Eval benchmark, the proposed SpeechJudge-GRM demonstrates superior performance, achieving 77.2% accuracy (and 79.4% after inference-time scaling @10) compared to a classic Bradley-Terry reward model (72.7%). Furthermore, SpeechJudge-GRM can be also employed as a reward function during the post-training of speech generation models to facilitate their alignment with human preferences.",
    "authors": [
      "Xueyao Zhang",
      "Chaoren Wang",
      "Huan Liao",
      "Ziniu Li",
      "Yuancheng Wang",
      "Li Wang",
      "Dongya Jia",
      "Yuanzhe Chen",
      "Xiulin Li",
      "Zhuo Chen",
      "Zhizheng Wu"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07931v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07931v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.08077v1",
    "title": "An Integrated Fusion Framework for Ensemble Learning Leveraging Gradient Boosting and Fuzzy Rule-Based Models",
    "summary": "The integration of different learning paradigms has long been a focus of machine learning research, aimed at overcoming the inherent limitations of individual methods. Fuzzy rule-based models excel in interpretability and have seen widespread application across diverse fields. However, they face challenges such as complex design specifications and scalability issues with large datasets. The fusion of different techniques and strategies, particularly Gradient Boosting, with Fuzzy Rule-Based Models offers a robust solution to these challenges. This paper proposes an Integrated Fusion Framework that merges the strengths of both paradigms to enhance model performance and interpretability. At each iteration, a Fuzzy Rule-Based Model is constructed and controlled by a dynamic factor to optimize its contribution to the overall ensemble. This control factor serves multiple purposes: it prevents model dominance, encourages diversity, acts as a regularization parameter, and provides a mechanism for dynamic tuning based on model performance, thus mitigating the risk of overfitting. Additionally, the framework incorporates a sample-based correction mechanism that allows for adaptive adjustments based on feedback from a validation set. Experimental results substantiate the efficacy of the presented gradient boosting framework for fuzzy rule-based models, demonstrating performance enhancement, especially in terms of mitigating overfitting and complexity typically associated with many rules. By leveraging an optimal factor to govern the contribution of each model, the framework improves performance, maintains interpretability, and simplifies the maintenance and update of the models.",
    "authors": [
      "Jinbo Li",
      "Peng Liu",
      "Long Chen",
      "Witold Pedrycz",
      "Weiping Ding"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08077v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08077v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.06818v1",
    "title": "Learning to Focus: Focal Attention for Selective and Scalable Transformers",
    "summary": "Attention is a core component of transformer architecture, whether encoder-only, decoder-only, or encoder-decoder model. However, the standard softmax attention often produces noisy probability distribution, which can impair effective feature selection at every layer of these models, particularly for long contexts. We propose Focal Attention, a simple yet effective modification that sharpens the attention distribution by controlling the softmax temperature, either as a fixed hyperparameter or as a learnable parameter during training. This sharpening enables the model to concentrate on the most relevant tokens while suppressing irrelevant ones. Empirically, Focal Attention scales more favorably than standard transformer with respect to model size, training data, and context length. Across diverse benchmarks, it achieves the same accuracy with up to 42% fewer parameters or 33% less training data. On long-context tasks, it delivers substantial relative improvements ranging from 17% to 82%, demonstrating its effectiveness in real world applications.",
    "authors": [
      "Dhananjay Ram",
      "Wei Xia",
      "Stefano Soatto"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06818v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06818v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.07732v1",
    "title": "ViPRA: Video Prediction for Robot Actions",
    "summary": "Can we turn a video prediction model into a robot policy? Videos, including those of humans or teleoperated robots, capture rich physical interactions. However, most of them lack labeled actions, which limits their use in robot learning. We present Video Prediction for Robot Actions (ViPRA), a simple pretraining-finetuning framework that learns continuous robot control from these actionless videos. Instead of directly predicting actions, we train a video-language model to predict both future visual observations and motion-centric latent actions, which serve as intermediate representations of scene dynamics. We train these latent actions using perceptual losses and optical flow consistency to ensure they reflect physically grounded behavior. For downstream control, we introduce a chunked flow matching decoder that maps latent actions to robot-specific continuous action sequences, using only 100 to 200 teleoperated demonstrations. This approach avoids expensive action annotation, supports generalization across embodiments, and enables smooth, high-frequency continuous control upto 22 Hz via chunked action decoding. Unlike prior latent action works that treat pretraining as autoregressive policy learning, explicitly models both what changes and how. Our method outperforms strong baselines, with a 16% gain on the SIMPLER benchmark and a 13% improvement across real world manipulation tasks. We will release models and code at https://vipra-project.github.io",
    "authors": [
      "Sandeep Routray",
      "Hengkai Pan",
      "Unnat Jain",
      "Shikhar Bahl",
      "Deepak Pathak"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07732v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07732v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06618v1",
    "title": "GRAPH-GRPO-LEX: Contract Graph Modeling and Reinforcement Learning with Group Relative Policy Optimization",
    "summary": "Contracts are complex documents featuring detailed formal structures, explicit and implicit dependencies and rich semantic content. Given these document properties, contract drafting and manual examination of contracts have proven to be both arduous and susceptible to errors. This work aims to simplify and automate the task of contract review and analysis using a novel framework for transforming legal contracts into structured semantic graphs, enabling computational analysis and data-driven insights. We introduce a detailed ontology mapping core legal contract elements to their graph-theoretic equivalents of nodes and edges. We then present a reinforcement learning based Large Language Model (LLM) framework for segmentation and extraction of entities and relationships from contracts. Our method, GRAPH-GRPO-LEX, incorporates both LLMs and reinforcement learning with group relative policy optimization (GRPO). By applying a carefully drafted reward function of graph metrics, we demonstrate the ability to automatically identify direct relationships between clauses, and even uncover hidden dependencies. Our introduction of the gated GRPO approach shows a strong learning signal and can move contract analysis from a linear, manual reading process to an easily visualized graph. This allows for a more dynamic analysis, including building the groundwork for contract linting similar to what is now practiced in software engineering.",
    "authors": [
      "Moriya Dechtiar",
      "Daniel Martin Katz",
      "Mari Sundaresan",
      "Sylvain Jaume",
      "Hongming Wang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SE"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06618v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06618v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06761v1",
    "title": "SRNN: Spatiotemporal Relational Neural Network for Intuitive Physics Understanding",
    "summary": "Human prowess in intuitive physics remains unmatched by machines. To bridge this gap, we argue for a fundamental shift towards brain-inspired computational principles. This paper introduces the Spatiotemporal Relational Neural Network (SRNN), a model that establishes a unified neural representation for object attributes, relations, and timeline, with computations governed by a Hebbian ``Fire Together, Wire Together'' mechanism across dedicated \\textit{What} and \\textit{How} pathways. This unified representation is directly used to generate structured linguistic descriptions of the visual scene, bridging perception and language within a shared neural substrate. Moreover, unlike the prevalent ``pretrain-then-finetune'' paradigm, SRNN adopts a ``predefine-then-finetune'' approach. On the CLEVRER benchmark, SRNN achieves competitive performance. Our analysis further reveals a benchmark bias, outlines a path for a more holistic evaluation, and demonstrates SRNN's white-box utility for precise error diagnosis. Our work confirms the viability of translating biological intelligence into engineered systems for intuitive physics understanding.",
    "authors": [
      "Fei Yang"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06761v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06761v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.07876v1",
    "title": "LoopLLM: Transferable Energy-Latency Attacks in LLMs via Repetitive Generation",
    "summary": "As large language models (LLMs) scale, their inference incurs substantial computational resources, exposing them to energy-latency attacks, where crafted prompts induce high energy and latency cost. Existing attack methods aim to prolong output by delaying the generation of termination symbols. However, as the output grows longer, controlling the termination symbols through input becomes difficult, making these methods less effective. Therefore, we propose LoopLLM, an energy-latency attack framework based on the observation that repetitive generation can trigger low-entropy decoding loops, reliably compelling LLMs to generate until their output limits. LoopLLM introduces (1) a repetition-inducing prompt optimization that exploits autoregressive vulnerabilities to induce repetitive generation, and (2) a token-aligned ensemble optimization that aggregates gradients to improve cross-model transferability. Extensive experiments on 12 open-source and 2 commercial LLMs show that LoopLLM significantly outperforms existing methods, achieving over 90% of the maximum output length, compared to 20% for baselines, and improving transferability by around 40% to DeepSeek-V3 and Gemini 2.5 Flash.",
    "authors": [
      "Xingyu Li",
      "Xiaolei Liu",
      "Cheng Liu",
      "Yixiao Xu",
      "Kangyi Ding",
      "Bangzhou Xin",
      "Jia-Li Yin"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07876v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07876v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.07990v1",
    "title": "Hardware-Aware YOLO Compression for Low-Power Edge AI on STM32U5 for Weeds Detection in Digital Agriculture",
    "summary": "Weeds significantly reduce crop yields worldwide and pose major challenges to sustainable agriculture. Traditional weed management methods, primarily relying on chemical herbicides, risk environmental contamination and lead to the emergence of herbicide-resistant species. Precision weeding, leveraging computer vision and machine learning methods, offers a promising eco-friendly alternative but is often limited by reliance on high-power computational platforms. This work presents an optimized, low-power edge AI system for weeds detection based on the YOLOv8n object detector deployed on the STM32U575ZI microcontroller. Several compression techniques are applied to the detection model, including structured pruning, integer quantization and input image resolution scaling in order to meet strict hardware constraints. The model is trained and evaluated on the CropAndWeed dataset with 74 plant species, achieving a balanced trade-off between detection accuracy and efficiency. Our system supports real-time, in-situ weeds detection with a minimal energy consumption of 51.8mJ per inference, enabling scalable deployment in power-constrained agricultural environments.",
    "authors": [
      "Charalampos S. Kouzinopoulos",
      "Yuri Manna"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07990v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07990v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.07317v1",
    "title": "RLVE: Scaling Up Reinforcement Learning for Language Models with Adaptive Verifiable Environments",
    "summary": "We introduce Reinforcement Learning (RL) with Adaptive Verifiable Environments (RLVE), an approach using verifiable environments that procedurally generate problems and provide algorithmically verifiable rewards, to scale up RL for language models (LMs). RLVE enables each verifiable environment to dynamically adapt its problem difficulty distribution to the policy model's capabilities as training progresses. In contrast, static data distributions often lead to vanishing learning signals when problems are either too easy or too hard for the policy. To implement RLVE, we create RLVE-Gym, a large-scale suite of 400 verifiable environments carefully developed through manual environment engineering. Using RLVE-Gym, we show that environment scaling, i.e., expanding the collection of training environments, consistently improves generalizable reasoning capabilities. RLVE with joint training across all 400 environments in RLVE-Gym yields a 3.37% absolute average improvement across six reasoning benchmarks, starting from one of the strongest 1.5B reasoning LMs. By comparison, continuing this LM's original RL training yields only a 0.49% average absolute gain despite using over 3x more compute. We release our code publicly.",
    "authors": [
      "Zhiyuan Zeng",
      "Hamish Ivison",
      "Yiping Wang",
      "Lifan Yuan",
      "Shuyue Stella Li",
      "Zhuorui Ye",
      "Siting Li",
      "Jacqueline He",
      "Runlong Zhou",
      "Tong Chen",
      "Chenyang Zhao",
      "Yulia Tsvetkov",
      "Simon Shaolei Du",
      "Natasha Jaques",
      "Hao Peng",
      "Pang Wei Koh",
      "Hannaneh Hajishirzi"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07317v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07317v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06894v1",
    "title": "COGNOS: Universal Enhancement for Time Series Anomaly Detection via Constrained Gaussian-Noise Optimization and Smoothing",
    "summary": "Reconstruction-based methods are a dominant paradigm in time series anomaly detection (TSAD), however, their near-universal reliance on Mean Squared Error (MSE) loss results in statistically flawed reconstruction residuals. This fundamental weakness leads to noisy, unstable anomaly scores with a poor signal-to-noise ratio, hindering reliable detection. To address this, we propose Constrained Gaussian-Noise Optimization and Smoothing (COGNOS), a universal, model-agnostic enhancement framework that tackles this issue at its source. COGNOS introduces a novel Gaussian-White Noise Regularization strategy during training, which directly constrains the model's output residuals to conform to a Gaussian white noise distribution. This engineered statistical property creates the ideal precondition for our second contribution: a Kalman Smoothing Post-processor that provably operates as a statistically optimal estimator to denoise the raw anomaly scores. The synergy between these two components allows COGNOS to robustly separate the true anomaly signal from random fluctuations. Extensive experiments demonstrate that COGNOS is highly effective, delivering an average F-score uplift of 57.9% when applied to 12 diverse backbone models across multiple real-world benchmark datasets. Our work reveals that directly regularizing output statistics is a powerful and generalizable strategy for significantly improving anomaly detection systems.",
    "authors": [
      "Wenlong Shang",
      "Peng Chang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06894v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06894v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.07065v1",
    "title": "Aligning Attention with Human Rationales for Self-Explaining Hate Speech Detection",
    "summary": "The opaque nature of deep learning models presents significant challenges for the ethical deployment of hate speech detection systems. To address this limitation, we introduce Supervised Rational Attention (SRA), a framework that explicitly aligns model attention with human rationales, improving both interpretability and fairness in hate speech classification. SRA integrates a supervised attention mechanism into transformer-based classifiers, optimizing a joint objective that combines standard classification loss with an alignment loss term that minimizes the discrepancy between attention weights and human-annotated rationales. We evaluated SRA on hate speech benchmarks in English (HateXplain) and Portuguese (HateBRXplain) with rationale annotations. Empirically, SRA achieves 2.4x better explainability compared to current baselines, and produces token-level explanations that are more faithful and human-aligned. In terms of fairness, SRA achieves competitive fairness across all measures, with second-best performance in detecting toxic posts targeting identity groups, while maintaining comparable results on other metrics. These findings demonstrate that incorporating human rationales into attention mechanisms can enhance interpretability and faithfulness without compromising fairness.",
    "authors": [
      "Brage Eilertsen",
      "Røskva Bjørgfinsdóttir",
      "Francielle Vargas",
      "Ali Ramezani-Kebrya"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07065v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07065v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.08046v1",
    "title": "ProSona: Prompt-Guided Personalization for Multi-Expert Medical Image Segmentation",
    "summary": "Automated medical image segmentation suffers from high inter-observer variability, particularly in tasks such as lung nodule delineation, where experts often disagree. Existing approaches either collapse this variability into a consensus mask or rely on separate model branches for each annotator. We introduce ProSona, a two-stage framework that learns a continuous latent space of annotation styles, enabling controllable personalization via natural language prompts. A probabilistic U-Net backbone captures diverse expert hypotheses, while a prompt-guided projection mechanism navigates this latent space to generate personalized segmentations. A multi-level contrastive objective aligns textual and visual representations, promoting disentangled and interpretable expert styles. Across the LIDC-IDRI lung nodule and multi-institutional prostate MRI datasets, ProSona reduces the Generalized Energy Distance by 17% and improves mean Dice by more than one point compared with DPersona. These results demonstrate that natural-language prompts can provide flexible, accurate, and interpretable control over personalized medical image segmentation. Our implementation is available online 1 .",
    "authors": [
      "Aya Elgebaly",
      "Nikolaos Delopoulos",
      "Juliane Hörner-Rieber",
      "Carolin Rippke",
      "Sebastian Klüter",
      "Luca Boldrini",
      "Lorenzo Placidi",
      "Riccardo Dal Bello",
      "Nicolaus Andratschke",
      "Michael Baumgartl",
      "Claus Belka",
      "Christopher Kurz",
      "Guillaume Landry",
      "Shadi Albarqouni"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08046v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08046v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.08399v1",
    "title": "Aligning by Misaligning: Boundary-aware Curriculum Learning for Multimodal Alignment",
    "summary": "Most multimodal models treat every negative pair alike, ignoring the ambiguous negatives that differ from the positive by only a small detail. We propose Boundary-Aware Curriculum with Local Attention (BACL), a lightweight add-on that turns these borderline cases into a curriculum signal. A Boundary-aware Negative Sampler gradually raises difficulty, while a Contrastive Local Attention loss highlights where the mismatch occurs. The two modules are fully differentiable and work with any off-the-shelf dual encoder. Theory predicts a fast O(1/n) error rate; practice shows up to +32% R@1 over CLIP and new SOTA on four large-scale benchmarks, all without extra labels.",
    "authors": [
      "Hua Ye",
      "Hang Ding",
      "Siyuan Chen",
      "Yiyang Jiang",
      "Changyuan Zhang",
      "Xuan Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08399v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08399v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.06722v1",
    "title": "Revisiting the Data Sampling in Multimodal Post-training from a Difficulty-Distinguish View",
    "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have spurred significant progress in Chain-of-Thought (CoT) reasoning. Building on the success of Deepseek-R1, researchers extended multimodal reasoning to post-training paradigms based on reinforcement learning (RL), focusing predominantly on mathematical datasets. However, existing post-training paradigms tend to neglect two critical aspects: (1) The lack of quantifiable difficulty metrics capable of strategically screening samples for post-training optimization. (2) Suboptimal post-training paradigms that fail to jointly optimize perception and reasoning capabilities. To address this gap, we propose two novel difficulty-aware sampling strategies: Progressive Image Semantic Masking (PISM) quantifies sample hardness through systematic image degradation, while Cross-Modality Attention Balance (CMAB) assesses cross-modal interaction complexity via attention distribution analysis. Leveraging these metrics, we design a hierarchical training framework that incorporates both GRPO-only and SFT+GRPO hybrid training paradigms, and evaluate them across six benchmark datasets. Experiments demonstrate consistent superiority of GRPO applied to difficulty-stratified samples compared to conventional SFT+GRPO pipelines, indicating that strategic data sampling can obviate the need for supervised fine-tuning while improving model accuracy. Our code will be released at https://github.com/qijianyu277/DifficultySampling.",
    "authors": [
      "Jianyu Qi",
      "Ding Zou",
      "Wenrui Yan",
      "Rui Ma",
      "Jiaxu Li",
      "Zhijie Zheng",
      "Zhiguo Yang",
      "Rongchang Zhao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06722v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06722v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07288v1",
    "title": "Enabling Off-Policy Imitation Learning with Deep Actor Critic Stabilization",
    "summary": "Learning complex policies with Reinforcement Learning (RL) is often hindered by instability and slow convergence, a problem exacerbated by the difficulty of reward engineering. Imitation Learning (IL) from expert demonstrations bypasses this reliance on rewards. However, state-of-the-art IL methods, exemplified by Generative Adversarial Imitation Learning (GAIL)Ho et. al, suffer from severe sample inefficiency. This is a direct consequence of their foundational on-policy algorithms, such as TRPO Schulman et.al. In this work, we introduce an adversarial imitation learning algorithm that incorporates off-policy learning to improve sample efficiency. By combining an off-policy framework with auxiliary techniques specifically, double Q network based stabilization and value learning without reward function inference we demonstrate a reduction in the samples required to robustly match expert behavior.",
    "authors": [
      "Sayambhu Sen",
      "Shalabh Bhatnagar"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07288v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07288v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07976v1",
    "title": "Morphing Through Time: Diffusion-Based Bridging of Temporal Gaps for Robust Alignment in Change Detection",
    "summary": "Remote sensing change detection is often challenged by spatial misalignment between bi-temporal images, especially when acquisitions are separated by long seasonal or multi-year gaps. While modern convolutional and transformer-based models perform well on aligned data, their reliance on precise co-registration limits their robustness in real-world conditions. Existing joint registration-detection frameworks typically require retraining and transfer poorly across domains. We introduce a modular pipeline that improves spatial and temporal robustness without altering existing change detection networks. The framework integrates diffusion-based semantic morphing, dense registration, and residual flow refinement. A diffusion module synthesizes intermediate morphing frames that bridge large appearance gaps, enabling RoMa to estimate stepwise correspondences between consecutive frames. The composed flow is then refined through a lightweight U-Net to produce a high-fidelity warp that co-registers the original image pair. Extensive experiments on LEVIR-CD, WHU-CD, and DSIFN-CD show consistent gains in both registration accuracy and downstream change detection across multiple backbones, demonstrating the generality and effectiveness of the proposed approach.",
    "authors": [
      "Seyedehanita Madani",
      "Vishal M. Patel"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07976v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07976v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07091v1",
    "title": "How Bias Binds: Measuring Hidden Associations for Bias Control in Text-to-Image Compositions",
    "summary": "Text-to-image generative models often exhibit bias related to sensitive attributes. However, current research tends to focus narrowly on single-object prompts with limited contextual diversity. In reality, each object or attribute within a prompt can contribute to bias. For example, the prompt \"an assistant wearing a pink hat\" may reflect female-inclined biases associated with a pink hat. The neglected joint effects of the semantic binding in the prompts cause significant failures in current debiasing approaches. This work initiates a preliminary investigation on how bias manifests under semantic binding, where contextual associations between objects and attributes influence generative outcomes. We demonstrate that the underlying bias distribution can be amplified based on these associations. Therefore, we introduce a bias adherence score that quantifies how specific object-attribute bindings activate bias. To delve deeper, we develop a training-free context-bias control framework to explore how token decoupling can facilitate the debiasing of semantic bindings. This framework achieves over 10% debiasing improvement in compositional generation tasks. Our analysis of bias scores across various attribute-object bindings and token decorrelation highlights a fundamental challenge: reducing bias without disrupting essential semantic relationships. These findings expose critical limitations in current debiasing approaches when applied to semantically bound contexts, underscoring the need to reassess prevailing bias mitigation strategies.",
    "authors": [
      "Jeng-Lin Li",
      "Ming-Ching Chang",
      "Wei-Chao Chen"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07091v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07091v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.06961v1",
    "title": "Hybrid Autoencoders for Tabular Data: Leveraging Model-Based Augmentation in Low-Label Settings",
    "summary": "Deep neural networks often under-perform on tabular data due to their sensitivity to irrelevant features and a spectral bias toward smooth, low-frequency functions. These limitations hinder their ability to capture the sharp, high-frequency signals that often define tabular structure, especially under limited labeled samples. While self-supervised learning (SSL) offers promise in such settings, it remains challenging in tabular domains due to the lack of effective data augmentations. We propose a hybrid autoencoder that combines a neural encoder with an oblivious soft decision tree (OSDT) encoder, each guided by its own stochastic gating network that performs sample-specific feature selection. Together, these structurally different encoders and model-specific gating networks implement model-based augmentation, producing complementary input views tailored to each architecture. The two encoders, trained with a shared decoder and cross-reconstruction loss, learn distinct yet aligned representations that reflect their respective inductive biases. During training, the OSDT encoder (robust to noise and effective at modeling localized, high-frequency structure) guides the neural encoder toward representations more aligned with tabular data. At inference, only the neural encoder is used, preserving flexibility and SSL compatibility. Spectral analysis highlights the distinct inductive biases of each encoder. Our method achieves consistent gains in low-label classification and regression across diverse tabular datasets, outperforming deep and tree-based supervised baselines.",
    "authors": [
      "Erel Naor",
      "Ofir Lindenbaum"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06961v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06961v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07930v1",
    "title": "IBMA: An Imputation-Based Mixup Augmentation Using Self-Supervised Learning for Time Series Data",
    "summary": "Data augmentation in time series forecasting plays a crucial role in enhancing model performance by introducing variability while maintaining the underlying temporal patterns. However, time series data offers fewer augmentation strategies compared to fields such as image or text, with advanced techniques like Mixup rarely being used. In this work, we propose a novel approach, Imputation-Based Mixup Augmentation (IBMA), which combines Imputation-Augmented data with Mixup augmentation to bolster model generalization and improve forecasting performance. We evaluate the effectiveness of this method across several forecasting models, including DLinear (MLP), TimesNet (CNN), and iTrainformer (Transformer), these models represent some of the most recent advances in time series forecasting. Our experiments, conducted on four datasets (ETTh1, ETTh2, ETTm1, ETTm2) and compared against eight other augmentation techniques, demonstrate that IBMA consistently enhances performance, achieving 22 improvements out of 24 instances, with 10 of those being the best performances, particularly with iTrainformer imputation.",
    "authors": [
      "Dang Nha Nguyen",
      "Hai Dang Nguyen",
      "Khoa Tho Anh Nguyen"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07930v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07930v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.06694v1",
    "title": "ML-EcoLyzer: Quantifying the Environmental Cost of Machine Learning Inference Across Frameworks and Hardware",
    "summary": "Machine learning inference occurs at a massive scale, yet its environmental impact remains poorly quantified, especially on low-resource hardware. We present ML-EcoLyzer, a cross-framework tool for measuring the carbon, energy, thermal, and water costs of inference across CPUs, consumer GPUs, and datacenter accelerators. The tool supports both classical and modern models, applying adaptive monitoring and hardware-aware evaluation.   We introduce the Environmental Sustainability Score (ESS), which quantifies the number of effective parameters served per gram of CO$_2$ emitted. Our evaluation covers over 1,900 inference configurations, spanning diverse model architectures, task modalities (text, vision, audio, tabular), hardware types, and precision levels. These rigorous and reliable measurements demonstrate that quantization enhances ESS, huge accelerators can be inefficient for lightweight applications, and even small models may incur significant costs when implemented suboptimally. ML-EcoLyzer sets a standard for sustainability-conscious model selection and offers an extensive empirical evaluation of environmental costs during inference.",
    "authors": [
      "Jose Marie Antonio Minoza",
      "Rex Gregor Laylo",
      "Christian F Villarin",
      "Sebastian C. Ibanez"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06694v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06694v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.06582v1",
    "title": "TabRAG: Tabular Document Retrieval via Structured Language Representations",
    "summary": "Ingesting data for Retrieval-Augmented Generation (RAG) involves either fine-tuning the embedding model directly on the target corpus or parsing documents for embedding model encoding. The former, while accurate, incurs high computational hardware requirements, while the latter suffers from suboptimal performance when extracting tabular data. In this work, we address the latter by presenting TabRAG, a parsing-based RAG pipeline designed to tackle table-heavy documents via structured language representations. TabRAG outperforms existing popular parsing-based methods for generation and retrieval. Code is available at https://github.com/jacobyhsi/TabRAG.",
    "authors": [
      "Jacob Si",
      "Mike Qu",
      "Michelle Lee",
      "Yingzhen Li"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06582v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06582v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06790v1",
    "title": "Robust Causal Discovery under Imperfect Structural Constraints",
    "summary": "Robust causal discovery from observational data under imperfect prior knowledge remains a significant and largely unresolved challenge. Existing methods typically presuppose perfect priors or can only handle specific, pre-identified error types. And their performance degrades substantially when confronted with flawed constraints of unknown location and type. This decline arises because most of them rely on inflexible and biased thresholding strategies that may conflict with the data distribution. To overcome these limitations, we propose to harmonizes knowledge and data through prior alignment and conflict resolution. First, we assess the credibility of imperfect structural constraints through a surrogate model, which then guides a sparse penalization term measuring the loss between the learned and constrained adjacency matrices. We theoretically prove that, under ideal assumption, the knowledge-driven objective aligns with the data-driven objective. Furthermore, to resolve conflicts when this assumption is violated, we introduce a multi-task learning framework optimized via multi-gradient descent, jointly minimizing both objectives. Our proposed method is robust to both linear and nonlinear settings. Extensive experiments, conducted under diverse noise conditions and structural equation model types, demonstrate the effectiveness and efficiency of our method under imperfect structural constraints.",
    "authors": [
      "Zidong Wang",
      "Xi Lin",
      "Chuchao He",
      "Xiaoguang Gao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06790v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06790v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07772v1",
    "title": "SALT: Steering Activations towards Leakage-free Thinking in Chain of Thought",
    "summary": "As Large Language Models (LLMs) evolve into personal assistants with access to sensitive user data, they face a critical privacy challenge: while prior work has addressed output-level privacy, recent findings reveal that LLMs often leak private information through their internal reasoning processes, violating contextual privacy expectations. These leaky thoughts occur when models inadvertently expose sensitive details in their reasoning traces, even when final outputs appear safe. The challenge lies in preventing such leakage without compromising the model's reasoning capabilities, requiring a delicate balance between privacy and utility. We introduce Steering Activations towards Leakage-free Thinking (SALT), a lightweight test-time intervention that mitigates privacy leakage in model's Chain of Thought (CoT) by injecting targeted steering vectors into hidden state. We identify the high-leakage layers responsible for this behavior. Through experiments across multiple LLMs, we demonstrate that SALT achieves reductions including $18.2\\%$ reduction in CPL on QwQ-32B, $17.9\\%$ reduction in CPL on Llama-3.1-8B, and $31.2\\%$ reduction in CPL on Deepseek in contextual privacy leakage dataset AirGapAgent-R while maintaining comparable task performance and utility. Our work establishes SALT as a practical approach for test-time privacy protection in reasoning-capable language models, offering a path toward safer deployment of LLM-based personal agents.",
    "authors": [
      "Shourya Batra",
      "Pierce Tillman",
      "Samarth Gaggar",
      "Shashank Kesineni",
      "Kevin Zhu",
      "Sunishchal Dev",
      "Ashwinee Panda",
      "Vasu Sharma",
      "Maheep Chaudhary"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07772v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07772v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07109v1",
    "title": "A Provably-Correct and Robust Convex Model for Smooth Separable NMF",
    "summary": "Nonnegative matrix factorization (NMF) is a linear dimensionality reduction technique for nonnegative data, with applications such as hyperspectral unmixing and topic modeling. NMF is a difficult problem in general (NP-hard), and its solutions are typically not unique. To address these two issues, additional constraints or assumptions are often used. In particular, separability assumes that the basis vectors in the NMF are equal to some columns of the input matrix. In that case, the problem is referred to as separable NMF (SNMF) and can be solved in polynomial-time with robustness guarantees, while identifying a unique solution. However, in real-world scenarios, due to noise or variability, multiple data points may lie near the basis vectors, which SNMF does not leverage. In this work, we rely on the smooth separability assumption, which assumes that each basis vector is close to multiple data points. We explore the properties of the corresponding problem, referred to as smooth SNMF (SSNMF), and examine how it relates to SNMF and orthogonal NMF. We then propose a convex model for SSNMF and show that it provably recovers the sought-after factors, even in the presence of noise. We finally adapt an existing fast gradient method to solve this convex model for SSNMF, and show that it compares favorably with state-of-the-art methods on both synthetic and hyperspectral datasets.",
    "authors": [
      "Junjun Pan",
      "Valentin Leplat",
      "Michael Ng",
      "Nicolas Gillis"
    ],
    "categories": [
      "math.NA",
      "cs.LG",
      "eess.SP",
      "math.OC",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07109v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07109v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06781v1",
    "title": "On the Mechanisms of Collaborative Learning in VAE Recommenders",
    "summary": "Variational Autoencoders (VAEs) are a powerful alternative to matrix factorization for recommendation. A common technique in VAE-based collaborative filtering (CF) consists in applying binary input masking to user interaction vectors, which improves performance but remains underexplored theoretically. In this work, we analyze how collaboration arises in VAE-based CF and show it is governed by latent proximity: we derive a latent sharing radius that informs when an SGD update on one user strictly reduces the loss on another user, with influence decaying as the latent Wasserstein distance increases. We further study the induced geometry: with clean inputs, VAE-based CF primarily exploits \\emph{local} collaboration between input-similar users and under-utilizes global collaboration between far-but-related users. We compare two mechanisms that encourage \\emph{global} mixing and characterize their trade-offs: (1) $β$-KL regularization directly tightens the information bottleneck, promoting posterior overlap but risking representational collapse if too large; (2) input masking induces stochastic geometric contractions and expansions, which can bring distant users onto the same latent neighborhood but also introduce neighborhood drift. To preserve user identity while enabling global consistency, we propose an anchor regularizer that aligns user posteriors with item embeddings, stabilizing users under masking and facilitating signal sharing across related items. Our analyses are validated on the Netflix, MovieLens-20M, and Million Song datasets. We also successfully deployed our proposed algorithm on an Amazon streaming platform following a successful online experiment.",
    "authors": [
      "Tung-Long Vuong",
      "Julien Monteil",
      "Hien Dang",
      "Volodymyr Vaskovych",
      "Trung Le",
      "Vu Nguyen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06781v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06781v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.06886v1",
    "title": "Inclusion of Role into Named Entity Recognition and Ranking",
    "summary": "Most of the Natural Language Processing systems are involved in entity-based processing for several tasks like Information Extraction, Question-Answering, Text-Summarization and so on. A new challenge comes when entities play roles according to their act or attributes in certain context. Entity Role Detection is the task of assigning such roles to the entities. Usually real-world entities are of types: person, location and organization etc. Roles could be considered as domain-dependent subtypes of these types. In the cases, where retrieving a subset of entities based on their roles is needed, poses the problem of defining the role and entities having those roles. This paper presents the study of study of solving Entity Role Detection problem by modeling it as Named Entity Recognition (NER) and Entity Retrieval/Ranking task. In NER, these roles could be considered as mutually exclusive classes and standard NER methods like sequence tagging could be used. For Entity Retrieval, Roles could be formulated as Query and entities as Collection on which the query needs to be executed. The aspect of Entity Retrieval task, which is different than document retrieval task is that the entities and roles against which they need to be retrieved are indirectly described. We have formulated automated ways of learning representative words and phrases and building representations of roles and entities using them. We have also explored different contexts like sentence and document. Since the roles depend upon context, so it is not always possible to have large domain-specific dataset or knowledge bases for learning purposes, so we have tried to exploit the information from small dataset in domain-agnostic way.",
    "authors": [
      "Neelesh Kumar Shukla",
      "Sanasam Ranbir Singh"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06886v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06886v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.08512v1",
    "title": "CleverBirds: A Multiple-Choice Benchmark for Fine-grained Human Knowledge Tracing",
    "summary": "Mastering fine-grained visual recognition, essential in many expert domains, can require that specialists undergo years of dedicated training. Modeling the progression of such expertize in humans remains challenging, and accurately inferring a human learner's knowledge state is a key step toward understanding visual learning. We introduce CleverBirds, a large-scale knowledge tracing benchmark for fine-grained bird species recognition. Collected by the citizen-science platform eBird, it offers insight into how individuals acquire expertize in complex fine-grained classification. More than 40,000 participants have engaged in the quiz, answering over 17 million multiple-choice questions spanning over 10,000 bird species, with long-range learning patterns across an average of 400 questions per participant. We release this dataset to support the development and evaluation of new methods for visual knowledge tracing. We show that tracking learners' knowledge is challenging, especially across participant subgroups and question types, with different forms of contextual information offering varying degrees of predictive benefit. CleverBirds is among the largest benchmark of its kind, offering a substantially higher number of learnable concepts. With it, we hope to enable new avenues for studying the development of visual expertize over time and across individuals.",
    "authors": [
      "Leonie Bossemeyer",
      "Samuel Heinrich",
      "Grant Van Horn",
      "Oisin Mac Aodha"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08512v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08512v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07392v2",
    "title": "Surgical Agent Orchestration Platform for Voice-directed Patient Data Interaction",
    "summary": "In da Vinci robotic surgery, surgeons' hands and eyes are fully engaged in the procedure, making it difficult to access and manipulate multimodal patient data without interruption. We propose a voice-directed Surgical Agent Orchestrator Platform (SAOP) built on a hierarchical multi-agent framework, consisting of an orchestration agent and three task-specific agents driven by Large Language Models (LLMs). These LLM-based agents autonomously plan, refine, validate, and reason to map voice commands into specific tasks such as retrieving clinical information, manipulating CT scans, or navigating 3D anatomical models on the surgical video. We also introduce a Multi-level Orchestration Evaluation Metric (MOEM) to comprehensively assess the performance and robustness from command-level and category-level perspectives. The SAOP achieves high accuracy and success rates across 240 voice commands, while LLM-based agents improve robustness against speech recognition errors and diverse or ambiguous free-form commands, demonstrating strong potential to support minimally invasive da Vinci robotic surgery.",
    "authors": [
      "Hyeryun Park",
      "Byung Mo Gu",
      "Jun Hee Lee",
      "Byeong Hyeon Choi",
      "Sekeun Kim",
      "Hyun Koo Kim",
      "Kyungsang Kim"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07392v2",
    "pdf_url": "https://arxiv.org/pdf/2511.07392v2.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07230v1",
    "title": "Discourse Graph Guided Document Translation with Large Language Models",
    "summary": "Adapting large language models to full document translation remains challenging due to the difficulty of capturing long-range dependencies and preserving discourse coherence throughout extended texts. While recent agentic machine translation systems mitigate context window constraints through multi-agent orchestration and persistent memory, they require substantial computational resources and are sensitive to memory retrieval strategies. We introduce TransGraph, a discourse-guided framework that explicitly models inter-chunk relationships through structured discourse graphs and selectively conditions each translation segment on relevant graph neighbourhoods rather than relying on sequential or exhaustive context. Across three document-level MT benchmarks spanning six languages and diverse domains, TransGraph consistently surpasses strong baselines in translation quality and terminology consistency while incurring significantly lower token overhead.",
    "authors": [
      "Viet-Thanh Pham",
      "Minghan Wang",
      "Hao-Han Liao",
      "Thuy-Trang Vu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07230v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07230v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07197v1",
    "title": "Simulation-based Methods for Optimal Sampling Design in Systems Biology",
    "summary": "In many areas of systems biology, including virology, pharmacokinetics, and population biology, dynamical systems are commonly used to describe biological processes. These systems can be characterized by estimating their parameters from sampled data. The key problem is how to optimally select sampling points to achieve accurate parameter estimation. Classical approaches often rely on Fisher information matrix-based criteria such as A-, D-, and E-optimality, which require an initial parameter estimate and may yield suboptimal results when the estimate is inaccurate. This study proposes two simulation-based methods for optimal sampling design that do not depend on initial parameter estimates. The first method, E-optimal-ranking (EOR), employs the E-optimal criterion, while the second utilizes a Long Short-Term Memory (LSTM) neural network. Simulation studies based on the Lotka-Volterra and three-compartment models demonstrate that the proposed methods outperform both random selection and classical E-optimal design.",
    "authors": [
      "Tuan Minh Ha",
      "Binh Thanh Nguyen",
      "Lam Si Tung Ho"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07197v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07197v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07604v1",
    "title": "Infinite-Dimensional Operator/Block Kaczmarz Algorithms: Regret Bounds and $λ$-Effectiveness",
    "summary": "We present a variety of projection-based linear regression algorithms with a focus on modern machine-learning models and their algorithmic performance. We study the role of the relaxation parameter in generalized Kaczmarz algorithms and establish a priori regret bounds with explicit $λ$-dependence to quantify how much an algorithm's performance deviates from its optimal performance. A detailed analysis of relaxation parameter is also provided. Applications include: explicit regret bounds for the framework of Kaczmarz algorithm models, non-orthogonal Fourier expansions, and the use of regret estimates in modern machine learning models, including for noisy data, i.e., regret bounds for the noisy Kaczmarz algorithms. Motivated by machine-learning practice, our wider framework treats bounded operators (on infinite-dimensional Hilbert spaces), with updates realized as (block) Kaczmarz algorithms, leading to new and versatile results.",
    "authors": [
      "Halyun Jeong",
      "Palle E. T. Jorgensen",
      "Hyun-Kyoung Kwon",
      "Myung-Sin Song"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.FA"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07604v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07604v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07496v1",
    "title": "Laplacian Score Sharpening for Mitigating Hallucination in Diffusion Models",
    "summary": "Diffusion models, though successful, are known to suffer from hallucinations that create incoherent or unrealistic samples. Recent works have attributed this to the phenomenon of mode interpolation and score smoothening, but they lack a method to prevent their generation during sampling. In this paper, we propose a post-hoc adjustment to the score function during inference that leverages the Laplacian (or sharpness) of the score to reduce mode interpolation hallucination in unconditional diffusion models across 1D, 2D, and high-dimensional image data. We derive an efficient Laplacian approximation for higher dimensions using a finite-difference variant of the Hutchinson trace estimator. We show that this correction significantly reduces the rate of hallucinated samples across toy 1D/2D distributions and a high- dimensional image dataset. Furthermore, our analysis explores the relationship between the Laplacian and uncertainty in the score.",
    "authors": [
      "Barath Chandran. C",
      "Srinivas Anumasa",
      "Dianbo Liu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07496v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07496v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.07378v1",
    "title": "Transformers Provably Learn Chain-of-Thought Reasoning with Length Generalization",
    "summary": "The ability to reason lies at the core of artificial intelligence (AI), and challenging problems usually call for deeper and longer reasoning to tackle. A crucial question about AI reasoning is whether models can extrapolate learned reasoning patterns to solve harder tasks with longer chain-of-thought (CoT). In this work, we present a theoretical analysis of transformers learning on synthetic state-tracking tasks with gradient descent. We mathematically prove how the algebraic structure of state-tracking problems governs the degree of extrapolation of the learned CoT. Specifically, our theory characterizes the length generalization of transformers through the mechanism of attention concentration, linking the retrieval robustness of the attention layer to the state-tracking task structure of long-context reasoning. Moreover, for transformers with limited reasoning length, we prove that a recursive self-training scheme can progressively extend the range of solvable problem lengths. To our knowledge, we provide the first optimization guarantee that constant-depth transformers provably learn $\\mathsf{NC}^1$-complete problems with CoT, significantly going beyond prior art confined in $\\mathsf{TC}^0$, unless the widely held conjecture $\\mathsf{TC}^0 \\neq \\mathsf{NC}^1$ fails. Finally, we present a broad set of experiments supporting our theoretical results, confirming the length generalization behaviors and the mechanism of attention concentration.",
    "authors": [
      "Yu Huang",
      "Zixin Wen",
      "Aarti Singh",
      "Yuejie Chi",
      "Yuxin Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07378v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07378v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.07926v1",
    "title": "CNN-Based Automated Parameter Extraction Framework for Modeling Memristive Devices",
    "summary": "Resistive random access memory (RRAM) is a promising candidate for next-generation nonvolatile memory (NVM) and in-memory computing applications. Compact models are essential for analyzing the circuit and system-level performance of experimental RRAM devices. However, most existing RRAM compact models rely on multiple fitting parameters to reproduce the device I-V characteristics, and in most cases, as the parameters are not directly related to measurable quantities, their extraction requires extensive manual tuning, making the process time-consuming and limiting adaptability across different devices. This work presents an automated framework for extracting the fitting parameters of the widely used Stanford RRAM model directly from the device I-V characteristics. The framework employs a convolutional neural network (CNN) trained on a synthetic dataset to generate initial parameter estimates, which are then refined through three heuristic optimization blocks that minimize errors via adaptive binary search in the parameter space. We evaluated the framework using four key NVM metrics: set voltage, reset voltage, hysteresis loop area, and low resistance state (LRS) slope. Benchmarking against RRAM device characteristics derived from previously reported Stanford model fits, other analytical models, and experimental data shows that the framework achieves low error across diverse device characteristics, offering a fast, reliable, and robust solution for RRAM modeling.",
    "authors": [
      "Akif Hamid",
      "Orchi Hassan"
    ],
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07926v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07926v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.07368v1",
    "title": "Consistency Is Not Always Correct: Towards Understanding the Role of Exploration in Post-Training Reasoning",
    "summary": "Foundation models exhibit broad knowledge but limited task-specific reasoning, motivating post-training strategies such as RLVR and inference scaling with outcome or process reward models (ORM/PRM). While recent work highlights the role of exploration and entropy stability in improving pass@K, empirical evidence points to a paradox: RLVR and ORM/PRM typically reinforce existing tree-like reasoning paths rather than expanding the reasoning scope, raising the question of why exploration helps at all if no new patterns emerge.   To reconcile this paradox, we adopt the perspective of Kim et al. (2025), viewing easy (e.g., simplifying a fraction) versus hard (e.g., discovering a symmetry) reasoning steps as low- versus high-probability Markov transitions, and formalize post-training dynamics through Multi-task Tree-structured Markov Chains (TMC). In this tractable model, pretraining corresponds to tree expansion, while post-training corresponds to chain-of-thought reweighting. We show that several phenomena recently observed in empirical studies arise naturally in this setting: (1) RLVR induces a squeezing effect, reducing reasoning entropy and forgetting some correct paths; (2) population rewards of ORM/PRM encourage consistency rather than accuracy, thereby favoring common patterns; and (3) certain rare, high-uncertainty reasoning paths by the base model are responsible for solving hard problem instances.   Together, these explain why exploration -- even when confined to the base model's reasoning scope -- remains essential: it preserves access to rare but crucial reasoning traces needed for difficult cases, which are squeezed out by RLVR or unfavored by inference scaling. Building on this, we further show that exploration strategies such as rejecting easy instances and KL regularization help preserve rare reasoning traces. Empirical simulations corroborate our theoretical results.",
    "authors": [
      "Dake Bu",
      "Wei Huang",
      "Andi Han",
      "Atsushi Nitanda",
      "Bo Xue",
      "Qingfu Zhang",
      "Hau-San Wong",
      "Taiji Suzuki"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07368v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07368v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.08436v1",
    "title": "Understanding Electro-communication and Electro-sensing in Weakly Electric Fish using Multi-Agent Deep Reinforcement Learning",
    "summary": "Weakly electric fish, like Gnathonemus petersii, use a remarkable electrical modality for active sensing and communication, but studying their rich electrosensing and electrocommunication behavior and associated neural activity in naturalistic settings remains experimentally challenging. Here, we present a novel biologically-inspired computational framework to study these behaviors, where recurrent neural network (RNN) based artificial agents trained via multi-agent reinforcement learning (MARL) learn to modulate their electric organ discharges (EODs) and movement patterns to collectively forage in virtual environments. Trained agents demonstrate several emergent features consistent with real fish collectives, including heavy tailed EOD interval distributions, environmental context dependent shifts in EOD interval distributions, and social interaction patterns like freeloading, where agents reduce their EOD rates while benefiting from neighboring agents' active sensing. A minimal two-fish assay further isolates the role of electro-communication, showing that access to conspecific EODs and relative dominance jointly shape foraging success. Notably, these behaviors emerge through evolution-inspired rewards for individual fitness and emergent inter-agent interactions, rather than through rewarding agents explicitly for social interactions. Our work has broad implications for the neuroethology of weakly electric fish, as well as other social, communicating animals in which extensive recordings from multiple individuals, and thus traditional data-driven modeling, are infeasible.",
    "authors": [
      "Satpreet H. Singh",
      "Sonja Johnson-Yu",
      "Zhouyang Lu",
      "Aaron Walsman",
      "Federico Pedraja",
      "Denis Turcu",
      "Pratyusha Sharma",
      "Naomi Saphra",
      "Nathaniel B. Sawtell",
      "Kanaka Rajan"
    ],
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.MA",
      "eess.SY",
      "q-bio.NC"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08436v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08436v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.07322v2",
    "title": "FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for Equity Research Report Generation",
    "summary": "While LLMs have shown great success in financial tasks like stock prediction and question answering, their application in fully automating Equity Research Report generation remains uncharted territory. In this paper, we formulate the Equity Research Report (ERR) Generation task for the first time. To address the data scarcity and the evaluation metrics absence, we present an open-source evaluation benchmark for ERR generation - FinRpt. We frame a Dataset Construction Pipeline that integrates 7 financial data types and produces a high-quality ERR dataset automatically, which could be used for model training and evaluation. We also introduce a comprehensive evaluation system including 11 metrics to assess the generated ERRs. Moreover, we propose a multi-agent framework specifically tailored to address this task, named FinRpt-Gen, and train several LLM-based agents on the proposed datasets using Supervised Fine-Tuning and Reinforcement Learning. Experimental results indicate the data quality and metrics effectiveness of the benchmark FinRpt and the strong performance of FinRpt-Gen, showcasing their potential to drive innovation in the ERR generation field. All code and datasets are publicly available.",
    "authors": [
      "Song Jin",
      "Shuqi Li",
      "Shukun Zhang",
      "Rui Yan"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07322v2",
    "pdf_url": "https://arxiv.org/pdf/2511.07322v2.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.06798v1",
    "title": "Recursive Dynamics in Fast-Weights Homeostatic Reentry Networks: Toward Reflective Intelligence",
    "summary": "This study introduces the Fast-Weights Homeostatic Reentry Layer (FH-RL), a neural mechanism that integrates fast-weight associative memory, homeostatic regularization, and learned reentrant feedback to approximate self-referential computation in neural networks. Unlike standard transformer architectures that operate in a purely feedforward manner during inference, FH-RL enables internal recurrence without external looping, allowing prior latent states to be dynamically re-entered into the ongoing computation stream. We conduct controlled experiments sweeping the reentry gain $γ$ and evaluate emergent internal dynamics using three novel metrics: the Information Reentry Ratio (IRR), Eigen-Spectrum Recursion Index (ESRI), and Representational Drift Periodicity (RDP). Results show that reentry quantity increases proportionally with~$γ$, while the learned feedback matrix $W_r$ remains bounded and becomes more structured at moderate gains. Critically, a stable reflective band emerges around $γ\\approx 0.10-0.20$, where internal feedback is maximally expressive yet spectrally stable: IRR rises smoothly, ESRI remains near zero, and RDP exhibits consistent low-frequency cycles. These findings provide quantitative evidence that reflective, thought-like internal processing can arise from a principled balance between feedback amplification and homeostatic regulation, linking modern fast-weight architectures to theories of cortical reentry and recursive cognition.",
    "authors": [
      "B. G. Chae"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06798v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06798v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07118v1",
    "title": "On the Joint Minimization of Regularization Loss Functions in Deep Variational Bayesian Methods for Attribute-Controlled Symbolic Music Generation",
    "summary": "Explicit latent variable models provide a flexible yet powerful framework for data synthesis, enabling controlled manipulation of generative factors. With latent variables drawn from a tractable probability density function that can be further constrained, these models enable continuous and semantically rich exploration of the output space by navigating their latent spaces. Structured latent representations are typically obtained through the joint minimization of regularization loss functions. In variational information bottleneck models, reconstruction loss and Kullback-Leibler Divergence (KLD) are often linearly combined with an auxiliary Attribute-Regularization (AR) loss. However, balancing KLD and AR turns out to be a very delicate matter. When KLD dominates over AR, generative models tend to lack controllability; when AR dominates over KLD, the stochastic encoder is encouraged to violate the standard normal prior. We explore this trade-off in the context of symbolic music generation with explicit control over continuous musical attributes. We show that existing approaches struggle to jointly minimize both regularization objectives, whereas suitable attribute transformations can help achieve both controllability and regularization of the target latent dimensions.",
    "authors": [
      "Matteo Pettenó",
      "Alessandro Ilic Mezza",
      "Alberto Bernardini"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.AS"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07118v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07118v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07208v1",
    "title": "SMiLE: Provably Enforcing Global Relational Properties in Neural Networks",
    "summary": "Artificial Intelligence systems are increasingly deployed in settings where ensuring robustness, fairness, or domain-specific properties is essential for regulation compliance and alignment with human values. However, especially on Neural Networks, property enforcement is very challenging, and existing methods are limited to specific constraints or local properties (defined around datapoints), or fail to provide full guarantees. We tackle these limitations by extending SMiLE, a recently proposed enforcement framework for NNs, to support global relational properties (defined over the entire input space). The proposed approach scales well with model complexity, accommodates general properties and backbones, and provides full satisfaction guarantees. We evaluate SMiLE on monotonicity, global robustness, and individual fairness, on synthetic and real data, for regression and classification tasks. Our approach is competitive with property-specific baselines in terms of accuracy and runtime, and strictly superior in terms of generality and level of guarantees. Overall, our results emphasize the potential of the SMiLE framework as a platform for future research and applications.",
    "authors": [
      "Matteo Francobaldi",
      "Michele Lombardi",
      "Andrea Lodi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07208v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07208v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.06913v1",
    "title": "Sampling and Loss Weights in Multi-Domain Training",
    "summary": "In the training of large deep neural networks, there is a need for vast amounts of training data. To meet this need, data is collected from multiple domains, such as Wikipedia and GitHub. These domains are heterogeneous in both data quality and the diversity of information they provide. This raises the question of how much we should rely on each domain. Several methods have attempted to address this issue by assigning sampling weights to each data domain using heuristics or approximations. As a first step toward a deeper understanding of the role of data mixing, this work revisits the problem by studying two kinds of weights: sampling weights, which control how much each domain contributes in a batch, and loss weights, which scale the loss from each domain during training. Through a rigorous study of linear regression, we show that these two weights play complementary roles. First, they can reduce the variance of gradient estimates in iterative methods such as stochastic gradient descent (SGD). Second, they can improve generalization performance by reducing the generalization gap. We provide both theoretical and empirical support for these claims. We further study the joint dynamics of sampling weights and loss weights, examining how they can be combined to capture both contributions.",
    "authors": [
      "Mahdi Salmani",
      "Pratik Worah",
      "Meisam Razaviyayn",
      "Vahab Mirrokni"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06913v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06913v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.08314v1",
    "title": "Improving the accuracy and generalizability of molecular property regression models with a substructure-substitution-rule-informed framework",
    "summary": "Artificial Intelligence (AI)-aided drug discovery is an active research field, yet AI models often exhibit poor accuracy in regression tasks for molecular property prediction, and perform catastrophically poorly for out-of-distribution (OOD) molecules. Here, we present MolRuleLoss, a substructure-substitution-rule-informed framework that improves the accuracy and generalizability of multiple molecular property regression models (MPRMs) such as GEM and UniMol for diverse molecular property prediction tasks. MolRuleLoss incorporates partial derivative constraints for substructure substitution rules (SSRs) into an MPRM's loss function. When using GEM models for predicting lipophilicity, water solubility, and solvation-free energy (using lipophilicity, ESOL, and freeSolv datasets from MoleculeNet), the root mean squared error (RMSE) values with and without MolRuleLoss were 0.587 vs. 0.660, 0.777 vs. 0.798, and 1.252 vs. 1.877, respectively, representing 2.6-33.3% performance improvements. We show that both the number and the quality of SSRs contribute to the magnitude of prediction accuracy gains obtained upon adding MolRuleLoss to an MPRM. MolRuleLoss improved the generalizability of MPRMs for \"activity cliff\" molecules in a lipophilicity prediction task and improved the generalizability of MPRMs for OOD molecules in a melting point prediction task. In a molecular weight prediction task for OOD molecules, MolRuleLoss reduced the RMSE value of a GEM model from 29.507 to 0.007. We also provide a formal demonstration that the upper bound of the variation for property change of SSRs is positively correlated with an MPRM's error. Together, we show that using the MolRuleLoss framework as a bolt-on boosts the prediction accuracy and generalizability of multiple MPRMs, supporting diverse applications in areas like cheminformatics and AI-aided drug discovery.",
    "authors": [
      "Xiaoyu Fan",
      "Lin Guo",
      "Ruizhen Jia",
      "Yang Tian",
      "Zhihao Yang",
      "Boxue Tian"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08314v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08314v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.08082v1",
    "title": "Prudential Reliability of Large Language Models in Reinsurance: Governance, Assurance, and Capital Efficiency",
    "summary": "This paper develops a prudential framework for assessing the reliability of large language models (LLMs) in reinsurance. A five-pillar architecture--governance, data lineage, assurance, resilience, and regulatory alignment--translates supervisory expectations from Solvency II, SR 11-7, and guidance from EIOPA (2025), NAIC (2023), and IAIS (2024) into measurable lifecycle controls. The framework is implemented through the Reinsurance AI Reliability and Assurance Benchmark (RAIRAB), which evaluates whether governance-embedded LLMs meet prudential standards for grounding, transparency, and accountability. Across six task families, retrieval-grounded configurations achieved higher grounding accuracy (0.90), reduced hallucination and interpretive drift by roughly 40%, and nearly doubled transparency. These mechanisms lower informational frictions in risk transfer and capital allocation, showing that existing prudential doctrines already accommodate reliable AI when governance is explicit, data are traceable, and assurance is verifiable.",
    "authors": [
      "Stella C. Dong"
    ],
    "categories": [
      "cs.AI",
      "cs.LG",
      "econ.GN"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08082v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08082v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.06816v1",
    "title": "Controllable Flow Matching for Online Reinforcement Learning",
    "summary": "Model-based reinforcement learning (MBRL) typically relies on modeling environment dynamics for data efficiency. However, due to the accumulation of model errors over long-horizon rollouts, such methods often face challenges in maintaining modeling stability. To address this, we propose CtrlFlow, a trajectory-level synthetic method using conditional flow matching (CFM), which directly modeling the distribution of trajectories from initial states to high-return terminal states without explicitly modeling the environment transition function. Our method ensures optimal trajectory sampling by minimizing the control energy governed by the non-linear Controllability Gramian Matrix, while the generated diverse trajectory data significantly enhances the robustness and cross-task generalization of policy learning. In online settings, CtrlFlow demonstrates the better performance on common MuJoCo benchmark tasks than dynamics models and achieves superior sample efficiency compared to standard MBRL methods.",
    "authors": [
      "Bin Wang",
      "Boxiang Tao",
      "Haifeng Jing",
      "Hongbo Dou",
      "Zijian Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06816v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06816v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07947v1",
    "title": "Class-feature Watermark: A Resilient Black-box Watermark Against Model Extraction Attacks",
    "summary": "Machine learning models constitute valuable intellectual property, yet remain vulnerable to model extraction attacks (MEA), where adversaries replicate their functionality through black-box queries. Model watermarking counters MEAs by embedding forensic markers for ownership verification. Current black-box watermarks prioritize MEA survival through representation entanglement, yet inadequately explore resilience against sequential MEAs and removal attacks. Our study reveals that this risk is underestimated because existing removal methods are weakened by entanglement. To address this gap, we propose Watermark Removal attacK (WRK), which circumvents entanglement constraints by exploiting decision boundaries shaped by prevailing sample-level watermark artifacts. WRK effectively reduces watermark success rates by at least 88.79% across existing watermarking benchmarks.   For robust protection, we propose Class-Feature Watermarks (CFW), which improve resilience by leveraging class-level artifacts. CFW constructs a synthetic class using out-of-domain samples, eliminating vulnerable decision boundaries between original domain samples and their artifact-modified counterparts (watermark samples). CFW concurrently optimizes both MEA transferability and post-MEA stability. Experiments across multiple domains show that CFW consistently outperforms prior methods in resilience, maintaining a watermark success rate of at least 70.15% in extracted models even under the combined MEA and WRK distortion, while preserving the utility of protected models.",
    "authors": [
      "Yaxin Xiao",
      "Qingqing Ye",
      "Zi Liang",
      "Haoyang Li",
      "RongHua Li",
      "Huadi Zheng",
      "Haibo Hu"
    ],
    "categories": [
      "cs.CR",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07947v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07947v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.08207v1",
    "title": "FedPoP: Federated Learning Meets Proof of Participation",
    "summary": "Federated learning (FL) offers privacy preserving, distributed machine learning, allowing clients to contribute to a global model without revealing their local data. As models increasingly serve as monetizable digital assets, the ability to prove participation in their training becomes essential for establishing ownership. In this paper, we address this emerging need by introducing FedPoP, a novel FL framework that allows nonlinkable proof of participation while preserving client anonymity and privacy without requiring either extensive computations or a public ledger. FedPoP is designed to seamlessly integrate with existing secure aggregation protocols to ensure compatibility with real-world FL deployments. We provide a proof of concept implementation and an empirical evaluation under realistic client dropouts. In our prototype, FedPoP introduces 0.97 seconds of per-round overhead atop securely aggregated FL and enables a client to prove its participation/contribution to a model held by a third party in 0.0612 seconds. These results indicate FedPoP is practical for real-world deployments that require auditable participation without sacrificing privacy.",
    "authors": [
      "Devriş İşler",
      "Elina van Kempen",
      "Seoyeon Hwang",
      "Nikolaos Laoutaris"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08207v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08207v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.08085v1",
    "title": "BARD10: A New Benchmark Reveals Significance of Bangla Stop-Words in Authorship Attribution",
    "summary": "This research presents a comprehensive investigation into Bangla authorship attribution, introducing a new balanced benchmark corpus BARD10 (Bangla Authorship Recognition Dataset of 10 authors) and systematically analyzing the impact of stop-word removal across classical and deep learning models to uncover the stylistic significance of Bangla stop-words. BARD10 is a curated corpus of Bangla blog and opinion prose from ten contemporary authors, alongside the methodical assessment of four representative classifiers: SVM (Support Vector Machine), Bangla BERT (Bidirectional Encoder Representations from Transformers), XGBoost, and a MLP (Multilayer Perception), utilizing uniform preprocessing on both BARD10 and the benchmark corpora BAAD16 (Bangla Authorship Attribution Dataset of 16 authors). In all datasets, the classical TF-IDF + SVM baseline outperformed, attaining a macro-F1 score of 0.997 on BAAD16 and 0.921 on BARD10, while Bangla BERT lagged by as much as five points. This study reveals that BARD10 authors are highly sensitive to stop-word pruning, while BAAD16 authors remain comparatively robust highlighting genre-dependent reliance on stop-word signatures. Error analysis revealed that high frequency components transmit authorial signatures that are diminished or reduced by transformer models. Three insights are identified: Bangla stop-words serve as essential stylistic indicators; finely calibrated ML models prove effective within short-text limitations; and BARD10 connects formal literature with contemporary web dialogue, offering a reproducible benchmark for future long-context or domain-adapted transformers.",
    "authors": [
      "Abdullah Muhammad Moosa",
      "Nusrat Sultana",
      "Mahdi Muhammad Moosa",
      "Md. Miraiz Hossain"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08085v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08085v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07112v1",
    "title": "More Agents Helps but Adversarial Robustness Gap Persists",
    "summary": "When LLM agents work together, they seem to be more powerful than a single LLM in mathematical question answering. However, are they also more robust to adversarial inputs? We investigate this question using adversarially perturbed math questions. These perturbations include punctuation noise with three intensities (10, 30, and 50 percent), plus real-world and human-like typos (WikiTypo, R2ATA). Using a unified sampling-and-voting framework (Agent Forest), we evaluate six open-source models (Qwen3-4B/14B, Llama3.1-8B, Mistral-7B, Gemma3-4B/12B) across four benchmarks (GSM8K, MATH, MMLU-Math, MultiArith), with various numbers of agents n from one to 25 (1, 2, 5, 10, 15, 20, 25). Our findings show that (1) Noise type matters: punctuation noise harm scales with its severity, and the human typos remain the dominant bottleneck, yielding the largest gaps to Clean accuracy and the highest ASR even with a large number of agents. And (2) Collaboration reliably improves accuracy as the number of agents, n, increases, with the largest gains from one to five agents and diminishing returns beyond 10 agents. However, the adversarial robustness gap persists regardless of the agent count.",
    "authors": [
      "Khashayar Alavi",
      "Zhastay Yeltay",
      "Lucie Flek",
      "Akbar Karimi"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07112v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07112v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07585v1",
    "title": "LLM Output Drift: Cross-Provider Validation & Mitigation for Financial Workflows",
    "summary": "Financial institutions deploy Large Language Models (LLMs) for reconciliations, regulatory reporting, and client communications, but nondeterministic outputs (output drift) undermine auditability and trust. We quantify drift across five model architectures (7B-120B parameters) on regulated financial tasks, revealing a stark inverse relationship: smaller models (Granite-3-8B, Qwen2.5-7B) achieve 100% output consistency at T=0.0, while GPT-OSS-120B exhibits only 12.5% consistency (95% CI: 3.5-36.0%) regardless of configuration (p<0.0001, Fisher's exact test). This finding challenges conventional assumptions that larger models are universally superior for production deployment.   Our contributions include: (i) a finance-calibrated deterministic test harness combining greedy decoding (T=0.0), fixed seeds, and SEC 10-K structure-aware retrieval ordering; (ii) task-specific invariant checking for RAG, JSON, and SQL outputs using finance-calibrated materiality thresholds (plus or minus 5%) and SEC citation validation; (iii) a three-tier model classification system enabling risk-appropriate deployment decisions; and (iv) an audit-ready attestation system with dual-provider validation.   We evaluated five models (Qwen2.5-7B via Ollama, Granite-3-8B via IBM watsonx.ai, Llama-3.3-70B, Mistral-Medium-2505, and GPT-OSS-120B) across three regulated financial tasks. Across 480 runs (n=16 per condition), structured tasks (SQL) remain stable even at T=0.2, while RAG tasks show drift (25-75%), revealing task-dependent sensitivity. Cross-provider validation confirms deterministic behavior transfers between local and cloud deployments. We map our framework to Financial Stability Board (FSB), Bank for International Settlements (BIS), and Commodity Futures Trading Commission (CFTC) requirements, demonstrating practical pathways for compliance-ready AI deployments.",
    "authors": [
      "Raffi Khatchadourian",
      "Rolando Franco"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07585v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07585v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.08136v1",
    "title": "SafeMIL: Learning Offline Safe Imitation Policy from Non-Preferred Trajectories",
    "summary": "In this work, we study the problem of offline safe imitation learning (IL). In many real-world settings, online interactions can be risky, and accurately specifying the reward and the safety cost information at each timestep can be difficult. However, it is often feasible to collect trajectories reflecting undesirable or risky behavior, implicitly conveying the behavior the agent should avoid. We refer to these trajectories as non-preferred trajectories. Unlike standard IL, which aims to mimic demonstrations, our agent must also learn to avoid risky behavior using non-preferred trajectories. In this paper, we propose a novel approach, SafeMIL, to learn a parameterized cost that predicts if the state-action pair is risky via \\textit{Multiple Instance Learning}. The learned cost is then used to avoid non-preferred behaviors, resulting in a policy that prioritizes safety. We empirically demonstrate that our approach can learn a safer policy that satisfies cost constraints without degrading the reward performance, thereby outperforming several baselines.",
    "authors": [
      "Returaj Burnwal",
      "Nirav Pravinbhai Bhatt",
      "Balaraman Ravindran"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08136v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08136v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.07011v1",
    "title": "Multilingual Lexical Feature Analysis of Spoken Language for Predicting Major Depression Symptom Severity",
    "summary": "Background: Captured between clinical appointments using mobile devices, spoken language has potential for objective, more regular assessment of symptom severity and earlier detection of relapse in major depressive disorder. However, research to date has largely been in non-clinical cross-sectional samples of written language using complex machine learning (ML) approaches with limited interpretability.   Methods: We describe an initial exploratory analysis of longitudinal speech data and PHQ-8 assessments from 5,836 recordings of 586 participants in the UK, Netherlands, and Spain, collected in the RADAR-MDD study. We sought to identify interpretable lexical features associated with MDD symptom severity with linear mixed-effects modelling. Interpretable features and high-dimensional vector embeddings were also used to test the prediction performance of four regressor ML models.   Results: In English data, MDD symptom severity was associated with 7 features including lexical diversity measures and absolutist language. In Dutch, associations were observed with words per sentence and positive word frequency; no associations were observed in recordings collected in Spain. The predictive power of lexical features and vector embeddings was near chance level across all languages.   Limitations: Smaller samples in non-English speech and methodological choices, such as the elicitation prompt, may have also limited the effect sizes observable. A lack of NLP tools in languages other than English restricted our feature choice.   Conclusion: To understand the value of lexical markers in clinical research and practice, further research is needed in larger samples across several languages using improved protocols, and ML models that account for within- and between-individual variations in language.",
    "authors": [
      "Anastasiia Tokareva",
      "Judith Dineley",
      "Zoe Firth",
      "Pauline Conde",
      "Faith Matcham",
      "Sara Siddi",
      "Femke Lamers",
      "Ewan Carr",
      "Carolin Oetzmann",
      "Daniel Leightley",
      "Yuezhou Zhang",
      "Amos A. Folarin",
      "Josep Maria Haro",
      "Brenda W. J. H. Penninx",
      "Raquel Bailon",
      "Srinivasan Vairavan",
      "Til Wykes",
      "Richard J. B. Dobson",
      "Vaibhav A. Narayan",
      "Matthew Hotopf",
      "Nicholas Cummins",
      "The RADAR-CNS Consortium"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07011v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07011v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.06700v1",
    "title": "Place Matters: Comparing LLM Hallucination Rates for Place-Based Legal Queries",
    "summary": "How do we make a meaningful comparison of a large language model's knowledge of the law in one place compared to another? Quantifying these differences is critical to understanding if the quality of the legal information obtained by users of LLM-based chatbots varies depending on their location. However, obtaining meaningful comparative metrics is challenging because legal institutions in different places are not themselves easily comparable. In this work we propose a methodology to obtain place-to-place metrics based on the comparative law concept of functionalism. We construct a dataset of factual scenarios drawn from Reddit posts by users seeking legal advice for family, housing, employment, crime and traffic issues. We use these to elicit a summary of a law from the LLM relevant to each scenario in Los Angeles, London and Sydney. These summaries, typically of a legislative provision, are manually evaluated for hallucinations. We show that the rate of hallucination of legal information by leading closed-source LLMs is significantly associated with place. This suggests that the quality of legal solutions provided by these models is not evenly distributed across geography. Additionally, we show a strong negative correlation between hallucination rate and the frequency of the majority response when the LLM is sampled multiple times, suggesting a measure of uncertainty of model predictions of legal facts.",
    "authors": [
      "Damian Curran",
      "Vanessa Sporne",
      "Lea Frermann",
      "Jeannie Paterson"
    ],
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06700v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06700v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.06698v1",
    "title": "Lassoed Forests: Random Forests with Adaptive Lasso Post-selection",
    "summary": "Random forests are a statistical learning technique that use bootstrap aggregation to average high-variance and low-bias trees. Improvements to random forests, such as applying Lasso regression to the tree predictions, have been proposed in order to reduce model bias. However, these changes can sometimes degrade performance (e.g., an increase in mean squared error). In this paper, we show in theory that the relative performance of these two methods, standard and Lasso-weighted random forests, depends on the signal-to-noise ratio. We further propose a unified framework to combine random forests and Lasso selection by applying adaptive weighting and show mathematically that it can strictly outperform the other two methods. We compare the three methods through simulation, including bias-variance decomposition, error estimates evaluation, and variable importance analysis. We also show the versatility of our method by applications to a variety of real-world datasets.",
    "authors": [
      "Jing Shang",
      "James Bannon",
      "Benjamin Haibe-Kains",
      "Robert Tibshirani"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06698v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06698v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.07689v1",
    "title": "Stress Testing Factual Consistency Metrics for Long-Document Summarization",
    "summary": "Evaluating the factual consistency of abstractive text summarization remains a significant challenge, particularly for long documents, where conventional metrics struggle with input length limitations and long-range dependencies. In this work, we systematically evaluate the reliability of six widely used reference-free factuality metrics, originally proposed for short-form summarization, in the long-document setting. We probe metric robustness through seven factuality-preserving perturbations applied to summaries, namely paraphrasing, simplification, synonym replacement, logically equivalent negations, vocabulary reduction, compression, and source text insertion, and further analyze their sensitivity to retrieval context and claim information density. Across three long-form benchmark datasets spanning science fiction, legal, and scientific domains, our results reveal that existing short-form metrics produce inconsistent scores for semantically equivalent summaries and exhibit declining reliability for information-dense claims whose content is semantically similar to many parts of the source document. While expanding the retrieval context improves stability in some domains, no metric consistently maintains factual alignment under long-context conditions. Finally, our results highlight concrete directions for improving factuality evaluation, including multi-span reasoning, context-aware calibration, and training on meaning-preserving variations to enhance robustness in long-form summarization. We release all code, perturbed data, and scripts required to reproduce our results at https://github.com/zainmujahid/metricEval-longSum.",
    "authors": [
      "Zain Muhammad Mujahid",
      "Dustin Wright",
      "Isabelle Augenstein"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07689v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07689v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.06641v1",
    "title": "Neyman-Pearson Classification under Both Null and Alternative Distributions Shift",
    "summary": "We consider the problem of transfer learning in Neyman-Pearson classification, where the objective is to minimize the error w.r.t. a distribution $μ_1$, subject to the constraint that the error w.r.t. a distribution $μ_0$ remains below a prescribed threshold. While transfer learning has been extensively studied in traditional classification, transfer learning in imbalanced classification such as Neyman-Pearson classification has received much less attention. This setting poses unique challenges, as both types of errors must be simultaneously controlled. Existing works address only the case of distribution shift in $μ_1$, whereas in many practical scenarios shifts may occur in both $μ_0$ and $μ_1$. We derive an adaptive procedure that not only guarantees improved Type-I and Type-II errors when the source is informative, but also automatically adapt to situations where the source is uninformative, thereby avoiding negative transfer. In addition to such statistical guarantees, the procedures is efficient, as shown via complementary computational guarantees.",
    "authors": [
      "Mohammadreza M. Kalan",
      "Yuyang Deng",
      "Eitan J. Neugut",
      "Samory Kpotufe"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06641v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06641v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.07325v1",
    "title": "Garbage Vulnerable Point Monitoring using IoT and Computer Vision",
    "summary": "This paper proposes a smart way to manage municipal solid waste by using the Internet of Things (IoT) and computer vision (CV) to monitor illegal waste dumping at garbage vulnerable points (GVPs) in urban areas. The system can quickly detect and monitor dumped waste using a street-level camera and object detection algorithm. Data was collected from the Sangareddy district in Telangana, India. A series of comprehensive experiments was carried out using the proposed dataset to assess the accuracy and overall performance of various object detection models. Specifically, we performed an in-depth evaluation of YOLOv8, YOLOv10, YOLO11m, and RT-DETR on our dataset. Among these models, YOLO11m achieved the highest accuracy of 92.39\\% in waste detection, demonstrating its effectiveness in detecting waste. Additionally, it attains an mAP@50 of 0.91, highlighting its high precision. These findings confirm that the object detection model is well-suited for monitoring and tracking waste dumping events at GVP locations. Furthermore, the system effectively captures waste disposal patterns, including hourly, daily, and weekly dumping trends, ensuring comprehensive daily and nightly monitoring.",
    "authors": [
      "R. Kumar",
      "A. Lall",
      "S. Chaudhari",
      "M. Kale",
      "A. Vattem"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07325v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07325v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.07865v1",
    "title": "LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost",
    "summary": "Chaos Engineering (CE) is an engineering technique aimed at improving the resilience of distributed systems. It involves intentionally injecting faults into a system to test its resilience, uncover weaknesses, and address them before they cause failures in production. Recent CE tools automate the execution of predefined CE experiments. However, planning such experiments and improving the system based on the experimental results still remain manual. These processes are labor-intensive and require multi-domain expertise. To address these challenges and enable anyone to build resilient systems at low cost, this paper proposes ChaosEater, a system that automates the entire CE cycle with Large Language Models (LLMs). It predefines an agentic workflow according to a systematic CE cycle and assigns subdivided processes within the workflow to LLMs. ChaosEater targets CE for software systems built on Kubernetes. Therefore, the LLMs in ChaosEater complete CE cycles through software engineering tasks, including requirement definition, code generation, testing, and debugging. We evaluate ChaosEater through case studies on small- and large-scale Kubernetes systems. The results demonstrate that it consistently completes reasonable CE cycles with significantly low time and monetary costs. Its cycles are also qualitatively validated by human engineers and LLMs.",
    "authors": [
      "Daisuke Kikuta",
      "Hiroki Ikeuchi",
      "Kengo Tajiri"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07865v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07865v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.08015v1",
    "title": "Invisible Triggers, Visible Threats! Road-Style Adversarial Creation Attack for Visual 3D Detection in Autonomous Driving",
    "summary": "Modern autonomous driving (AD) systems leverage 3D object detection to perceive foreground objects in 3D environments for subsequent prediction and planning. Visual 3D detection based on RGB cameras provides a cost-effective solution compared to the LiDAR paradigm. While achieving promising detection accuracy, current deep neural network-based models remain highly susceptible to adversarial examples. The underlying safety concerns motivate us to investigate realistic adversarial attacks in AD scenarios. Previous work has demonstrated the feasibility of placing adversarial posters on the road surface to induce hallucinations in the detector. However, the unnatural appearance of the posters makes them easily noticeable by humans, and their fixed content can be readily targeted and defended. To address these limitations, we propose the AdvRoad to generate diverse road-style adversarial posters. The adversaries have naturalistic appearances resembling the road surface while compromising the detector to perceive non-existent objects at the attack locations. We employ a two-stage approach, termed Road-Style Adversary Generation and Scenario-Associated Adaptation, to maximize the attack effectiveness on the input scene while ensuring the natural appearance of the poster, allowing the attack to be carried out stealthily without drawing human attention. Extensive experiments show that AdvRoad generalizes well to different detectors, scenes, and spoofing locations. Moreover, physical attacks further demonstrate the practical threats in real-world environments.",
    "authors": [
      "Jian Wang",
      "Lijun He",
      "Yixing Yong",
      "Haixia Bi",
      "Fan Li"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08015v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08015v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.08368v1",
    "title": "A Circular Argument : Does RoPE need to be Equivariant for Vision?",
    "summary": "Rotary Positional Encodings (RoPE) have emerged as a highly effective technique for one-dimensional sequences in Natural Language Processing spurring recent progress towards generalizing RoPE to higher-dimensional data such as images and videos. The success of RoPE has been thought to be due to its positional equivariance, i.e. its status as a relative positional encoding. In this paper, we mathematically show RoPE to be one of the most general solutions for equivariant positional embedding in one-dimensional data. Moreover, we show Mixed RoPE to be the analogously general solution for M-dimensional data, if we require commutative generators -- a property necessary for RoPE's equivariance. However, we question whether strict equivariance plays a large role in RoPE's performance. We propose Spherical RoPE, a method analogous to Mixed RoPE, but assumes non-commutative generators. Empirically, we find Spherical RoPE to have the equivalent or better learning behavior compared to its equivariant analogues. This suggests that relative positional embeddings are not as important as is commonly believed, at least within computer vision. We expect this discovery to facilitate future work in positional encodings for vision that can be faster and generalize better by removing the preconception that they must be relative.",
    "authors": [
      "Chase van de Geijn",
      "Timo Lüddecke",
      "Polina Turishcheva",
      "Alexander S. Ecker"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08368v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08368v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.06895v1",
    "title": "On The Presence of Double-Descent in Deep Reinforcement Learning",
    "summary": "The double descent (DD) paradox, where over-parameterized models see generalization improve past the interpolation point, remains largely unexplored in the non-stationary domain of Deep Reinforcement Learning (DRL). We present preliminary evidence that DD exists in model-free DRL, investigating it systematically across varying model capacity using the Actor-Critic framework. We rely on an information-theoretic metric, Policy Entropy, to measure policy uncertainty throughout training. Preliminary results show a clear epoch-wise DD curve; the policy's entrance into the second descent region correlates with a sustained, significant reduction in Policy Entropy. This entropic decay suggests that over-parameterization acts as an implicit regularizer, guiding the policy towards robust, flatter minima in the loss landscape. These findings establish DD as a factor in DRL and provide an information-based mechanism for designing agents that are more general, transferable, and robust.",
    "authors": [
      "Viktor Veselý",
      "Aleksandar Todorov",
      "Matthia Sabatelli"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06895v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06895v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.07270v1",
    "title": "High-Dimensional Asymptotics of Differentially Private PCA",
    "summary": "In differential privacy, statistics of a sensitive dataset are privatized by introducing random noise. Most privacy analyses provide privacy bounds specifying a noise level sufficient to achieve a target privacy guarantee. Sometimes, these bounds are pessimistic and suggest adding excessive noise, which overwhelms the meaningful signal. It remains unclear if such high noise levels are truly necessary or a limitation of the proof techniques. This paper explores whether we can obtain sharp privacy characterizations that identify the smallest noise level required to achieve a target privacy level for a given mechanism. We study this problem in the context of differentially private principal component analysis, where the goal is to privatize the leading principal components (PCs) of a dataset with n samples and p features. We analyze the exponential mechanism for this problem in a model-free setting and provide sharp utility and privacy characterizations in the high-dimensional limit ($p\\rightarrow\\infty$). Our privacy result shows that, in high dimensions, detecting the presence of a target individual in the dataset using the privatized PCs is exactly as hard as distinguishing two Gaussians with slightly different means, where the mean difference depends on certain spectral properties of the dataset. Our privacy analysis combines the hypothesis-testing formulation of privacy guarantees proposed by Dong, Roth, and Su (2022) with classical contiguity arguments due to Le Cam to obtain sharp high-dimensional privacy characterizations.",
    "authors": [
      "Youngjoo Yun",
      "Rishabh Dudeja"
    ],
    "categories": [
      "math.ST",
      "cs.IT",
      "cs.LG",
      "math.PR",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07270v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07270v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.07899v1",
    "title": "Statistically Assuring Safety of Control Systems using Ensembles of Safety Filters and Conformal Prediction",
    "summary": "Safety assurance is a fundamental requirement for deploying learning-enabled autonomous systems. Hamilton-Jacobi (HJ) reachability analysis is a fundamental method for formally verifying safety and generating safe controllers. However, computing the HJ value function that characterizes the backward reachable set (BRS) of a set of user-defined failure states is computationally expensive, especially for high-dimensional systems, motivating the use of reinforcement learning approaches to approximate the value function. Unfortunately, a learned value function and its corresponding safe policy are not guaranteed to be correct. The learned value function evaluated at a given state may not be equal to the actual safety return achieved by following the learned safe policy. To address this challenge, we introduce a conformal prediction-based (CP) framework that bounds such uncertainty. We leverage CP to provide probabilistic safety guarantees when using learned HJ value functions and policies to prevent control systems from reaching failure states. Specifically, we use CP to calibrate the switching between the unsafe nominal controller and the learned HJ-based safe policy and to derive safety guarantees under this switched policy. We also investigate using an ensemble of independently trained HJ value functions as a safety filter and compare this ensemble approach to using individual value functions alone.",
    "authors": [
      "Ihab Tabbara",
      "Yuxuan Yang",
      "Hussein Sibai"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "eess.SY"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07899v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07899v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08307v1",
    "title": "Concentration bounds on response-based vector embeddings of black-box generative models",
    "summary": "Generative models, such as large language models or text-to-image diffusion models, can generate relevant responses to user-given queries. Response-based vector embeddings of generative models facilitate statistical analysis and inference on a given collection of black-box generative models. The Data Kernel Perspective Space embedding is one particular method of obtaining response-based vector embeddings for a given set of generative models, already discussed in the literature. In this paper, under appropriate regularity conditions, we establish high probability concentration bounds on the sample vector embeddings for a given set of generative models, obtained through the method of Data Kernel Perspective Space embedding. Our results tell us the required number of sample responses needed in order to approximate the population-level vector embeddings with a desired level of accuracy. The algebraic tools used to establish our results can be used further for establishing concentration bounds on Classical Multidimensional Scaling embeddings in general, when the dissimilarities are observed with noise.",
    "authors": [
      "Aranyak Acharyya",
      "Joshua Agterberg",
      "Youngser Park",
      "Carey E. Priebe"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08307v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08307v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08275v1",
    "title": "Bi-Objective Evolutionary Optimization for Large-Scale Open Pit Mine Scheduling Problem under Uncertainty with Chance Constraints",
    "summary": "The open-pit mine scheduling problem (OPMSP) is a complex, computationally expensive process in long-term mine planning, constrained by operational and geological dependencies. Traditional deterministic approaches often ignore geological uncertainty, leading to suboptimal and potentially infeasible production schedules. Chance constraints allow modeling of stochastic components by ensuring probabilistic constraints are satisfied with high probability. This paper presents a bi-objective formulation of the OPMSP that simultaneously maximizes expected net present value and minimizes scheduling risk, independent of the confidence level required for the constraint. Solutions are represented using integer encoding, inherently satisfying reserve constraints. We introduce a domain-specific greedy randomized initialization and a precedence-aware period-swap mutation operator. We integrate these operators into three multi-objective evolutionary algorithms: the global simple evolutionary multi-objective optimizer (GSEMO), a mutation-only variant of multi-objective evolutionary algorithm based on decomposition (MOEA/D), and non-dominated sorting genetic algorithm II (NSGA-II). We compare our bi-objective formulation against the single-objective approach, which depends on a specific confidence level, by analyzing mine deposits consisting of up to 112 687 blocks. Results demonstrate that the proposed bi-objective formulation yields more robust and balanced trade-offs between economic value and risk compared to single-objective, confidence-dependent approach.",
    "authors": [
      "Ishara Hewa Pathiranage",
      "Aneta Neumann"
    ],
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08275v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08275v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08585v1",
    "title": "Simulating the Visual World with Artificial Intelligence: A Roadmap",
    "summary": "The landscape of video generation is shifting, from a focus on generating visually appealing clips to building virtual environments that support interaction and maintain physical plausibility. These developments point toward the emergence of video foundation models that function not only as visual generators but also as implicit world models, models that simulate the physical dynamics, agent-environment interactions, and task planning that govern real or imagined worlds. This survey provides a systematic overview of this evolution, conceptualizing modern video foundation models as the combination of two core components: an implicit world model and a video renderer. The world model encodes structured knowledge about the world, including physical laws, interaction dynamics, and agent behavior. It serves as a latent simulation engine that enables coherent visual reasoning, long-term temporal consistency, and goal-driven planning. The video renderer transforms this latent simulation into realistic visual observations, effectively producing videos as a \"window\" into the simulated world. We trace the progression of video generation through four generations, in which the core capabilities advance step by step, ultimately culminating in a world model, built upon a video generation model, that embodies intrinsic physical plausibility, real-time multimodal interaction, and planning capabilities spanning multiple spatiotemporal scales. For each generation, we define its core characteristics, highlight representative works, and examine their application domains such as robotics, autonomous driving, and interactive gaming. Finally, we discuss open challenges and design principles for next-generation world models, including the role of agent intelligence in shaping and evaluating these systems. An up-to-date list of related works is maintained at this link.",
    "authors": [
      "Jingtong Yue",
      "Ziqi Huang",
      "Zhaoxi Chen",
      "Xintao Wang",
      "Pengfei Wan",
      "Ziwei Liu"
    ],
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08585v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08585v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08570v1",
    "title": "Automatic Grid Updates for Kolmogorov-Arnold Networks using Layer Histograms",
    "summary": "Kolmogorov-Arnold Networks (KANs) are a class of neural networks that have received increased attention in recent literature. In contrast to MLPs, KANs leverage parameterized, trainable activation functions and offer several benefits including improved interpretability and higher accuracy on learning symbolic equations. However, the original KAN architecture requires adjustments to the domain discretization of the network (called the \"domain grid\") during training, creating extra overhead for the user in the training process. Typical KAN layers are not designed with the ability to autonomously update their domains in a data-driven manner informed by the changing output ranges of previous layers. As an added benefit, this histogram algorithm may also be applied towards detecting out-of-distribution (OOD) inputs in a variety of settings. We demonstrate that AdaptKAN exceeds or matches the performance of prior KAN architectures and MLPs on four different tasks: learning scientific equations from the Feynman dataset, image classification from frozen features, learning a control Lyapunov function, and detecting OOD inputs on the OpenOOD v1.5 benchmark.",
    "authors": [
      "Jamison Moody",
      "James Usevitch"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08570v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08570v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06906v1",
    "title": "Counterfactual Explanation for Multivariate Time Series Forecasting with Exogenous Variables",
    "summary": "Currently, machine learning is widely used across various domains, including time series data analysis. However, some machine learning models function as black boxes, making interpretability a critical concern. One approach to address this issue is counterfactual explanation (CE), which aims to provide insights into model predictions. This study focuses on the relatively underexplored problem of generating counterfactual explanations for time series forecasting. We propose a method for extracting CEs in time series forecasting using exogenous variables, which are frequently encountered in fields such as business and marketing. In addition, we present methods for analyzing the influence of each variable over an entire time series, generating CEs by altering only specific variables, and evaluating the quality of the resulting CEs. We validate the proposed method through theoretical analysis and empirical experiments, showcasing its accuracy and practical applicability. These contributions are expected to support real-world decision-making based on time series data analysis.",
    "authors": [
      "Keita Kinjo"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06906v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06906v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06585v1",
    "title": "Learning Biomolecular Motion: The Physics-Informed Machine Learning Paradigm",
    "summary": "The convergence of statistical learning and molecular physics is transforming our approach to modeling biomolecular systems. Physics-informed machine learning (PIML) offers a systematic framework that integrates data-driven inference with physical constraints, resulting in models that are accurate, mechanistic, generalizable, and able to extrapolate beyond observed domains. This review surveys recent advances in physics-informed neural networks and operator learning, differentiable molecular simulation, and hybrid physics-ML potentials, with emphasis on long-timescale kinetics, rare events, and free-energy estimation. We frame these approaches as solutions to the \"biomolecular closure problem\", recovering unresolved interactions beyond classical force fields while preserving thermodynamic consistency and mechanistic interpretability. We examine theoretical foundations, tools and frameworks, computational trade-offs, and unresolved issues, including model expressiveness and stability. We outline prospective research avenues at the intersection of machine learning, statistical physics, and computational chemistry, contending that future advancements will depend on mechanistic inductive biases, and integrated differentiable physical learning frameworks for biomolecular simulation and discovery.",
    "authors": [
      "Aaryesh Deshpande"
    ],
    "categories": [
      "q-bio.BM",
      "cs.LG",
      "physics.comp-ph",
      "stat.ML"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06585v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06585v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08120v1",
    "title": "A robust methodology for long-term sustainability evaluation of Machine Learning models",
    "summary": "Sustainability and efficiency have become essential considerations in the development and deployment of Artificial Intelligence systems, yet existing regulatory and reporting practices lack standardized, model-agnostic evaluation protocols. Current assessments often measure only short-term experimental resource usage and disproportionately emphasize batch learning settings, failing to reflect real-world, long-term AI lifecycles. In this work, we propose a comprehensive evaluation protocol for assessing the long-term sustainability of ML models, applicable to both batch and streaming learning scenarios. Through experiments on diverse classification tasks using a range of model types, we demonstrate that traditional static train-test evaluations do not reliably capture sustainability under evolving data and repeated model updates. Our results show that long-term sustainability varies significantly across models, and in many cases, higher environmental cost yields little performance benefit.",
    "authors": [
      "Jorge Paz-Ruza",
      "João Gama",
      "Amparo Alonso-Betanzos",
      "Bertha Guijarro-Berdiñas"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08120v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08120v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08066v1",
    "title": "Information Capacity: Evaluating the Efficiency of Large Language Models via Text Compression",
    "summary": "Recent years have witnessed the rapid advancements of large language models (LLMs) and their expanding applications, leading to soaring demands for computational resources. The widespread adoption of test-time scaling further aggravates the tension between model capability and resource consumption, highlighting the importance of inference efficiency. However, a unified metric that accurately reflects an LLM's efficiency across different model sizes and architectures remains absent. Motivated by the correlation between compression and intelligence, we introduce information capacity, a measure of model efficiency based on text compression performance relative to computational complexity. Larger models can predict the next token more accurately, achieving greater compression gains but at higher computational costs. Empirical evaluations on mainstream open-source models show that models of varying sizes within a series exhibit consistent information capacity. This metric enables a fair efficiency comparison across model series and accurate performance prediction within a model series. A distinctive feature of information capacity is that it incorporates tokenizer efficiency, which affects both input and output token counts but is often neglected in LLM evaluations. We assess the information capacity of 49 models on 5 heterogeneous datasets and observe consistent results on the influences of tokenizer efficiency, pretraining data, and the mixture-of-experts architecture.",
    "authors": [
      "Cheng Yuan",
      "Jiawei Shao",
      "Chi Zhang",
      "Xuelong Li"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "eess.SP"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08066v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08066v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.06780v1",
    "title": "OntoTune: Ontology-Driven Learning for Query Optimization with Convolutional Models",
    "summary": "Query optimization has been studied using machine learning, reinforcement learning, and, more recently, graph-based convolutional networks. Ontology, as a structured, information-rich knowledge representation, can provide context, particularly in learning problems. This paper presents OntoTune, an ontology-based platform for enhancing learning for query optimization. By connecting SQL queries, database metadata, and statistics, the ontology developed in this research is promising in capturing relationships and important determinants of query performance. This research also develops a method to embed ontologies while preserving as much of the relationships and key information as possible, before feeding it into learning algorithms such as tree-based and graph-based convolutional networks. A case study shows how OntoTune's ontology-driven learning delivers performance gains compared with database system default query execution.",
    "authors": [
      "Songhui Yue",
      "Yang Shao",
      "Sean Hayes"
    ],
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06780v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06780v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.07298v1",
    "title": "LMM-IQA: Image Quality Assessment for Low-Dose CT Imaging",
    "summary": "Low-dose computed tomography (CT) represents a significant improvement in patient safety through lower radiation doses, but increased noise, blur, and contrast loss can diminish diagnostic quality. Therefore, consistency and robustness in image quality assessment become essential for clinical applications. In this study, we propose an LLM-based quality assessment system that generates both numerical scores and textual descriptions of degradations such as noise, blur, and contrast loss. Furthermore, various inference strategies - from the zero-shot approach to metadata integration and error feedback - are systematically examined, demonstrating the progressive contribution of each method to overall performance. The resultant assessments yield not only highly correlated scores but also interpretable output, thereby adding value to clinical workflows. The source codes of our study are available at https://github.com/itu-biai/lmms_ldct_iqa.",
    "authors": [
      "Kagan Celik",
      "Mehmet Ozan Unal",
      "Metin Ertas",
      "Isa Yildirim"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07298v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07298v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.07884v1",
    "title": "Meta-cognitive Multi-scale Hierarchical Reasoning for Motor Imagery Decoding",
    "summary": "Brain-computer interface (BCI) aims to decode motor intent from noninvasive neural signals to enable control of external devices, but practical deployment remains limited by noise and variability in motor imagery (MI)-based electroencephalogram (EEG) signals. This work investigates a hierarchical and meta-cognitive decoding framework for four-class MI classification. We introduce a multi-scale hierarchical signal processing module that reorganizes backbone features into temporal multi-scale representations, together with an introspective uncertainty estimation module that assigns per-cycle reliability scores and guides iterative refinement. We instantiate this framework on three standard EEG backbones (EEGNet, ShallowConvNet, and DeepConvNet) and evaluate four-class MI decoding using the BCI Competition IV-2a dataset under a subject-independent setting. Across all backbones, the proposed components improve average classification accuracy and reduce inter-subject variance compared to the corresponding baselines, indicating increased robustness to subject heterogeneity and noisy trials. These results suggest that combining hierarchical multi-scale processing with introspective confidence estimation can enhance the reliability of MI-based BCI systems.",
    "authors": [
      "Si-Hyun Kim",
      "Heon-Gyu Kwak",
      "Byoung-Hee Kwon",
      "Seong-Whan Lee"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07884v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07884v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.07413v1",
    "title": "DigiData: Training and Evaluating General-Purpose Mobile Control Agents",
    "summary": "AI agents capable of controlling user interfaces have the potential to transform human interaction with digital devices. To accelerate this transformation, two fundamental building blocks are essential: high-quality datasets that enable agents to achieve complex and human-relevant goals, and robust evaluation methods that allow researchers and practitioners to rapidly enhance agent performance. In this paper, we introduce DigiData, a large-scale, high-quality, diverse, multi-modal dataset designed for training mobile control agents. Unlike existing datasets, which derive goals from unstructured interactions, DigiData is meticulously constructed through comprehensive exploration of app features, resulting in greater diversity and higher goal complexity. Additionally, we present DigiData-Bench, a benchmark for evaluating mobile control agents on real-world complex tasks. We demonstrate that the commonly used step-accuracy metric falls short in reliably assessing mobile control agents and, to address this, we propose dynamic evaluation protocols and AI-powered evaluations as rigorous alternatives for agent assessment. Our contributions aim to significantly advance the development of mobile control agents, paving the way for more intuitive and effective human-device interactions.",
    "authors": [
      "Yuxuan Sun",
      "Manchen Wang",
      "Shengyi Qian",
      "William R. Wong",
      "Eric Gan",
      "Pierluca D'Oro",
      "Alejandro Castillejo Munoz",
      "Sneha Silwal",
      "Pedro Matias",
      "Nitin Kamra",
      "Satwik Kottur",
      "Nick Raines",
      "Xuanyi Zhao",
      "Joy Chen",
      "Joseph Greer",
      "Andrea Madotto",
      "Allen Bolourchi",
      "James Valori",
      "Kevin Carlberg",
      "Karl Ridgeway",
      "Joseph Tighe"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07413v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07413v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.07384v1",
    "title": "Teaching Pretrained Language Models to Think Deeper with Retrofitted Recurrence",
    "summary": "Recent advances in depth-recurrent language models show that recurrence can decouple train-time compute and parameter count from test-time compute. In this work, we study how to convert existing pretrained non-recurrent language models into depth-recurrent models. We find that using a curriculum of recurrences to increase the effective depth of the model over the course of training preserves performance while reducing total computational cost. In our experiments, on mathematics, we observe that converting pretrained models to recurrent ones results in better performance at a given compute budget than simply post-training the original non-recurrent language model.",
    "authors": [
      "Sean McLeish",
      "Ang Li",
      "John Kirchenbauer",
      "Dayal Singh Kalra",
      "Brian R. Bartoldson",
      "Bhavya Kailkhura",
      "Avi Schwarzschild",
      "Jonas Geiping",
      "Tom Goldstein",
      "Micah Goldblum"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07384v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07384v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.08565v1",
    "title": "Moral Susceptibility and Robustness under Persona Role-Play in Large Language Models",
    "summary": "Large language models (LLMs) increasingly operate in social contexts, motivating analysis of how they express and shift moral judgments. In this work, we investigate the moral response of LLMs to persona role-play, prompting a LLM to assume a specific character. Using the Moral Foundations Questionnaire (MFQ), we introduce a benchmark that quantifies two properties: moral susceptibility and moral robustness, defined from the variability of MFQ scores across and within personas, respectively. We find that, for moral robustness, model family accounts for most of the variance, while model size shows no systematic effect. The Claude family is, by a significant margin, the most robust, followed by Gemini and GPT-4 models, with other families exhibiting lower robustness. In contrast, moral susceptibility exhibits a mild family effect but a clear within-family size effect, with larger variants being more susceptible. Moreover, robustness and susceptibility are positively correlated, an association that is more pronounced at the family level. Additionally, we present moral foundation profiles for models without persona role-play and for personas averaged across models. Together, these analyses provide a systematic view of how persona conditioning shapes moral behavior in large language models.",
    "authors": [
      "Davi Bastos Costa",
      "Felippe Alves",
      "Renato Vicente"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08565v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08565v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.07312v1",
    "title": "Superhuman AI for Stratego Using Self-Play Reinforcement Learning and Test-Time Search",
    "summary": "Few classical games have been regarded as such significant benchmarks of artificial intelligence as to have justified training costs in the millions of dollars. Among these, Stratego -- a board wargame exemplifying the challenge of strategic decision making under massive amounts of hidden information -- stands apart as a case where such efforts failed to produce performance at the level of top humans. This work establishes a step change in both performance and cost for Stratego, showing that it is now possible not only to reach the level of top humans, but to achieve vastly superhuman level -- and that doing so requires not an industrial budget, but merely a few thousand dollars. We achieved this result by developing general approaches for self-play reinforcement learning and test-time search under imperfect information.",
    "authors": [
      "Samuel Sokota",
      "Eugene Vinitsky",
      "Hengyuan Hu",
      "J. Zico Kolter",
      "Gabriele Farina"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.07312v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07312v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.08086v1",
    "title": "Dynamic Sparsity: Challenging Common Sparsity Assumptions for Learning World Models in Robotic Reinforcement Learning Benchmarks",
    "summary": "The use of learned dynamics models, also known as world models, can improve the sample efficiency of reinforcement learning. Recent work suggests that the underlying causal graphs of such dynamics models are sparsely connected, with each of the future state variables depending only on a small subset of the current state variables, and that learning may therefore benefit from sparsity priors. Similarly, temporal sparsity, i.e. sparsely and abruptly changing local dynamics, has also been proposed as a useful inductive bias.   In this work, we critically examine these assumptions by analyzing ground-truth dynamics from a set of robotic reinforcement learning environments in the MuJoCo Playground benchmark suite, aiming to determine whether the proposed notions of state and temporal sparsity actually tend to hold in typical reinforcement learning tasks.   We study (i) whether the causal graphs of environment dynamics are sparse, (ii) whether such sparsity is state-dependent, and (iii) whether local system dynamics change sparsely.   Our results indicate that global sparsity is rare, but instead the tasks show local, state-dependent sparsity in their dynamics and this sparsity exhibits distinct structures, appearing in temporally localized clusters (e.g., during contact events) and affecting specific subsets of state dimensions. These findings challenge common sparsity prior assumptions in dynamics learning, emphasizing the need for grounded inductive biases that reflect the state-dependent sparsity structure of real-world dynamics.",
    "authors": [
      "Muthukumar Pandaram",
      "Jakob Hollenstein",
      "David Drexel",
      "Samuele Tosatto",
      "Antonio Rodríguez-Sánchez",
      "Justus Piater"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08086v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08086v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.06763v1",
    "title": "Sensitivity of Small Language Models to Fine-tuning Data Contamination",
    "summary": "Small Language Models (SLMs) are increasingly being deployed in resource-constrained environments, yet their behavioral robustness to data contamination during instruction tuning remains poorly understood. We systematically investigate the contamination sensitivity of 23 SLMs (270M to 4B parameters) across multiple model families by measuring susceptibility to syntactic and semantic transformation types during instruction tuning: syntactic transformations (character and word reversal) and semantic transformations (irrelevant and counterfactual responses), each applied at contamination levels of 25\\%, 50\\%, 75\\%, and 100\\%. Our results reveal fundamental asymmetries in vulnerability patterns: syntactic transformations cause catastrophic performance degradation, with character reversal producing near-complete failure across all models regardless of size or family, while semantic transformations demonstrate distinct threshold behaviors and greater resilience in core linguistic capabilities. Critically, we discover a ``\\textit{capability curse}\" where larger, more capable models become more susceptible to learning semantic corruptions, effectively following harmful instructions more readily, while our analysis of base versus instruction-tuned variants reveals that alignment provides inconsistent robustness benefits, sometimes even reducing resilience. Our work establishes three core contributions: (1) empirical evidence of SLMs' disproportionate vulnerability to syntactic pattern contamination, (2) identification of asymmetric sensitivity patterns between syntactic and semantic transformations, and (3) systematic evaluation protocols for contamination robustness assessment. These findings have immediate deployment implications, suggesting that current robustness assumptions may not hold for smaller models and highlighting the need for contamination-aware training protocols.",
    "authors": [
      "Nicy Scaria",
      "Silvester John Joseph Kennedy",
      "Deepak Subramani"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-10",
    "url": "https://arxiv.org/abs/2511.06763v1",
    "pdf_url": "https://arxiv.org/pdf/2511.06763v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.08401v1",
    "title": "Source-Optimal Training is Transfer-Suboptimal",
    "summary": "We prove a fundamental misalignment in transfer learning: the source regularization that minimizes source risk almost never coincides with the regularization maximizing transfer benefit. Through sharp phase boundaries for L2-SP ridge regression, we characterize the transfer-optimal source penalty $τ_0^*$ and show it diverges predictably from task-optimal values, requiring stronger regularization in high-SNR regimes and weaker regularization in low-SNR regimes. Additionally, in isotropic settings the decision to transfer is remarkably independent of target sample size and noise, depending only on task alignment and source characteristics. CIFAR-10 and MNIST experiments confirm this counterintuitive pattern persists in non-linear networks.",
    "authors": [
      "C. Evans Hedges"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08401v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08401v1.pdf",
    "date": "2025-11-12",
    "source": "arxiv",
    "research_score": 0.5
  }
]