[
  {
    "arxiv_id": "2512.07821v1",
    "title": "WorldReel: 4D Video Generation with Consistent Geometry and Motion Modeling",
    "summary": "Recent video generators achieve striking photorealism, yet remain fundamentally inconsistent in 3D. We present WorldReel, a 4D video generator that is natively spatio-temporally consistent. WorldReel jointly produces RGB frames together with 4D scene representations, including pointmaps, camera trajectory, and dense flow mapping, enabling coherent geometry and appearance modeling over time. Our explicit 4D representation enforces a single underlying scene that persists across viewpoints and dynamic content, yielding videos that remain consistent even under large non-rigid motion and significant camera movement. We train WorldReel by carefully combining synthetic and real data: synthetic data providing precise 4D supervision (geometry, motion, and camera), while real videos contribute visual diversity and realism. This blend allows WorldReel to generalize to in-the-wild footage while preserving strong geometric fidelity. Extensive experiments demonstrate that WorldReel sets a new state-of-the-art for consistent video generation with dynamic scenes and moving cameras, improving metrics of geometric consistency, motion coherence, and reducing view-time artifacts over competing methods. We believe that WorldReel brings video generation closer to 4D-consistent world modeling, where agents can render, interact, and reason about scenes through a single and stable spatiotemporal representation.",
    "authors": [
      "Shaoheng Fang",
      "Hanwen Jiang",
      "Yunpeng Bai",
      "Niloy J. Mitra",
      "Qixing Huang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07821v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07821v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.88
  },
  {
    "arxiv_id": "2512.07737v1",
    "title": "A scalable and real-time neural decoder for topological quantum codes",
    "summary": "Fault-tolerant quantum computing will require error rates far below those achievable with physical qubits. Quantum error correction (QEC) bridges this gap, but depends on decoders being simultaneously fast, accurate, and scalable. This combination of requirements has not yet been met by a machine-learning decoder, nor by any decoder for promising resource-efficient codes such as the colour code. Here we introduce AlphaQubit 2, a neural-network decoder that achieves near-optimal logical error rates for both surface and colour codes at large scales under realistic noise. For the colour code, it is orders of magnitude faster than other high-accuracy decoders. For the surface code, we demonstrate real-time decoding faster than 1 microsecond per cycle up to distance 11 on current commercial accelerators with better accuracy than leading real-time decoders. These results support the practical application of a wider class of promising QEC codes, and establish a credible path towards high-accuracy, real-time neural decoding at the scales required for fault-tolerant quantum computation.",
    "authors": [
      "Andrew W. Senior",
      "Thomas Edlich",
      "Francisco J. H. Heras",
      "Lei M. Zhang",
      "Oscar Higgott",
      "James S. Spencer",
      "Taylor Applebaum",
      "Sam Blackwell",
      "Justin Ledford",
      "Akvilė Žemgulytė",
      "Augustin Žídek",
      "Noah Shutty",
      "Andrew Cowie",
      "Yin Li",
      "George Holland",
      "Peter Brooks",
      "Charlie Beattie",
      "Michael Newman",
      "Alex Davies",
      "Cody Jones",
      "Sergio Boixo",
      "Hartmut Neven",
      "Pushmeet Kohli",
      "Johannes Bausch"
    ],
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07737v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07737v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.88
  },
  {
    "arxiv_id": "2512.07606v1",
    "title": "Decomposition Sampling for Efficient Region Annotations in Active Learning",
    "summary": "Active learning improves annotation efficiency by selecting the most informative samples for annotation and model training. While most prior work has focused on selecting informative images for classification tasks, we investigate the more challenging setting of dense prediction, where annotations are more costly and time-intensive, especially in medical imaging. Region-level annotation has been shown to be more efficient than image-level annotation for these tasks. However, existing methods for representative annotation region selection suffer from high computational and memory costs, irrelevant region choices, and heavy reliance on uncertainty sampling. We propose decomposition sampling (DECOMP), a new active learning sampling strategy that addresses these limitations. It enhances annotation diversity by decomposing images into class-specific components using pseudo-labels and sampling regions from each class. Class-wise predictive confidence further guides the sampling process, ensuring that difficult classes receive additional annotations. Across ROI classification, 2-D segmentation, and 3-D segmentation, DECOMP consistently surpasses baseline methods by better sampling minority-class regions and boosting performance on these challenging classes. Code is in https://github.com/JingnaQiu/DECOMP.git.",
    "authors": [
      "Jingna Qiu",
      "Frauke Wilm",
      "Mathias Öttl",
      "Jonas Utz",
      "Maja Schlereth",
      "Moritz Schillinger",
      "Marc Aubreville",
      "Katharina Breininger"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07606v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07606v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.87
  },
  {
    "arxiv_id": "2512.07795v1",
    "title": "ReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning",
    "summary": "Large language models (LLMs) are increasingly deployed in settings where reasoning, such as multi-step problem solving and chain-of-thought, is essential. Yet, current evaluation practices overwhelmingly report single-run accuracy while ignoring the intrinsic uncertainty that naturally arises from stochastic decoding. This omission creates a blind spot because practitioners cannot reliably assess whether a method's reported performance is stable, reproducible, or cost-consistent. We introduce ReasonBENCH, the first benchmark designed to quantify the underlying instability in LLM reasoning. ReasonBENCH provides (i) a modular evaluation library that standardizes reasoning frameworks, models, and tasks, (ii) a multi-run protocol that reports statistically reliable metrics for both quality and cost, and (iii) a public leaderboard to encourage variance-aware reporting. Across tasks from different domains, we find that the vast majority of reasoning strategies and models exhibit high instability. Notably, even strategies with similar average performance can display confidence intervals up to four times wider, and the top-performing methods often incur higher and less stable costs. Such instability compromises reproducibility across runs and, consequently, the reliability of reported performance. To better understand these dynamics, we further analyze the impact of prompts, model families, and scale on the trade-off between solve rate and stability. Our results highlight reproducibility as a critical dimension for reliable LLM reasoning and provide a foundation for future reasoning methods and uncertainty quantification techniques. ReasonBENCH is publicly available at https://github.com/au-clan/ReasonBench .",
    "authors": [
      "Nearchos Potamitis",
      "Lars Klein",
      "Akhil Arora"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07795v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07795v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.86
  },
  {
    "arxiv_id": "2512.07458v1",
    "title": "Optimized Machine Learning Methods for Studying the Thermodynamic Behavior of Complex Spin Systems",
    "summary": "This paper presents a systematic study of the application of convolutional neural networks (CNNs) as an efficient and versatile tool for the analysis of critical and low-temperature phase states in spin system models. The problem of calculating the dependence of the average energy on the spatial distribution of exchange integrals for the Edwards-Anderson model on a square lattice with frustrated interactions is considered. We further construct a single convolutional classifier of phase states of the ferromagnetic Ising model on square, triangular, honeycomb, and kagome lattices, trained on configurations generated by the Swendsen-Wang cluster algorithm. Computed temperature profiles of the averaged posterior probability of the high-temperature phase form clear S-shaped curves that intersect in the vicinity of the theoretical critical temperatures and allow one to determine the critical temperature for the kagome lattice without additional retraining. It is shown that convolutional models substantially reduce the root-mean-square error (RMSE) compared with fully connected architectures and efficiently capture complex correlations between thermodynamic characteristics and the structure of magnetic correlated systems.",
    "authors": [
      "Dmitrii Kapitan",
      "Pavel Ovchinnikov",
      "Konstantin Soldatov",
      "Petr Andriushchenko",
      "Vitalii Kapitan"
    ],
    "categories": [
      "physics.comp-ph",
      "cond-mat.dis-nn",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07458v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07458v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.84
  },
  {
    "arxiv_id": "2512.07461v1",
    "title": "Native Parallel Reasoner: Reasoning in Parallelism via Self-Distilled Reinforcement Learning",
    "summary": "We introduce Native Parallel Reasoner (NPR), a teacher-free framework that enables Large Language Models (LLMs) to self-evolve genuine parallel reasoning capabilities. NPR transforms the model from sequential emulation to native parallel cognition through three key innovations: 1) a self-distilled progressive training paradigm that transitions from ``cold-start'' format discovery to strict topological constraints without external supervision; 2) a novel Parallel-Aware Policy Optimization (PAPO) algorithm that optimizes branching policies directly within the execution graph, allowing the model to learn adaptive decomposition via trial and error; and 3) a robust NPR Engine that refactors memory management and flow control of SGLang to enable stable, large-scale parallel RL training. Across eight reasoning benchmarks, NPR trained on Qwen3-4B achieves performance gains of up to 24.5% and inference speedups up to 4.6x. Unlike prior baselines that often fall back to autoregressive decoding, NPR demonstrates 100% genuine parallel execution, establishing a new standard for self-evolving, efficient, and scalable agentic reasoning.",
    "authors": [
      "Tong Wu",
      "Yang Liu",
      "Jun Bai",
      "Zixia Jia",
      "Shuyi Zhang",
      "Ziyong Lin",
      "Yanting Wang",
      "Song-Chun Zhu",
      "Zilong Zheng"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07461v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07461v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2512.07419v1",
    "title": "Revolutionizing Mixed Precision Quantization: Towards Training-free Automatic Proxy Discovery via Large Language Models",
    "summary": "Mixed-Precision Quantization (MPQ) liberates the Deep Neural Networks (DNNs) from the Out-Of-Memory (OOM) bottleneck, which garnered increasing research attention. However, conventional methods either searched from costly differentiable optimization, which is neither efficient nor flexible, or learned a quantized DNN from the proxy (i.e., HAWQ) manually designed by human experts, which is labor-intensive and requires huge expert knowledge. Can we design a proxy without involving any human experts and training? In this paper, we provide an affirmative answer by proposing a novel Large Language Models (LLMs)-driven Training-free Automatic Proxy (dubbed TAP) discovery framework, which reforms the design paradigm of MPQ by utilizing LLMs to find superior TAP tailored for MPQ, automatically. In addition, to bridge the gap between black-box LLMs and the tough MPQ task, we ingeniously propose simple Direct Policy Optimization (DPO) based reinforcement learning to enhance LLMs' reasoning by optimizing prompts, which can construct a positive feedback loop between the LLM and the MPQ task, enabling LLMs to generate better TAP in the next evolution. Extensive experiments on mainstream benchmarks demonstrate that TAP achieves state-of-the-art performance. Finally, we truly believe that our TAP will significantly contribute to the MPQ community by providing a new perspective on LLM-driven design algorithms.",
    "authors": [
      "Haidong Kang",
      "Jun Du",
      "Lihong Lin"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07419v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07419v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2512.07697v1",
    "title": "Delay-Aware Diffusion Policy: Bridging the Observation-Execution Gap in Dynamic Tasks",
    "summary": "As a robot senses and selects actions, the world keeps changing. This inference delay creates a gap of tens to hundreds of milliseconds between the observed state and the state at execution. In this work, we take the natural generalization from zero delay to measured delay during training and inference. We introduce Delay-Aware Diffusion Policy (DA-DP), a framework for explicitly incorporating inference delays into policy learning. DA-DP corrects zero-delay trajectories to their delay-compensated counterparts, and augments the policy with delay conditioning. We empirically validate DA-DP on a variety of tasks, robots, and delays and find its success rate more robust to delay than delay-unaware methods. DA-DP is architecture agnostic and transfers beyond diffusion policies, offering a general pattern for delay-aware imitation learning. More broadly, DA-DP encourages evaluation protocols that report performance as a function of measured latency, not just task difficulty.",
    "authors": [
      "Aileen Liao",
      "Dong-Ki Kim",
      "Max Olan Smith",
      "Ali-akbar Agha-mohammadi",
      "Shayegan Omidshafiei"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07697v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07697v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.79
  },
  {
    "arxiv_id": "2512.07454v1",
    "title": "Persian-Phi: Efficient Cross-Lingual Adaptation of Compact LLMs via Curriculum Learning",
    "summary": "The democratization of AI is currently hindered by the immense computational costs required to train Large Language Models (LLMs) for low-resource languages. This paper presents Persian-Phi, a 3.8B parameter model that challenges the assumption that robust multilingual capabilities require massive model sizes or multilingual baselines. We demonstrate how Microsoft Phi-3 Mini -- originally a monolingual English model -- can be effectively adapted to Persian through a novel, resource-efficient curriculum learning pipeline. Our approach employs a unique \"warm-up\" stage using bilingual narratives (Tiny Stories) to align embeddings prior to heavy training, followed by continual pretraining and instruction tuning via Parameter-Efficient Fine-Tuning (PEFT). Despite its compact size, Persian-Phi achieves competitive results on Open Persian LLM Leaderboard in HuggingFace. Our findings provide a validated, scalable framework for extending the reach of state-of-the-art LLMs to underrepresented languages with minimal hardware resources. The Persian-Phi model is publicly available at https://huggingface.co/amirakhlaghiqqq/PersianPhi.",
    "authors": [
      "Amir Mohammad Akhlaghi",
      "Amirhossein Shabani",
      "Mostafa Abdolmaleki",
      "Saeed Reza Kheradpisheh"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07454v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07454v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2512.07277v1",
    "title": "Efficient ASR for Low-Resource Languages: Leveraging Cross-Lingual Unlabeled Data",
    "summary": "Automatic speech recognition for low-resource languages remains fundamentally constrained by the scarcity of labeled data and computational resources required by state-of-the-art models. We present a systematic investigation into cross-lingual continuous pretraining for low-resource languages, using Perso-Arabic languages (Persian, Arabic, and Urdu) as our primary case study. Our approach demonstrates that strategic utilization of unlabeled speech data can effectively bridge the resource gap without sacrificing recognition accuracy. We construct a 3,000-hour multilingual corpus through a scalable unlabeled data collection pipeline and employ targeted continual pretraining combined with morphologically-aware tokenization to develop a 300M parameter model that achieves performance comparable to systems 5 times larger. Our model outperforms Whisper Large v3 (1.5B parameters) on Persian and achieves competitive results on Arabic and Urdu despite using significantly fewer parameters and substantially less labeled data. These findings challenge the prevailing assumption that ASR quality scales primarily with model size, revealing instead that data relevance and strategic pretraining are more critical factors for low-resource scenarios. This work provides a practical pathway toward inclusive speech technology, enabling effective ASR for underrepresented languages without dependence on massive computational infrastructure or proprietary datasets.",
    "authors": [
      "Srihari Bandarupalli",
      "Bhavana Akkiraju",
      "Charan Devarakonda",
      "Vamsiraghusimha Narsinga",
      "Anil Kumar Vuppala"
    ],
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07277v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07277v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2512.07541v1",
    "title": "High-Dimensional Change Point Detection using Graph Spanning Ratio",
    "summary": "Inspired by graph-based methodologies, we introduce a novel graph-spanning algorithm designed to identify changes in both offline and online data across low to high dimensions. This versatile approach is applicable to Euclidean and graph-structured data with unknown distributions, while maintaining control over error probabilities. Theoretically, we demonstrate that the algorithm achieves high detection power when the magnitude of the change surpasses the lower bound of the minimax separation rate, which scales on the order of $\\sqrt{nd}$. Our method outperforms other techniques in terms of accuracy for both Gaussian and non-Gaussian data. Notably, it maintains strong detection power even with small observation windows, making it particularly effective for online environments where timely and precise change detection is critical.",
    "authors": [
      "Youngwen Sun",
      "Katerina Papagiannouli",
      "Vladimir Spokoiny"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07541v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07541v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2512.07501v1",
    "title": "AutoICE: Automatically Synthesizing Verifiable C Code via LLM-driven Evolution",
    "summary": "Automatically synthesizing verifiable code from natural language requirements ensures software correctness and reliability while significantly lowering the barrier to adopting the techniques of formal methods. With the rise of large language models (LLMs), long-standing efforts at autoformalization have gained new momentum. However, existing approaches suffer from severe syntactic and semantic errors due to the scarcity of domain-specific pre-training corpora and often fail to formalize implicit knowledge effectively. In this paper, we propose AutoICE, an LLM-driven evolutionary search for synthesizing verifiable C code. It introduces the diverse individual initialization and the collaborative crossover to enable diverse iterative updates, thereby mitigating error propagation inherent in single-agent iterations. Besides, it employs the self-reflective mutation to facilitate the discovery of implicit knowledge. Evaluation results demonstrate the effectiveness of AutoICE: it successfully verifies $90.36$\\% of code, outperforming the state-of-the-art (SOTA) approach. Besides, on a developer-friendly dataset variant, AutoICE achieves a $88.33$\\% verification success rate, significantly surpassing the $65$\\% success rate of the SOTA approach.",
    "authors": [
      "Weilin Luo",
      "Xueyi Liang",
      "Haotian Deng",
      "Yanan Liu",
      "Hai Wan"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07501v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07501v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2512.07533v1",
    "title": "VulnLLM-R: Specialized Reasoning LLM with Agent Scaffold for Vulnerability Detection",
    "summary": "We propose VulnLLM-R, the~\\emph{first specialized reasoning LLM} for vulnerability detection. Our key insight is that LLMs can reason about program states and analyze the potential vulnerabilities, rather than simple pattern matching. This can improve the model's generalizability and prevent learning shortcuts. However, SOTA reasoning LLMs are typically ultra-large, closed-source, or have limited performance in vulnerability detection. To address this, we propose a novel training recipe with specialized data selection, reasoning data generation, reasoning data filtering and correction, and testing-phase optimization. Using our proposed methodology, we train a reasoning model with seven billion parameters. Through extensive experiments on SOTA datasets across Python, C/C++, and Java, we show that VulnLLM-R has superior effectiveness and efficiency than SOTA static analysis tools and both open-source and commercial large reasoning models. We further conduct a detailed ablation study to validate the key designs in our training recipe. Finally, we construct an agent scaffold around our model and show that it outperforms CodeQL and AFL++ in real-world projects. Our agent further discovers a set of zero-day vulnerabilities in actively maintained repositories. This work represents a pioneering effort to enable real-world, project-level vulnerability detection using AI agents powered by specialized reasoning models. The code is available at~\\href{https://github.com/ucsb-mlsec/VulnLLM-R}{github}.",
    "authors": [
      "Yuzhou Nie",
      "Hongwei Li",
      "Chengquan Guo",
      "Ruizhe Jiang",
      "Zhun Wang",
      "Bo Li",
      "Dawn Song",
      "Wenbo Guo"
    ],
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07533v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07533v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2512.07344v1",
    "title": "Venus: An Efficient Edge Memory-and-Retrieval System for VLM-based Online Video Understanding",
    "summary": "Vision-language models (VLMs) have demonstrated impressive multimodal comprehension capabilities and are being deployed in an increasing number of online video understanding applications. While recent efforts extensively explore advancing VLMs' reasoning power in these cases, deployment constraints are overlooked, leading to overwhelming system overhead in real-world deployments. To address that, we propose Venus, an on-device memory-and-retrieval system for efficient online video understanding. Venus proposes an edge-cloud disaggregated architecture that sinks memory construction and keyframe retrieval from cloud to edge, operating in two stages. In the ingestion stage, Venus continuously processes streaming edge videos via scene segmentation and clustering, where the selected keyframes are embedded with a multimodal embedding model to build a hierarchical memory for efficient storage and retrieval. In the querying stage, Venus indexes incoming queries from memory, and employs a threshold-based progressive sampling algorithm for keyframe selection that enhances diversity and adaptively balances system cost and reasoning accuracy. Our extensive evaluation shows that Venus achieves a 15x-131x speedup in total response latency compared to state-of-the-art methods, enabling real-time responses within seconds while maintaining comparable or even superior reasoning accuracy.",
    "authors": [
      "Shengyuan Ye",
      "Bei Ouyang",
      "Tianyi Qian",
      "Liekang Zeng",
      "Mu Yuan",
      "Xiaowen Chu",
      "Weijie Hong",
      "Xu Chen"
    ],
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07344v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07344v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2512.07539v1",
    "title": "FRWKV:Frequency-Domain Linear Attention for Long-Term Time Series Forecasting",
    "summary": "Traditional Transformers face a major bottleneck in long-sequence time series forecasting due to their quadratic complexity $(\\mathcal{O}(T^2))$ and their limited ability to effectively exploit frequency-domain information. Inspired by RWKV's $\\mathcal{O}(T)$ linear attention and frequency-domain modeling, we propose FRWKV, a frequency-domain linear-attention framework that overcomes these limitations. Our model integrates linear attention mechanisms with frequency-domain analysis, achieving $\\mathcal{O}(T)$ computational complexity in the attention path while exploiting spectral information to enhance temporal feature representations for scalable long-sequence modeling. Across eight real-world datasets, FRWKV achieves a first-place average rank. Our ablation studies confirm the critical roles of both the linear attention and frequency-encoder components. This work demonstrates the powerful synergy between linear attention and frequency analysis, establishing a new paradigm for scalable time series modeling. Code is available at this repository: https://github.com/yangqingyuan-byte/FRWKV.",
    "authors": [
      "Qingyuan Yang",
      " Shizhuo",
      "Dongyue Chen",
      "Da Teng",
      "Zehua Gan"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07539v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07539v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2512.07374v1",
    "title": "Recover-to-Forget: Gradient Reconstruction from LoRA for Efficient LLM Unlearning",
    "summary": "Unlearning in large foundation models (e.g., LLMs) is essential for enabling dynamic knowledge updates, enforcing data deletion rights, and correcting model behavior. However, existing unlearning methods often require full-model fine-tuning or access to the original training data, which limits their scalability and practicality. In this work, we introduce Recover-to-Forget (R2F), a novel framework for efficient unlearning in LLMs based on reconstructing full-model gradient directions from low-rank LoRA adapter updates. Rather than performing backpropagation through the full model, we compute gradients with respect to LoRA parameters using multiple paraphrased prompts and train a gradient decoder to approximate the corresponding full-model gradients. To ensure applicability to larger or black-box models, the decoder is trained on a proxy model and transferred to target models. We provide a theoretical analysis of cross-model generalization and demonstrate that our method achieves effective unlearning while preserving general model performance. Experimental results demonstrate that R2F offers a scalable and lightweight alternative for unlearning in pretrained LLMs without requiring full retraining or access to internal parameters.",
    "authors": [
      "Yezi Liu",
      "Hanning Chen",
      "Wenjun Huang",
      "Yang Ni",
      "Mohsen Imani"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07374v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07374v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2512.07328v1",
    "title": "ContextAnyone: Context-Aware Diffusion for Character-Consistent Text-to-Video Generation",
    "summary": "Text-to-video (T2V) generation has advanced rapidly, yet maintaining consistent character identities across scenes remains a major challenge. Existing personalization methods often focus on facial identity but fail to preserve broader contextual cues such as hairstyle, outfit, and body shape, which are critical for visual coherence. We propose \\textbf{ContextAnyone}, a context-aware diffusion framework that achieves character-consistent video generation from text and a single reference image. Our method jointly reconstructs the reference image and generates new video frames, enabling the model to fully perceive and utilize reference information. Reference information is effectively integrated into a DiT-based diffusion backbone through a novel Emphasize-Attention module that selectively reinforces reference-aware features and prevents identity drift across frames. A dual-guidance loss combines diffusion and reference reconstruction objectives to enhance appearance fidelity, while the proposed Gap-RoPE positional embedding separates reference and video tokens to stabilize temporal modeling. Experiments demonstrate that ContextAnyone outperforms existing reference-to-video methods in identity consistency and visual quality, generating coherent and context-preserving character videos across diverse motions and scenes. Project page: \\href{https://github.com/ziyang1106/ContextAnyone}{https://github.com/ziyang1106/ContextAnyone}.",
    "authors": [
      "Ziyang Mai",
      "Yu-Wing Tai"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07328v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07328v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2512.07666v1",
    "title": "Bridging Code Graphs and Large Language Models for Better Code Understanding",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable performance in code intelligence tasks such as code generation, summarization, and translation. However, their reliance on linearized token sequences limits their ability to understand the structural semantics of programs. While prior studies have explored graphaugmented prompting and structure-aware pretraining, they either suffer from prompt length constraints or require task-specific architectural changes that are incompatible with large-scale instructionfollowing LLMs. To address these limitations, this paper proposes CGBridge, a novel plug-and-play method that enhances LLMs with Code Graph information through an external, trainable Bridge module. CGBridge first pre-trains a code graph encoder via selfsupervised learning on a large-scale dataset of 270K code graphs to learn structural code semantics. It then trains an external module to bridge the modality gap among code, graph, and text by aligning their semantics through cross-modal attention mechanisms. Finally, the bridge module generates structure-informed prompts, which are injected into a frozen LLM, and is fine-tuned for downstream code intelligence tasks. Experiments show that CGBridge achieves notable improvements over both the original model and the graphaugmented prompting method. Specifically, it yields a 16.19% and 9.12% relative gain in LLM-as-a-Judge on code summarization, and a 9.84% and 38.87% relative gain in Execution Accuracy on code translation. Moreover, CGBridge achieves over 4x faster inference than LoRA-tuned models, demonstrating both effectiveness and efficiency in structure-aware code understanding.",
    "authors": [
      "Zeqi Chen",
      "Zhaoyang Chu",
      "Yi Gui",
      "Feng Guo",
      "Yao Wan",
      "Chuan Shi"
    ],
    "categories": [
      "cs.CL",
      "cs.SE"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07666v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07666v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2512.07253v1",
    "title": "DGGAN: Degradation Guided Generative Adversarial Network for Real-time Endoscopic Video Enhancement",
    "summary": "Endoscopic surgery relies on intraoperative video, making image quality a decisive factor for surgical safety and efficacy. Yet, endoscopic videos are often degraded by uneven illumination, tissue scattering, occlusions, and motion blur, which obscure critical anatomical details and complicate surgical manipulation. Although deep learning-based methods have shown promise in image enhancement, most existing approaches remain too computationally demanding for real-time surgical use. To address this challenge, we propose a degradation-aware framework for endoscopic video enhancement, which enables real-time, high-quality enhancement by propagating degradation representations across frames. In our framework, degradation representations are first extracted from images using contrastive learning. We then introduce a fusion mechanism that modulates image features with these representations to guide a single-frame enhancement model, which is trained with a cycle-consistency constraint between degraded and restored images to improve robustness and generalization. Experiments demonstrate that our framework achieves a superior balance between performance and efficiency compared with several state-of-the-art methods. These results highlight the effectiveness of degradation-aware modeling for real-time endoscopic video enhancement. Nevertheless, our method suggests that implicitly learning and propagating degradation representation offer a practical pathway for clinical application.",
    "authors": [
      "Handing Xu",
      "Zhenguo Nie",
      "Tairan Peng",
      "Huimin Pan",
      "Xin-Jun Liu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07253v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07253v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2512.07234v1",
    "title": "Dropout Prompt Learning: Towards Robust and Adaptive Vision-Language Models",
    "summary": "Dropout is a widely used regularization technique which improves the generalization ability of a model by randomly dropping neurons. In light of this, we propose Dropout Prompt Learning, which aims for applying dropout to improve the robustness of the vision-language models. Different from the vanilla dropout, we apply dropout on the tokens of the textual and visual branches, where we evaluate the token significance considering both intra-modal context and inter-modal alignment, enabling flexible dropout probabilities for each token. Moreover, to maintain semantic alignment for general knowledge transfer while encouraging the diverse representations that dropout introduces, we further propose residual entropy regularization. Experiments on 15 benchmarks show our method's effectiveness in challenging scenarios like low-shot learning, long-tail classification, and out-of-distribution generalization. Notably, our method surpasses regularization-based methods including KgCoOp by 5.10% and PromptSRC by 2.13% in performance on base-to-novel generalization.",
    "authors": [
      "Biao Chen",
      "Lin Zuo",
      "Mengmeng Jing",
      "Kunbin He",
      "Yuchen Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07234v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07234v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2512.07430v1",
    "title": "MIDG: Mixture of Invariant Experts with knowledge injection for Domain Generalization in Multimodal Sentiment Analysis",
    "summary": "Existing methods in domain generalization for Multimodal Sentiment Analysis (MSA) often overlook inter-modal synergies during invariant features extraction, which prevents the accurate capture of the rich semantic information within multimodal data. Additionally, while knowledge injection techniques have been explored in MSA, they often suffer from fragmented cross-modal knowledge, overlooking specific representations that exist beyond the confines of unimodal. To address these limitations, we propose a novel MSA framework designed for domain generalization. Firstly, the framework incorporates a Mixture of Invariant Experts model to extract domain-invariant features, thereby enhancing the model's capacity to learn synergistic relationships between modalities. Secondly, we design a Cross-Modal Adapter to augment the semantic richness of multimodal representations through cross-modal knowledge injection. Extensive domain experiments conducted on three datasets demonstrate that the proposed MIDG achieves superior performance.",
    "authors": [
      "Yangle Li",
      "Danli Luo",
      "Haifeng Hu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07430v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07430v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2512.07730v1",
    "title": "SAVE: Sparse Autoencoder-Driven Visual Information Enhancement for Mitigating Object Hallucination",
    "summary": "Although Multimodal Large Language Models (MLLMs) have advanced substantially, they remain vulnerable to object hallucination caused by language priors and visual information loss. To address this, we propose SAVE (Sparse Autoencoder-Driven Visual Information Enhancement), a framework that mitigates hallucination by steering the model along Sparse Autoencoder (SAE) latent features. A binary object-presence question-answering probe identifies the SAE features most indicative of the model's visual information processing, referred to as visual understanding features. Steering the model along these identified features reinforces grounded visual understanding and effectively reduces hallucination. With its simple design, SAVE outperforms state-of-the-art training-free methods on standard benchmarks, achieving a 10\\%p improvement in CHAIR\\_S and consistent gains on POPE and MMHal-Bench. Extensive evaluations across multiple models and layers confirm the robustness and generalizability of our approach. Further analysis reveals that steering along visual understanding features suppresses the generation of uncertain object tokens and increases attention to image tokens, mitigating hallucination. Code is released at https://github.com/wiarae/SAVE.",
    "authors": [
      "Sangha Park",
      "Seungryong Yoo",
      "Jisoo Mok",
      "Sungroh Yoon"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07730v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07730v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2512.07314v1",
    "title": "M-STAR: Multi-Scale Spatiotemporal Autoregression for Human Mobility Modeling",
    "summary": "Modeling human mobility is vital for extensive applications such as transportation planning and epidemic modeling. With the rise of the Artificial Intelligence Generated Content (AIGC) paradigm, recent works explore synthetic trajectory generation using autoregressive and diffusion models. While these methods show promise for generating single-day trajectories, they remain limited by inefficiencies in long-term generation (e.g., weekly trajectories) and a lack of explicit spatiotemporal multi-scale modeling. This study proposes Multi-Scale Spatio-Temporal AutoRegression (M-STAR), a new framework that generates long-term trajectories through a coarse-to-fine spatiotemporal prediction process. M-STAR combines a Multi-scale Spatiotemporal Tokenizer that encodes hierarchical mobility patterns with a Transformer-based decoder for next-scale autoregressive prediction. Experiments on two real-world datasets show that M-STAR outperforms existing methods in fidelity and significantly improves generation speed. The data and codes are available at https://github.com/YuxiaoLuo0013/M-STAR.",
    "authors": [
      "Yuxiao Luo",
      "Songming Zhang",
      "Sijie Ruan",
      "Siran Chen",
      "Kang Liu",
      "Yang Xu",
      "Yu Zheng",
      "Ling Yin"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07314v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07314v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2512.07684v1",
    "title": "When Large Language Models Do Not Work: Online Incivility Prediction through Graph Neural Networks",
    "summary": "Online incivility has emerged as a widespread and persistent problem in digital communities, imposing substantial social and psychological burdens on users. Although many platforms attempt to curb incivility through moderation and automated detection, the performance of existing approaches often remains limited in both accuracy and efficiency. To address this challenge, we propose a Graph Neural Network (GNN) framework for detecting three types of uncivil behavior (i.e., toxicity, aggression, and personal attacks) within the English Wikipedia community. Our model represents each user comment as a node, with textual similarity between comments defining the edges, allowing the network to jointly learn from both linguistic content and relational structures among comments. We also introduce a dynamically adjusted attention mechanism that adaptively balances nodal and topological features during information aggregation. Empirical evaluations demonstrate that our proposed architecture outperforms 12 state-of-the-art Large Language Models (LLMs) across multiple metrics while requiring significantly lower inference cost. These findings highlight the crucial role of structural context in detecting online incivility and address the limitations of text-only LLM paradigms in behavioral prediction. All datasets and comparative outputs will be publicly available in our repository to support further research and reproducibility.",
    "authors": [
      "Zihan Chen",
      "Lanyu Yu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07684v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07684v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2512.07584v1",
    "title": "LongCat-Image Technical Report",
    "summary": "We introduce LongCat-Image, a pioneering open-source and bilingual (Chinese-English) foundation model for image generation, designed to address core challenges in multilingual text rendering, photorealism, deployment efficiency, and developer accessibility prevalent in current leading models. 1) We achieve this through rigorous data curation strategies across the pre-training, mid-training, and SFT stages, complemented by the coordinated use of curated reward models during the RL phase. This strategy establishes the model as a new state-of-the-art (SOTA), delivering superior text-rendering capabilities and remarkable photorealism, and significantly enhancing aesthetic quality. 2) Notably, it sets a new industry standard for Chinese character rendering. By supporting even complex and rare characters, it outperforms both major open-source and commercial solutions in coverage, while also achieving superior accuracy. 3) The model achieves remarkable efficiency through its compact design. With a core diffusion model of only 6B parameters, it is significantly smaller than the nearly 20B or larger Mixture-of-Experts (MoE) architectures common in the field. This ensures minimal VRAM usage and rapid inference, significantly reducing deployment costs. Beyond generation, LongCat-Image also excels in image editing, achieving SOTA results on standard benchmarks with superior editing consistency compared to other open-source works. 4) To fully empower the community, we have established the most comprehensive open-source ecosystem to date. We are releasing not only multiple model versions for text-to-image and image editing, including checkpoints after mid-training and post-training stages, but also the entire toolchain of training procedure. We believe that the openness of LongCat-Image will provide robust support for developers and researchers, pushing the frontiers of visual content creation.",
    "authors": [
      " Meituan LongCat Team",
      "Hanghang Ma",
      "Haoxian Tan",
      "Jiale Huang",
      "Junqiang Wu",
      "Jun-Yan He",
      "Lishuai Gao",
      "Songlin Xiao",
      "Xiaoming Wei",
      "Xiaoqi Ma",
      "Xunliang Cai",
      "Yayong Guan",
      "Jie Hu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07584v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07584v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2512.07558v1",
    "title": "ReLaX: Reasoning with Latent Exploration for Large Reasoning Models",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated remarkable potential in enhancing the reasoning capability of Large Reasoning Models (LRMs). However, RLVR often leads to entropy collapse, resulting in premature policy convergence and performance saturation. While manipulating token-level entropy has proven effective for promoting policy exploration, we argue that the latent dynamics underlying token generation encode a far richer computational structure for steering policy optimization toward a more effective exploration-exploitation tradeoff. To enable tractable analysis and intervention of the latent dynamics of LRMs, we leverage Koopman operator theory to obtain a linearized representation of their hidden-state dynamics. This enables us to introduce Dynamic Spectral Dispersion (DSD), a new metric to quantify the heterogeneity of the model's latent dynamics, serving as a direct indicator of policy exploration. Building upon these foundations, we propose Reasoning with Latent eXploration (ReLaX), a paradigm that explicitly incorporates latent dynamics to regulate exploration and exploitation during policy optimization. Comprehensive experiments across a wide range of multimodal and text-only reasoning benchmarks show that ReLaX significantly mitigates premature convergence and consistently achieves state-of-the-art performance.",
    "authors": [
      "Shimin Zhang",
      "Xianwei Chen",
      "Yufan Shen",
      "Ziyuan Ye",
      "Jibin Wu"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07558v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07558v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2512.07478v1",
    "title": "Enhancing Agentic RL with Progressive Reward Shaping and Value-based Sampling Policy Optimization",
    "summary": "Large Language Models (LLMs) empowered with Tool-Integrated Reasoning (TIR) can iteratively plan, call external tools, and integrate returned information to solve complex, long-horizon reasoning tasks. Agentic Reinforcement Learning (Agentic RL) optimizes such models over full tool-interaction trajectories, but two key challenges hinder effectiveness: (1) Sparse, non-instructive rewards, such as binary 0-1 verifiable signals, provide limited guidance for intermediate steps and slow convergence; (2) Gradient degradation in Group Relative Policy Optimization (GRPO), where identical rewards within a rollout group yield zero advantage, reducing sample efficiency and destabilizing training. To address these challenges, we propose two complementary techniques: Progressive Reward Shaping (PRS) and Value-based Sampling Policy Optimization (VSPO). PRS is a curriculum-inspired reward design that introduces dense, stage-wise feedback - encouraging models to first master parseable and properly formatted tool calls, then optimize for factual correctness and answer quality. We instantiate PRS for short-form QA (with a length-aware BLEU to fairly score concise answers) and long-form QA (with LLM-as-a-Judge scoring to prevent reward hacking). VSPO is an enhanced GRPO variant that replaces low-value samples with prompts selected by a task-value metric balancing difficulty and uncertainty, and applies value-smoothing clipping to stabilize gradient updates. Experiments on multiple short-form and long-form QA benchmarks show that PRS consistently outperforms traditional binary rewards, and VSPO achieves superior stability, faster convergence, and higher final performance compared to PPO, GRPO, CISPO, and SFT-only baselines. Together, PRS and VSPO yield LLM-based TIR agents that generalize better across domains.",
    "authors": [
      "Zhuoran Zhuang",
      "Ye Chen",
      "Jianghao Su",
      "Chao Luo",
      "Luhui Liu",
      "Xia Zeng"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07478v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07478v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2512.07808v1",
    "title": "LUNA: LUT-Based Neural Architecture for Fast and Low-Cost Qubit Readout",
    "summary": "Qubit readout is a critical operation in quantum computing systems, which maps the analog response of qubits into discrete classical states. Deep neural networks (DNNs) have recently emerged as a promising solution to improve readout accuracy . Prior hardware implementations of DNN-based readout are resource-intensive and suffer from high inference latency, limiting their practical use in low-latency decoding and quantum error correction (QEC) loops. This paper proposes LUNA, a fast and efficient superconducting qubit readout accelerator that combines low-cost integrator-based preprocessing with Look-Up Table (LUT) based neural networks for classification. The architecture uses simple integrators for dimensionality reduction with minimal hardware overhead, and employs LogicNets (DNNs synthesized into LUT logic) to drastically reduce resource usage while enabling ultra-low-latency inference. We integrate this with a differential evolution based exploration and optimization framework to identify high-quality design points. Our results show up to a 10.95x reduction in area and 30% lower latency with little to no loss in fidelity compared to the state-of-the-art. LUNA enables scalable, low-footprint, and high-speed qubit readout, supporting the development of larger and more reliable quantum computing systems.",
    "authors": [
      "M. A. Farooq",
      "G. Di Guglielmo",
      "A. Rajagopala",
      "N. Tran",
      "V. A. Chhabria",
      "A. Arora"
    ],
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07808v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07808v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2512.07703v1",
    "title": "PVeRA: Probabilistic Vector-Based Random Matrix Adaptation",
    "summary": "Large foundation models have emerged in the last years and are pushing performance boundaries for a variety of tasks. Training or even finetuning such models demands vast datasets and computational resources, which are often scarce and costly. Adaptation methods provide a computationally efficient solution to address these limitations by allowing such models to be finetuned on small amounts of data and computing power. This is achieved by appending new trainable modules to frozen backbones with only a fraction of the trainable parameters and fitting only these modules on novel tasks. Recently, the VeRA adapter was shown to excel in parameter-efficient adaptations by utilizing a pair of frozen random low-rank matrices shared across all layers. In this paper, we propose PVeRA, a probabilistic version of the VeRA adapter, which modifies the low-rank matrices of VeRA in a probabilistic manner. This modification naturally allows handling inherent ambiguities in the input and allows for different sampling configurations during training and testing. A comprehensive evaluation was performed on the VTAB-1k benchmark and seven adapters, with PVeRA outperforming VeRA and other adapters. Our code for training models with PVeRA and benchmarking all adapters is available https://github.com/leofillioux/pvera.",
    "authors": [
      "Leo Fillioux",
      "Enzo Ferrante",
      "Paul-Henry Cournède",
      "Maria Vakalopoulou",
      "Stergios Christodoulidis"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07703v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07703v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2512.07612v1",
    "title": "PCMind-2.1-Kaiyuan-2B Technical Report",
    "summary": "The rapid advancement of Large Language Models (LLMs) has resulted in a significant knowledge gap between the open-source community and industry, primarily because the latter relies on closed-source, high-quality data and training recipes. To address this, we introduce PCMind-2.1-Kaiyuan-2B, a fully open-source 2-billion-parameter model focused on improving training efficiency and effectiveness under resource constraints. Our methodology includes three key innovations: a Quantile Data Benchmarking method for systematically comparing heterogeneous open-source datasets and providing insights on data mixing strategies; a Strategic Selective Repetition scheme within a multi-phase paradigm to effectively leverage sparse, high-quality data; and a Multi-Domain Curriculum Training policy that orders samples by quality. Supported by a highly optimized data preprocessing pipeline and architectural modifications for FP16 stability, Kaiyuan-2B achieves performance competitive with state-of-the-art fully open-source models, demonstrating practical and scalable solutions for resource-limited pretraining. We release all assets (including model weights, data, and code) under Apache 2.0 license at https://huggingface.co/thu-pacman/PCMind-2.1-Kaiyuan-2B.",
    "authors": [
      "Kairong Luo",
      "Zhenbo Sun",
      "Xinyu Shi",
      "Shengqi Chen",
      "Bowen Yu",
      "Yunyi Chen",
      "Chenyi Dang",
      "Hengtao Tao",
      "Hui Wang",
      "Fangming Liu",
      "Kaifeng Lyu",
      "Wenguang Chen"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07612v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07612v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2512.07383v1",
    "title": "LogicCBMs: Logic-Enhanced Concept-Based Learning",
    "summary": "Concept Bottleneck Models (CBMs) provide a basis for semantic abstractions within a neural network architecture. Such models have primarily been seen through the lens of interpretability so far, wherein they offer transparency by inferring predictions as a linear combination of semantic concepts. However, a linear combination is inherently limiting. So we propose the enhancement of concept-based learning models through propositional logic. We introduce a logic module that is carefully designed to connect the learned concepts from CBMs through differentiable logic operations, such that our proposed LogicCBM can go beyond simple weighted combinations of concepts to leverage various logical operations to yield the final predictions, while maintaining end-to-end learnability. Composing concepts using a set of logic operators enables the model to capture inter-concept relations, while simultaneously improving the expressivity of the model in terms of logic operations. Our empirical studies on well-known benchmarks and synthetic datasets demonstrate that these models have better accuracy, perform effective interventions and are highly interpretable.",
    "authors": [
      "Deepika SN Vemuri",
      "Gautham Bellamkonda",
      "Aditya Pola",
      "Vineeth N Balasubramanian"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07383v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07383v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2512.07729v1",
    "title": "Improving action classification with brain-inspired deep networks",
    "summary": "Action recognition is also key for applications ranging from robotics to healthcare monitoring. Action information can be extracted from the body pose and movements, as well as from the background scene. However, the extent to which deep neural networks (DNNs) make use of information about the body and information about the background remains unclear. Since these two sources of information may be correlated within a training dataset, DNNs might learn to rely predominantly on one of them, without taking full advantage of the other. Unlike DNNs, humans have domain-specific brain regions selective for perceiving bodies, and regions selective for perceiving scenes. The present work tests whether humans are thus more effective at extracting information from both body and background, and whether building brain-inspired deep network architectures with separate domain-specific streams for body and scene perception endows them with more human-like performance. We first demonstrate that DNNs trained using the HAA500 dataset perform almost as accurately on versions of the stimuli that show both body and background and on versions of the stimuli from which the body was removed, but are at chance-level for versions of the stimuli from which the background was removed. Conversely, human participants (N=28) can recognize the same set of actions accurately with all three versions of the stimuli, and perform significantly better on stimuli that show only the body than on stimuli that show only the background. Finally, we implement and test a novel architecture patterned after domain specificity in the brain with separate streams to process body and background information. We show that 1) this architecture improves action recognition performance, and 2) its accuracy across different versions of the stimuli follows a pattern that matches more closely the pattern of accuracy observed in human participants.",
    "authors": [
      "Aidas Aglinskas",
      "Stefano Anzellotti"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07729v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07729v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2512.07710v1",
    "title": "Each Prompt Matters: Scaling Reinforcement Learning Without Wasting Rollouts on Hundred-Billion-Scale MoE",
    "summary": "We present CompassMax-V3-Thinking, a hundred-billion-scale MoE reasoning model trained with a new RL framework built on one principle: each prompt must matter. Scaling RL to this size exposes critical inefficiencies-zero-variance prompts that waste rollouts, unstable importance sampling over long horizons, advantage inversion from standard reward models, and systemic bottlenecks in rollout processing. To overcome these challenges, we introduce several unified innovations: (1) Multi-Stage Zero-Variance Elimination, which filters out non-informative prompts and stabilizes group-based policy optimization (e.g. GRPO) by removing wasted rollouts; (2) ESPO, an entropy-adaptive optimization method that balances token-level and sequence-level importance sampling to maintain stable learning dynamics; (3) a Router Replay strategy that aligns training-time MoE router decisions with inference-time behavior to mitigate train-infer discrepancies, coupled with a reward model adjustment to prevent advantage inversion; (4) a high-throughput RL system with FP8-precision rollouts, overlapped reward computation, and length-aware scheduling to eliminate performance bottlenecks. Together, these contributions form a cohesive pipeline that makes RL on hundred-billion-scale MoE models stable and efficient. The resulting model delivers strong performance across both internal and public evaluations.",
    "authors": [
      "Anxiang Zeng",
      "Haibo Zhang",
      "Hailing Zhang",
      "Kaixiang Mo",
      "Liang Yao",
      "Ling Hu",
      "Long Zhang",
      "Shuman Liu",
      "Shuyi Xie",
      "Yanshi Li",
      "Yizhang Chen",
      "Yuepeng Sheng",
      "Yuwei Huang",
      "Zhaochen Xu",
      "Zhiqiang Zhou",
      "Ziqin Liew"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07710v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07710v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2512.07650v1",
    "title": "Exploring Test-time Scaling via Prediction Merging on Large-Scale Recommendation",
    "summary": "Inspired by the success of language models (LM), scaling up deep learning recommendation systems (DLRS) has become a recent trend in the community. All previous methods tend to scale up the model parameters during training time. However, how to efficiently utilize and scale up computational resources during test time remains underexplored, which can prove to be a scaling-efficient approach and bring orthogonal improvements in LM domains. The key point in applying test-time scaling to DLRS lies in effectively generating diverse yet meaningful outputs for the same instance. We propose two ways: One is to explore the heterogeneity of different model architectures. The other is to utilize the randomness of model initialization under a homogeneous architecture. The evaluation is conducted across eight models, including both classic and SOTA models, on three benchmarks. Sufficient evidence proves the effectiveness of both solutions. We further prove that under the same inference budget, test-time scaling can outperform parameter scaling. Our test-time scaling can also be seamlessly accelerated with the increase in parallel servers when deployed online, without affecting the inference time on the user side. Code is available.",
    "authors": [
      "Fuyuan Lyu",
      "Zhentai Chen",
      "Jingyan Jiang",
      "Lingjie Li",
      "Xing Tang",
      "Xiuqiang He",
      "Xue Liu"
    ],
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07650v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07650v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2512.07515v1",
    "title": "SPAD: Seven-Source Token Probability Attribution with Syntactic Aggregation for Detecting Hallucinations in RAG",
    "summary": "Detecting hallucinations in Retrieval-Augmented Generation (RAG) remains a challenge. Prior approaches attribute hallucinations to a binary conflict between internal knowledge (stored in FFNs) and retrieved context. However, this perspective is incomplete, failing to account for the impact of other components in the generative process, such as the user query, previously generated tokens, the current token itself, and the final LayerNorm adjustment. To address this, we introduce SPAD. First, we mathematically attribute each token's probability into seven distinct sources: Query, RAG, Past, Current Token, FFN, Final LayerNorm, and Initial Embedding. This attribution quantifies how each source contributes to the generation of the current token. Then, we aggregate these scores by POS tags to quantify how different components drive specific linguistic categories. By identifying anomalies, such as Nouns relying on Final LayerNorm, SPAD effectively detects hallucinations. Extensive experiments demonstrate that SPAD achieves state-of-the-art performance",
    "authors": [
      "Pengqian Lu",
      "Jie Lu",
      "Anjin Liu",
      "Guangquan Zhang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07515v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07515v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2512.07463v1",
    "title": "Parallel Algorithms for Combined Regularized Support Vector Machines: Application in Music Genre Classification",
    "summary": "In the era of rapid development of artificial intelligence, its applications span across diverse fields, relying heavily on effective data processing and model optimization. Combined Regularized Support Vector Machines (CR-SVMs) can effectively handle the structural information among data features, but there is a lack of efficient algorithms in distributed-stored big data. To address this issue, we propose a unified optimization framework based on consensus structure. This framework is not only applicable to various loss functions and combined regularization terms but can also be effectively extended to non-convex regularization terms, showing strong scalability. Based on this framework, we develop a distributed parallel alternating direction method of multipliers (ADMM) algorithm to efficiently compute CR-SVMs when data is stored in a distributed manner. To ensure the convergence of the algorithm, we also introduce the Gaussian back-substitution method. Meanwhile, for the integrity of the paper, we introduce a new model, the sparse group lasso support vector machine (SGL-SVM), and apply it to music information retrieval. Theoretical analysis confirms that the computational complexity of the proposed algorithm is not affected by different regularization terms and loss functions, highlighting the universality of the parallel algorithm. Experiments on synthetic and free music archiv datasets demonstrate the reliability, stability, and efficiency of the algorithm.",
    "authors": [
      "Rongmei Liang",
      "Zizheng Liu",
      "Xiaofei Wu",
      "Jingwen Tu"
    ],
    "categories": [
      "cs.LG",
      "stat.AP",
      "stat.CO"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07463v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07463v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2512.07436v1",
    "title": "LocalSearchBench: Benchmarking Agentic Search in Real-World Local Life Services",
    "summary": "Recent advances in large reasoning models (LRMs) have enabled agentic search systems to perform complex multi-step reasoning across multiple sources. However, most studies focus on general information retrieval and rarely explores vertical domains with unique challenges. In this work, we focus on local life services and introduce LocalSearchBench, which encompass diverse and complex business scenarios. Real-world queries in this domain are often ambiguous and require multi-hop reasoning across merchants and products, remaining challenging and not fully addressed. As the first comprehensive benchmark for agentic search in local life services, LocalSearchBench includes over 150,000 high-quality entries from various cities and business types. We construct 300 multi-hop QA tasks based on real user queries, challenging agents to understand questions and retrieve information in multiple steps. We also developed LocalPlayground, a unified environment integrating multiple tools for agent interaction. Experiments show that even state-of-the-art LRMs struggle on LocalSearchBench: the best model (DeepSeek-V3.1) achieves only 34.34% correctness, and most models have issues with completeness (average 77.33%) and faithfulness (average 61.99%). This highlights the need for specialized benchmarks and domain-specific agent training in local life services. Code, Benchmark, and Leaderboard are available at localsearchbench.github.io.",
    "authors": [
      "Hang He",
      "Chuhuai Yue",
      "Chengqi Dong",
      "Mingxue Tian",
      "Zhenfeng Liu",
      "Jiajun Chai",
      "Xiaohan Wang",
      "Yufei Zhang",
      "Qun Liao",
      "Guojun Yin",
      "Wei Lin",
      "Chengcheng Wan",
      "Haiying Sun",
      "Ting Su"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07436v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07436v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2512.07391v1",
    "title": "GlimmerNet: A Lightweight Grouped Dilated Depthwise Convolutions for UAV-Based Emergency Monitoring",
    "summary": "Convolutional Neural Networks (CNNs) have proven highly effective for edge and mobile vision tasks due to their computational efficiency. While many recent works seek to enhance CNNs with global contextual understanding via self-attention-based Vision Transformers, these approaches often introduce significant computational overhead. In this work, we demonstrate that it is possible to retain strong global perception without relying on computationally expensive components. We present GlimmerNet, an ultra-lightweight convolutional network built on the principle of separating receptive field diversity from feature recombination. GlimmerNet introduces Grouped Dilated Depthwise Convolutions(GDBlocks), which partition channels into groups with distinct dilation rates, enabling multi-scale feature extraction at no additional parameter cost. To fuse these features efficiently, we design a novel Aggregator module that recombines cross-group representations using grouped pointwise convolution, significantly lowering parameter overhead. With just 31K parameters and 29% fewer FLOPs than the most recent baseline, GlimmerNet achieves a new state-of-the-art weighted F1-score of 0.966 on the UAV-focused AIDERv2 dataset. These results establish a new accuracy-efficiency trade-off frontier for real-time emergency monitoring on resource-constrained UAV platforms. Our implementation is publicly available at https://github.com/djordjened92/gdd-cnn.",
    "authors": [
      "Đorđe Nedeljković"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07391v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07391v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2512.07375v1",
    "title": "LUNE: Efficient LLM Unlearning via LoRA Fine-Tuning with Negative Examples",
    "summary": "Large language models (LLMs) possess vast knowledge acquired from extensive training corpora, but they often cannot remove specific pieces of information when needed, which makes it hard to handle privacy, bias mitigation, and knowledge correction. Traditional model unlearning approaches require computationally expensive fine-tuning or direct weight editing, making them impractical for real-world deployment. In this work, we introduce LoRA-based Unlearning with Negative Examples (LUNE), a lightweight framework that performs negative-only unlearning by updating only low-rank adapters while freezing the backbone, thereby localizing edits and avoiding disruptive global changes. Leveraging Low-Rank Adaptation (LoRA), LUNE targets intermediate representations to suppress (or replace) requested knowledge with an order-of-magnitude lower compute and memory than full fine-tuning or direct weight editing. Extensive experiments on multiple factual unlearning tasks show that LUNE: (I) achieves effectiveness comparable to full fine-tuning and memory-editing methods, and (II) reduces computational cost by about an order of magnitude.",
    "authors": [
      "Yezi Liu",
      "Hanning Chen",
      "Wenjun Huang",
      "Yang Ni",
      "Mohsen Imani"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07375v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07375v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2512.07829v1",
    "title": "One Layer Is Enough: Adapting Pretrained Visual Encoders for Image Generation",
    "summary": "Visual generative models (e.g., diffusion models) typically operate in compressed latent spaces to balance training efficiency and sample quality. In parallel, there has been growing interest in leveraging high-quality pre-trained visual representations, either by aligning them inside VAEs or directly within the generative model. However, adapting such representations remains challenging due to fundamental mismatches between understanding-oriented features and generation-friendly latent spaces. Representation encoders benefit from high-dimensional latents that capture diverse hypotheses for masked regions, whereas generative models favor low-dimensional latents that must faithfully preserve injected noise. This discrepancy has led prior work to rely on complex objectives and architectures. In this work, we propose FAE (Feature Auto-Encoder), a simple yet effective framework that adapts pre-trained visual representations into low-dimensional latents suitable for generation using as little as a single attention layer, while retaining sufficient information for both reconstruction and understanding. The key is to couple two separate deep decoders: one trained to reconstruct the original feature space, and a second that takes the reconstructed features as input for image generation. FAE is generic; it can be instantiated with a variety of self-supervised encoders (e.g., DINO, SigLIP) and plugged into two distinct generative families: diffusion models and normalizing flows. Across class-conditional and text-to-image benchmarks, FAE achieves strong performance. For example, on ImageNet 256x256, our diffusion model with CFG attains a near state-of-the-art FID of 1.29 (800 epochs) and 1.70 (80 epochs). Without CFG, FAE reaches the state-of-the-art FID of 1.48 (800 epochs) and 2.08 (80 epochs), demonstrating both high quality and fast learning.",
    "authors": [
      "Yuan Gao",
      "Chen Chen",
      "Tianrong Chen",
      "Jiatao Gu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07829v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07829v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.07807v1",
    "title": "Lang3D-XL: Language Embedded 3D Gaussians for Large-scale Scenes",
    "summary": "Embedding a language field in a 3D representation enables richer semantic understanding of spatial environments by linking geometry with descriptive meaning. This allows for a more intuitive human-computer interaction, enabling querying or editing scenes using natural language, and could potentially improve tasks like scene retrieval, navigation, and multimodal reasoning. While such capabilities could be transformative, in particular for large-scale scenes, we find that recent feature distillation approaches cannot effectively learn over massive Internet data due to challenges in semantic feature misalignment and inefficiency in memory and runtime. To this end, we propose a novel approach to address these challenges. First, we introduce extremely low-dimensional semantic bottleneck features as part of the underlying 3D Gaussian representation. These are processed by rendering and passing them through a multi-resolution, feature-based, hash encoder. This significantly improves efficiency both in runtime and GPU memory. Second, we introduce an Attenuated Downsampler module and propose several regularizations addressing the semantic misalignment of ground truth 2D features. We evaluate our method on the in-the-wild HolyScenes dataset and demonstrate that it surpasses existing approaches in both performance and efficiency.",
    "authors": [
      "Shai Krakovsky",
      "Gal Fiebelman",
      "Sagie Benaim",
      "Hadar Averbuch-Elor"
    ],
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07807v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07807v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.07522v1",
    "title": "LIME: Making LLM Data More Efficient with Linguistic Metadata Embeddings",
    "summary": "Pre-training decoder-only language models relies on vast amounts of high-quality data, yet the availability of such data is increasingly reaching its limits. While metadata is commonly used to create and curate these datasets, its potential as a direct training signal remains under-explored. We challenge this status quo and propose LIME (Linguistic Metadata Embeddings), a method that enriches token embeddings with metadata capturing syntax, semantics, and contextual properties. LIME substantially improves pre-training efficiency. Specifically, it adapts up to 56% faster to the training data distribution, while introducing only 0.01% additional parameters at negligible compute overhead. Beyond efficiency, LIME improves tokenization, leading to remarkably stronger language modeling capabilities and generative task performance. These benefits persist across model scales (500M to 2B). In addition, we develop a variant with shifted metadata, LIME+1, that can guide token generation. Given prior metadata for the next token, LIME+1 improves reasoning performance by up to 38% and arithmetic accuracy by up to 35%.",
    "authors": [
      "Sebastian Sztwiertnia",
      "Felix Friedrich",
      "Kristian Kersting",
      "Patrick Schramowski",
      "Björn Deiseroth"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07522v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07522v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.07474v1",
    "title": "Living the Novel: A System for Generating Self-Training Timeline-Aware Conversational Agents from Novels",
    "summary": "We present the Living Novel, an end-to-end system that transforms any literary work into an immersive, multi-character conversational experience. This system is designed to solve two fundamental challenges for LLM-driven characters. Firstly, generic LLMs suffer from persona drift, often failing to stay in character. Secondly, agents often exhibit abilities that extend beyond the constraints of the story's world and logic, leading to both narrative incoherence (spoiler leakage) and robustness failures (frame-breaking). To address these challenges, we introduce a novel two-stage training pipeline. Our Deep Persona Alignment (DPA) stage uses data-free reinforcement finetuning to instill deep character fidelity. Our Coherence and Robustness Enhancing (CRE) stage then employs a story-time-aware knowledge graph and a second retrieval-grounded training pass to architecturally enforce these narrative constraints. We validate our system through a multi-phase evaluation using Jules Verne's Twenty Thousand Leagues Under the Sea. A lab study with a detailed ablation of system components is followed by a 5-day in-the-wild diary study. Our DPA pipeline helps our specialized model outperform GPT-4o on persona-specific metrics, and our CRE stage achieves near-perfect performance in coherence and robustness measures. Our study surfaces practical design guidelines for AI-driven narrative systems: we find that character-first self-training is foundational for believability, while explicit story-time constraints are crucial for sustaining coherent, interruption-resilient mobile-web experiences.",
    "authors": [
      "Yifei Huang",
      "Tianyu Yan",
      "Sitong Gong",
      "Xiwei Gao",
      "Caixin Kang",
      "Ruicong Liu",
      "Huchuan Lu",
      "Bo Zheng"
    ],
    "categories": [
      "cs.HC",
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07474v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07474v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.07469v1",
    "title": "Unified Video Editing with Temporal Reasoner",
    "summary": "Existing video editing methods face a critical trade-off: expert models offer precision but rely on task-specific priors like masks, hindering unification; conversely, unified temporal in-context learning models are mask-free but lack explicit spatial cues, leading to weak instruction-to-region mapping and imprecise localization. To resolve this conflict, we propose VideoCoF, a novel Chain-of-Frames approach inspired by Chain-of-Thought reasoning. VideoCoF enforces a ``see, reason, then edit\" procedure by compelling the video diffusion model to first predict reasoning tokens (edit-region latents) before generating the target video tokens. This explicit reasoning step removes the need for user-provided masks while achieving precise instruction-to-region alignment and fine-grained video editing. Furthermore, we introduce a RoPE alignment strategy that leverages these reasoning tokens to ensure motion alignment and enable length extrapolation beyond the training duration. We demonstrate that with a minimal data cost of only 50k video pairs, VideoCoF achieves state-of-the-art performance on VideoCoF-Bench, validating the efficiency and effectiveness of our approach. Our code, weight, data are available at https://github.com/knightyxp/VideoCoF.",
    "authors": [
      "Xiangpeng Yang",
      "Ji Xie",
      "Yiyuan Yang",
      "Yan Huang",
      "Min Xu",
      "Qiang Wu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07469v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07469v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.07379v1",
    "title": "Enhancing Small Object Detection with YOLO: A Novel Framework for Improved Accuracy and Efficiency",
    "summary": "This paper investigates and develops methods for detecting small objects in large-scale aerial images. Current approaches for detecting small objects in aerial images often involve image cropping and modifications to detector network architectures. Techniques such as sliding window cropping and architectural enhancements, including higher-resolution feature maps and attention mechanisms, are commonly employed. Given the growing importance of aerial imagery in various critical and industrial applications, the need for robust frameworks for small object detection becomes imperative. To address this need, we adopted the base SW-YOLO approach to enhance speed and accuracy in small object detection by refining cropping dimensions and overlap in sliding window usage and subsequently enhanced it through architectural modifications. we propose a novel model by modifying the base model architecture, including advanced feature extraction modules in the neck for feature map enhancement, integrating CBAM in the backbone to preserve spatial and channel information, and introducing a new head to boost small object detection accuracy. Finally, we compared our method with SAHI, one of the most powerful frameworks for processing large-scale images, and CZDet, which is also based on image cropping, achieving significant improvements in accuracy. The proposed model achieves significant accuracy gains on the VisDrone2019 dataset, outperforming baseline YOLOv5L detection by a substantial margin. Specifically, the final proposed model elevates the mAP .5.5 accuracy on the VisDrone2019 dataset from the base accuracy of 35.5 achieved by the YOLOv5L detector to 61.2. Notably, the accuracy of CZDet, which is another classic method applied to this dataset, is 58.36. This research demonstrates a significant improvement, achieving an increase in accuracy from 35.5 to 61.2.",
    "authors": [
      "Mahila Moghadami",
      "Mohammad Ali Keyvanrad",
      "Melika Sabaghian"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07379v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07379v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.07360v1",
    "title": "Structure-Aware Feature Rectification with Region Adjacency Graphs for Training-Free Open-Vocabulary Semantic Segmentation",
    "summary": "Benefiting from the inductive biases learned from large-scale datasets, open-vocabulary semantic segmentation (OVSS) leverages the power of vision-language models, such as CLIP, to achieve remarkable progress without requiring task-specific training. However, due to CLIP's pre-training nature on image-text pairs, it tends to focus on global semantic alignment, resulting in suboptimal performance when associating fine-grained visual regions with text. This leads to noisy and inconsistent predictions, particularly in local areas. We attribute this to a dispersed bias stemming from its contrastive training paradigm, which is difficult to alleviate using CLIP features alone. To address this, we propose a structure-aware feature rectification approach that incorporates instance-specific priors derived directly from the image. Specifically, we construct a region adjacency graph (RAG) based on low-level features (e.g., colour and texture) to capture local structural relationships and use it to refine CLIP features by enhancing local discrimination. Extensive experiments show that our method effectively suppresses segmentation noise, improves region-level consistency, and achieves strong performance on multiple open-vocabulary segmentation benchmarks.",
    "authors": [
      "Qiming Huang",
      "Hao Ai",
      "Jianbo Jiao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07360v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07360v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.07351v1",
    "title": "DeepAgent: A Dual Stream Multi Agent Fusion for Robust Multimodal Deepfake Detection",
    "summary": "The increasing use of synthetic media, particularly deepfakes, is an emerging challenge for digital content verification. Although recent studies use both audio and visual information, most integrate these cues within a single model, which remains vulnerable to modality mismatches, noise, and manipulation. To address this gap, we propose DeepAgent, an advanced multi-agent collaboration framework that simultaneously incorporates both visual and audio modalities for the effective detection of deepfakes. DeepAgent consists of two complementary agents. Agent-1 examines each video with a streamlined AlexNet-based CNN to identify the symbols of deepfake manipulation, while Agent-2 detects audio-visual inconsistencies by combining acoustic features, audio transcriptions from Whisper, and frame-reading sequences of images through EasyOCR. Their decisions are fused through a Random Forest meta-classifier that improves final performance by taking advantage of the different decision boundaries learned by each agent. This study evaluates the proposed framework using three benchmark datasets to demonstrate both component-level and fused performance. Agent-1 achieves a test accuracy of 94.35% on the combined Celeb-DF and FakeAVCeleb datasets. On the FakeAVCeleb dataset, Agent-2 and the final meta-classifier attain accuracies of 93.69% and 81.56%, respectively. In addition, cross-dataset validation on DeepFakeTIMIT confirms the robustness of the meta-classifier, which achieves a final accuracy of 97.49%, and indicates a strong capability across diverse datasets. These findings confirm that hierarchy-based fusion enhances robustness by mitigating the weaknesses of individual modalities and demonstrate the effectiveness of a multi-agent approach in addressing diverse types of manipulations in deepfakes.",
    "authors": [
      "Sayeem Been Zaman",
      "Wasimul Karim",
      "Arefin Ittesafun Abian",
      "Reem E. Mohamed",
      "Md Rafiqul Islam",
      "Asif Karim",
      "Sami Azam"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SD"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07351v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07351v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.07247v1",
    "title": "AdLift: Lifting Adversarial Perturbations to Safeguard 3D Gaussian Splatting Assets Against Instruction-Driven Editing",
    "summary": "Recent studies have extended diffusion-based instruction-driven 2D image editing pipelines to 3D Gaussian Splatting (3DGS), enabling faithful manipulation of 3DGS assets and greatly advancing 3DGS content creation. However, it also exposes these assets to serious risks of unauthorized editing and malicious tampering. Although imperceptible adversarial perturbations against diffusion models have proven effective for protecting 2D images, applying them to 3DGS encounters two major challenges: view-generalizable protection and balancing invisibility with protection capability. In this work, we propose the first editing safeguard for 3DGS, termed AdLift, which prevents instruction-driven editing across arbitrary views and dimensions by lifting strictly bounded 2D adversarial perturbations into 3D Gaussian-represented safeguard. To ensure both adversarial perturbations effectiveness and invisibility, these safeguard Gaussians are progressively optimized across training views using a tailored Lifted PGD, which first conducts gradient truncation during back-propagation from the editing model at the rendered image and applies projected gradients to strictly constrain the image-level perturbation. Then, the resulting perturbation is backpropagated to the safeguard Gaussian parameters via an image-to-Gaussian fitting operation. We alternate between gradient truncation and image-to-Gaussian fitting, yielding consistent adversarial-based protection performance across different viewpoints and generalizes to novel views. Empirically, qualitative and quantitative results demonstrate that AdLift effectively protects against state-of-the-art instruction-driven 2D image and 3DGS editing.",
    "authors": [
      "Ziming Hong",
      "Tianyu Huang",
      "Runnan Chen",
      "Shanshan Ye",
      "Mingming Gong",
      "Bo Han",
      "Tongliang Liu"
    ],
    "categories": [
      "cs.CV",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07247v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07247v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2512.07674v1",
    "title": "DIST-CLIP: Arbitrary Metadata and Image Guided MRI Harmonization via Disentangled Anatomy-Contrast Representations",
    "summary": "Deep learning holds immense promise for transforming medical image analysis, yet its clinical generalization remains profoundly limited. A major barrier is data heterogeneity. This is particularly true in Magnetic Resonance Imaging, where scanner hardware differences, diverse acquisition protocols, and varying sequence parameters introduce substantial domain shifts that obscure underlying biological signals. Data harmonization methods aim to reduce these instrumental and acquisition variability, but existing approaches remain insufficient. When applied to imaging data, image-based harmonization approaches are often restricted by the need for target images, while existing text-guided methods rely on simplistic labels that fail to capture complex acquisition details or are typically restricted to datasets with limited variability, failing to capture the heterogeneity of real-world clinical environments. To address these limitations, we propose DIST-CLIP (Disentangled Style Transfer with CLIP Guidance), a unified framework for MRI harmonization that flexibly uses either target images or DICOM metadata for guidance. Our framework explicitly disentangles anatomical content from image contrast, with the contrast representations being extracted using pre-trained CLIP encoders. These contrast embeddings are then integrated into the anatomical content via a novel Adaptive Style Transfer module. We trained and evaluated DIST-CLIP on diverse real-world clinical datasets, and showed significant improvements in performance when compared against state-of-the-art methods in both style translation fidelity and anatomical preservation, offering a flexible solution for style transfer and standardizing MRI data. Our code and weights will be made publicly available upon publication.",
    "authors": [
      "Mehmet Yigit Avci",
      "Pedro Borges",
      "Virginia Fernandez",
      "Paul Wright",
      "Mehmet Yigitsoy",
      "Sebastien Ourselin",
      "Jorge Cardoso"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07674v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07674v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.07667v1",
    "title": "Depth-Wise Activation Steering for Honest Language Models",
    "summary": "Large language models sometimes assert falsehoods despite internally representing the correct answer, failures of honesty rather than accuracy, which undermines auditability and safety. Existing approaches largely optimize factual correctness or depend on retraining and brittle single-layer edits, offering limited leverage over truthful reporting. We present a training-free activation steering method that weights steering strength across network depth using a Gaussian schedule. On the MASK benchmark, which separates honesty from knowledge, we evaluate seven models spanning the LLaMA, Qwen, and Mistral families and find that Gaussian scheduling improves honesty over no-steering and single-layer baselines in six of seven models. Equal-budget ablations on LLaMA-3.1-8B-Instruct and Qwen-2.5-7B-Instruct show the Gaussian schedule outperforms random, uniform, and box-filter depth allocations, indicating that how intervention is distributed across depth materially affects outcomes beyond total strength. The method is simple, model-agnostic, requires no finetuning, and provides a low-cost control knob for eliciting truthful reporting from models' existing capabilities.",
    "authors": [
      "Gracjan Góral",
      "Marysia Winkels",
      "Steven Basart"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07667v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07667v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.07611v1",
    "title": "Comparative Analysis and Parametric Tuning of PPO, GRPO, and DAPO for LLM Reasoning Enhancement",
    "summary": "This study presents a systematic comparison of three Reinforcement Learning (RL) algorithms (PPO, GRPO, and DAPO) for improving complex reasoning in large language models (LLMs). Our main contribution is a controlled transfer-learning evaluation: models are first fine-tuned on the specialized Countdown Game and then assessed on a suite of general-purpose reasoning benchmarks. Across all tasks, RL-trained models outperform their corresponding base models, although the degree of improvement differs by benchmark.   Our parametric analysis offers practical guidance for RL-based LLM training. Increasing the group size in GRPO and DAPO leads to more stable training dynamics and higher accuracy, while the impact of the KL-penalty coefficient is non-monotonic. Additionally, we find that the Dynamic Sampling (DS) component in DAPO does not improve performance; in fact, the best overall results are achieved with DAPO when DS is disabled.",
    "authors": [
      "Yongsheng Lian"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07611v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07611v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.07540v1",
    "title": "Minimum Bayes Risk Decoding for Error Span Detection in Reference-Free Automatic Machine Translation Evaluation",
    "summary": "Error Span Detection (ESD) is a subtask of automatic machine translation evaluation that localizes error spans in translations and labels their severity. State-of-the-art generative ESD methods typically decode using Maximum a Posteriori (MAP), assuming that model-estimated probabilities are perfectly correlated with similarity to human annotation. However, we observed that annotations dissimilar to the human annotation could achieve a higher model likelihood than the human annotation. We address this issue by applying Minimum Bayes Risk (MBR) decoding to generative ESD models. Specifically, we employ sentence- and span-level similarity metrics as utility functions to select candidate hypotheses based on their approximate similarity to the human annotation. Extensive experimental results show that our MBR decoding outperforms the MAP baseline at the system, sentence, and span-levels. Furthermore, to mitigate the computational cost of MBR decoding, we demonstrate that applying MBR distillation enables a standard greedy model to match MBR decoding performance, effectively eliminating the inference-time latency bottleneck.",
    "authors": [
      "Boxuan Lyu",
      "Haiyue Song",
      "Hidetaka Kamigaito",
      "Chenchen Ding",
      "Hideki Tanaka",
      "Masao Utiyama",
      "Kotaro Funakoshi",
      "Manabu Okumura"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07540v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07540v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.07538v1",
    "title": "SwissGov-RSD: A Human-annotated, Cross-lingual Benchmark for Token-level Recognition of Semantic Differences Between Related Documents",
    "summary": "Recognizing semantic differences across documents, especially in different languages, is crucial for text generation evaluation and multilingual content alignment. However, as a standalone task it has received little attention. We address this by introducing SwissGov-RSD, the first naturalistic, document-level, cross-lingual dataset for semantic difference recognition. It encompasses a total of 224 multi-parallel documents in English-German, English-French, and English-Italian with token-level difference annotations by human annotators. We evaluate a variety of open-source and closed source large language models as well as encoder models across different fine-tuning settings on this new benchmark. Our results show that current automatic approaches perform poorly compared to their performance on monolingual, sentence-level, and synthetic benchmarks, revealing a considerable gap for both LLMs and encoder models. We make our code and datasets publicly available.",
    "authors": [
      "Michelle Wastl",
      "Jannis Vamvas",
      "Rico Sennrich"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07538v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07538v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.07472v1",
    "title": "Affordance Field Intervention: Enabling VLAs to Escape Memory Traps in Robotic Manipulation",
    "summary": "Vision-Language-Action (VLA) models have shown great performance in robotic manipulation by mapping visual observations and language instructions directly to actions. However, they remain brittle under distribution shifts: when test scenarios change, VLAs often reproduce memorized trajectories instead of adapting to the updated scene, which is a failure mode we refer to as the \"Memory Trap\". This limitation stems from the end-to-end design, which lacks explicit 3D spatial reasoning and prevents reliable identification of actionable regions in unfamiliar environments. To compensate for this missing spatial understanding, 3D Spatial Affordance Fields (SAFs) can provide a geometric representation that highlights where interactions are physically feasible, offering explicit cues about regions the robot should approach or avoid. We therefore introduce Affordance Field Intervention (AFI), a lightweight hybrid framework that uses SAFs as an on-demand plug-in to guide VLA behavior. Our system detects memory traps through proprioception, repositions the robot to recent high-affordance regions, and proposes affordance-driven waypoints that anchor VLA-generated actions. A SAF-based scorer then selects trajectories with the highest cumulative affordance. Extensive experiments demonstrate that our method achieves an average improvement of 23.5% across different VLA backbones ($π_{0}$ and $π_{0.5}$) under out-of-distribution scenarios on real-world robotic platforms, and 20.2% on the LIBERO-Pro benchmark, validating its effectiveness in enhancing VLA robustness to distribution shifts.",
    "authors": [
      "Siyu Xu",
      "Zijian Wang",
      "Yunke Wang",
      "Chenghao Xia",
      "Tao Huang",
      "Chang Xu"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07472v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07472v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.07410v1",
    "title": "InterAgent: Physics-based Multi-agent Command Execution via Diffusion on Interaction Graphs",
    "summary": "Humanoid agents are expected to emulate the complex coordination inherent in human social behaviors. However, existing methods are largely confined to single-agent scenarios, overlooking the physically plausible interplay essential for multi-agent interactions. To bridge this gap, we propose InterAgent, the first end-to-end framework for text-driven physics-based multi-agent humanoid control. At its core, we introduce an autoregressive diffusion transformer equipped with multi-stream blocks, which decouples proprioception, exteroception, and action to mitigate cross-modal interference while enabling synergistic coordination. We further propose a novel interaction graph exteroception representation that explicitly captures fine-grained joint-to-joint spatial dependencies to facilitate network learning. Additionally, within it we devise a sparse edge-based attention mechanism that dynamically prunes redundant connections and emphasizes critical inter-agent spatial relations, thereby enhancing the robustness of interaction modeling. Extensive experiments demonstrate that InterAgent consistently outperforms multiple strong baselines, achieving state-of-the-art performance. It enables producing coherent, physically plausible, and semantically faithful multi-agent behaviors from only text prompts. Our code and data will be released to facilitate future research.",
    "authors": [
      "Bin Li",
      "Ruichi Zhang",
      "Han Liang",
      "Jingyan Zhang",
      "Juze Zhang",
      "Xin Chen",
      "Lan Xu",
      "Jingyi Yu",
      "Jingya Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07410v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07410v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.07407v1",
    "title": "Training Language Models to Use Prolog as a Tool",
    "summary": "Ensuring reliable tool use is critical for safe agentic AI systems. Language models frequently produce unreliable reasoning with plausible but incorrect solutions that are difficult to verify. To address this, we investigate fine-tuning models to use Prolog as an external tool for verifiable computation. Using Group Relative Policy Optimization (GRPO), we fine-tune Qwen2.5-3B-Instruct on a cleaned GSM8K-Prolog-Prover dataset while varying (i) prompt structure, (ii) reward composition (execution, syntax, semantics, structure), and (iii) inference protocol: single-shot, best-of-N, and two agentic modes where Prolog is invoked internally or independently. Our reinforcement learning approach outperforms supervised fine-tuning, with our 3B model achieving zero-shot MMLU performance comparable to 7B few-shot results. Our findings reveal that: 1) joint tuning of prompt, reward, and inference shapes program syntax and logic; 2) best-of-N with external Prolog verification maximizes accuracy on GSM8K; 3) agentic inference with internal repair yields superior zero-shot generalization on MMLU-Stem and MMLU-Pro. These results demonstrate that grounding model reasoning in formal verification systems substantially improves reliability and auditability for safety-critical applications. The source code for reproducing our experiments is available under https://github.com/niklasmellgren/grpo-prolog-inference",
    "authors": [
      "Niklas Mellgren",
      "Peter Schneider-Kamp",
      "Lukas Galke Poech"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07407v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07407v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.07342v1",
    "title": "PrivORL: Differentially Private Synthetic Dataset for Offline Reinforcement Learning",
    "summary": "Recently, offline reinforcement learning (RL) has become a popular RL paradigm. In offline RL, data providers share pre-collected datasets -- either as individual transitions or sequences of transitions forming trajectories -- to enable the training of RL models (also called agents) without direct interaction with the environments. Offline RL saves interactions with environments compared to traditional RL, and has been effective in critical areas, such as navigation tasks. Meanwhile, concerns about privacy leakage from offline RL datasets have emerged.   To safeguard private information in offline RL datasets, we propose the first differential privacy (DP) offline dataset synthesis method, PrivORL, which leverages a diffusion model and diffusion transformer to synthesize transitions and trajectories, respectively, under DP. The synthetic dataset can then be securely released for downstream analysis and research. PrivORL adopts the popular approach of pre-training a synthesizer on public datasets, and then fine-tuning on sensitive datasets using DP Stochastic Gradient Descent (DP-SGD). Additionally, PrivORL introduces curiosity-driven pre-training, which uses feedback from the curiosity module to diversify the synthetic dataset and thus can generate diverse synthetic transitions and trajectories that closely resemble the sensitive dataset. Extensive experiments on five sensitive offline RL datasets show that our method achieves better utility and fidelity in both DP transition and trajectory synthesis compared to baselines. The replication package is available at the GitHub repository.",
    "authors": [
      "Chen Gong",
      "Zheng Liu",
      "Kecen Li",
      "Tianhao Wang"
    ],
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07342v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07342v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.07302v1",
    "title": "Towards Accurate UAV Image Perception: Guiding Vision-Language Models with Stronger Task Prompts",
    "summary": "Existing image perception methods based on VLMs generally follow a paradigm wherein models extract and analyze image content based on user-provided textual task prompts. However, such methods face limitations when applied to UAV imagery, which presents challenges like target confusion, scale variations, and complex backgrounds. These challenges arise because VLMs' understanding of image content depends on the semantic alignment between visual and textual tokens. When the task prompt is simplistic and the image content is complex, achieving effective alignment becomes difficult, limiting the model's ability to focus on task-relevant information. To address this issue, we introduce AerialVP, the first agent framework for task prompt enhancement in UAV image perception. AerialVP proactively extracts multi-dimensional auxiliary information from UAV images to enhance task prompts, overcoming the limitations of traditional VLM-based approaches. Specifically, the enhancement process includes three stages: (1) analyzing the task prompt to identify the task type and enhancement needs, (2) selecting appropriate tools from the tool repository, and (3) generating enhanced task prompts based on the analysis and selected tools. To evaluate AerialVP, we introduce AerialSense, a comprehensive benchmark for UAV image perception that includes Aerial Visual Reasoning, Aerial Visual Question Answering, and Aerial Visual Grounding tasks. AerialSense provides a standardized basis for evaluating model generalization and performance across diverse resolutions, lighting conditions, and both urban and natural scenes. Experimental results demonstrate that AerialVP significantly enhances task prompt guidance, leading to stable and substantial performance improvements in both open-source and proprietary VLMs. Our work will be available at https://github.com/lostwolves/AerialVP.",
    "authors": [
      "Mingning Guo",
      "Mengwei Wu",
      "Shaoxian Li",
      "Haifeng Li",
      "Chao Tao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07302v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07302v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.07289v1",
    "title": "Equivariant Diffusion for Crystal Structure Prediction",
    "summary": "In addressing the challenge of Crystal Structure Prediction (CSP), symmetry-aware deep learning models, particularly diffusion models, have been extensively studied, which treat CSP as a conditional generation task. However, ensuring permutation, rotation, and periodic translation equivariance during diffusion process remains incompletely addressed. In this work, we propose EquiCSP, a novel equivariant diffusion-based generative model. We not only address the overlooked issue of lattice permutation equivariance in existing models, but also develop a unique noising algorithm that rigorously maintains periodic translation equivariance throughout both training and inference processes. Our experiments indicate that EquiCSP significantly surpasses existing models in terms of generating accurate structures and demonstrates faster convergence during the training process.",
    "authors": [
      "Peijia Lin",
      "Pin Chen",
      "Rui Jiao",
      "Qing Mo",
      "Jianhuan Cen",
      "Wenbing Huang",
      "Yang Liu",
      "Dan Huang",
      "Yutong Lu"
    ],
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07289v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07289v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.07232v1",
    "title": "Cross-platform Product Matching Based on Entity Alignment of Knowledge Graph with RAEA model",
    "summary": "Product matching aims to identify identical or similar products sold on different platforms. By building knowledge graphs (KGs), the product matching problem can be converted to the Entity Alignment (EA) task, which aims to discover the equivalent entities from diverse KGs. The existing EA methods inadequately utilize both attribute triples and relation triples simultaneously, especially the interactions between them. This paper introduces a two-stage pipeline consisting of rough filter and fine filter to match products from eBay and Amazon. For fine filtering, a new framework for Entity Alignment, Relation-aware and Attribute-aware Graph Attention Networks for Entity Alignment (RAEA), is employed. RAEA focuses on the interactions between attribute triples and relation triples, where the entity representation aggregates the alignment signals from attributes and relations with Attribute-aware Entity Encoder and Relation-aware Graph Attention Networks. The experimental results indicate that the RAEA model achieves significant improvements over 12 baselines on EA task in the cross-lingual dataset DBP15K (6.59% on average Hits@1) and delivers competitive results in the monolingual dataset DWY100K. The source code for experiments on DBP15K and DWY100K is available at github (https://github.com/Mockingjay-liu/RAEA-model-for-Entity-Alignment).",
    "authors": [
      "Wenlong Liu",
      "Jiahua Pan",
      "Xingyu Zhang",
      "Xinxin Gong",
      "Yang Ye",
      "Xujin Zhao",
      "Xin Wang",
      "Kent Wu",
      "Hua Xiang",
      "Houmin Yan",
      "Qingpeng Zhang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07232v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07232v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2512.07810v1",
    "title": "Auditing Games for Sandbagging",
    "summary": "Future AI systems could conceal their capabilities ('sandbagging') during evaluations, potentially misleading developers and auditors. We stress-tested sandbagging detection techniques using an auditing game. First, a red team fine-tuned five models, some of which conditionally underperformed, as a proxy for sandbagging. Second, a blue team used black-box, model-internals, or training-based approaches to identify sandbagging models. We found that the blue team could not reliably discriminate sandbaggers from benign models. Black-box approaches were defeated by effective imitation of a weaker model. Linear probes, a model-internals approach, showed more promise but their naive application was vulnerable to behaviours instilled by the red team. We also explored capability elicitation as a strategy for detecting sandbagging. Although Prompt-based elicitation was not reliable, training-based elicitation consistently elicited full performance from the sandbagging models, using only a single correct demonstration of the evaluation task. However the performance of benign models was sometimes also raised, so relying on elicitation as a detection strategy was prone to false-positives. In the short-term, we recommend developers remove potential sandbagging using on-distribution training for elicitation. In the longer-term, further research is needed to ensure the efficacy of training-based elicitation, and develop robust methods for sandbagging detection. We open source our model organisms at https://github.com/AI-Safety-Institute/sandbagging_auditing_games and select transcripts and results at https://huggingface.co/datasets/sandbagging-games/evaluation_logs . A demo illustrating the game can be played at https://sandbagging-demo.far.ai/ .",
    "authors": [
      "Jordan Taylor",
      "Sid Black",
      "Dillon Bowen",
      "Thomas Read",
      "Satvik Golechha",
      "Alex Zelenka-Martin",
      "Oliver Makins",
      "Connor Kissane",
      "Kola Ayonrinde",
      "Jacob Merizian",
      "Samuel Marks",
      "Chris Cundy",
      "Joseph Bloom"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07810v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07810v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2512.07702v1",
    "title": "Guiding What Not to Generate: Automated Negative Prompting for Text-Image Alignment",
    "summary": "Despite substantial progress in text-to-image generation, achieving precise text-image alignment remains challenging, particularly for prompts with rich compositional structure or imaginative elements. To address this, we introduce Negative Prompting for Image Correction (NPC), an automated pipeline that improves alignment by identifying and applying negative prompts that suppress unintended content. We begin by analyzing cross-attention patterns to explain why both targeted negatives-those directly tied to the prompt's alignment error-and untargeted negatives-tokens unrelated to the prompt but present in the generated image-can enhance alignment. To discover useful negatives, NPC generates candidate prompts using a verifier-captioner-proposer framework and ranks them with a salient text-space score, enabling effective selection without requiring additional image synthesis. On GenEval++ and Imagine-Bench, NPC outperforms strong baselines, achieving 0.571 vs. 0.371 on GenEval++ and the best overall performance on Imagine-Bench. By guiding what not to generate, NPC provides a principled, fully automated route to stronger text-image alignment in diffusion models. Code is released at https://github.com/wiarae/NPC.",
    "authors": [
      "Sangha Park",
      "Eunji Kim",
      "Yeongtak Oh",
      "Jooyoung Choi",
      "Sungroh Yoon"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07702v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07702v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2512.07583v1",
    "title": "Complementary Learning Approach for Text Classification using Large Language Models",
    "summary": "In this study, we propose a structured methodology that utilizes large language models (LLMs) in a cost-efficient and parsimonious manner, integrating the strengths of scholars and machines while offsetting their respective weaknesses. Our methodology, facilitated through a chain of thought and few-shot learning prompting from computer science, extends best practices for co-author teams in qualitative research to human-machine teams in quantitative research. This allows humans to utilize abductive reasoning and natural language to interrogate not just what the machine has done but also what the human has done. Our method highlights how scholars can manage inherent weaknesses OF LLMs using careful, low-cost techniques. We demonstrate how to use the methodology to interrogate human-machine rating discrepancies for a sample of 1,934 press releases announcing pharmaceutical alliances (1990-2017).",
    "authors": [
      "Navid Asgari",
      "Benjamin M. Cole"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07583v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07583v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2512.07833v1",
    "title": "Relational Visual Similarity",
    "summary": "Humans do not just see attribute similarity -- we also see relational similarity. An apple is like a peach because both are reddish fruit, but the Earth is also like a peach: its crust, mantle, and core correspond to the peach's skin, flesh, and pit. This ability to perceive and recognize relational similarity, is arguable by cognitive scientist to be what distinguishes humans from other species. Yet, all widely used visual similarity metrics today (e.g., LPIPS, CLIP, DINO) focus solely on perceptual attribute similarity and fail to capture the rich, often surprising relational similarities that humans perceive. How can we go beyond the visible content of an image to capture its relational properties? How can we bring images with the same relational logic closer together in representation space? To answer these questions, we first formulate relational image similarity as a measurable problem: two images are relationally similar when their internal relations or functions among visual elements correspond, even if their visual attributes differ. We then curate 114k image-caption dataset in which the captions are anonymized -- describing the underlying relational logic of the scene rather than its surface content. Using this dataset, we finetune a Vision-Language model to measure the relational similarity between images. This model serves as the first step toward connecting images by their underlying relational structure rather than their visible appearance. Our study shows that while relational similarity has a lot of real-world applications, existing image similarity models fail to capture it -- revealing a critical gap in visual computing.",
    "authors": [
      "Thao Nguyen",
      "Sicheng Mo",
      "Krishna Kumar Singh",
      "Yilin Wang",
      "Jing Shi",
      "Nicholas Kolkin",
      "Eli Shechtman",
      "Yong Jae Lee",
      "Yuheng Li"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07833v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07833v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.07694v1",
    "title": "Automated Generation of Custom MedDRA Queries Using SafeTerm Medical Map",
    "summary": "In pre-market drug safety review, grouping related adverse event terms into standardised MedDRA queries or the FDA Office of New Drugs Custom Medical Queries (OCMQs) is critical for signal detection. We present a novel quantitative artificial intelligence system that understands and processes medical terminology and automatically retrieves relevant MedDRA Preferred Terms (PTs) for a given input query, ranking them by a relevance score using multi-criteria statistical methods. The system (SafeTerm) embeds medical query terms and MedDRA PTs in a multidimensional vector space, then applies cosine similarity and extreme-value clustering to generate a ranked list of PTs. Validation was conducted against the FDA OCMQ v3.0 (104 queries), restricted to valid MedDRA PTs. Precision, recall and F1 were computed across similarity-thresholds. High recall (>95%) is achieved at moderate thresholds. Higher thresholds improve precision (up to 86%). The optimal threshold (~0.70 - 0.75) yielded recall ~50% and precision ~33%. Narrow-term PT subsets performed similarly but required slightly higher similarity thresholds. The SafeTerm AI-driven system provides a viable supplementary method for automated MedDRA query generation. A similarity threshold of ~0.60 is recommended initially, with increased thresholds for refined term selection.",
    "authors": [
      "Francois Vandenhende",
      "Anna Georgiou",
      "Michalis Georgiou",
      "Theodoros Psaras",
      "Ellie Karekla",
      "Elena Hadjicosta"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07694v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07694v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.07552v1",
    "title": "Performance of the SafeTerm AI-Based MedDRA Query System Against Standardised MedDRA Queries",
    "summary": "In pre-market drug safety review, grouping related adverse event terms into SMQs or OCMQs is critical for signal detection. We assess the performance of SafeTerm Automated Medical Query (AMQ) on MedDRA SMQs. The AMQ is a novel quantitative artificial intelligence system that understands and processes medical terminology and automatically retrieves relevant MedDRA Preferred Terms (PTs) for a given input query, ranking them by a relevance score (0-1) using multi-criteria statistical methods. The system (SafeTerm) embeds medical query terms and MedDRA PTs in a multidimensional vector space, then applies cosine similarity, and extreme-value clustering to generate a ranked list of PTs. Validation was conducted against tier-1 SMQs (110 queries, v28.1). Precision, recall and F1 were computed at multiple similarity-thresholds, defined either manually or using an automated method. High recall (94%)) is achieved at moderate similarity thresholds, indicative of good retrieval sensitivity. Higher thresholds filter out more terms, resulting in improved precision (up to 89%). The optimal threshold (0.70)) yielded an overall recall of (48%) and precision of (45%) across all 110 queries. Restricting to narrow-term PTs achieved slightly better performance at an increased (+0.05) similarity threshold, confirming increased relatedness of narrow versus broad terms. The automatic threshold (0.66) selection prioritizes recall (0.58) to precision (0.29). SafeTerm AMQ achieves comparable, satisfactory performance on SMQs and sanitized OCMQs. It is therefore a viable supplementary method for automated MedDRA query generation, balancing recall and precision. We recommend using suitable MedDRA PT terminology in query formulation and applying the automated threshold method to optimise recall. Increasing similarity scores allows refined, narrow terms selection.",
    "authors": [
      "Francois Vandenhende",
      "Anna Georgiou",
      "Michalis Georgiou",
      "Theodoros Psaras",
      "Ellie Karekla",
      "Elena Hadjicosta"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07552v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07552v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.07500v1",
    "title": "MultiMotion: Multi Subject Video Motion Transfer via Video Diffusion Transformer",
    "summary": "Multi-object video motion transfer poses significant challenges for Diffusion Transformer (DiT) architectures due to inherent motion entanglement and lack of object-level control. We present MultiMotion, a novel unified framework that overcomes these limitations. Our core innovation is Maskaware Attention Motion Flow (AMF), which utilizes SAM2 masks to explicitly disentangle and control motion features for multiple objects within the DiT pipeline. Furthermore, we introduce RectPC, a high-order predictor-corrector solver for efficient and accurate sampling, particularly beneficial for multi-entity generation. To facilitate rigorous evaluation, we construct the first benchmark dataset specifically for DiT-based multi-object motion transfer. MultiMotion demonstrably achieves precise, semantically aligned, and temporally coherent motion transfer for multiple distinct objects, maintaining DiT's high quality and scalability. The code is in the supp.",
    "authors": [
      "Penghui Liu",
      "Jiangshan Wang",
      "Yutong Shen",
      "Shanhui Mo",
      "Chenyang Qi",
      "Yue Ma"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07500v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07500v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.07490v1",
    "title": "Efficient Low-Tubal-Rank Tensor Estimation via Alternating Preconditioned Gradient Descent",
    "summary": "The problem of low-tubal-rank tensor estimation is a fundamental task with wide applications across high-dimensional signal processing, machine learning, and image science. Traditional approaches tackle such a problem by performing tensor singular value decomposition, which is computationally expensive and becomes infeasible for large-scale tensors. Recent approaches address this issue by factorizing the tensor into two smaller factor tensors and solving the resulting problem using gradient descent. However, this kind of approach requires an accurate estimate of the tensor rank, and when the rank is overestimated, the convergence of gradient descent and its variants slows down significantly or even diverges. To address this problem, we propose an Alternating Preconditioned Gradient Descent (APGD) algorithm, which accelerates convergence in the over-parameterized setting by adding a preconditioning term to the original gradient and updating these two factors alternately. Based on certain geometric assumptions on the objective function, we establish linear convergence guarantees for more general low-tubal-rank tensor estimation problems. Then we further analyze the specific cases of low-tubal-rank tensor factorization and low-tubal-rank tensor recovery. Our theoretical results show that APGD achieves linear convergence even under over-parameterization, and the convergence rate is independent of the tensor condition number. Extensive simulations on synthetic data are carried out to validate our theoretical assertions.",
    "authors": [
      "Zhiyu Liu",
      "Zhi Han",
      "Yandong Tang",
      "Jun Fan",
      "Yao Wang"
    ],
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07490v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07490v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.07390v1",
    "title": "Towards Reliable Test-Time Adaptation: Style Invariance as a Correctness Likelihood",
    "summary": "Test-time adaptation (TTA) enables efficient adaptation of deployed models, yet it often leads to poorly calibrated predictive uncertainty - a critical issue in high-stakes domains such as autonomous driving, finance, and healthcare. Existing calibration methods typically assume fixed models or static distributions, resulting in degraded performance under real-world, dynamic test conditions. To address these challenges, we introduce Style Invariance as a Correctness Likelihood (SICL), a framework that leverages style-invariance for robust uncertainty estimation. SICL estimates instance-wise correctness likelihood by measuring prediction consistency across style-altered variants, requiring only the model's forward pass. This makes it a plug-and-play, backpropagation-free calibration module compatible with any TTA method. Comprehensive evaluations across four baselines, five TTA methods, and two realistic scenarios with three model architecture demonstrate that SICL reduces calibration error by an average of 13 percentage points compared to conventional calibration approaches.",
    "authors": [
      "Gilhyun Nam",
      "Taewon Kim",
      "Joonhyun Jeong",
      "Eunho Yang"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07390v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07390v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.07371v1",
    "title": "ESPADA: Execution Speedup via Semantics Aware Demonstration Data Downsampling for Imitation Learning",
    "summary": "Behavior-cloning based visuomotor policies enable precise manipulation but often inherit the slow, cautious tempo of human demonstrations, limiting practical deployment. However, prior studies on acceleration methods mainly rely on statistical or heuristic cues that ignore task semantics and can fail across diverse manipulation settings. We present ESPADA, a semantic and spatially aware framework that segments demonstrations using a VLM-LLM pipeline with 3D gripper-object relations, enabling aggressive downsampling only in non-critical segments while preserving precision-critical phases, without requiring extra data or architectural modifications, or any form of retraining. To scale from a single annotated episode to the full dataset, ESPADA propagates segment labels via Dynamic Time Warping (DTW) on dynamics-only features. Across both simulation and real-world experiments with ACT and DP baselines, ESPADA achieves approximately a 2x speed-up while maintaining success rates, narrowing the gap between human demonstrations and efficient robot control.",
    "authors": [
      "Byungju Kim",
      "Jinu Pahk",
      "Chungwoo Lee",
      "Jaejoon Kim",
      "Jangha Lee",
      "Theo Taeyeong Kim",
      "Kyuhwan Shim",
      "Jun Ki Lee",
      "Byoung-Tak Zhang"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07371v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07371v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.07335v1",
    "title": "Machine learning in an expectation-maximisation framework for nowcasting",
    "summary": "Decision making often occurs in the presence of incomplete information, leading to the under- or overestimation of risk. Leveraging the observable information to learn the complete information is called nowcasting. In practice, incomplete information is often a consequence of reporting or observation delays. In this paper, we propose an expectation-maximisation (EM) framework for nowcasting that uses machine learning techniques to model both the occurrence as well as the reporting process of events. We allow for the inclusion of covariate information specific to the occurrence and reporting periods as well as characteristics related to the entity for which events occurred. We demonstrate how the maximisation step and the information flow between EM iterations can be tailored to leverage the predictive power of neural networks and (extreme) gradient boosting machines (XGBoost). With simulation experiments, we show that we can effectively model both the occurrence and reporting of events when dealing with high-dimensional covariate information. In the presence of non-linear effects, we show that our methodology outperforms existing EM-based nowcasting frameworks that use generalised linear models in the maximisation step. Finally, we apply the framework to the reporting of Argentinian Covid-19 cases, where the XGBoost-based approach again is most performant.",
    "authors": [
      "Paul Wilsens",
      "Katrien Antonio",
      "Gerda Claeskens"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07335v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07335v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.07246v1",
    "title": "Ensembling LLM-Induced Decision Trees for Explainable and Robust Error Detection",
    "summary": "Error detection (ED), which aims to identify incorrect or inconsistent cell values in tabular data, is important for ensuring data quality. Recent state-of-the-art ED methods leverage the pre-trained knowledge and semantic capability embedded in large language models (LLMs) to directly label whether a cell is erroneous. However, this LLM-as-a-labeler pipeline (1) relies on the black box, implicit decision process, thus failing to provide explainability for the detection results, and (2) is highly sensitive to prompts, yielding inconsistent outputs due to inherent model stochasticity, therefore lacking robustness. To address these limitations, we propose an LLM-as-an-inducer framework that adopts LLM to induce the decision tree for ED (termed TreeED) and further ensembles multiple such trees for consensus detection (termed ForestED), thereby improving explainability and robustness. Specifically, based on prompts derived from data context, decision tree specifications and output requirements, TreeED queries the LLM to induce the decision tree skeleton, whose root-to-leaf decision paths specify the stepwise procedure for evaluating a given sample. Each tree contains three types of nodes: (1) rule nodes that perform simple validation checks (e.g., format or range), (2) Graph Neural Network (GNN) nodes that capture complex patterns (e.g., functional dependencies), and (3) leaf nodes that output the final decision types (error or clean). Furthermore, ForestED employs uncertainty-based sampling to obtain multiple row subsets, constructing a decision tree for each subset using TreeED. It then leverages an Expectation-Maximization-based algorithm that jointly estimates tree reliability and optimizes the consensus ED prediction. Extensive xperiments demonstrate that our methods are accurate, explainable and robust, achieving an average F1-score improvement of 16.1% over the best baseline.",
    "authors": [
      "Mengqi Wang",
      "Jianwei Wang",
      "Qing Liu",
      "Xiwei Xu",
      "Zhenchang Xing",
      "Liming Zhu",
      "Wenjie Zhang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07246v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07246v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2512.07814v1",
    "title": "Understanding Privacy Risks in Code Models Through Training Dynamics: A Causal Approach",
    "summary": "Large language models for code (LLM4Code) have greatly improved developer productivity but also raise privacy concerns due to their reliance on open-source repositories containing abundant personally identifiable information (PII). Prior work shows that commercial models can reproduce sensitive PII, yet existing studies largely treat PII as a single category and overlook the heterogeneous risks among different types. We investigate whether distinct PII types vary in their likelihood of being learned and leaked by LLM4Code, and whether this relationship is causal. Our methodology includes building a dataset with diverse PII types, fine-tuning representative models of different scales, computing training dynamics on real PII data, and formulating a structural causal model to estimate the causal effect of learnability on leakage. Results show that leakage risks differ substantially across PII types and correlate with their training dynamics: easy-to-learn instances such as IP addresses exhibit higher leakage, while harder types such as keys and passwords leak less frequently. Ambiguous types show mixed behaviors. This work provides the first causal evidence that leakage risks are type-dependent and offers guidance for developing type-aware and learnability-aware defenses for LLM4Code.",
    "authors": [
      "Hua Yang",
      "Alejandro Velasco",
      "Sen Fang",
      "Bowen Xu",
      "Denys Poshyvanyk"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07814v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07814v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.07602v1",
    "title": "Algorithm-hardware co-design of neuromorphic networks with dual memory pathways",
    "summary": "Spiking neural networks excel at event-driven sensing yet maintaining task-relevant context over long timescales. However building these networks in hardware respecting both tight energy and memory budgets, remains a core challenge in the field. We address this challenge through novel algorithm-hardware co-design effort. At the algorithm level, inspired by the cortical fast-slow organization in the brain, we introduce a neural network with an explicit slow memory pathway that, combined with fast spiking activity, enables a dual memory pathway (DMP) architecture in which each layer maintains a compact low-dimensional state that summarizes recent activity and modulates spiking dynamics. This explicit memory stabilizes learning while preserving event-driven sparsity, achieving competitive accuracy on long-sequence benchmarks with 40-60% fewer parameters than equivalent state-of-the-art spiking neural networks. At the hardware level, we introduce a near-memory-compute architecture that fully leverages the advantages of the DMP architecture by retaining its compact shared state while optimizing dataflow, across heterogeneous sparse-spike and dense-memory pathways. We show experimental results that demonstrate more than a 4x increase in throughput and over a 5x improvement in energy efficiency compared with state-of-the-art implementations. Together, these contributions demonstrate that biological principles can guide functional abstractions that are both algorithmically effective and hardware-efficient, establishing a scalable co-design paradigm for real-time neuromorphic computation and learning.",
    "authors": [
      "Pengfei Sun",
      "Zhe Su",
      "Jascha Achterberg",
      "Giacomo Indiveri",
      "Dan F. M. Goodman",
      "Danyal Akarca"
    ],
    "categories": [
      "cs.NE"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07602v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07602v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.07571v1",
    "title": "A Simple Method to Enhance Pre-trained Language Models with Speech Tokens for Classification",
    "summary": "This paper presents a simple method that allows to easily enhance textual pre-trained large language models with speech information, when fine-tuned for a specific classification task. A classical issue with the fusion of many embeddings from audio with text is the large length of the audio sequence compared to the text one. Our method benefits from an existing speech tokenizer trained for Audio Speech Recognition that output long sequences of tokens from a large vocabulary, making it difficult to integrate it at low cost in a large language model. By applying a simple lasso-based feature selection on multimodal Bag-of-Words representation, we retain only the most important audio tokens for the task, and adapt the language model to them with a self-supervised language modeling objective, before fine-tuning it on the downstream task. We show this helps to improve the performances compared to an unimodal model, to a bigger SpeechLM or to integrating audio via a learned representation. We show the effectiveness of our method on two recent Argumentative Fallacy Detection and Classification tasks where the use of audio was believed counterproductive, reaching state-of-the-art results. We also provide an in-depth analysis of the method, showing that even a random audio token selection helps enhancing the unimodal model. Our code is available [online](https://github.com/salocinc/EACL26SpeechTokFallacy/).",
    "authors": [
      "Nicolas Calbucura",
      "Valentin Barriere"
    ],
    "categories": [
      "cs.CL",
      "cs.MM"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07571v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07571v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.07306v1",
    "title": "Exact Synthetic Populations for Scalable Societal and Market Modeling",
    "summary": "We introduce a constraint-programming framework for generating synthetic populations that reproduce target statistics with high precision while enforcing full individual consistency. Unlike data-driven approaches that infer distributions from samples, our method directly encodes aggregated statistics and structural relations, enabling exact control of demographic profiles without requiring any microdata. We validate the approach on official demographic sources and study the impact of distributional deviations on downstream analyses. This work is conducted within the Pollitics project developed by Emotia, where synthetic populations can be queried through large language models to model societal behaviors, explore market and policy scenarios, and provide reproducible decision-grade insights without personal data.",
    "authors": [
      "Thierry Petit",
      "Arnault Pachot"
    ],
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07306v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07306v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.07276v1",
    "title": "Geo3DVQA: Evaluating Vision-Language Models for 3D Geospatial Reasoning from Aerial Imagery",
    "summary": "Three-dimensional geospatial analysis is critical to applications in urban planning, climate adaptation, and environmental assessment. Current methodologies depend on costly, specialized sensors (e.g., LiDAR and multispectral), which restrict global accessibility. Existing sensor-based and rule-driven methods further struggle with tasks requiring the integration of multiple 3D cues, handling diverse queries, and providing interpretable reasoning. We hereby present Geo3DVQA, a comprehensive benchmark for evaluating vision-language models (VLMs) in height-aware, 3D geospatial reasoning using RGB-only remote sensing imagery. Unlike conventional sensor-based frameworks, Geo3DVQA emphasizes realistic scenarios that integrate elevation, sky view factors, and land cover patterns. The benchmark encompasses 110k curated question-answer pairs spanning 16 task categories across three complexity levels: single-feature inference, multi-feature reasoning, and application-level spatial analysis. The evaluation of ten state-of-the-art VLMs highlights the difficulty of RGB-to-3D reasoning. GPT-4o and Gemini-2.5-Flash achieved only 28.6% and 33.0% accuracy respectively, while domain-specific fine-tuning of Qwen2.5-VL-7B achieved 49.6% (+24.8 points). These results reveal both the limitations of current VLMs and the effectiveness of domain adaptation. Geo3DVQA introduces new challenge frontiers for scalable, accessible, and holistic 3D geospatial analysis. The dataset and code will be released upon publication at https://github.com/mm1129/Geo3DVQA.",
    "authors": [
      "Mai Tsujimoto",
      "Junjue Wang",
      "Weihao Xuan",
      "Naoto Yokoya"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07276v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07276v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.07265v1",
    "title": "TeluguST-46: A Benchmark Corpus and Comprehensive Evaluation for Telugu-English Speech Translation",
    "summary": "Despite Telugu being spoken by over 80 million people, speech translation research for this morphologically rich language remains severely underexplored. We address this gap by developing a high-quality Telugu--English speech translation benchmark from 46 hours of manually verified CSTD corpus data (30h/8h/8h train/dev/test split). Our systematic comparison of cascaded versus end-to-end architectures shows that while IndicWhisper + IndicMT achieves the highest performance due to extensive Telugu-specific training data, finetuned SeamlessM4T models demonstrate remarkable competitiveness despite using significantly less Telugu-specific training data. This finding suggests that with careful hyperparameter tuning and sufficient parallel data (potentially less than 100 hours), end-to-end systems can achieve performance comparable to cascaded approaches in low-resource settings. Our metric reliability study evaluating BLEU, METEOR, ChrF++, ROUGE-L, TER, and BERTScore against human judgments reveals that traditional metrics provide better quality discrimination than BERTScore for Telugu--English translation. The work delivers three key contributions: a reproducible Telugu--English benchmark, empirical evidence of competitive end-to-end performance potential in low-resource scenarios, and practical guidance for automatic evaluation in morphologically complex language pairs.",
    "authors": [
      "Bhavana Akkiraju",
      "Srihari Bandarupalli",
      "Swathi Sambangi",
      "Vasavi Ravuri",
      "R Vijaya Saraswathi",
      "Anil Kumar Vuppala"
    ],
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07265v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07265v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2512.07782v1",
    "title": "GatedFWA: Linear Flash Windowed Attention with Gated Associative Memory",
    "summary": "Modern autoregressive models rely on attention, yet the Softmax full attention in Transformers scales quadratically with sequence length. Sliding Window Attention (SWA) achieves linear-time encoding/decoding by constraining the attention pattern, but under an \\textit{Associative Memory} interpretation, its difference-style update renders the training objective effectively \\emph{unbounded}. In contrast, Softmax attention normalizes updates, leading to \\emph{memory shrinkage and gradient vanishing}. We propose GatedFWA: a Memory-\\underline{Gated} (\\underline{F}lash) \\underline{W}indowed \\underline{A}ttention mechanism that preserves SWAs efficiency while stabilizing memory updates and making gradient flow controllable. In essence, GatedFWA accumulate a per-token/head gate into a decay bias added to the attention logits, acting as a learnable contraction in the memory recurrence. We implement a fused one-pass gate preprocessing and a FlashAttention-compatible kernel that injects the gate under a sliding mask, ensuring I/O efficiency and numerical stability. On language modelling benchmarks, GatedFWA delivers competitive throughput with negligible overhead and better use of global context, and it integrates cleanly with token compression/selection methods such as NSA and generalizes to various autoregressive domains.",
    "authors": [
      "Jiaxu Liu",
      "Yuhe Bai",
      "Christos-Savvas Bouganis"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07782v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07782v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07770v1",
    "title": "Distribution-informed Online Conformal Prediction",
    "summary": "Conformal prediction provides a pivotal and flexible technique for uncertainty quantification by constructing prediction sets with a predefined coverage rate. Many online conformal prediction methods have been developed to address data distribution shifts in fully adversarial environments, resulting in overly conservative prediction sets. We propose Conformal Optimistic Prediction (COP), an online conformal prediction algorithm incorporating underlying data pattern into the update rule. Through estimated cumulative distribution function of non-conformity scores, COP produces tighter prediction sets when predictable pattern exists, while retaining valid coverage guarantees even when estimates are inaccurate. We establish a joint bound on coverage and regret, which further confirms the validity of our approach. We also prove that COP achieves distribution-free, finite-sample coverage under arbitrary learning rates and can converge when scores are $i.i.d.$. The experimental results also show that COP can achieve valid coverage and construct shorter prediction intervals than other baselines.",
    "authors": [
      "Dongjian Hu",
      "Junxi Wu",
      "Shu-Tao Xia",
      "Changliang Zou"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07770v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07770v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07766v1",
    "title": "Formalized Hopfield Networks and Boltzmann Machines",
    "summary": "Neural networks are widely used, yet their analysis and verification remain challenging. In this work, we present a Lean 4 formalization of neural networks, covering both deterministic and stochastic models. We first formalize Hopfield networks, recurrent networks that store patterns as stable states. We prove convergence and the correctness of Hebbian learning, a training rule that updates network parameters to encode patterns, here limited to the case of pairwise-orthogonal patterns. We then consider stochastic networks, where updates are probabilistic and convergence is to a stationary distribution. As a canonical example, we formalize the dynamics of Boltzmann machines and prove their ergodicity, showing convergence to a unique stationary distribution using a new formalization of the Perron-Frobenius theorem.",
    "authors": [
      "Matteo Cipollina",
      "Michail Karatarakis",
      "Freek Wiedijk"
    ],
    "categories": [
      "cs.LG",
      "cs.LO"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07766v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07766v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07724v1",
    "title": "The Native Spiking Microarchitecture: From Iontronic Primitives to Bit-Exact FP8 Arithmetic",
    "summary": "The 2025 Nobel Prize in Chemistry for Metal-Organic Frameworks (MOFs) and recent breakthroughs by Huanting Wang's team at Monash University establish angstrom-scale channels as promising post-silicon substrates with native integrate-and-fire (IF) dynamics. However, utilizing these stochastic, analog materials for deterministic, bit-exact AI workloads (e.g., FP8) remains a paradox. Existing neuromorphic methods often settle for approximation, failing Transformer precision standards. To traverse the gap \"from stochastic ions to deterministic floats,\" we propose a Native Spiking Microarchitecture. Treating noisy neurons as logic primitives, we introduce a Spatial Combinational Pipeline and a Sticky-Extra Correction mechanism. Validation across all 16,129 FP8 pairs confirms 100% bit-exact alignment with PyTorch. Crucially, our architecture reduces Linear layer latency to O(log N), yielding a 17x speedup. Physical simulations further demonstrate robustness against extreme membrane leakage (beta approx 0.01), effectively immunizing the system against the stochastic nature of the hardware.",
    "authors": [
      "Zhengzheng Tang"
    ],
    "categories": [
      "cs.ET",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07724v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07724v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07720v1",
    "title": "ViSA: 3D-Aware Video Shading for Real-Time Upper-Body Avatar Creation",
    "summary": "Generating high-fidelity upper-body 3D avatars from one-shot input image remains a significant challenge. Current 3D avatar generation methods, which rely on large reconstruction models, are fast and capable of producing stable body structures, but they often suffer from artifacts such as blurry textures and stiff, unnatural motion. In contrast, generative video models show promising performance by synthesizing photorealistic and dynamic results, but they frequently struggle with unstable behavior, including body structural errors and identity drift. To address these limitations, we propose a novel approach that combines the strengths of both paradigms. Our framework employs a 3D reconstruction model to provide robust structural and appearance priors, which in turn guides a real-time autoregressive video diffusion model for rendering. This process enables the model to synthesize high-frequency, photorealistic details and fluid dynamics in real time, effectively reducing texture blur and motion stiffness while preventing the structural inconsistencies common in video generation methods. By uniting the geometric stability of 3D reconstruction with the generative capabilities of video models, our method produces high-fidelity digital avatars with realistic appearance and dynamic, temporally coherent motion. Experiments demonstrate that our approach significantly reduces artifacts and achieves substantial improvements in visual quality over leading methods, providing a robust and efficient solution for real-time applications such as gaming and virtual reality. Project page: https://lhyfst.github.io/visa",
    "authors": [
      "Fan Yang",
      "Heyuan Li",
      "Peihao Li",
      "Weihao Yuan",
      "Lingteng Qiu",
      "Chaoyue Song",
      "Cheng Chen",
      "Yisheng He",
      "Shifeng Zhang",
      "Xiaoguang Han",
      "Steven Hoi",
      "Guosheng Lin"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07720v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07720v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07705v1",
    "title": "In-Context and Few-Shots Learning for Forecasting Time Series Data based on Large Language Models",
    "summary": "Existing data-driven approaches in modeling and predicting time series data include ARIMA (Autoregressive Integrated Moving Average), Transformer-based models, LSTM (Long Short-Term Memory) and TCN (Temporal Convolutional Network). These approaches, and in particular deep learning-based models such as LSTM and TCN, have shown great results in predicting time series data. With the advancement of leveraging pre-trained foundation models such as Large Language Models (LLMs) and more notably Google's recent foundation model for time series data, {\\it TimesFM} (Time Series Foundation Model), it is of interest to investigate whether these foundation models have the capability of outperforming existing modeling approaches in analyzing and predicting time series data.   This paper investigates the performance of using LLM models for time series data prediction. We investigate the in-context learning methodology in the training of LLM models that are specific to the underlying application domain. More specifically, the paper explores training LLMs through in-context, zero-shot and few-shot learning and forecasting time series data with OpenAI {\\tt o4-mini} and Gemini 2.5 Flash Lite, as well as the recent Google's Transformer-based TimesFM, a time series-specific foundation model, along with two deep learning models, namely TCN and LSTM networks. The findings indicate that TimesFM has the best overall performance with the lowest RMSE value (0.3023) and the competitive inference time (266 seconds). Furthermore, OpenAI's o4-mini also exhibits a good performance based on Zero Shot learning.   These findings highlight pre-trained time series foundation models as a promising direction for real-time forecasting, enabling accurate and scalable deployment with minimal model adaptation.",
    "authors": [
      "Saroj Gopali",
      "Bipin Chhetri",
      "Deepika Giri",
      "Sima Siami-Namini",
      "Akbar Siami Namin"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07705v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07705v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07627v1",
    "title": "Incorporating Structure and Chord Constraints in Symbolic Transformer-based Melodic Harmonization",
    "summary": "Transformer architectures offer significant advantages regarding the generation of symbolic music; their capabilities for incorporating user preferences toward what they generate is being studied under many aspects. This paper studies the inclusion of predefined chord constraints in melodic harmonization, i.e., where a desired chord at a specific location is provided along with the melody as inputs and the autoregressive transformer model needs to incorporate the chord in the harmonization that it generates. The peculiarities of involving such constraints is discussed and an algorithm is proposed for tackling this task. This algorithm is called B* and it combines aspects of beam search and A* along with backtracking to force pretrained transformers to satisfy the chord constraints, at the correct onset position within the correct bar. The algorithm is brute-force and has exponential complexity in the worst case; however, this paper is a first attempt to highlight the difficulties of the problem and proposes an algorithm that offers many possibilities for improvements since it accommodates the involvement of heuristics.",
    "authors": [
      "Maximos Kaliakatsos-Papakostas",
      "Konstantinos Soiledis",
      "Theodoros Tsamis",
      "Dimos Makris",
      "Vassilis Katsouros",
      "Emilios Cambouropoulos"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.SC"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07627v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07627v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07564v1",
    "title": "Toward More Reliable Artificial Intelligence: Reducing Hallucinations in Vision-Language Models",
    "summary": "Vision-language models (VLMs) frequently generate hallucinated content plausible but incorrect claims about image content. We propose a training-free self-correction framework enabling VLMs to iteratively refine responses through uncertainty-guided visual re-attention. Our method combines multidimensional uncertainty quantification (token entropy, attention dispersion, semantic consistency, claim confidence) with attention-guided cropping of under-explored regions. Operating entirely with frozen, pretrained VLMs, our framework requires no gradient updates. We validate our approach on the POPE and MMHAL BENCH benchmarks using the Qwen2.5-VL-7B [23] architecture. Experimental results demonstrate that our method reduces hallucination rates by 9.8 percentage points compared to the baseline, while improving object existence accuracy by 4.7 points on adversarial splits. Furthermore, qualitative analysis confirms that uncertainty-guided re-attention successfully grounds corrections in visual evidence where standard decoding fails. We validate our approach on Qwen2.5-VL-7B [23], with plans to extend validation across diverse architectures in future versions. We release our code and methodology to facilitate future research in trustworthy multimodal systems.",
    "authors": [
      "Kassoum Sanogo",
      "Renzo Ardiccioni"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07564v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07564v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07525v1",
    "title": "Beyond Real: Imaginary Extension of Rotary Position Embeddings for Long-Context LLMs",
    "summary": "Rotary Position Embeddings (RoPE) have become a standard for encoding sequence order in Large Language Models (LLMs) by applying rotations to query and key vectors in the complex plane. Standard implementations, however, utilize only the real component of the complex-valued dot product for attention score calculation. This simplification discards the imaginary component, which contains valuable phase information, leading to a potential loss of relational details crucial for modeling long-context dependencies. In this paper, we propose an extension that re-incorporates this discarded imaginary component. Our method leverages the full complex-valued representation to create a dual-component attention score. We theoretically and empirically demonstrate that this approach enhances the modeling of long-context dependencies by preserving more positional information. Furthermore, evaluations on a suite of long-context language modeling benchmarks show that our method consistently improves performance over the standard RoPE, with the benefits becoming more significant as context length increases. The code is available at https://github.com/OpenMOSS/rope_pp.",
    "authors": [
      "Xiaoran Liu",
      "Yuerong Song",
      "Zhigeng Liu",
      "Zengfeng Huang",
      "Qipeng Guo",
      "Zhaoxiang Liu",
      "Shiguo Lian",
      "Ziwei He",
      "Xipeng Qiu"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07525v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07525v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07437v1",
    "title": "KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models",
    "summary": "DreamerV3 is a state-of-the-art online model-based reinforcement learning (MBRL) algorithm known for remarkable sample efficiency. Concurrently, Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to Multi-Layer Perceptrons (MLPs), offering superior parameter efficiency and interpretability. To mitigate KANs' computational overhead, variants like FastKAN leverage Radial Basis Functions (RBFs) to accelerate inference. In this work, we investigate integrating KAN architectures into the DreamerV3 framework. We introduce KAN-Dreamer, replacing specific MLP and convolutional components of DreamerV3 with KAN and FastKAN layers. To ensure efficiency within the JAX-based World Model, we implement a tailored, fully vectorized version with simplified grid management. We structure our investigation into three subsystems: Visual Perception, Latent Prediction, and Behavior Learning. Empirical evaluations on the DeepMind Control Suite (walker_walk) analyze sample efficiency, training time, and asymptotic performance. Experimental results demonstrate that utilizing our adapted FastKAN as a drop-in replacement for the Reward and Continue predictors yields performance on par with the original MLP-based architecture, maintaining parity in both sample efficiency and training speed. This report serves as a preliminary study for future developments in KAN-based world models.",
    "authors": [
      "Chenwei Shi",
      "Xueyu Luan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE",
      "cs.RO"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07437v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07437v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07425v1",
    "title": "Microseismic event classification with a lightweight Fourier Neural Operator model",
    "summary": "Real-time monitoring of induced seismicity is crucial for mitigating operational hazards, relying on the rapid and accurate classification of microseismic events from continuous data streams. However, while many deep learning models excel at this task, their high computational requirements often limit their practical application in real-time monitoring systems. To address this limitation, a lightweight model based on the Fourier Neural Operator (FNO) is proposed for microseismic event classification, leveraging its inherent resolution-invariance and computational efficiency for waveform processing. In the STanford EArthquake Dataset (STEAD), a global and large-scale database of seismic waveforms, the FNO-based model demonstrates high effectiveness for trigger classification, with an F1 score of 95% even in the scenario of data sparsity in training. The new FNO model greatly decreases the computer power needed relative to current deep learning models without sacrificing the classification success rate measured by the F1 score. A test on a real microseismic dataset shows a classification success rate with an F1 score of 98%, outperforming many traditional deep-learning techniques. A combination of high success rate and low computational power indicates that the FNO model can serve as a methodology of choice for real-time monitoring of microseismicity for induced seismicity. The method saves computational resources and facilitates both post-processing and real-time seismic processing suitable for the implementation of traffic light systems to prevent undesired induced seismicity.",
    "authors": [
      "Ayrat Abdullin",
      "Umair bin Waheed",
      "Leo Eisner",
      "Abdullatif Al-Shuhail"
    ],
    "categories": [
      "physics.geo-ph",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07425v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07425v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07415v1",
    "title": "Data-driven Exploration of Mobility Interaction Patterns",
    "summary": "Understanding the movement behaviours of individuals and the way they react to the external world is a key component of any problem that involves the modelling of human dynamics at a physical level. In particular, it is crucial to capture the influence that the presence of an individual can have on the others. Important examples of applications include crowd simulation and emergency management, where the simulation of the mass of people passes through the simulation of the individuals, taking into consideration the others as part of the general context. While existing solutions basically start from some preconceived behavioural model, in this work we propose an approach that starts directly from the data, adopting a data mining perspective. Our method searches the mobility events in the data that might be possible evidences of mutual interactions between individuals, and on top of them looks for complex, persistent patterns and time evolving configurations of events. The study of these patterns can provide new insights on the mechanics of mobility interactions between individuals, which can potentially help in improving existing simulation models. We instantiate the general methodology on two real case studies, one on cars and one on pedestrians, and a full experimental evaluation is performed, both in terms of performances, parameter sensitivity and interpretation of sample results.",
    "authors": [
      "Gabriele Galatolo",
      "Mirco Nanni"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07415v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07415v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07367v1",
    "title": "Multilingual corpora for the study of new concepts in the social sciences and humanities:",
    "summary": "This article presents a hybrid methodology for building a multilingual corpus designed to support the study of emerging concepts in the humanities and social sciences (HSS), illustrated here through the case of ``non-technological innovation''. The corpus relies on two complementary sources: (1) textual content automatically extracted from company websites, cleaned for French and English, and (2) annual reports collected and automatically filtered according to documentary criteria (year, format, duplication). The processing pipeline includes automatic language detection, filtering of non-relevant content, extraction of relevant segments, and enrichment with structural metadata. From this initial corpus, a derived dataset in English is created for machine learning purposes. For each occurrence of a term from the expert lexicon, a contextual block of five sentences is extracted (two preceding and two following the sentence containing the term). Each occurrence is annotated with the thematic category associated with the term, enabling the construction of data suitable for supervised classification tasks. This approach results in a reproducible and extensible resource, suitable both for analyzing lexical variability around emerging concepts and for generating datasets dedicated to natural language processing applications.",
    "authors": [
      "Revekka Kyriakoglou",
      "Anna Pappa"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07367v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07367v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07332v1",
    "title": "Local-Curvature-Aware Knowledge Graph Embedding: An Extended Ricci Flow Approach",
    "summary": "Knowledge graph embedding (KGE) relies on the geometry of the embedding space to encode semantic and structural relations. Existing methods place all entities on one homogeneous manifold, Euclidean, spherical, hyperbolic, or their product/multi-curvature variants, to model linear, symmetric, or hierarchical patterns. Yet a predefined, homogeneous manifold cannot accommodate the sharply varying curvature that real-world graphs exhibit across local regions. Since this geometry is imposed a priori, any mismatch with the knowledge graph's local curvatures will distort distances between entities and hurt the expressiveness of the resulting KGE. To rectify this, we propose RicciKGE to have the KGE loss gradient coupled with local curvatures in an extended Ricci flow such that entity embeddings co-evolve dynamically with the underlying manifold geometry towards mutual adaptation. Theoretically, when the coupling coefficient is bounded and properly selected, we rigorously prove that i) all the edge-wise curvatures decay exponentially, meaning that the manifold is driven toward the Euclidean flatness; and ii) the KGE distances strictly converge to a global optimum, which indicates that geometric flattening and embedding optimization are promoting each other. Experimental improvements on link prediction and node classification benchmarks demonstrate RicciKGE's effectiveness in adapting to heterogeneous knowledge graph structures.",
    "authors": [
      "Zhengquan Luo",
      "Guy Tadmor",
      "Or Amar",
      "David Zeevi",
      "Zhiqiang Xu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07332v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07332v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07313v1",
    "title": "Learning-Augmented Ski Rental with Discrete Distributions: A Bayesian Approach",
    "summary": "We revisit the classic ski rental problem through the lens of Bayesian decision-making and machine-learned predictions. While traditional algorithms minimize worst-case cost without assumptions, and recent learning-augmented approaches leverage noisy forecasts with robustness guarantees, our work unifies these perspectives. We propose a discrete Bayesian framework that maintains exact posterior distributions over the time horizon, enabling principled uncertainty quantification and seamless incorporation of expert priors. Our algorithm achieves prior-dependent competitive guarantees and gracefully interpolates between worst-case and fully-informed settings. Our extensive experimental evaluation demonstrates superior empirical performance across diverse scenarios, achieving near-optimal results under accurate priors while maintaining robust worst-case guarantees. This framework naturally extends to incorporate multiple predictions, non-uniform priors, and contextual information, highlighting the practical advantages of Bayesian reasoning in online decision problems with imperfect predictions.",
    "authors": [
      "Bosun Kang",
      "Hyejun Park",
      "Chenglin Fan"
    ],
    "categories": [
      "cs.LG",
      "cs.DS"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07313v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07313v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07275v1",
    "title": "Effective Attention-Guided Multi-Scale Medical Network for Skin Lesion Segmentation",
    "summary": "In the field of healthcare, precise skin lesion segmentation is crucial for the early detection and accurate diagnosis of skin diseases. Despite significant advances in deep learning for image processing, existing methods have yet to effectively address the challenges of irregular lesion shapes and low contrast. To address these issues, this paper proposes an innovative encoder-decoder network architecture based on multi-scale residual structures, capable of extracting rich feature information from different receptive fields to effectively identify lesion areas. By introducing a Multi-Resolution Multi-Channel Fusion (MRCF) module, our method captures cross-scale features, enhancing the clarity and accuracy of the extracted information. Furthermore, we propose a Cross-Mix Attention Module (CMAM), which redefines the attention scope and dynamically calculates weights across multiple contexts, thus improving the flexibility and depth of feature capture and enabling deeper exploration of subtle features. To overcome the information loss caused by skip connections in traditional U-Net, an External Attention Bridge (EAB) is introduced, facilitating the effective utilization of information in the decoder and compensating for the loss during upsampling. Extensive experimental evaluations on several skin lesion segmentation datasets demonstrate that the proposed model significantly outperforms existing transformer and convolutional neural network-based models, showcasing exceptional segmentation accuracy and robustness.",
    "authors": [
      "Siyu Wang",
      "Hua Wang",
      "Huiyu Li",
      "Fan Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07275v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07275v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07249v1",
    "title": "IFFair: Influence Function-driven Sample Reweighting for Fair Classification",
    "summary": "Because machine learning has significantly improved efficiency and convenience in the society, it's increasingly used to assist or replace human decision-making. However, the data-based pattern makes related algorithms learn and even exacerbate potential bias in samples, resulting in discriminatory decisions against certain unprivileged groups, depriving them of the rights to equal treatment, thus damaging the social well-being and hindering the development of related applications. Therefore, we propose a pre-processing method IFFair based on the influence function. Compared with other fairness optimization approaches, IFFair only uses the influence disparity of training samples on different groups as a guidance to dynamically adjust the sample weights during training without modifying the network structure, data features and decision boundaries. To evaluate the validity of IFFair, we conduct experiments on multiple real-world datasets and metrics. The experimental results show that our approach mitigates bias of multiple accepted metrics in the classification setting, including demographic parity, equalized odds, equality of opportunity and error rate parity without conflicts. It also demonstrates that IFFair achieves better trade-off between multiple utility and fairness metrics compared with previous pre-processing methods.",
    "authors": [
      "Jingran Yang",
      "Min Zhang",
      "Lingfeng Zhang",
      "Zhaohui Wang",
      "Yonggang Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07249v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07249v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2512.07828v1",
    "title": "The Adoption and Usage of AI Agents: Early Evidence from Perplexity",
    "summary": "This paper presents the first large-scale field study of the adoption, usage intensity, and use cases of general-purpose AI agents operating in open-world web environments. Our analysis centers on Comet, an AI-powered browser developed by Perplexity, and its integrated agent, Comet Assistant. Drawing on hundreds of millions of anonymized user interactions, we address three fundamental questions: Who is using AI agents? How intensively are they using them? And what are they using them for? Our findings reveal substantial heterogeneity in adoption and usage across user segments. Earlier adopters, users in countries with higher GDP per capita and educational attainment, and individuals working in digital or knowledge-intensive sectors -- such as digital technology, academia, finance, marketing, and entrepreneurship -- are more likely to adopt or actively use the agent. To systematically characterize the substance of agent usage, we introduce a hierarchical agentic taxonomy that organizes use cases across three levels: topic, subtopic, and task. The two largest topics, Productivity & Workflow and Learning & Research, account for 57% of all agentic queries, while the two largest subtopics, Courses and Shopping for Goods, make up 22%. The top 10 out of 90 tasks represent 55% of queries. Personal use constitutes 55% of queries, while professional and educational contexts comprise 30% and 16%, respectively. In the short term, use cases exhibit strong stickiness, but over time users tend to shift toward more cognitively oriented topics. The diffusion of increasingly capable AI agents carries important implications for researchers, businesses, policymakers, and educators, inviting new lines of inquiry into this rapidly emerging class of AI capabilities.",
    "authors": [
      "Jeremy Yang",
      "Noah Yonack",
      "Kate Zyskowski",
      "Denis Yarats",
      "Johnny Ho",
      "Jerry Ma"
    ],
    "categories": [
      "cs.LG",
      "econ.GN"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07828v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07828v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.07827v1",
    "title": "An Adaptive Multi-Layered Honeynet Architecture for Threat Behavior Analysis via Deep Learning",
    "summary": "The escalating sophistication and variety of cyber threats have rendered static honeypots inadequate, necessitating adaptive, intelligence-driven deception. In this work, ADLAH is introduced: an Adaptive Deep Learning Anomaly Detection Honeynet designed to maximize high-fidelity threat intelligence while minimizing cost through autonomous orchestration of infrastructure. The principal contribution is offered as an end-to-end architectural blueprint and vision for an AI-driven deception platform. Feasibility is evidenced by a functional prototype of the central decision mechanism, in which a reinforcement learning (RL) agent determines, in real time, when sessions should be escalated from low-interaction sensor nodes to dynamically provisioned, high-interaction honeypots. Because sufficient live data were unavailable, field-scale validation is not claimed; instead, design trade-offs and limitations are detailed, and a rigorous roadmap toward empirical evaluation at scale is provided. Beyond selective escalation and anomaly detection, the architecture pursues automated extraction, clustering, and versioning of bot attack chains, a core capability motivated by the empirical observation that exposed services are dominated by automated traffic. Together, these elements delineate a practical path toward cost-efficient capture of high-value adversary behavior, systematic bot versioning, and the production of actionable threat intelligence.",
    "authors": [
      "Lukas Johannes Möller"
    ],
    "categories": [
      "cs.CR",
      "cs.DC",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07827v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07827v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.07820v1",
    "title": "Graph-Based Learning of Spectro-Topographical EEG Representations with Gradient Alignment for Brain-Computer Interfaces",
    "summary": "We present a novel graph-based learning of EEG representations with gradient alignment (GEEGA) that leverages multi-domain information to learn EEG representations for brain-computer interfaces. Our model leverages graph convolutional networks to fuse embeddings from frequency-based topographical maps and time-frequency spectrograms, capturing inter-domain relationships. GEEGA addresses the challenge of achieving high inter-class separability, which arises from the temporally dynamic and subject-sensitive nature of EEG signals by incorporating the center loss and pairwise difference loss. Additionally, GEEGA incorporates a gradient alignment strategy to resolve conflicts between gradients from different domains and the fused embeddings, ensuring that discrepancies, where gradients point in conflicting directions, are aligned toward a unified optimization direction. We validate the efficacy of our method through extensive experiments on three publicly available EEG datasets: BCI-2a, CL-Drive and CLARE. Comprehensive ablation studies further highlight the impact of various components of our model.",
    "authors": [
      "Prithila Angkan",
      "Amin Jalali",
      "Paul Hungler",
      "Ali Etemad"
    ],
    "categories": [
      "cs.HC",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07820v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07820v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.07783v1",
    "title": "On the Interplay of Pre-Training, Mid-Training, and RL on Reasoning Language Models",
    "summary": "Recent reinforcement learning (RL) techniques have yielded impressive reasoning improvements in language models, yet it remains unclear whether post-training truly extends a model's reasoning ability beyond what it acquires during pre-training. A central challenge is the lack of control in modern training pipelines: large-scale pre-training corpora are opaque, mid-training is often underexamined, and RL objectives interact with unknown prior knowledge in complex ways. To resolve this ambiguity, we develop a fully controlled experimental framework that isolates the causal contributions of pre-training, mid-training, and RL-based post-training. Our approach employs synthetic reasoning tasks with explicit atomic operations, parseable step-by-step reasoning traces, and systematic manipulation of training distributions. We evaluate models along two axes: extrapolative generalization to more complex compositions and contextual generalization across surface contexts. Using this framework, we reconcile competing views on RL's effectiveness. We show that: 1) RL produces true capability gains (pass@128) only when pre-training leaves sufficient headroom and when RL data target the model's edge of competence, tasks at the boundary that are difficult but not yet out of reach. 2) Contextual generalization requires minimal yet sufficient pre-training exposure, after which RL can reliably transfer. 3) Mid-training significantly enhances performance under fixed compute compared with RL only, demonstrating its central but underexplored role in training pipelines. 4) Process-level rewards reduce reward hacking and improve reasoning fidelity. Together, these results clarify the interplay between pre-training, mid-training, and RL, offering a foundation for understanding and improving reasoning LM training strategies.",
    "authors": [
      "Charlie Zhang",
      "Graham Neubig",
      "Xiang Yue"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07783v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07783v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.07776v1",
    "title": "GorillaWatch: An Automated System for In-the-Wild Gorilla Re-Identification and Population Monitoring",
    "summary": "Monitoring critically endangered western lowland gorillas is currently hampered by the immense manual effort required to re-identify individuals from vast archives of camera trap footage. The primary obstacle to automating this process has been the lack of large-scale, \"in-the-wild\" video datasets suitable for training robust deep learning models. To address this gap, we introduce a comprehensive benchmark with three novel datasets: Gorilla-SPAC-Wild, the largest video dataset for wild primate re-identification to date; Gorilla-Berlin-Zoo, for assessing cross-domain re-identification generalization; and Gorilla-SPAC-MoT, for evaluating multi-object tracking in camera trap footage. Building on these datasets, we present GorillaWatch, an end-to-end pipeline integrating detection, tracking, and re-identification. To exploit temporal information, we introduce a multi-frame self-supervised pretraining strategy that leverages consistency in tracklets to learn domain-specific features without manual labels. To ensure scientific validity, a differentiable adaptation of AttnLRP verifies that our model relies on discriminative biometric traits rather than background correlations. Extensive benchmarking subsequently demonstrates that aggregating features from large-scale image backbones outperforms specialized video architectures. Finally, we address unsupervised population counting by integrating spatiotemporal constraints into standard clustering to mitigate over-segmentation. We publicly release all code and datasets to facilitate scalable, non-invasive monitoring of endangered species",
    "authors": [
      "Maximilian Schall",
      "Felix Leonard Knöfel",
      "Noah Elias König",
      "Jan Jonas Kubeler",
      "Maximilian von Klinski",
      "Joan Wilhelm Linnemann",
      "Xiaoshi Liu",
      "Iven Jelle Schlegelmilch",
      "Ole Woyciniuk",
      "Alexandra Schild",
      "Dante Wasmuht",
      "Magdalena Bermejo Espinet",
      "German Illera Basas",
      "Gerard de Melo"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07776v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07776v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.07544v1",
    "title": "MoCoRP: Modeling Consistent Relations between Persona and Response for Persona-based Dialogue",
    "summary": "As dialogue systems become increasingly important across various domains, a key challenge in persona-based dialogue is generating engaging and context-specific interactions while ensuring the model acts with a coherent personality. However, existing persona-based dialogue datasets lack explicit relations between persona sentences and responses, which makes it difficult for models to effectively capture persona information. To address these issues, we propose MoCoRP (Modeling Consistent Relations between Persona and Response), a framework that incorporates explicit relations into language models. MoCoRP leverages an NLI expert to explicitly extract the NLI relations between persona sentences and responses, enabling the model to effectively incorporate appropriate persona information from the context into its responses. We applied this framework to pre-trained models like BART and further extended it to modern large language models (LLMs) through alignment tuning. Experimental results on the public datasets ConvAI2 and MPChat demonstrate that MoCoRP outperforms existing baselines, achieving superior persona consistency and engaging, context-aware dialogue generation. Furthermore, our model not only excels in quantitative metrics but also shows significant improvements in qualitative aspects. These results highlight the effectiveness of explicitly modeling persona-response relations in persona-based dialogue. The source codes of MoCoRP are available at https://github.com/DMCB-GIST/MoCoRP.",
    "authors": [
      "Kyungro Lee",
      "Dongha Choi",
      "Hyunju Lee"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07544v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07544v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.07462v1",
    "title": "Understanding LLM Agent Behaviours via Game Theory: Strategy Recognition, Biases and Multi-Agent Dynamics",
    "summary": "As Large Language Models (LLMs) increasingly operate as autonomous decision-makers in interactive and multi-agent systems and human societies, understanding their strategic behaviour has profound implications for safety, coordination, and the design of AI-driven social and economic infrastructures. Assessing such behaviour requires methods that capture not only what LLMs output, but the underlying intentions that guide their decisions. In this work, we extend the FAIRGAME framework to systematically evaluate LLM behaviour in repeated social dilemmas through two complementary advances: a payoff-scaled Prisoners Dilemma isolating sensitivity to incentive magnitude, and an integrated multi-agent Public Goods Game with dynamic payoffs and multi-agent histories. These environments reveal consistent behavioural signatures across models and languages, including incentive-sensitive cooperation, cross-linguistic divergence and end-game alignment toward defection. To interpret these patterns, we train traditional supervised classification models on canonical repeated-game strategies and apply them to FAIRGAME trajectories, showing that LLMs exhibit systematic, model- and language-dependent behavioural intentions, with linguistic framing at times exerting effects as strong as architectural differences. Together, these findings provide a unified methodological foundation for auditing LLMs as strategic agents and reveal systematic cooperation biases with direct implications for AI governance, collective decision-making, and the design of safe multi-agent systems.",
    "authors": [
      "Trung-Kiet Huynh",
      "Duy-Minh Dao-Sy",
      "Thanh-Bang Cao",
      "Phong-Hao Le",
      "Hong-Dan Nguyen",
      "Phu-Quy Nguyen-Lam",
      "Minh-Luan Nguyen-Vo",
      "Hong-Phat Pham",
      "Phu-Hoa Pham",
      "Thien-Kim Than",
      "Chi-Nguyen Tran",
      "Huy Tran",
      "Gia-Thoai Tran-Le",
      "Alessio Buscemi",
      "Le Hong Trang",
      "The Anh Han"
    ],
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT",
      "cs.LG",
      "math.DS"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07462v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07462v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.07459v1",
    "title": "Human Geometry Distribution for 3D Animation Generation",
    "summary": "Generating realistic human geometry animations remains a challenging task, as it requires modeling natural clothing dynamics with fine-grained geometric details under limited data. To address these challenges, we propose two novel designs. First, we propose a compact distribution-based latent representation that enables efficient and high-quality geometry generation. We improve upon previous work by establishing a more uniform mapping between SMPL and avatar geometries. Second, we introduce a generative animation model that fully exploits the diversity of limited motion data. We focus on short-term transitions while maintaining long-term consistency through an identity-conditioned design. These two designs formulate our method as a two-stage framework: the first stage learns a latent space, while the second learns to generate animations within this latent space. We conducted experiments on both our latent space and animation model. We demonstrate that our latent space produces high-fidelity human geometry surpassing previous methods ($90\\%$ lower Chamfer Dist.). The animation model synthesizes diverse animations with detailed and natural dynamics ($2.2 \\times$ higher user study score), achieving the best results across all evaluation metrics.",
    "authors": [
      "Xiangjun Tang",
      "Biao Zhang",
      "Peter Wonka"
    ],
    "categories": [
      "cs.GR",
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07459v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07459v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.07426v1",
    "title": "When normalization hallucinates: unseen risks in AI-powered whole slide image processing",
    "summary": "Whole slide image (WSI) normalization remains a vital preprocessing step in computational pathology. Increasingly driven by deep learning, these models learn to approximate data distributions from training examples. This often results in outputs that gravitate toward the average, potentially masking diagnostically important features. More critically, they can introduce hallucinated content, artifacts that appear realistic but are not present in the original tissue, posing a serious threat to downstream analysis. These hallucinations are nearly impossible to detect visually, and current evaluation practices often overlook them. In this work, we demonstrate that the risk of hallucinations is real and underappreciated. While many methods perform adequately on public datasets, we observe a concerning frequency of hallucinations when these same models are retrained and evaluated on real-world clinical data. To address this, we propose a novel image comparison measure designed to automatically detect hallucinations in normalized outputs. Using this measure, we systematically evaluate several well-cited normalization methods retrained on real-world data, revealing significant inconsistencies and failures that are not captured by conventional metrics. Our findings underscore the need for more robust, interpretable normalization techniques and stricter validation protocols in clinical deployment.",
    "authors": [
      "Karel Moens",
      "Matthew B. Blaschko",
      "Tinne Tuytelaars",
      "Bart Diricx",
      "Jonas De Vylder",
      "Mustafa Yousif"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07426v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07426v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.07309v1",
    "title": "Radiance-Field Reinforced Pretraining: Scaling Localization Models with Unlabeled Wireless Signals",
    "summary": "Radio frequency (RF)-based indoor localization offers significant promise for applications such as indoor navigation, augmented reality, and pervasive computing. While deep learning has greatly enhanced localization accuracy and robustness, existing localization models still face major challenges in cross-scene generalization due to their reliance on scene-specific labeled data. To address this, we introduce Radiance-Field Reinforced Pretraining (RFRP). This novel self-supervised pretraining framework couples a large localization model (LM) with a neural radio-frequency radiance field (RF-NeRF) in an asymmetrical autoencoder architecture. In this design, the LM encodes received RF spectra into latent, position-relevant representations, while the RF-NeRF decodes them to reconstruct the original spectra. This alignment between input and output enables effective representation learning using large-scale, unlabeled RF data, which can be collected continuously with minimal effort. To this end, we collected RF samples at 7,327,321 positions across 100 diverse scenes using four common wireless technologies--RFID, BLE, WiFi, and IIoT. Data from 75 scenes were used for training, and the remaining 25 for evaluation. Experimental results show that the RFRP-pretrained LM reduces localization error by over 40% compared to non-pretrained models and by 21% compared to those pretrained using supervised learning.",
    "authors": [
      "Guosheng Wang",
      "Shen Wang",
      "Lei Yang"
    ],
    "categories": [
      "cs.IT",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07309v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07309v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.07287v1",
    "title": "SIT-Graph: State Integrated Tool Graph for Multi-Turn Agents",
    "summary": "Despite impressive advances in agent systems, multi-turn tool-use scenarios remain challenging. It is mainly because intent is clarified progressively and the environment evolves with each tool call. While reusing past experience is natural, current LLM agents either treat entire trajectories or pre-defined subtasks as indivisible units, or solely exploit tool-to-tool dependencies, hindering adaptation as states and information evolve across turns. In this paper, we propose a State Integrated Tool Graph (SIT-Graph), which enhances multi-turn tool use by exploiting partially overlapping experience. Inspired by human decision-making that integrates episodic and procedural memory, SIT-Graph captures both compact state representations (episodic-like fragments) and tool-to-tool dependencies (procedural-like routines) from historical trajectories. Specifically, we first build a tool graph from accumulated tool-use sequences, and then augment each edge with a compact state summary of the dialog and tool history that may shape the next action. At inference time, SIT-Graph enables a human-like balance between episodic recall and procedural execution: when the next decision requires recalling prior context, the agent retrieves the state summaries stored on relevant edges and uses them to guide its next action; when the step is routine, it follows high-confidence tool dependencies without explicit recall. Experiments across multiple stateful multi-turn tool-use benchmarks show that SIT-Graph consistently outperforms strong memory- and graph-based baselines, delivering more robust tool selection and more effective experience transfer.",
    "authors": [
      "Sijia Li",
      "Yuchen Huang",
      "Zifan Liu",
      "Zijian Li",
      "Jingjing fu",
      "Lei Song",
      "Jiang Bian",
      "Jun Zhang",
      "Rui Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07287v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07287v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.07279v1",
    "title": "Verifiable Deep Quantitative Group Testing",
    "summary": "We present a neural network-based framework for solving the quantitative group testing (QGT) problem that achieves both high decoding accuracy and structural verifiability. In QGT, the objective is to identify a small subset of defective items among $N$ candidates using only $M \\ll N$ pooled tests, each reporting the number of defectives in the tested subset. We train a multi-layer perceptron to map noisy measurement vectors to binary defect indicators, achieving accurate and robust recovery even under sparse, bounded perturbations. Beyond accuracy, we show that the trained network implicitly learns the underlying pooling structure that links items to tests, allowing this structure to be recovered directly from the network's Jacobian. This indicates that the model does not merely memorize training patterns but internalizes the true combinatorial relationships governing QGT. Our findings reveal that standard feedforward architectures can learn verifiable inverse mappings in structured combinatorial recovery problems.",
    "authors": [
      "Shreyas Jayant Grampurohit",
      "Satish Mulleti",
      "Ajit Rajwade"
    ],
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07279v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07279v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.07267v1",
    "title": "Non-negative DAG Learning from Time-Series Data",
    "summary": "This work aims to learn the directed acyclic graph (DAG) that captures the instantaneous dependencies underlying a multivariate time series. The observed data follow a linear structural vector autoregressive model (SVARM) with both instantaneous and time-lagged dependencies, where the instantaneous structure is modeled by a DAG to reflect potential causal relationships. While recent continuous relaxation approaches impose acyclicity through smooth constraint functions involving powers of the adjacency matrix, they lead to non-convex optimization problems that are challenging to solve. In contrast, we assume that the underlying DAG has only non-negative edge weights, and leverage this additional structure to impose acyclicity via a convex constraint. This enables us to cast the problem of non-negative DAG recovery from multivariate time-series data as a convex optimization problem in abstract form, which we solve using the method of multipliers. Crucially, the convex formulation guarantees global optimality of the solution. Finally, we assess the performance of the proposed method on synthetic time-series data, where it outperforms existing alternatives.",
    "authors": [
      "Samuel Rey",
      "Gonzalo Mateos"
    ],
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07267v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07267v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2512.07796v1",
    "title": "Large Causal Models from Large Language Models",
    "summary": "We introduce a new paradigm for building large causal models (LCMs) that exploits the enormous potential latent in today's large language models (LLMs). We describe our ongoing experiments with an implemented system called DEMOCRITUS (Decentralized Extraction of Manifold Ontologies of Causal Relations Integrating Topos Universal Slices) aimed at building, organizing, and visualizing LCMs that span disparate domains extracted from carefully targeted textual queries to LLMs. DEMOCRITUS is methodologically distinct from traditional narrow domain and hypothesis centered causal inference that builds causal models from experiments that produce numerical data. A high-quality LLM is used to propose topics, generate causal questions, and extract plausible causal statements from a diverse range of domains. The technical challenge is then to take these isolated, fragmented, potentially ambiguous and possibly conflicting causal claims, and weave them into a coherent whole, converting them into relational causal triples and embedding them into a LCM. Addressing this technical challenge required inventing new categorical machine learning methods, which we can only briefly summarize in this paper, as it is focused more on the systems side of building DEMOCRITUS. We describe the implementation pipeline for DEMOCRITUS comprising of six modules, examine its computational cost profile to determine where the current bottlenecks in scaling the system to larger models. We describe the results of using DEMOCRITUS over a wide range of domains, spanning archaeology, biology, climate change, economics, medicine and technology. We discuss the limitations of the current DEMOCRITUS system, and outline directions for extending its capabilities.",
    "authors": [
      "Sridhar Mahadevan"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07796v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07796v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2512.07580v1",
    "title": "All You Need Are Random Visual Tokens? Demystifying Token Pruning in VLLMs",
    "summary": "Vision Large Language Models (VLLMs) incur high computational costs due to their reliance on hundreds of visual tokens to represent images. While token pruning offers a promising solution for accelerating inference, this paper, however, identifies a key observation: in deeper layers (e.g., beyond the 20th), existing training-free pruning methods perform no better than random pruning. We hypothesize that this degradation is caused by \"vanishing token information\", where visual tokens progressively lose their salience with increasing network depth. To validate this hypothesis, we quantify a token's information content by measuring the change in the model output probabilities upon its removal. Using this proposed metric, our analysis of the information of visual tokens across layers reveals three key findings: (1) As layers deepen, the information of visual tokens gradually becomes uniform and eventually vanishes at an intermediate layer, which we term as \"information horizon\", beyond which the visual tokens become redundant; (2) The position of this horizon is not static; it extends deeper for visually intensive tasks, such as Optical Character Recognition (OCR), compared to more general tasks like Visual Question Answering (VQA); (3) This horizon is also strongly correlated with model capacity, as stronger VLLMs (e.g., Qwen2.5-VL) employ deeper visual tokens than weaker models (e.g., LLaVA-1.5). Based on our findings, we show that simple random pruning in deep layers efficiently balances performance and efficiency. Moreover, integrating random pruning consistently enhances existing methods. Using DivPrune with random pruning achieves state-of-the-art results, maintaining 96.9% of Qwen-2.5-VL-7B performance while pruning 50% of visual tokens. The code will be publicly available at https://github.com/YahongWang1/Information-Horizon.",
    "authors": [
      "Yahong Wang",
      "Juncheng Wu",
      "Zhangkai Ni",
      "Longzhen Yang",
      "Yihang Liu",
      "Chengmei Yang",
      "Ying Wen",
      "Xianfeng Tang",
      "Hui Liu",
      "Yuyin Zhou",
      "Lianghua He"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07580v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07580v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2512.07527v1",
    "title": "From Orbit to Ground: Generative City Photogrammetry from Extreme Off-Nadir Satellite Images",
    "summary": "City-scale 3D reconstruction from satellite imagery presents the challenge of extreme viewpoint extrapolation, where our goal is to synthesize ground-level novel views from sparse orbital images with minimal parallax. This requires inferring nearly $90^\\circ$ viewpoint gaps from image sources with severely foreshortened facades and flawed textures, causing state-of-the-art reconstruction engines such as NeRF and 3DGS to fail.   To address this problem, we propose two design choices tailored for city structures and satellite inputs. First, we model city geometry as a 2.5D height map, implemented as a Z-monotonic signed distance field (SDF) that matches urban building layouts from top-down viewpoints. This stabilizes geometry optimization under sparse, off-nadir satellite views and yields a watertight mesh with crisp roofs and clean, vertically extruded facades. Second, we paint the mesh appearance from satellite images via differentiable rendering techniques. While the satellite inputs may contain long-range, blurry captures, we further train a generative texture restoration network to enhance the appearance, recovering high-frequency, plausible texture details from degraded inputs.   Our method's scalability and robustness are demonstrated through extensive experiments on large-scale urban reconstruction. For example, in our teaser figure, we reconstruct a $4\\,\\mathrm{km}^2$ real-world region from only a few satellite images, achieving state-of-the-art performance in synthesizing photorealistic ground views. The resulting models are not only visually compelling but also serve as high-fidelity, application-ready assets for downstream tasks like urban planning and simulation.",
    "authors": [
      "Fei Yu",
      "Yu Liu",
      "Luyang Tang",
      "Mingchao Sun",
      "Zengye Ge",
      "Rui Bu",
      "Yuchao Jin",
      "Haisen Zhao",
      "He Sun",
      "Yangyan Li",
      "Mu Xu",
      "Wenzheng Chen",
      "Baoquan Chen"
    ],
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07527v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07527v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2512.07486v1",
    "title": "Materium: An Autoregressive Approach for Material Generation",
    "summary": "We present Materium: an autoregressive transformer for generating crystal structures that converts 3D material representations into token sequences. These sequences include elements with oxidation states, fractional coordinates and lattice parameters. Unlike diffusion approaches, which refine atomic positions iteratively through many denoising steps, Materium places atoms at precise fractional coordinates, enabling fast, scalable generation. With this design, the model can be trained in a few hours on a single GPU and generate samples much faster on GPUs and CPUs than diffusion-based approaches. The model was trained and evaluated using multiple properties as conditions, including fundamental properties, such as density and space group, as well as more practical targets, such as band gap and magnetic density. In both single and combined conditions, the model performs consistently well, producing candidates that align with the requested inputs.",
    "authors": [
      "Niklas Dobberstein",
      "Jan Hamaekers"
    ],
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07486v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07486v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2512.07404v1",
    "title": "Do LLMs Trust the Code They Write?",
    "summary": "Despite the effectiveness of large language models (LLMs) for code generation, they often output incorrect code. One reason is that model output probabilities are often not well-correlated with correctness, and reflect only the final output of the generation process. Inspired by findings that LLMs internally encode concepts like truthfulness, this paper explores if LLMs similarly represent code correctness. Specifically, we identify a correctness representation inside LLMs by contrasting the hidden states between pairs of correct and incorrect code for the same programming tasks. By experimenting on four LLMs, we show that exploiting this extracted correctness representation outperforms standard log-likelihood ranking, as well as verbalized model confidence. Furthermore, we explore how this internal correctness signal can be used to select higher-quality code samples, without requiring test execution. Ultimately, this work demonstrates how leveraging internal representations can enhance code generation systems and make LLMs more reliable, thus improving confidence in automatically generated code.",
    "authors": [
      "Francisco Ribeiro",
      "Claudio Spiess",
      "Prem Devanbu",
      "Sarah Nadi"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07404v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07404v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2512.07269v1",
    "title": "A graph generation pipeline for critical infrastructures based on heuristics, images and depth data",
    "summary": "Virtual representations of physical critical infrastructures, such as water or energy plants, are used for simulations and digital twins to ensure resilience and continuity of their services. These models usually require 3D point clouds from laser scanners that are expensive to acquire and require specialist knowledge to use. In this article, we present a graph generation pipeline based on photogrammetry. The pipeline detects relevant objects and predicts their relation using RGB images and depth data generated by a stereo camera. This more cost-effective approach uses deep learning for object detection and instance segmentation of the objects, and employs user-defined heuristics or rules to infer their relations. Results of two hydraulic systems show that this strategy can produce graphs close to the ground truth while its flexibility allows the method to be tailored to specific applications and its transparency qualifies it to be used in the high stakes decision-making that is required for critical infrastructures.",
    "authors": [
      "Mike Diessner",
      "Yannick Tarant"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07269v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07269v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2512.07802v1",
    "title": "OneStory: Coherent Multi-Shot Video Generation with Adaptive Memory",
    "summary": "Storytelling in real-world videos often unfolds through multiple shots -- discontinuous yet semantically connected clips that together convey a coherent narrative. However, existing multi-shot video generation (MSV) methods struggle to effectively model long-range cross-shot context, as they rely on limited temporal windows or single keyframe conditioning, leading to degraded performance under complex narratives. In this work, we propose OneStory, enabling global yet compact cross-shot context modeling for consistent and scalable narrative generation. OneStory reformulates MSV as a next-shot generation task, enabling autoregressive shot synthesis while leveraging pretrained image-to-video (I2V) models for strong visual conditioning. We introduce two key modules: a Frame Selection module that constructs a semantically-relevant global memory based on informative frames from prior shots, and an Adaptive Conditioner that performs importance-guided patchification to generate compact context for direct conditioning. We further curate a high-quality multi-shot dataset with referential captions to mirror real-world storytelling patterns, and design effective training strategies under the next-shot paradigm. Finetuned from a pretrained I2V model on our curated 60K dataset, OneStory achieves state-of-the-art narrative coherence across diverse and complex scenes in both text- and image-conditioned settings, enabling controllable and immersive long-form video storytelling.",
    "authors": [
      "Zhaochong An",
      "Menglin Jia",
      "Haonan Qiu",
      "Zijian Zhou",
      "Xiaoke Huang",
      "Zhiheng Liu",
      "Weiming Ren",
      "Kumara Kahatapitiya",
      "Ding Liu",
      "Sen He",
      "Chenyang Zhang",
      "Tao Xiang",
      "Fanny Yang",
      "Serge Belongie",
      "Tian Xie"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07802v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07802v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.07755v1",
    "title": "Physics-Informed Neural Networks for Source Inversion and Parameters Estimation in Atmospheric Dispersion",
    "summary": "Recent studies have shown the success of deep learning in solving forward and inverse problems in engineering and scientific computing domains, such as physics-informed neural networks (PINNs). In the fields of atmospheric science and environmental monitoring, estimating emission source locations is a central task that further relies on multiple model parameters that dictate velocity profiles and diffusion parameters. Estimating these parameters at the same time as emission sources from scarce data is a difficult task. In this work, we achieve this by leveraging the flexibility and generality of PINNs. We use a weighted adaptive method based on the neural tangent kernels to solve a source inversion problem with parameter estimation on the 2D and 3D advection-diffusion equations with unknown velocity and diffusion coefficients that may vary in space and time. Our proposed weighted adaptive method is presented as an extension of PINNs for forward PDE problems to a highly ill-posed source inversion and parameter estimation problem. The key idea behind our methodology is to attempt the joint recovery of the solution, the sources along with the unknown parameters, thereby using the underlying partial differential equation as a constraint that couples multiple unknown functional parameters, leading to more efficient use of the limited information in the measurements. We present various numerical experiments, using different types of measurements that model practical engineering systems, to show that our proposed method is indeed successful and robust to additional noise in the measurements.",
    "authors": [
      "Brenda Anague",
      "Bamdad Hosseini",
      "Issa Karambal",
      "Jean Medard Ngnotchouye"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07755v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07755v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.07745v1",
    "title": "DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving",
    "summary": "Generative diffusion models for end-to-end autonomous driving often suffer from mode collapse, tending to generate conservative and homogeneous behaviors. While DiffusionDrive employs predefined anchors representing different driving intentions to partition the action space and generate diverse trajectories, its reliance on imitation learning lacks sufficient constraints, resulting in a dilemma between diversity and consistent high quality. In this work, we propose DiffusionDriveV2, which leverages reinforcement learning to both constrain low-quality modes and explore for superior trajectories. This significantly enhances the overall output quality while preserving the inherent multimodality of its core Gaussian Mixture Model. First, we use scale-adaptive multiplicative noise, ideal for trajectory planning, to promote broad exploration. Second, we employ intra-anchor GRPO to manage advantage estimation among samples generated from a single anchor, and inter-anchor truncated GRPO to incorporate a global perspective across different anchors, preventing improper advantage comparisons between distinct intentions (e.g., turning vs. going straight), which can lead to further mode collapse. DiffusionDriveV2 achieves 91.2 PDMS on the NAVSIM v1 dataset and 85.5 EPDMS on the NAVSIM v2 dataset in closed-loop evaluation with an aligned ResNet-34 backbone, setting a new record. Further experiments validate that our approach resolves the dilemma between diversity and consistent high quality for truncated diffusion models, achieving the best trade-off. Code and model will be available at https://github.com/hustvl/DiffusionDriveV2",
    "authors": [
      "Jialv Zou",
      "Shaoyu Chen",
      "Bencheng Liao",
      "Zhiyu Zheng",
      "Yuehao Song",
      "Lefei Zhang",
      "Qian Zhang",
      "Wenyu Liu",
      "Xinggang Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07745v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07745v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.07687v1",
    "title": "HalluShift++: Bridging Language and Vision through Internal Representation Shifts for Hierarchical Hallucinations in MLLMs",
    "summary": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in vision-language understanding tasks. While these models often produce linguistically coherent output, they often suffer from hallucinations, generating descriptions that are factually inconsistent with the visual content, potentially leading to adverse consequences. Therefore, the assessment of hallucinations in MLLM has become increasingly crucial in the model development process. Contemporary methodologies predominantly depend on external LLM evaluators, which are themselves susceptible to hallucinations and may present challenges in terms of domain adaptation. In this study, we propose the hypothesis that hallucination manifests as measurable irregularities within the internal layer dynamics of MLLMs, not merely due to distributional shifts but also in the context of layer-wise analysis of specific assumptions. By incorporating such modifications, \\textsc{\\textsc{HalluShift++}} broadens the efficacy of hallucination detection from text-based large language models (LLMs) to encompass multimodal scenarios. Our codebase is available at https://github.com/C0mRD/HalluShift_Plus.",
    "authors": [
      "Sujoy Nath",
      "Arkaprabha Basu",
      "Sharanya Dasgupta",
      "Swagatam Das"
    ],
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07687v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07687v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.07676v1",
    "title": "A Bootstrap Perspective on Stochastic Gradient Descent",
    "summary": "Machine learning models trained with \\emph{stochastic} gradient descent (SGD) can generalize better than those trained with deterministic gradient descent (GD). In this work, we study SGD's impact on generalization through the lens of the statistical bootstrap: SGD uses gradient variability under batch sampling as a proxy for solution variability under the randomness of the data collection process. We use empirical results and theoretical analysis to substantiate this claim. In idealized experiments on empirical risk minimization, we show that SGD is drawn to parameter choices that are robust under resampling and thus avoids spurious solutions even if they lie in wider and deeper minima of the training loss. We prove rigorously that by implicitly regularizing the trace of the gradient covariance matrix, SGD controls the algorithmic variability. This regularization leads to solutions that are less sensitive to sampling noise, thereby improving generalization. Numerical experiments on neural network training show that explicitly incorporating the estimate of the algorithmic variability as a regularizer improves test performance. This fact supports our claim that bootstrap estimation underpins SGD's generalization advantages.",
    "authors": [
      "Hongjian Lan",
      "Yucong Liu",
      "Florian Schäfer"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07676v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07676v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.07647v1",
    "title": "A Mathematical Theory of Top-$k$ Sparse Attention via Total Variation Distance",
    "summary": "We develop a unified mathematical framework for certified Top-$k$ attention truncation that quantifies approximation error at both the distribution and output levels. For a single attention distribution $P$ and its Top-$k$ truncation $\\hat P$, we show that the total-variation distance coincides with the discarded softmax tail mass and satisfies $\\mathrm{TV}(P,\\hat P)=1-e^{-\\mathrm{KL}(\\hat P\\Vert P)}$, yielding sharp Top-$k$-specific bounds in place of generic inequalities. From this we derive non-asymptotic deterministic bounds -- from a single boundary gap through multi-gap and blockwise variants -- that control $\\mathrm{TV}(P,\\hat P)$ using only the ordered logits. Using an exact head-tail decomposition, we prove that the output error factorizes as $\\|\\mathrm{Attn}(q,K,V)-\\mathrm{Attn}_k(q,K,V)\\|_2=τ\\|μ_{\\mathrm{tail}}-μ_{\\mathrm{head}}\\|_2$ with $τ=\\mathrm{TV}(P,\\hat P)$, yielding a new head-tail diameter bound $\\|\\mathrm{Attn}(q,K,V)-\\mathrm{Attn}_k(q,K,V)\\|_2\\leτ\\,\\mathrm{diam}_{H,T}$ and refinements linking the error to $\\mathrm{Var}_P(V)$. Under an i.i.d. Gaussian score model $s_i\\sim\\mathcal N(μ,σ^2)$ we derive closed-form tail masses and an asymptotic rule for the minimal $k_\\varepsilon$ ensuring $\\mathrm{TV}(P,\\hat P)\\le\\varepsilon$, namely $k_\\varepsilon/n\\approxΦ_c(σ+Φ^{-1}(\\varepsilon))$. Experiments on bert-base-uncased and synthetic logits confirm the predicted scaling of $k_\\varepsilon/n$ and show that certified Top-$k$ can reduce scored keys by 2-4$\\times$ on average while meeting the prescribed total-variation budget.",
    "authors": [
      "Georgios Tzachristas",
      "Lei Deng",
      "Ioannis Tzachristas",
      "Gong Zhang",
      "Renhai Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07647v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07647v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.07628v1",
    "title": "MoCA: Mixture-of-Components Attention for Scalable Compositional 3D Generation",
    "summary": "Compositionality is critical for 3D object and scene generation, but existing part-aware 3D generation methods suffer from poor scalability due to quadratic global attention costs when increasing the number of components. In this work, we present MoCA, a compositional 3D generative model with two key designs: (1) importance-based component routing that selects top-k relevant components for sparse global attention, and (2) unimportant components compression that preserve contextual priors of unselected components while reducing computational complexity of global attention. With these designs, MoCA enables efficient, fine-grained compositional 3D asset creation with scalable number of components. Extensive experiments show MoCA outperforms baselines on both compositional object and scene generation tasks. Project page: https://lizhiqi49.github.io/MoCA",
    "authors": [
      "Zhiqi Li",
      "Wenhuan Li",
      "Tengfei Wang",
      "Zhenwei Wang",
      "Junta Wu",
      "Haoyuan Wang",
      "Yunhan Yang",
      "Zehuan Huang",
      "Yang Li",
      "Peidong Liu",
      "Chunchao Guo"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07628v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07628v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.07599v1",
    "title": "Online Segment Any 3D Thing as Instance Tracking",
    "summary": "Online, real-time, and fine-grained 3D segmentation constitutes a fundamental capability for embodied intelligent agents to perceive and comprehend their operational environments. Recent advancements employ predefined object queries to aggregate semantic information from Vision Foundation Models (VFMs) outputs that are lifted into 3D point clouds, facilitating spatial information propagation through inter-query interactions. Nevertheless, perception is an inherently dynamic process, rendering temporal understanding a critical yet overlooked dimension within these prevailing query-based pipelines. Therefore, to further unlock the temporal environmental perception capabilities of embodied agents, our work reconceptualizes online 3D segmentation as an instance tracking problem (AutoSeg3D). Our core strategy involves utilizing object queries for temporal information propagation, where long-term instance association promotes the coherence of features and object identities, while short-term instance update enriches instant observations. Given that viewpoint variations in embodied robotics often lead to partial object visibility across frames, this mechanism aids the model in developing a holistic object understanding beyond incomplete instantaneous views. Furthermore, we introduce spatial consistency learning to mitigate the fragmentation problem inherent in VFMs, yielding more comprehensive instance information for enhancing the efficacy of both long-term and short-term temporal learning. The temporal information exchange and consistency learning facilitated by these sparse object queries not only enhance spatial comprehension but also circumvent the computational burden associated with dense temporal point cloud interactions. Our method establishes a new state-of-the-art, surpassing ESAM by 2.8 AP on ScanNet200 and delivering consistent gains on ScanNet, SceneNN, and 3RScan datasets.",
    "authors": [
      "Hanshi Wang",
      "Zijian Cai",
      "Jin Gao",
      "Yiwei Zhang",
      "Weiming Hu",
      "Ke Wang",
      "Zhipeng Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07599v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07599v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.07568v1",
    "title": "Dual-Stream Cross-Modal Representation Learning via Residual Semantic Decorrelation",
    "summary": "Cross-modal learning has become a fundamental paradigm for integrating heterogeneous information sources such as images, text, and structured attributes. However, multimodal representations often suffer from modality dominance, redundant information coupling, and spurious cross-modal correlations, leading to suboptimal generalization and limited interpretability. In particular, high-variance modalities tend to overshadow weaker but semantically important signals, while naïve fusion strategies entangle modality-shared and modality-specific factors in an uncontrolled manner. This makes it difficult to understand which modality actually drives a prediction and to maintain robustness when some modalities are noisy or missing. To address these challenges, we propose a Dual-Stream Residual Semantic Decorrelation Network (DSRSD-Net), a simple yet effective framework that disentangles modality-specific and modality-shared information through residual decomposition and explicit semantic decorrelation constraints. DSRSD-Net introduces: (1) a dual-stream representation learning module that separates intra-modal (private) and inter-modal (shared) latent factors via residual projection; (2) a residual semantic alignment head that maps shared factors from different modalities into a common space using a combination of contrastive and regression-style objectives; and (3) a decorrelation and orthogonality loss that regularizes the covariance structure of the shared space while enforcing orthogonality between shared and private streams, thereby suppressing cross-modal redundancy and preventing feature collapse. Experimental results on two large-scale educational benchmarks demonstrate that DSRSD-Net consistently improves next-step prediction and final outcome prediction over strong single-modality, early-fusion, late-fusion, and co-attention baselines.",
    "authors": [
      "Xuecheng Li",
      "Weikuan Jia",
      "Alisher Kurbonaliev",
      "Qurbonaliev Alisher",
      "Khudzhamkulov Rustam",
      "Ismoilov Shuhratjon",
      "Eshmatov Javhariddin",
      "Yuanjie Zheng"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07568v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07568v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.07543v1",
    "title": "Most over-representation of phonological features in basic vocabulary disappears when controlling for spatial and phylogenetic effects",
    "summary": "The statistical over-representation of phonological features in the basic vocabulary of languages is often interpreted as reflecting potentially universal sound symbolic patterns. However, most of those results have not been tested explicitly for reproducibility and might be prone to biases in the study samples or models. Many studies on the topic do not adequately control for genealogical and areal dependencies between sampled languages, casting doubts on the robustness of the results. In this study, we test the robustness of a recent study on sound symbolism of basic vocabulary concepts which analyzed245 languages.The new sample includes data on 2864 languages from Lexibank. We modify the original model by adding statistical controls for spatial and phylogenetic dependencies between languages. The new results show that most of the previously observed patterns are not robust, and in fact many patterns disappear completely when adding the genealogical and areal controls. A small number of patterns, however, emerges as highly stable even with the new sample. Through the new analysis, we are able to assess the distribution of sound symbolism on a larger scale than previously. The study further highlights the need for testing all universal claims on language for robustness on various levels.",
    "authors": [
      "Frederic Blum"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07543v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07543v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.07528v1",
    "title": "Model-Based Reinforcement Learning Under Confounding",
    "summary": "We investigate model-based reinforcement learning in contextual Markov decision processes (C-MDPs) in which the context is unobserved and induces confounding in the offline dataset. In such settings, conventional model-learning methods are fundamentally inconsistent, as the transition and reward mechanisms generated under a behavioral policy do not correspond to the interventional quantities required for evaluating a state-based policy. To address this issue, we adapt a proximal off-policy evaluation approach that identifies the confounded reward expectation using only observable state-action-reward trajectories under mild invertibility conditions on proxy variables. When combined with a behavior-averaged transition model, this construction yields a surrogate MDP whose Bellman operator is well defined and consistent for state-based policies, and which integrates seamlessly with the maximum causal entropy (MaxCausalEnt) model-learning framework. The proposed formulation enables principled model learning and planning in confounded environments where contextual information is unobserved, unavailable, or impractical to collect.",
    "authors": [
      "Nishanth Venkatesh",
      "Andreas A. Malikopoulos"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07528v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07528v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.07482v1",
    "title": "From Real-World Traffic Data to Relevant Critical Scenarios",
    "summary": "The reliable operation of autonomous vehicles, automated driving functions, and advanced driver assistance systems across a wide range of relevant scenarios is critical for their development and deployment. Identifying a near-complete set of relevant driving scenarios for such functionalities is challenging due to numerous degrees of freedom involved, each affecting the outcomes of the driving scenario differently. Moreover, with increasing technical complexity of new functionalities, the number of potentially relevant, particularly \"unknown unsafe\" scenarios is increasing. To enhance validation efficiency, it is essential to identify relevant scenarios in advance, starting with simpler domains like highways before moving to more complex environments such as urban traffic. To address this, this paper focuses on analyzing lane change scenarios in highway traffic, which involve multiple degrees of freedom and present numerous safetyrelevant scenarios. We describe the process of data acquisition and processing of real-world data from public highway traffic, followed by the application of criticality measures on trajectory data to evaluate scenarios, as conducted within the AVEAS project (www.aveas.org). By linking the calculated measures to specific lane change driving scenarios and the conditions under which the data was collected, we facilitate the identification of safetyrelevant driving scenarios for various applications. Further, to tackle the extensive range of \"unknown unsafe\" scenarios, we propose a way to generate relevant scenarios by creating synthetic scenarios based on recorded ones. Consequently, we demonstrate and evaluate a processing chain that enables the identification of safety-relevant scenarios, the development of data-driven methods for extracting these scenarios, and the generation of synthetic critical scenarios via sampling on highways.",
    "authors": [
      "Florian Lüttner",
      "Nicole Neis",
      "Daniel Stadler",
      "Robin Moss",
      "Mirjam Fehling-Kaschek",
      "Matthias Pfriem",
      "Alexander Stolz",
      "Jens Ziehn"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07482v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07482v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.07312v1",
    "title": "DCO: Dynamic Cache Orchestration for LLM Accelerators through Predictive Management",
    "summary": "The rapid adoption of large language models (LLMs) is pushing AI accelerators toward increasingly powerful and specialized designs. Instead of further complicating software development with deeply hierarchical scratchpad memories (SPMs) and their asynchronous management, we investigate the opposite point of the design spectrum: a multi-core AI accelerator equipped with a shared system-level cache and application-aware management policies, which keeps the programming effort modest. Our approach exploits dataflow information available in the software stack to guide cache replacement (including dead-block prediction), in concert with bypass decisions and mechanisms that alleviate cache thrashing.   We assess the proposal using a cycle-accurate simulator and observe substantial performance gains (up to 1.80x speedup) compared with conventional cache architectures. In addition, we build and validate an analytical model that takes into account the actual overlapping behaviors to extend the measurement results of our policies to real-world larger-scale workloads. Experiment results show that when functioning together, our bypassing and thrashing mitigation strategies can handle scenarios both with and without inter-core data sharing and achieve remarkable speedups.   Finally, we implement the design in RTL and the area of our design is $\\mathbf{0.064mm^2}$ with 15nm process, which can run at 2 GHz clock frequency. Our findings explore the potential of the shared cache design to assist the development of future AI accelerator systems.",
    "authors": [
      "Zhongchun Zhou",
      "Chengtao Lai",
      "Yuhang Gu",
      "Wei Zhang"
    ],
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.DC"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07312v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07312v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.07266v1",
    "title": "SINRL: Socially Integrated Navigation with Reinforcement Learning using Spiking Neural Networks",
    "summary": "Integrating autonomous mobile robots into human environments requires human-like decision-making and energy-efficient, event-based computation. Despite progress, neuromorphic methods are rarely applied to Deep Reinforcement Learning (DRL) navigation approaches due to unstable training. We address this gap with a hybrid socially integrated DRL actor-critic approach that combines Spiking Neural Networks (SNNs) in the actor with Artificial Neural Networks (ANNs) in the critic and a neuromorphic feature extractor to capture temporal crowd dynamics and human-robot interactions. Our approach enhances social navigation performance and reduces estimated energy consumption by approximately 1.69 orders of magnitude.",
    "authors": [
      "Florian Tretter",
      "Daniel Flögel",
      "Alexandru Vasilache",
      "Max Grobbel",
      "Jürgen Becker",
      "Sören Hohmann"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "eess.SY"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07266v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07266v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.07244v1",
    "title": "PINE: Pipeline for Important Node Exploration in Attributed Networks",
    "summary": "A graph with semantically attributed nodes are a common data structure in a wide range of domains. It could be interlinked web data or citation networks of scientific publications. The essential problem for such a data type is to determine nodes that carry greater importance than all the others, a task that markedly enhances system monitoring and management. Traditional methods to identify important nodes in networks introduce centrality measures, such as node degree or more complex PageRank. However, they consider only the network structure, neglecting the rich node attributes. Recent methods adopt neural networks capable of handling node features, but they require supervision. This work addresses the identified gap--the absence of approaches that are both unsupervised and attribute-aware--by introducing a Pipeline for Important Node Exploration (PINE). At the core of the proposed framework is an attention-based graph model that incorporates node semantic features in the learning process of identifying the structural graph properties. The PINE's node importance scores leverage the obtained attention distribution. We demonstrate the superior performance of the proposed PINE method on various homogeneous and heterogeneous attributed networks. As an industry-implemented system, PINE tackles the real-world challenge of unsupervised identification of key entities within large-scale enterprise graphs.",
    "authors": [
      "Elizaveta Kovtun",
      "Maksim Makarenko",
      "Natalia Semenova",
      "Alexey Zaytsev",
      "Semen Budennyy"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07244v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07244v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2512.07806v1",
    "title": "Multi-view Pyramid Transformer: Look Coarser to See Broader",
    "summary": "We propose Multi-view Pyramid Transformer (MVP), a scalable multi-view transformer architecture that directly reconstructs large 3D scenes from tens to hundreds of images in a single forward pass. Drawing on the idea of ``looking broader to see the whole, looking finer to see the details,\" MVP is built on two core design principles: 1) a local-to-global inter-view hierarchy that gradually broadens the model's perspective from local views to groups and ultimately the full scene, and 2) a fine-to-coarse intra-view hierarchy that starts from detailed spatial representations and progressively aggregates them into compact, information-dense tokens. This dual hierarchy achieves both computational efficiency and representational richness, enabling fast reconstruction of large and complex scenes. We validate MVP on diverse datasets and show that, when coupled with 3D Gaussian Splatting as the underlying 3D representation, it achieves state-of-the-art generalizable reconstruction quality while maintaining high efficiency and scalability across a wide range of view configurations.",
    "authors": [
      "Gyeongjin Kang",
      "Seungkwon Yang",
      "Seungtae Nam",
      "Younggeun Lee",
      "Jungwoo Kim",
      "Eunbyung Park"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07806v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07806v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.07805v1",
    "title": "Group Representational Position Encoding",
    "summary": "We present GRAPE (Group RepresentAtional Position Encoding), a unified framework for positional encoding based on group actions. GRAPE brings together two families of mechanisms: (i) multiplicative rotations (Multiplicative GRAPE) in $\\mathrm{SO}(d)$ and (ii) additive logit biases (Additive GRAPE) arising from unipotent actions in the general linear group $\\mathrm{GL}$. In Multiplicative GRAPE, a position $n \\in \\mathbb{Z}$ (or $t \\in \\mathbb{R}$) acts as $\\mathbf{G}(n)=\\exp(n\\,ω\\,\\mathbf{L})$ with a rank-2 skew generator $\\mathbf{L} \\in \\mathbb{R}^{d \\times d}$, yielding a relative, compositional, norm-preserving map with a closed-form matrix exponential. RoPE is recovered exactly when the $d/2$ planes are the canonical coordinate pairs with log-uniform spectrum. Learned commuting subspaces and compact non-commuting mixtures strictly extend this geometry to capture cross-subspace feature coupling at $O(d)$ and $O(r d)$ cost per head, respectively. In Additive GRAPE, additive logits arise as rank-1 (or low-rank) unipotent actions, recovering ALiBi and the Forgetting Transformer (FoX) as exact special cases while preserving an exact relative law and streaming cacheability. Altogether, GRAPE supplies a principled design space for positional geometry in long-context models, subsuming RoPE and ALiBi as special cases. Project Page: https://github.com/model-architectures/GRAPE.",
    "authors": [
      "Yifan Zhang",
      "Zixiang Chen",
      "Yifeng Liu",
      "Zhen Qin",
      "Huizhuo Yuan",
      "Kangping Xu",
      "Yang Yuan",
      "Quanquan Gu",
      "Andrew Chi-Chih Yao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07805v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07805v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.07761v1",
    "title": "RL-MTJail: Reinforcement Learning for Automated Black-Box Multi-Turn Jailbreaking of Large Language Models",
    "summary": "Large language models are vulnerable to jailbreak attacks, threatening their safe deployment in real-world applications. This paper studies black-box multi-turn jailbreaks, aiming to train attacker LLMs to elicit harmful content from black-box models through a sequence of prompt-output interactions. Existing approaches typically rely on single turn optimization, which is insufficient for learning long-term attack strategies. To bridge this gap, we formulate the problem as a multi-turn reinforcement learning task, directly optimizing the harmfulness of the final-turn output as the outcome reward. To mitigate sparse supervision and promote long-term attack strategies, we propose two heuristic process rewards: (1) controlling the harmfulness of intermediate outputs to prevent triggering the black-box model's rejection mechanisms, and (2) maintaining the semantic relevance of intermediate outputs to avoid drifting into irrelevant content. Experimental results on multiple benchmarks show consistently improved attack success rates across multiple models, highlighting the effectiveness of our approach. The code is available at https://github.com/xxiqiao/RL-MTJail. Warning: This paper contains examples of harmful content.",
    "authors": [
      "Xiqiao Xiong",
      "Ouxiang Li",
      "Zhuo Liu",
      "Moxin Li",
      "Wentao Shi",
      "Fuli Feng",
      "Xiangnan He"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07761v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07761v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.07741v1",
    "title": "A multimodal Bayesian Network for symptom-level depression and anxiety prediction from voice and speech data",
    "summary": "During psychiatric assessment, clinicians observe not only what patients report, but important nonverbal signs such as tone, speech rate, fluency, responsiveness, and body language. Weighing and integrating these different information sources is a challenging task and a good candidate for support by intelligence-driven tools - however this is yet to be realized in the clinic. Here, we argue that several important barriers to adoption can be addressed using Bayesian network modelling. To demonstrate this, we evaluate a model for depression and anxiety symptom prediction from voice and speech features in large-scale datasets (30,135 unique speakers). Alongside performance for conditions and symptoms (for depression, anxiety ROC-AUC=0.842,0.831 ECE=0.018,0.015; core individual symptom ROC-AUC>0.74), we assess demographic fairness and investigate integration across and redundancy between different input modality types. Clinical usefulness metrics and acceptability to mental health service users are explored. When provided with sufficiently rich and large-scale multimodal data streams and specified to represent common mental conditions at the symptom rather than disorder level, such models are a principled approach for building robust assessment support tools: providing clinically-relevant outputs in a transparent and explainable format that is directly amenable to expert clinical supervision.",
    "authors": [
      "Agnes Norbury",
      "George Fairs",
      "Alexandra L. Georgescu",
      "Matthew M. Nour",
      "Emilia Molimpakis",
      "Stefano Goria"
    ],
    "categories": [
      "cs.LG",
      "cs.SD"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07741v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07741v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.07738v1",
    "title": "HLTCOE Evaluation Team at TREC 2025: VQA Track",
    "summary": "The HLTCOE Evaluation team participated in TREC VQA's Answer Generation (AG) task, for which we developed a listwise learning framework that aims to improve semantic precision and ranking consistency in answer generation. Given a video-question pair, a base multimodal model first generates multiple candidate answers, which are then reranked using a model trained with a novel Masked Pointer Cross-Entropy Loss with Rank Weights. This objective integrates pointer-based candidate selection, rank-dependent weighting, and masked cross-entropy under vocabulary restriction, enabling stable and interpretable listwise optimization. By bridging generative modeling with discriminative ranking, our method produces coherent, fine-grained answer lists. Experiments reveal consistent gains in accuracy and ranking stability, especially for questions requiring temporal reasoning and semantic disambiguation.",
    "authors": [
      "Dengjia Zhang",
      "Charles Weng",
      "Katherine Guerrerio",
      "Yi Lu",
      "Kenton Murray",
      "Alexander Martin",
      "Reno Kriz",
      "Benjamin Van Durme"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07738v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07738v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.07723v1",
    "title": "Enabling Delayed-Full Charging Through Transformer-Based Real-Time-to-Departure Modeling for EV Battery Longevity",
    "summary": "Electric vehicles (EVs) are key to sustainable mobility, yet their lithium-ion batteries (LIBs) degrade more rapidly under prolonged high states of charge (SOC). This can be mitigated by delaying full charging \\ours until just before departure, which requires accurate prediction of user departure times. In this work, we propose Transformer-based real-time-to-event (TTE) model for accurate EV departure prediction. Our approach represents each day as a TTE sequence by discretizing time into grid-based tokens. Unlike previous methods primarily dependent on temporal dependency from historical patterns, our method leverages streaming contextual information to predict departures. Evaluation on a real-world study involving 93 users and passive smartphone data demonstrates that our method effectively captures irregular departure patterns within individual routines, outperforming baseline models. These results highlight the potential for practical deployment of the \\ours algorithm and its contribution to sustainable transportation systems.",
    "authors": [
      "Yonggeon Lee",
      "Jibin Hwang",
      "Alfred Malengo Kondoro",
      "Juhyun Song",
      "Youngtae Noh"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07723v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07723v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.07624v1",
    "title": "Time Series Foundation Models for Process Model Forecasting",
    "summary": "Process Model Forecasting (PMF) aims to predict how the control-flow structure of a process evolves over time by modeling the temporal dynamics of directly-follows (DF) relations, complementing predictive process monitoring that focuses on single-case prefixes. Prior benchmarks show that machine learning and deep learning models provide only modest gains over statistical baselines, mainly due to the sparsity and heterogeneity of the DF time series. We investigate Time Series Foundation Models (TSFMs), large pre-trained models for generic time series, as an alternative for PMF. Using DF time series derived from real-life event logs, we compare zero-shot use of TSFMs, without additional training, with fine-tuned variants adapted on PMF-specific data. TSFMs generally achieve lower forecasting errors (MAE and RMSE) than traditional and specialized models trained from scratch on the same logs, indicating effective transfer of temporal structure from non-process domains. While fine-tuning can further improve accuracy, the gains are often small and may disappear on smaller or more complex datasets, so zero-shot use remains a strong default. Our study highlights the generalization capability and data efficiency of TSFMs for process-related time series and, to the best of our knowledge, provides the first systematic evaluation of temporal foundation models for PMF.",
    "authors": [
      "Yongbo Yu",
      "Jari Peeperkorn",
      "Johannes De Smedt",
      "Jochen De Weerdt"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07624v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07624v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.07590v1",
    "title": "Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation",
    "summary": "To address the challenge of segmenting noisy images with blurred or fragmented boundaries, this paper presents a robust version of Variational Model Based Tailored UNet (VM_TUNet), a hybrid framework that integrates variational methods with deep learning. The proposed approach incorporates physical priors, an edge detector and a mean curvature term, into a modified Cahn-Hilliard equation, aiming to combine the interpretability and boundary-smoothing advantages of variational partial differential equations (PDEs) with the strong representational ability of deep neural networks. The architecture consists of two collaborative modules: an F module, which conducts efficient frequency domain preprocessing to alleviate poor local minima, and a T module, which ensures accurate and stable local computations, backed by a stability estimate. Extensive experiments on three benchmark datasets indicate that the proposed method achieves a balanced trade-off between performance and computational efficiency, which yields competitive quantitative results and improved visual quality compared to pure convolutional neural network (CNN) based models, while achieving performance close to that of transformer-based method with reasonable computational expense.",
    "authors": [
      "Kaili Qi",
      "Zhongyi Huang",
      "Wenli Yang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07590v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07590v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.07578v1",
    "title": "$φ$-test: Global Feature Selection and Inference for Shapley Additive Explanations",
    "summary": "We propose $φ$-test, a global feature-selection and significance procedure for black-box predictors that combines Shapley attributions with selective inference. Given a trained model and an evaluation dataset, $φ$-test performs SHAP-guided screening and fits a linear surrogate on the screened features via a selection rule with a tractable selective-inference form. For each retained feature, it outputs a Shapley-based global score, a surrogate coefficient, and post-selection $p$-values and confidence intervals in a global feature-importance table. Experiments on real tabular regression tasks with tree-based and neural backbones suggest that $φ$-test can retain much of the predictive ability of the original model while using only a few features and producing feature sets that remain fairly stable across resamples and backbone classes. In these settings, $φ$-test acts as a practical global explanation layer linking Shapley-based importance summaries with classical statistical inference.",
    "authors": [
      "Dongseok Kim",
      "Hyoungsun Choi",
      "Mohamed Jismy Aashik Rasool",
      "Gisung Oh"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07578v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07578v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.07542v1",
    "title": "RRAEDy: Adaptive Latent Linearization of Nonlinear Dynamical Systems",
    "summary": "Most existing latent-space models for dynamical systems require fixing the latent dimension in advance, they rely on complex loss balancing to approximate linear dynamics, and they don't regularize the latent variables. We introduce RRAEDy, a model that removes these limitations by discovering the appropriate latent dimension, while enforcing both regularized and linearized dynamics in the latent space. Built upon Rank-Reduction Autoencoders (RRAEs), RRAEDy automatically rank and prune latent variables through their singular values while learning a latent Dynamic Mode Decomposition (DMD) operator that governs their temporal progression. This structure-free yet linearly constrained formulation enables the model to learn stable and low-dimensional dynamics without auxiliary losses or manual tuning. We provide theoretical analysis demonstrating the stability of the learned operator and showcase the generality of our model by proposing an extension that handles parametric ODEs. Experiments on canonical benchmarks, including the Van der Pol oscillator, Burgers' equation, 2D Navier-Stokes, and Rotating Gaussians, show that RRAEDy achieves accurate and robust predictions. Our code is open-source and available at https://github.com/JadM133/RRAEDy. We also provide a video summarizing the main results at https://youtu.be/ox70mSSMGrM.",
    "authors": [
      "Jad Mounayer",
      "Sebastian Rodriguez",
      "Jerome Tomezyk",
      "Chady Ghnatios",
      "Francisco Chinesta"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07542v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07542v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.07417v1",
    "title": "Adaptive Tuning of Parameterized Traffic Controllers via Multi-Agent Reinforcement Learning",
    "summary": "Effective traffic control is essential for mitigating congestion in transportation networks. Conventional traffic management strategies, including route guidance, ramp metering, and traffic signal control, often rely on state feedback controllers, used for their simplicity and reactivity; however, they lack the adaptability required to cope with complex and time-varying traffic dynamics. This paper proposes a multi-agent reinforcement learning framework in which each agent adaptively tunes the parameters of a state feedback traffic controller, combining the reactivity of state feedback controllers with the adaptability of reinforcement learning. By tuning parameters at a lower frequency rather than directly determining control actions at a high frequency, the reinforcement learning agents achieve improved training efficiency while maintaining adaptability to varying traffic conditions. The multi-agent structure further enhances system robustness, as local controllers can operate independently in the event of partial failures. The proposed framework is evaluated on a simulated multi-class transportation network under varying traffic conditions. Results show that the proposed multi-agent framework outperforms the no control and fixed-parameter state feedback control cases, while performing on par with the single-agent RL-based adaptive state feedback control, with a much better resilience to partial failures.",
    "authors": [
      "Giray Önür",
      "Azita Dabiri",
      "Bart De Schutter"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07417v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07417v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.07394v1",
    "title": "Reconstructing Objects along Hand Interaction Timelines in Egocentric Video",
    "summary": "We introduce the task of Reconstructing Objects along Hand Interaction Timelines (ROHIT). We first define the Hand Interaction Timeline (HIT) from a rigid object's perspective. In a HIT, an object is first static relative to the scene, then is held in hand following contact, where its pose changes. This is usually followed by a firm grip during use, before it is released to be static again w.r.t. to the scene. We model these pose constraints over the HIT, and propose to propagate the object's pose along the HIT enabling superior reconstruction using our proposed Constrained Optimisation and Propagation (COP) framework. Importantly, we focus on timelines with stable grasps - i.e. where the hand is stably holding an object, effectively maintaining constant contact during use. This allows us to efficiently annotate, study, and evaluate object reconstruction in videos without 3D ground truth. We evaluate our proposed task, ROHIT, over two egocentric datasets, HOT3D and in-the-wild EPIC-Kitchens. In HOT3D, we curate 1.2K clips of stable grasps. In EPIC-Kitchens, we annotate 2.4K clips of stable grasps including 390 object instances across 9 categories from videos of daily interactions in 141 environments. Without 3D ground truth, we utilise 2D projection error to assess the reconstruction. Quantitatively, COP improves stable grasp reconstruction by 6.2-11.3% and HIT reconstruction by up to 24.5% with constrained pose propagation.",
    "authors": [
      "Zhifan Zhu",
      "Siddhant Bansal",
      "Shashank Tripathi",
      "Dima Damen"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07394v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07394v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.07381v1",
    "title": "Tessellation GS: Neural Mesh Gaussians for Robust Monocular Reconstruction of Dynamic Objects",
    "summary": "3D Gaussian Splatting (GS) enables highly photorealistic scene reconstruction from posed image sequences but struggles with viewpoint extrapolation due to its anisotropic nature, leading to overfitting and poor generalization, particularly in sparse-view and dynamic scene reconstruction. We propose Tessellation GS, a structured 2D GS approach anchored on mesh faces, to reconstruct dynamic scenes from a single continuously moving or static camera. Our method constrains 2D Gaussians to localized regions and infers their attributes via hierarchical neural features on mesh faces. Gaussian subdivision is guided by an adaptive face subdivision strategy driven by a detail-aware loss function. Additionally, we leverage priors from a reconstruction foundation model to initialize Gaussian deformations, enabling robust reconstruction of general dynamic objects from a single static camera, previously extremely challenging for optimization-based methods. Our method outperforms previous SOTA method, reducing LPIPS by 29.1% and Chamfer distance by 49.2% on appearance and mesh reconstruction tasks.",
    "authors": [
      "Shuohan Tao",
      "Boyao Zhou",
      "Hanzhang Tu",
      "Yuwang Wang",
      "Yebin Liu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07381v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07381v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.07338v1",
    "title": "Generalized Referring Expression Segmentation on Aerial Photos",
    "summary": "Referring expression segmentation is a fundamental task in computer vision that integrates natural language understanding with precise visual localization of target regions. Considering aerial imagery (e.g., modern aerial photos collected through drones, historical photos from aerial archives, high-resolution satellite imagery, etc.) presents unique challenges because spatial resolution varies widely across datasets, the use of color is not consistent, targets often shrink to only a few pixels, and scenes contain very high object densities and objects with partial occlusions. This work presents Aerial-D, a new large-scale referring expression segmentation dataset for aerial imagery, comprising 37,288 images with 1,522,523 referring expressions that cover 259,709 annotated targets, spanning across individual object instances, groups of instances, and semantic regions covering 21 distinct classes that range from vehicles and infrastructure to land coverage types. The dataset was constructed through a fully automatic pipeline that combines systematic rule-based expression generation with a Large Language Model (LLM) enhancement procedure that enriched both the linguistic variety and the focus on visual details within the referring expressions. Filters were additionally used to simulate historic imaging conditions for each scene. We adopted the RSRefSeg architecture, and trained models on Aerial-D together with prior aerial datasets, yielding unified instance and semantic segmentation from text for both modern and historical images. Results show that the combined training achieves competitive performance on contemporary benchmarks, while maintaining strong accuracy under monochrome, sepia, and grainy degradations that appear in archival aerial photography. The dataset, trained models, and complete software pipeline are publicly available at https://luispl77.github.io/aerial-d .",
    "authors": [
      "Luís Marnoto",
      "Alexandre Bernardino",
      "Bruno Martins"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07338v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07338v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2512.07826v1",
    "title": "OpenVE-3M: A Large-Scale High-Quality Dataset for Instruction-Guided Video Editing",
    "summary": "The quality and diversity of instruction-based image editing datasets are continuously increasing, yet large-scale, high-quality datasets for instruction-based video editing remain scarce. To address this gap, we introduce OpenVE-3M, an open-source, large-scale, and high-quality dataset for instruction-based video editing. It comprises two primary categories: spatially-aligned edits (Global Style, Background Change, Local Change, Local Remove, Local Add, and Subtitles Edit) and non-spatially-aligned edits (Camera Multi-Shot Edit and Creative Edit). All edit types are generated via a meticulously designed data pipeline with rigorous quality filtering. OpenVE-3M surpasses existing open-source datasets in terms of scale, diversity of edit types, instruction length, and overall quality. Furthermore, to address the lack of a unified benchmark in the field, we construct OpenVE-Bench, containing 431 video-edit pairs that cover a diverse range of editing tasks with three key metrics highly aligned with human judgment. We present OpenVE-Edit, a 5B model trained on our dataset that demonstrates remarkable efficiency and effectiveness by setting a new state-of-the-art on OpenVE-Bench, outperforming all prior open-source models including a 14B baseline. Project page is at https://github.com/lewandofskee/OpenVE.",
    "authors": [
      "Haoyang He",
      "Jie Wang",
      "Jiangning Zhang",
      "Zhucun Xue",
      "Xingyuan Bu",
      "Qiangpeng Yang",
      "Shilei Wen",
      "Lei Xie"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07826v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07826v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.07818v1",
    "title": "Provable Long-Range Benefits of Next-Token Prediction",
    "summary": "Why do modern language models, trained to do well on next-word prediction, appear to generate coherent documents and capture long-range structure? Here we show that next-token prediction is provably powerful for learning longer-range structure, even with common neural network architectures. Specifically, we prove that optimizing next-token prediction over a Recurrent Neural Network (RNN) yields a model that closely approximates the training distribution: for held-out documents sampled from the training distribution, no algorithm of bounded description length limited to examining the next $k$ tokens, for any $k$, can distinguish between $k$ consecutive tokens of such documents and $k$ tokens generated by the learned language model following the same prefix. We provide polynomial bounds (in $k$, independent of the document length) on the model size needed to achieve such $k$-token indistinguishability, offering a complexity-theoretic explanation for the long-range coherence observed in practice.",
    "authors": [
      "Xinyuan Cao",
      "Santosh S. Vempala"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07818v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07818v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.07652v1",
    "title": "An AI-Powered Autonomous Underwater System for Sea Exploration and Scientific Research",
    "summary": "Traditional sea exploration faces significant challenges due to extreme conditions, limited visibility, and high costs, resulting in vast unexplored ocean regions. This paper presents an innovative AI-powered Autonomous Underwater Vehicle (AUV) system designed to overcome these limitations by automating underwater object detection, analysis, and reporting. The system integrates YOLOv12 Nano for real-time object detection, a Convolutional Neural Network (CNN) (ResNet50) for feature extraction, Principal Component Analysis (PCA) for dimensionality reduction, and K-Means++ clustering for grouping marine objects based on visual characteristics. Furthermore, a Large Language Model (LLM) (GPT-4o Mini) is employed to generate structured reports and summaries of underwater findings, enhancing data interpretation. The system was trained and evaluated on a combined dataset of over 55,000 images from the DeepFish and OzFish datasets, capturing diverse Australian marine environments. Experimental results demonstrate the system's capability to detect marine objects with a mAP@0.5 of 0.512, a precision of 0.535, and a recall of 0.438. The integration of PCA effectively reduced feature dimensionality while preserving 98% variance, facilitating K-Means clustering which successfully grouped detected objects based on visual similarities. The LLM integration proved effective in generating insightful summaries of detections and clusters, supported by location data. This integrated approach significantly reduces the risks associated with human diving, increases mission efficiency, and enhances the speed and depth of underwater data analysis, paving the way for more effective scientific research and discovery in challenging marine environments.",
    "authors": [
      "Hamad Almazrouei",
      "Mariam Al Nasseri",
      "Maha Alzaabi"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07652v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07652v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.07608v1",
    "title": "Metric-Fair Prompting: Treating Similar Samples Similarly",
    "summary": "We introduce \\emph{Metric-Fair Prompting}, a fairness-aware prompting framework that guides large language models (LLMs) to make decisions under metric-fairness constraints. In the application of multiple-choice medical question answering, each {(question, option)} pair is treated as a binary instance with label $+1$ (correct) or $-1$ (incorrect). To promote {individual fairness}~--~treating similar instances similarly~--~we compute question similarity using NLP embeddings and solve items in \\emph{joint pairs of similar questions} rather than in isolation. The prompt enforces a global decision protocol: extract decisive clinical features, map each \\((\\text{question}, \\text{option})\\) to a score $f(x)$ that acts as confidence, and impose a Lipschitz-style constraint so that similar inputs receive similar scores and, hence, consistent outputs. Evaluated on the {MedQA (US)} benchmark, Metric-Fair Prompting is shown to improve performance over standard single-item prompting, demonstrating that fairness-guided, confidence-oriented reasoning can enhance LLM accuracy on high-stakes clinical multiple-choice questions.",
    "authors": [
      "Jing Wang",
      "Jie Shen",
      "Xing Niu",
      "Tong Zhang",
      "Jeremy Weiss"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07608v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07608v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.07497v1",
    "title": "How Do LLMs Fail In Agentic Scenarios? A Qualitative Analysis of Success and Failure Scenarios of Various LLMs in Agentic Simulations",
    "summary": "We investigate how large language models (LLMs) fail when operating as autonomous agents with tool-use capabilities. Using the Kamiwaza Agentic Merit Index (KAMI) v0.1 benchmark, we analyze 900 execution traces from three representative models - Granite 4 Small, Llama 4 Maverick, and DeepSeek V3.1 - across filesystem, text extraction, CSV analysis, and SQL scenarios. Rather than focusing on aggregate scores, we perform fine-grained, per-trial behavioral analysis to surface the strategies that enable successful multi-step tool execution and the recurrent failure modes that undermine reliability. Our findings show that model scale alone does not predict agentic robustness: Llama 4 Maverick (400B) performs only marginally better than Granite 4 Small (32B) in some uncertainty-driven tasks, while DeepSeek V3.1's superior reliability derives primarily from post-training reinforcement learning rather than architecture or size. Across models, we identify four recurring failure archetypes: premature action without grounding, over-helpfulness that substitutes missing entities, vulnerability to distractor-induced context pollution, and fragile execution under load. These patterns highlight the need for agentic evaluation methods that emphasize interactive grounding, recovery behavior, and environment-aware adaptation, suggesting that reliable enterprise deployment requires not just stronger models but deliberate training and design choices that reinforce verification, constraint discovery, and adherence to source-of-truth data.",
    "authors": [
      "JV Roig"
    ],
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07497v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07497v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.07355v1",
    "title": "A Geometric Unification of Concept Learning with Concept Cones",
    "summary": "Two traditions of interpretability have evolved side by side but seldom spoken to each other: Concept Bottleneck Models (CBMs), which prescribe what a concept should be, and Sparse Autoencoders (SAEs), which discover what concepts emerge. While CBMs use supervision to align activations with human-labeled concepts, SAEs rely on sparse coding to uncover emergent ones. We show that both paradigms instantiate the same geometric structure: each learns a set of linear directions in activation space whose nonnegative combinations form a concept cone. Supervised and unsupervised methods thus differ not in kind but in how they select this cone. Building on this view, we propose an operational bridge between the two paradigms. CBMs provide human-defined reference geometries, while SAEs can be evaluated by how well their learned cones approximate or contain those of CBMs. This containment framework yields quantitative metrics linking inductive biases -- such as SAE type, sparsity, or expansion ratio -- to emergence of plausible\\footnote{We adopt the terminology of \\citet{jacovi2020towards}, who distinguish between faithful explanations (accurately reflecting model computations) and plausible explanations (aligning with human intuition and domain knowledge). CBM concepts are plausible by construction -- selected or annotated by humans -- though not necessarily faithful to the true latent factors that organise the data manifold.} concepts. Using these metrics, we uncover a ``sweet spot'' in both sparsity and expansion factor that maximizes both geometric and semantic alignment with CBM concepts. Overall, our work unifies supervised and unsupervised concept discovery through a shared geometric framework, providing principled metrics to measure SAE progress and assess how well discovered concept align with plausible human concepts.",
    "authors": [
      "Alexandre Rocchi--Henry",
      "Thomas Fel",
      "Gianni Franchi"
    ],
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07355v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07355v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.07288v1",
    "title": "Investigating Training and Generalization in Faithful Self-Explanations of Large Language Models",
    "summary": "Large language models have the potential to generate explanations for their own predictions in a variety of styles based on user instructions. Recent research has examined whether these self-explanations faithfully reflect the models' actual behavior and has found that they often lack faithfulness. However, the question of how to improve faithfulness remains underexplored. Moreover, because different explanation styles have superficially distinct characteristics, it is unclear whether improvements observed in one style also arise when using other styles. This study analyzes the effects of training for faithful self-explanations and the extent to which these effects generalize, using three classification tasks and three explanation styles. We construct one-word constrained explanations that are likely to be faithful using a feature attribution method, and use these pseudo-faithful self-explanations for continual learning on instruction-tuned models. Our experiments demonstrate that training can improve self-explanation faithfulness across all classification tasks and explanation styles, and that these improvements also show signs of generalization to the multi-word settings and to unseen tasks. Furthermore, we find consistent cross-style generalization among three styles, suggesting that training may contribute to a broader improvement in faithful self-explanation ability.",
    "authors": [
      "Tomoki Doi",
      "Masaru Isonuma",
      "Hitomi Yanaka"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07288v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07288v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.07273v1",
    "title": "RVLF: A Reinforcing Vision-Language Framework for Gloss-Free Sign Language Translation",
    "summary": "Gloss-free sign language translation (SLT) is hindered by two key challenges: **inadequate sign representation** that fails to capture nuanced visual cues, and **sentence-level semantic misalignment** in current LLM-based methods, which limits translation quality. To address these issues, we propose a three-stage **r**einforcing **v**ision-**l**anguage **f**ramework (**RVLF**). We build a large vision-language model (LVLM) specifically designed for sign language, and then combine it with reinforcement learning (RL) to adaptively enhance translation performance. First, for a sufficient representation of sign language, RVLF introduces an effective semantic representation learning mechanism that fuses skeleton-based motion cues with semantically rich visual features extracted via DINOv2, followed by instruction tuning to obtain a strong SLT-SFT baseline. Then, to improve sentence-level semantic misalignment, we introduce a GRPO-based optimization strategy that fine-tunes the SLT-SFT model with a reward function combining translation fidelity (BLEU) and sentence completeness (ROUGE), yielding the optimized model termed SLT-GRPO. Our conceptually simple framework yields substantial gains under the gloss-free SLT setting without pre-training on any external large-scale sign language datasets, improving BLEU-4 scores by +5.1, +1.11, +1.4, and +1.61 on the CSL-Daily, PHOENIX-2014T, How2Sign, and OpenASL datasets, respectively. To the best of our knowledge, this is the first work to incorporate GRPO into SLT. Extensive experiments and ablation studies validate the effectiveness of GRPO-based optimization in enhancing both translation quality and semantic consistency.",
    "authors": [
      "Zhi Rao",
      "Yucheng Zhou",
      "Benjia Zhou",
      "Yiqing Huang",
      "Sergio Escalera",
      "Jun Wan"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07273v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07273v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2512.07832v1",
    "title": "Do Generalisation Results Generalise?",
    "summary": "A large language model's (LLM's) out-of-distribution (OOD) generalisation ability is crucial to its deployment. Previous work assessing LLMs' generalisation performance, however, typically focuses on a single out-of-distribution dataset. This approach may fail to precisely evaluate the capabilities of the model, as the data shifts encountered once a model is deployed are much more diverse. In this work, we investigate whether OOD generalisation results generalise. More specifically, we evaluate a model's performance across multiple OOD testsets throughout a finetuning run; we then evaluate the partial correlation of performances across these testsets, regressing out in-domain performance. This allows us to assess how correlated are generalisation performances once in-domain performance is controlled for. Analysing OLMo2 and OPT, we observe no overarching trend in generalisation results: the existence of a positive or negative correlation between any two OOD testsets depends strongly on the specific choice of model analysed.",
    "authors": [
      "Matteo Boglioni",
      "Andrea Sgobbi",
      "Gabriel Tavernini",
      "Francesco Rita",
      "Marius Mosbach",
      "Tiago Pimentel"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07832v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07832v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.07777v1",
    "title": "Mary, the Cheeseburger-Eating Vegetarian: Do LLMs Recognize Incoherence in Narratives?",
    "summary": "Leveraging a dataset of paired narratives, we investigate the extent to which large language models (LLMs) can reliably separate incoherent and coherent stories. A probing study finds that LLMs' internal representations can reliably identify incoherent narratives. However, LLMs generate responses to rating questions that fail to satisfactorily separate the coherent and incoherent narratives across several prompt variations, hinting at a gap in LLM's understanding of storytelling. The reasoning LLMs tested do not eliminate these deficits, indicating that thought strings may not be able to fully address the discrepancy between model internal state and behavior. Additionally, we find that LLMs appear to be more sensitive to incoherence resulting from an event that violates the setting (e.g., a rainy day in the desert) than to incoherence arising from a character violating an established trait (e.g., Mary, a vegetarian, later orders a cheeseburger), suggesting that LLMs may rely more on prototypical world knowledge than building meaning-based narrative coherence. The consistent asymmetry found in our results suggests that LLMs do not have a complete grasp on narrative coherence.",
    "authors": [
      "Karin de Langis",
      "Püren Öncel",
      "Ryan Peters",
      "Andrew Elfenbein",
      "Laura Kristen Allen",
      "Andreas Schramm",
      "Dongyeop Kang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07777v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07777v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.07698v1",
    "title": "sim2art: Accurate Articulated Object Modeling from a Single Video using Synthetic Training Data Only",
    "summary": "Understanding articulated objects is a fundamental challenge in robotics and digital twin creation. To effectively model such objects, it is essential to recover both part segmentation and the underlying joint parameters. Despite the importance of this task, previous work has largely focused on setups like multi-view systems, object scanning, or static cameras. In this paper, we present the first data-driven approach that jointly predicts part segmentation and joint parameters from monocular video captured with a freely moving camera. Trained solely on synthetic data, our method demonstrates strong generalization to real-world objects, offering a scalable and practical solution for articulated object understanding. Our approach operates directly on casually recorded video, making it suitable for real-time applications in dynamic environments. Project webpage: https://aartykov.github.io/sim2art/",
    "authors": [
      "Arslan Artykov",
      "Corentin Sautier",
      "Vincent Lepetit"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07698v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07698v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.07569v1",
    "title": "Weighted Contrastive Learning for Anomaly-Aware Time-Series Forecasting",
    "summary": "Reliable forecasting of multivariate time series under anomalous conditions is crucial in applications such as ATM cash logistics, where sudden demand shifts can disrupt operations. Modern deep forecasters achieve high accuracy on normal data but often fail when distribution shifts occur. We propose Weighted Contrastive Adaptation (WECA), a Weighted contrastive objective that aligns normal and anomaly-augmented representations, preserving anomaly-relevant information while maintaining consistency under benign variations. Evaluations on a nationwide ATM transaction dataset with domain-informed anomaly injection show that WECA improves SMAPE on anomaly-affected data by 6.1 percentage points compared to a normally trained baseline, with negligible degradation on normal data. These results demonstrate that WECA enhances forecasting reliability under anomalies without sacrificing performance during regular operations.",
    "authors": [
      "Joel Ekstrand",
      "Tor Mattsson",
      "Zahra Taghiyarrenani",
      "Slawomir Nowaczyk",
      "Jens Lundström",
      "Mikael Lindén"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07569v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07569v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.07557v1",
    "title": "On Conditional Independence Graph Learning From Multi-Attribute Gaussian Dependent Time Series",
    "summary": "Estimation of the conditional independence graph (CIG) of high-dimensional multivariate Gaussian time series from multi-attribute data is considered. Existing methods for graph estimation for such data are based on single-attribute models where one associates a scalar time series with each node. In multi-attribute graphical models, each node represents a random vector or vector time series. In this paper we provide a unified theoretical analysis of multi-attribute graph learning for dependent time series using a penalized log-likelihood objective function formulated in the frequency domain using the discrete Fourier transform of the time-domain data. We consider both convex (sparse-group lasso) and non-convex (log-sum and SCAD group penalties) penalty/regularization functions. We establish sufficient conditions in a high-dimensional setting for consistency (convergence of the inverse power spectral density to true value in the Frobenius norm), local convexity when using non-convex penalties, and graph recovery. We do not impose any incoherence or irrepresentability condition for our convergence results. We also empirically investigate selection of the tuning parameters based on the Bayesian information criterion, and illustrate our approach using numerical examples utilizing both synthetic and real data.",
    "authors": [
      "Jitendra K. Tugnait"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "eess.SP"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07557v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07557v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.07498v1",
    "title": "Towards Robust DeepFake Detection under Unstable Face Sequences: Adaptive Sparse Graph Embedding with Order-Free Representation and Explicit Laplacian Spectral Prior",
    "summary": "Ensuring the authenticity of video content remains challenging as DeepFake generation becomes increasingly realistic and robust against detection. Most existing detectors implicitly assume temporally consistent and clean facial sequences, an assumption that rarely holds in real-world scenarios where compression artifacts, occlusions, and adversarial attacks destabilize face detection and often lead to invalid or misdetected faces. To address these challenges, we propose a Laplacian-Regularized Graph Convolutional Network (LR-GCN) that robustly detects DeepFakes from noisy or unordered face sequences, while being trained only on clean facial data. Our method constructs an Order-Free Temporal Graph Embedding (OF-TGE) that organizes frame-wise CNN features into an adaptive sparse graph based on semantic affinities. Unlike traditional methods constrained by strict temporal continuity, OF-TGE captures intrinsic feature consistency across frames, making it resilient to shuffled, missing, or heavily corrupted inputs. We further impose a dual-level sparsity mechanism on both graph structure and node features to suppress the influence of invalid faces. Crucially, we introduce an explicit Graph Laplacian Spectral Prior that acts as a high-pass operator in the graph spectral domain, highlighting structural anomalies and forgery artifacts, which are then consolidated by a low-pass GCN aggregation. This sequential design effectively realizes a task-driven spectral band-pass mechanism that suppresses background information and random noise while preserving manipulation cues. Extensive experiments on FF++, Celeb-DFv2, and DFDC demonstrate that LR-GCN achieves state-of-the-art performance and significantly improved robustness under severe global and local disruptions, including missing faces, occlusions, and adversarially perturbed face detections.",
    "authors": [
      "Chih-Chung Hsu",
      "Shao-Ning Chen",
      "Chia-Ming Lee",
      "Yi-Fang Wang",
      "Yi-Shiuan Chou"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07498v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07498v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.07487v1",
    "title": "Artificial Intelligence and Nuclear Weapons Proliferation: The Technological Arms Race for (In)visibility",
    "summary": "A robust nonproliferation regime has contained the spread of nuclear weapons to just nine states. Yet, emerging and disruptive technologies are reshaping the landscape of nuclear risks, presenting a critical juncture for decision makers. This article lays out the contours of an overlooked but intensifying technological arms race for nuclear (in)visibility, driven by the interplay between proliferation-enabling technologies (PETs) and detection-enhancing technologies (DETs). We argue that the strategic pattern of proliferation will be increasingly shaped by the innovation pace in these domains. Artificial intelligence (AI) introduces unprecedented complexity to this equation, as its rapid scaling and knowledge substitution capabilities accelerate PET development and challenge traditional monitoring and verification methods. To analyze this dynamic, we develop a formal model centered on a Relative Advantage Index (RAI), quantifying the shifting balance between PETs and DETs. Our model explores how asymmetric technological advancement, particularly logistic AI-driven PET growth versus stepwise DET improvements, expands the band of uncertainty surrounding proliferation detectability. Through replicable scenario-based simulations, we evaluate the impact of varying PET growth rates and DET investment strategies on cumulative nuclear breakout risk. We identify a strategic fork ahead, where detection may no longer suffice without broader PET governance. Governments and international organizations should accordingly invest in policies and tools agile enough to keep pace with tomorrow's technology.",
    "authors": [
      "David M. Allison",
      "Stephen Herzog"
    ],
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07487v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07487v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.07480v1",
    "title": "Single-step Diffusion-based Video Coding with Semantic-Temporal Guidance",
    "summary": "While traditional and neural video codecs (NVCs) have achieved remarkable rate-distortion performance, improving perceptual quality at low bitrates remains challenging. Some NVCs incorporate perceptual or adversarial objectives but still suffer from artifacts due to limited generation capacity, whereas others leverage pretrained diffusion models to improve quality at the cost of heavy sampling complexity. To overcome these challenges, we propose S2VC, a Single-Step diffusion based Video Codec that integrates a conditional coding framework with an efficient single-step diffusion generator, enabling realistic reconstruction at low bitrates with reduced sampling cost. Recognizing the importance of semantic conditioning in single-step diffusion, we introduce Contextual Semantic Guidance to extract frame-adaptive semantics from buffered features. It replaces text captions with efficient, fine-grained conditioning, thereby improving generation realism. In addition, Temporal Consistency Guidance is incorporated into the diffusion U-Net to enforce temporal coherence across frames and ensure stable generation. Extensive experiments show that S2VC delivers state-of-the-art perceptual quality with an average 52.73% bitrate saving over prior perceptual methods, underscoring the promise of single-step diffusion for efficient, high-quality video compression.",
    "authors": [
      "Naifu Xue",
      "Zhaoyang Jia",
      "Jiahao Li",
      "Bin Li",
      "Zihan Zheng",
      "Yuan Zhang",
      "Yan Lu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07480v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07480v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.07251v1",
    "title": "See More, Change Less: Anatomy-Aware Diffusion for Contrast Enhancement",
    "summary": "Image enhancement improves visual quality and helps reveal details that are hard to see in the original image. In medical imaging, it can support clinical decision-making, but current models often over-edit. This can distort organs, create false findings, and miss small tumors because these models do not understand anatomy or contrast dynamics. We propose SMILE, an anatomy-aware diffusion model that learns how organs are shaped and how they take up contrast. It enhances only clinically relevant regions while leaving all other areas unchanged. SMILE introduces three key ideas: (1) structure-aware supervision that follows true organ boundaries and contrast patterns; (2) registration-free learning that works directly with unaligned multi-phase CT scans; (3) unified inference that provides fast and consistent enhancement across all contrast phases. Across six external datasets, SMILE outperforms existing methods in image quality (14.2% higher SSIM, 20.6% higher PSNR, 50% better FID) and in clinical usefulness by producing anatomically accurate and diagnostically meaningful images. SMILE also improves cancer detection from non-contrast CT, raising the F1 score by up to 10 percent.",
    "authors": [
      "Junqi Liu",
      "Zejun Wu",
      "Pedro R. A. S. Bassi",
      "Xinze Zhou",
      "Wenxuan Li",
      "Ibrahim E. Hamamci",
      "Sezgin Er",
      "Tianyu Lin",
      "Yi Luo",
      "Szymon Płotka",
      "Bjoern Menze",
      "Daguang Xu",
      "Kai Ding",
      "Kang Wang",
      "Yang Yang",
      "Yucheng Tang",
      "Alan L. Yuille",
      "Zongwei Zhou"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07251v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07251v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2512.07801v1",
    "title": "Collaborative Causal Sensemaking: Closing the Complementarity Gap in Human-AI Decision Support",
    "summary": "LLM-based agents are rapidly being plugged into expert decision-support, yet in messy, high-stakes settings they rarely make the team smarter: human-AI teams often underperform the best individual, experts oscillate between verification loops and over-reliance, and the promised complementarity does not materialise. We argue this is not just a matter of accuracy, but a fundamental gap in how we conceive AI assistance: expert decisions are made through collaborative cognitive processes where mental models, goals, and constraints are continually co-constructed, tested, and revised between human and AI. We propose Collaborative Causal Sensemaking (CCS) as a research agenda and organizing framework for decision-support agents: systems designed as partners in cognitive work, maintaining evolving models of how particular experts reason, helping articulate and revise goals, co-constructing and stress-testing causal hypotheses, and learning from the outcomes of joint decisions so that both human and agent improve over time. We sketch challenges around training ecologies that make collaborative thinking instrumentally valuable, representations and interaction protocols for co-authored models, and evaluation centred on trust and complementarity. These directions can reframe MAS research around agents that participate in collaborative sensemaking and act as AI teammates that think with their human partners.",
    "authors": [
      "Raunak Jain",
      "Mudita Khurana"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07801v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07801v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.07668v1",
    "title": "EgoCampus: Egocentric Pedestrian Eye Gaze Model and Dataset",
    "summary": "We address the challenge of predicting human visual attention during real-world navigation by measuring and modeling egocentric pedestrian eye gaze in an outdoor campus setting. We introduce the EgoCampus dataset, which spans 25 unique outdoor paths over 6 km across a university campus with recordings from more than 80 distinct human pedestrians, resulting in a diverse set of gaze-annotated videos. The system used for collection, Meta's Project Aria glasses, integrates eye tracking, front-facing RGB cameras, inertial sensors, and GPS to provide rich data from the human perspective. Unlike many prior egocentric datasets that focus on indoor tasks or exclude eye gaze information, our work emphasizes visual attention while subjects walk in outdoor campus paths. Using this data, we develop EgoCampusNet, a novel method to predict eye gaze of navigating pedestrians as they move through outdoor environments. Our contributions provide both a new resource for studying real-world attention and a resource for future work in gaze prediction models for navigation. Dataset and code are available upon request, and will be made publicly available at a later date at https://github.com/ComputerVisionRutgers/EgoCampus .",
    "authors": [
      "Ronan John",
      "Aditya Kesari",
      "Vincenzo DiMatteo",
      "Kristin Dana"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07668v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07668v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.07576v1",
    "title": "R2MF-Net: A Recurrent Residual Multi-Path Fusion Network for Robust Multi-directional Spine X-ray Segmentation",
    "summary": "Accurate segmentation of spinal structures in X-ray images is a prerequisite for quantitative scoliosis assessment, including Cobb angle measurement, vertebral translation estimation and curvature classification. In routine practice, clinicians acquire coronal, left-bending and right-bending radiographs to jointly evaluate deformity severity and spinal flexibility. However, the segmentation step remains heavily manual, time-consuming and non-reproducible, particularly in low-contrast images and in the presence of rib shadows or overlapping tissues. To address these limitations, this paper proposes R2MF-Net, a recurrent residual multi-path encoder--decoder network tailored for automatic segmentation of multi-directional spine X-ray images. The overall design consists of a coarse segmentation network and a fine segmentation network connected in cascade. Both stages adopt an improved Inception-style multi-branch feature extractor, while a recurrent residual jump connection (R2-Jump) module is inserted into skip paths to gradually align encoder and decoder semantics. A multi-scale cross-stage skip (MC-Skip) mechanism allows the fine network to reuse hierarchical representations from multiple decoder levels of the coarse network, thereby strengthening the stability of segmentation across imaging directions and contrast conditions. Furthermore, a lightweight spatial-channel squeeze-and-excitation block (SCSE-Lite) is employed at the bottleneck to emphasize spine-related activations and suppress irrelevant structures and background noise. We evaluate R2MF-Net on a clinical multi-view radiograph dataset comprising 228 sets of coronal, left-bending and right-bending spine X-ray images with expert annotations.",
    "authors": [
      "Xuecheng Li",
      "Weikuan Jia",
      "Komildzhon Sharipov",
      "Sharipov Hotam Beknazarovich",
      "Farzona S. Ataeva",
      "Qurbonaliev Alisher",
      "Yuanjie Zheng"
    ],
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07576v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07576v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.07453v1",
    "title": "Social welfare optimisation in well-mixed and structured populations",
    "summary": "Research on promoting cooperation among autonomous, self-regarding agents has often focused on the bi-objective optimisation problem: minimising the total incentive cost while maximising the frequency of cooperation. However, the optimal value of social welfare under such constraints remains largely unexplored. In this work, we hypothesise that achieving maximal social welfare is not guaranteed at the minimal incentive cost required to drive agents to a desired cooperative state. To address this gap, we adopt to a single-objective approach focused on maximising social welfare, building upon foundational evolutionary game theory models that examined cost efficiency in finite populations, in both well-mixed and structured population settings. Our analytical model and agent-based simulations show how different interference strategies, including rewarding local versus global behavioural patterns, affect social welfare and dynamics of cooperation. Our results reveal a significant gap in the per-individual incentive cost between optimising for pure cost efficiency or cooperation frequency and optimising for maximal social welfare. Overall, our findings indicate that incentive design, policy, and benchmarking in multi-agent systems and human societies should prioritise welfare-centric objectives over proxy targets of cost or cooperation frequency.",
    "authors": [
      "Van An Nguyen",
      "Vuong Khang Huynh",
      "Ho Nam Duong",
      "Huu Loi Bui",
      "Hai Anh Ha",
      "Quang Dung Le",
      "Le Quoc Dung Ngo",
      "Tan Dat Nguyen",
      "Ngoc Ngu Nguyen",
      "Hoai Thuong Nguyen",
      "Zhao Song",
      "Le Hong Trang",
      "The Anh Han"
    ],
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "cs.MA",
      "math.OC",
      "nlin.AO"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07453v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07453v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.07450v1",
    "title": "Forget and Explain: Transparent Verification of GNN Unlearning",
    "summary": "Graph neural networks (GNNs) are increasingly used to model complex patterns in graph-structured data. However, enabling them to \"forget\" designated information remains challenging, especially under privacy regulations such as the GDPR. Existing unlearning methods largely optimize for efficiency and scalability, yet they offer little transparency, and the black-box nature of GNNs makes it difficult to verify whether forgetting has truly occurred. We propose an explainability-driven verifier for GNN unlearning that snapshots the model before and after deletion, using attribution shifts and localized structural changes (for example, graph edit distance) as transparent evidence. The verifier uses five explainability metrics: residual attribution, heatmap shift, explainability score deviation, graph edit distance, and a diagnostic graph rule shift. We evaluate two backbones (GCN, GAT) and four unlearning strategies (Retrain, GraphEditor, GNNDelete, IDEA) across five benchmarks (Cora, Citeseer, Pubmed, Coauthor-CS, Coauthor-Physics). Results show that Retrain and GNNDelete achieve near-complete forgetting, GraphEditor provides partial erasure, and IDEA leaves residual signals. These explanation deltas provide the primary, human-readable evidence of forgetting; we also report membership-inference ROC-AUC as a complementary, graph-wide privacy signal.",
    "authors": [
      "Imran Ahsan",
      "Hyunwook Yu",
      "Jinsung Kim",
      "Mucheol Kim"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07450v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07450v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.07393v1",
    "title": "Empirical Results for Adjusting Truncated Backpropagation Through Time while Training Neural Audio Effects",
    "summary": "This paper investigates the optimization of Truncated Backpropagation Through Time (TBPTT) for training neural networks in digital audio effect modeling, with a focus on dynamic range compression. The study evaluates key TBPTT hyperparameters -- sequence number, batch size, and sequence length -- and their influence on model performance. Using a convolutional-recurrent architecture, we conduct extensive experiments across datasets with and without conditionning by user controls. Results demonstrate that carefully tuning these parameters enhances model accuracy and training stability, while also reducing computational demands. Objective evaluations confirm improved performance with optimized settings, while subjective listening tests indicate that the revised TBPTT configuration maintains high perceptual quality.",
    "authors": [
      "Yann Bourdin",
      "Pierrick Legrand",
      "Fanny Roche"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07393v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07393v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.07329v1",
    "title": "Two-dimensional RMSD projections for reaction path visualization and validation",
    "summary": "Transition state or minimum energy path finding methods constitute a routine component of the computational chemistry toolkit. Standard analysis involves trajectories conventionally plotted in terms of the relative energy to the initial state against a cumulative displacement variable, or the image number. These dimensional reductions obscure structural rearrangements in high dimensions and may often be trajectory dependent. This precludes the ability to compare optimization trajectories of different methods beyond the number of calculations, time taken, and final saddle geometry. We present a method mapping trajectories onto a two-dimension surface defined by a permutation corrected root mean square deviation from the reactant and product configurations. Energy is represented as an interpolated color-mapped surface constructed from all optimization steps using radial basis functions. This representation highlights optimization trajectories, identifies endpoint basins, and diagnoses convergence concerns invisible in one-dimensional profiles. We validate the framework on a cycloaddition reaction, showing that a machine-learned potential saddle and density functional theory reference lie on comparable energy contours despite geometric displacements.",
    "authors": [
      "Rohit Goswami"
    ],
    "categories": [
      "physics.chem-ph",
      "cond-mat.mtrl-sci",
      "cs.LG",
      "physics.comp-ph"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07329v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07329v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.07310v1",
    "title": "Towards a Relationship-Aware Transformer for Tabular Data",
    "summary": "Deep learning models for tabular data typically do not allow for imposing a graph of external dependencies between samples, which can be useful for accounting for relatedness in tasks such as treatment effect estimation. Graph neural networks only consider adjacent nodes, making them difficult to apply to sparse graphs. This paper proposes several solutions based on a modified attention mechanism, which accounts for possible relationships between data points by adding a term to the attention matrix. Our models are compared with each other and the gradient boosting decision trees in a regression task on synthetic and real-world datasets, as well as in a treatment effect estimation task on the IHDP dataset.",
    "authors": [
      "Andrei V. Konstantinov",
      "Valerii A. Zuev",
      "Lev V. Utkin"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07310v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07310v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.07245v1",
    "title": "Zero-Shot Textual Explanations via Translating Decision-Critical Features",
    "summary": "Textual explanations make image classifier decisions transparent by describing the prediction rationale in natural language. Large vision-language models can generate captions but are designed for general visual understanding, not classifier-specific reasoning. Existing zero-shot explanation methods align global image features with language, producing descriptions of what is visible rather than what drives the prediction. We propose TEXTER, which overcomes this limitation by isolating decision-critical features before alignment. TEXTER identifies the neurons contributing to the prediction and emphasizes the features encoded in those neurons -- i.e., the decision-critical features. It then maps these emphasized features into the CLIP feature space to retrieve textual explanations that reflect the model's reasoning. A sparse autoencoder further improves interpretability, particularly for Transformer architectures. Extensive experiments show that TEXTER generates more faithful and interpretable explanations than existing methods. The code will be publicly released.",
    "authors": [
      "Toshinori Yamauchi",
      "Hiroshi Kera",
      "Kazuhiko Kawamoto"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07245v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07245v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2512.07760v1",
    "title": "Modality-Aware Bias Mitigation and Invariance Learning for Unsupervised Visible-Infrared Person Re-Identification",
    "summary": "Unsupervised visible-infrared person re-identification (USVI-ReID) aims to match individuals across visible and infrared cameras without relying on any annotation. Given the significant gap across visible and infrared modality, estimating reliable cross-modality association becomes a major challenge in USVI-ReID. Existing methods usually adopt optimal transport to associate the intra-modality clusters, which is prone to propagating the local cluster errors, and also overlooks global instance-level relations. By mining and attending to the visible-infrared modality bias, this paper focuses on addressing cross-modality learning from two aspects: bias-mitigated global association and modality-invariant representation learning. Motivated by the camera-aware distance rectification in single-modality re-ID, we propose modality-aware Jaccard distance to mitigate the distance bias caused by modality discrepancy, so that more reliable cross-modality associations can be estimated through global clustering. To further improve cross-modality representation learning, a `split-and-contrast' strategy is designed to obtain modality-specific global prototypes. By explicitly aligning these prototypes under global association guidance, modality-invariant yet ID-discriminative representation learning can be achieved. While conceptually simple, our method obtains state-of-the-art performance on benchmark VI-ReID datasets and outperforms existing methods by a significant margin, validating its effectiveness.",
    "authors": [
      "Menglin Wang",
      "Xiaojin Gong",
      "Jiachen Li",
      "Genlin Ji"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07760v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07760v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.07631v1",
    "title": "The Agent Capability Problem: Predicting Solvability Through Information-Theoretic Bounds",
    "summary": "When should an autonomous agent commit resources to a task? We introduce the Agent Capability Problem (ACP), a framework for predicting whether an agent can solve a problem under resource constraints. Rather than relying on empirical heuristics, ACP frames problem-solving as information acquisition: an agent requires $\\Itotal$ bits to identify a solution and gains $\\Istep$ bits per action at cost $\\Cstep$, yielding an effective cost $\\Ceff = (\\Itotal/\\Istep), \\Cstep$ that predicts resource requirements before search. We prove that $\\Ceff$ lower-bounds expected cost and provide tight probabilistic upper bounds. Experimental validation shows that ACP predictions closely track actual agent performance, consistently bounding search effort while improving efficiency over greedy and random strategies. The framework generalizes across LLM-based and agentic workflows, linking principles from active learning, Bayesian optimization, and reinforcement learning through a unified information-theoretic lens. \\",
    "authors": [
      "Shahar Lutati"
    ],
    "categories": [
      "cs.AI",
      "cs.CC",
      "cs.IT",
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07631v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07631v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.07519v1",
    "title": "Machine Learning: Progress and Prospects",
    "summary": "This Inaugural Lecture was given at Royal Holloway University of London in 1996. It covers an introduction to machine learning and describes various theoretical advances and practical projects in the field. The Lecture here is presented in its original format, but a few remarks have been added in 2025 to reflect recent developments, and the list of references has been updated to enhance the convenience and accuracy for readers.   When did machine learning start? Maybe a good starting point is 1949, when Claude Shannon proposed a learning algorithm for chess-playing programs. Or maybe we should go back to the 1930s when Ronald Fisher developed discriminant analysis - a type of learning where the problem is to construct a decision rule that separates two types of vectors. Or could it be the 18th century when David Hume discussed the idea of induction? Or the 14th century, when William of Ockham formulated the principle of \"simplicity\" known as \"Ockham's razor\" (Ockham, by the way, is a small village not far from Royal Holloway). Or it may be that, like almost everything else in Western civilisation and culture, the origin of these ideas lies in the Mediterranean. After all, it was Aristotle who said that \"we learn some things only by doing things\".   The field of machine learning has been greatly influenced by other disciplines and the subject is in itself not a very homogeneous discipline, but includes separate, overlapping subfields. There are many parallel lines of research in ML: inductive learning, neural networks, clustering, and theories of learning. They are all part of the more general field of machine learning.",
    "authors": [
      "Alexander Gammerman"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07519v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07519v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.07509v1",
    "title": "Exploring possible vector systems for faster training of neural networks with preconfigured latent spaces",
    "summary": "The overall neural network (NN) performance is closely related to the properties of its embedding distribution in latent space (LS). It has recently been shown that predefined vector systems, specifically An root system vectors, can be used as targets for latent space configurations (LSC) to ensure the desired LS structure. One of the main LSC advantage is the possibility of training classifier NNs without classification layers, which facilitates training NNs on datasets with extremely large numbers of classes. This paper provides a more general overview of possible vector systems for NN training along with their properties and methods for vector system construction. These systems are used to configure LS of encoders and visual transformers to significantly speed up ImageNet-1K and 50k-600k classes LSC training. It is also shown that using the minimum number of LS dimensions for a specific number of classes results in faster convergence. The latter has potential advantages for reducing the size of vector databases used to store NN embeddings.",
    "authors": [
      "Nikita Gabdullin"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07509v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07509v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.07433v1",
    "title": "Mitigating Bias in Graph Hyperdimensional Computing",
    "summary": "Graph hyperdimensional computing (HDC) has emerged as a promising paradigm for cognitive tasks, emulating brain-like computation with high-dimensional vectors known as hypervectors. While HDC offers robustness and efficiency on graph-structured data, its fairness implications remain largely unexplored. In this paper, we study fairness in graph HDC, where biases in data representation and decision rules can lead to unequal treatment of different groups. We show how hypervector encoding and similarity-based classification can propagate or even amplify such biases, and we propose a fairness-aware training framework, FairGHDC, to mitigate them. FairGHDC introduces a bias correction term, derived from a gap-based demographic-parity regularizer, and converts it into a scalar fairness factor that scales the update of the class hypervector for the ground-truth label. This enables debiasing directly in the hypervector space without modifying the graph encoder or requiring backpropagation. Experimental results on six benchmark datasets demonstrate that FairGHDC substantially reduces demographic-parity and equal-opportunity gaps while maintaining accuracy comparable to standard GNNs and fairness-aware GNNs. At the same time, FairGHDC preserves the computational advantages of HDC, achieving up to about one order of magnitude ($\\approx 10\\times$) speedup in training time on GPU compared to GNN and fairness-aware GNN baselines.",
    "authors": [
      "Yezi Liu",
      "William Youngwoo Chung",
      "Yang Ni",
      "Hanning Chen",
      "Mohsen Imani"
    ],
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07433v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07433v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.07400v1",
    "title": "Asymptotic analysis of shallow and deep forgetting in replay with Neural Collapse",
    "summary": "A persistent paradox in continual learning (CL) is that neural networks often retain linearly separable representations of past tasks even when their output predictions fail. We formalize this distinction as the gap between deep feature-space and shallow classifier-level forgetting. We reveal a critical asymmetry in Experience Replay: while minimal buffers successfully anchor feature geometry and prevent deep forgetting, mitigating shallow forgetting typically requires substantially larger buffer capacities. To explain this, we extend the Neural Collapse framework to the sequential setting. We characterize deep forgetting as a geometric drift toward out-of-distribution subspaces and prove that any non-zero replay fraction asymptotically guarantees the retention of linear separability. Conversely, we identify that the \"strong collapse\" induced by small buffers leads to rank-deficient covariances and inflated class means, effectively blinding the classifier to true population boundaries. By unifying CL with out-of-distribution detection, our work challenges the prevailing reliance on large buffers, suggesting that explicitly correcting these statistical artifacts could unlock robust performance with minimal replay.",
    "authors": [
      "Giulia Lanzillotta",
      "Damiano Meier",
      "Thomas Hofmann"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07400v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07400v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.07385v1",
    "title": "How Far are Modern Trackers from UAV-Anti-UAV? A Million-Scale Benchmark and New Baseline",
    "summary": "Unmanned Aerial Vehicles (UAVs) offer wide-ranging applications but also pose significant safety and privacy violation risks in areas like airport and infrastructure inspection, spurring the rapid development of Anti-UAV technologies in recent years. However, current Anti-UAV research primarily focuses on RGB, infrared (IR), or RGB-IR videos captured by fixed ground cameras, with little attention to tracking target UAVs from another moving UAV platform. To fill this gap, we propose a new multi-modal visual tracking task termed UAV-Anti-UAV, which involves a pursuer UAV tracking a target adversarial UAV in the video stream. Compared to existing Anti-UAV tasks, UAV-Anti-UAV is more challenging due to severe dual-dynamic disturbances caused by the rapid motion of both the capturing platform and the target. To advance research in this domain, we construct a million-scale dataset consisting of 1,810 videos, each manually annotated with bounding boxes, a language prompt, and 15 tracking attributes. Furthermore, we propose MambaSTS, a Mamba-based baseline method for UAV-Anti-UAV tracking, which enables integrated spatial-temporal-semantic learning. Specifically, we employ Mamba and Transformer models to learn global semantic and spatial features, respectively, and leverage the state space model's strength in long-sequence modeling to establish video-level long-term context via a temporal token propagation mechanism. We conduct experiments on the UAV-Anti-UAV dataset to validate the effectiveness of our method. A thorough experimental evaluation of 50 modern deep tracking algorithms demonstrates that there is still significant room for improvement in the UAV-Anti-UAV domain. The dataset and codes will be available at {\\color{magenta}https://github.com/983632847/Awesome-Multimodal-Object-Tracking}.",
    "authors": [
      "Chunhui Zhang",
      "Li Liu",
      "Zhipeng Zhang",
      "Yong Wang",
      "Hao Wen",
      "Xi Zhou",
      "Shiming Ge",
      "Yanfeng Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07385v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07385v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2512.07831v1",
    "title": "UnityVideo: Unified Multi-Modal Multi-Task Learning for Enhancing World-Aware Video Generation",
    "summary": "Recent video generation models demonstrate impressive synthesis capabilities but remain limited by single-modality conditioning, constraining their holistic world understanding. This stems from insufficient cross-modal interaction and limited modal diversity for comprehensive world knowledge representation. To address these limitations, we introduce UnityVideo, a unified framework for world-aware video generation that jointly learns across multiple modalities (segmentation masks, human skeletons, DensePose, optical flow, and depth maps) and training paradigms. Our approach features two core components: (1) dynamic noising to unify heterogeneous training paradigms, and (2) a modality switcher with an in-context learner that enables unified processing via modular parameters and contextual learning. We contribute a large-scale unified dataset with 1.3M samples. Through joint optimization, UnityVideo accelerates convergence and significantly enhances zero-shot generalization to unseen data. We demonstrate that UnityVideo achieves superior video quality, consistency, and improved alignment with physical world constraints. Code and data can be found at: https://github.com/dvlab-research/UnityVideo",
    "authors": [
      "Jiehui Huang",
      "Yuechen Zhang",
      "Xu He",
      "Yuan Gao",
      "Zhi Cen",
      "Bin Xia",
      "Yan Zhou",
      "Xin Tao",
      "Pengfei Wan",
      "Jiaya Jia"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07831v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07831v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2512.07661v1",
    "title": "Optimization-Guided Diffusion for Interactive Scene Generation",
    "summary": "Realistic and diverse multi-agent driving scenes are crucial for evaluating autonomous vehicles, but safety-critical events which are essential for this task are rare and underrepresented in driving datasets. Data-driven scene generation offers a low-cost alternative by synthesizing complex traffic behaviors from existing driving logs. However, existing models often lack controllability or yield samples that violate physical or social constraints, limiting their usability. We present OMEGA, an optimization-guided, training-free framework that enforces structural consistency and interaction awareness during diffusion-based sampling from a scene generation model. OMEGA re-anchors each reverse diffusion step via constrained optimization, steering the generation towards physically plausible and behaviorally coherent trajectories. Building on this framework, we formulate ego-attacker interactions as a game-theoretic optimization in the distribution space, approximating Nash equilibria to generate realistic, safety-critical adversarial scenarios. Experiments on nuPlan and Waymo show that OMEGA improves generation realism, consistency, and controllability, increasing the ratio of physically and behaviorally valid scenes from 32.35% to 72.27% for free exploration capabilities, and from 11% to 80% for controllability-focused generation. Our approach can also generate $5\\times$ more near-collision frames with a time-to-collision under three seconds while maintaining the overall scene realism.",
    "authors": [
      "Shiaho Li",
      "Naisheng Ye",
      "Tianyu Li",
      "Kashyap Chitta",
      "Tuo An",
      "Peng Su",
      "Boyang Wang",
      "Haiou Liu",
      "Chen Lv",
      "Hongyang Li"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07661v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07661v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2512.07503v1",
    "title": "SJD++: Improved Speculative Jacobi Decoding for Training-free Acceleration of Discrete Auto-regressive Text-to-Image Generation",
    "summary": "Large autoregressive models can generate high-quality, high-resolution images but suffer from slow generation speed, because these models require hundreds to thousands of sequential forward passes for next-token prediction during inference. To accelerate autoregressive text-to-image generation, we propose Speculative Jacobi Decoding++ (SJD++), a training-free probabilistic parallel decoding algorithm. Unlike traditional next-token prediction, SJD++ performs multi-token prediction in each forward pass, drastically reducing generation steps. Specifically, it integrates the iterative multi-token prediction mechanism from Jacobi decoding, with the probabilistic drafting-and-verification mechanism from speculative sampling. More importantly, for further acceleration, SJD++ reuses high-confidence draft tokens after each verification phase instead of resampling them all. We conduct extensive experiments on several representative autoregressive text-to-image generation models and demonstrate that SJD++ achieves $2\\times$ to $3\\times$ inference latency reduction and $2\\times$ to $7\\times$ step compression, while preserving visual quality with no observable degradation.",
    "authors": [
      "Yao Teng",
      "Zhihuan Jiang",
      "Han Shi",
      "Xian Liu",
      "Xuefei Ning",
      "Guohao Dai",
      "Yu Wang",
      "Zhenguo Li",
      "Xihui Liu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07503v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07503v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2512.07241v1",
    "title": "Squeezed-Eff-Net: Edge-Computed Boost of Tomography Based Brain Tumor Classification leveraging Hybrid Neural Network Architecture",
    "summary": "Brain tumors are one of the most common and dangerous neurological diseases which require a timely and correct diagnosis to provide the right treatment procedures. Even with the promotion of magnetic resonance imaging (MRI), the process of tumor delineation is difficult and time-consuming, which is prone to inter-observer error. In order to overcome these limitations, this work proposes a hybrid deep learning model based on SqueezeNet v1 which is a lightweight model, and EfficientNet-B0, which is a high-performing model, and is enhanced with handcrafted radiomic descriptors, including Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), Gabor filters and Wavelet transforms. The framework was trained and tested only on publicly available Nickparvar Brain Tumor MRI dataset, which consisted of 7,023 contrast-enhanced T1-weighted axial MRI slices which were categorized into four groups: glioma, meningioma, pituitary tumor, and no tumor. The testing accuracy of the model was 98.93% that reached a level of 99.08% with Test Time Augmentation (TTA) showing great generalization and power. The proposed hybrid network offers a compromise between computation efficiency and diagnostic accuracy compared to current deep learning structures and only has to be trained using fewer than 2.1 million parameters and less than 1.2 GFLOPs. The handcrafted feature addition allowed greater sensitivity in texture and the EfficientNet-B0 backbone represented intricate hierarchical features. The resulting model has almost clinical reliability in automated MRI-based classification of tumors highlighting its possibility of use in clinical decision-support systems.",
    "authors": [
      "Md. Srabon Chowdhury",
      "Syeda Fahmida Tanzim",
      "Sheekar Banerjee",
      "Ishtiak Al Mamoon",
      "AKM Muzahidul Islam"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07241v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07241v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2512.07237v1",
    "title": "Unified Camera Positional Encoding for Controlled Video Generation",
    "summary": "Transformers have emerged as a universal backbone across 3D perception, video generation, and world models for autonomous driving and embodied AI, where understanding camera geometry is essential for grounding visual observations in three-dimensional space. However, existing camera encoding methods often rely on simplified pinhole assumptions, restricting generalization across the diverse intrinsics and lens distortions in real-world cameras. We introduce Relative Ray Encoding, a geometry-consistent representation that unifies complete camera information, including 6-DoF poses, intrinsics, and lens distortions. To evaluate its capability under diverse controllability demands, we adopt camera-controlled text-to-video generation as a testbed task. Within this setting, we further identify pitch and roll as two components effective for Absolute Orientation Encoding, enabling full control over the initial camera orientation. Together, these designs form UCPE (Unified Camera Positional Encoding), which integrates into a pretrained video Diffusion Transformer through a lightweight spatial attention adapter, adding less than 1% trainable parameters while achieving state-of-the-art camera controllability and visual fidelity. To facilitate systematic training and evaluation, we construct a large video dataset covering a wide range of camera motions and lens types. Extensive experiments validate the effectiveness of UCPE in camera-controllable video generation and highlight its potential as a general camera representation for Transformers across future multi-view, video, and 3D tasks. Code will be available at https://github.com/chengzhag/UCPE.",
    "authors": [
      "Cheng Zhang",
      "Boying Li",
      "Meng Wei",
      "Yan-Pei Cao",
      "Camilo Cruz Gambardella",
      "Dinh Phung",
      "Jianfei Cai"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07237v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07237v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.49
  },
  {
    "arxiv_id": "2512.07733v1",
    "title": "SpatialDreamer: Incentivizing Spatial Reasoning via Active Mental Imagery",
    "summary": "Despite advancements in Multi-modal Large Language Models (MLLMs) for scene understanding, their performance on complex spatial reasoning tasks requiring mental simulation remains significantly limited. Current methods often rely on passive observation of spatial data, failing to internalize an active mental imagery process. To bridge this gap, we propose SpatialDreamer, a reinforcement learning framework that enables spatial reasoning through a closedloop process of active exploration, visual imagination via a world model, and evidence-grounded reasoning. To address the lack of fine-grained reward supervision in longhorizontal reasoning tasks, we propose Geometric Policy Optimization (GeoPO), which introduces tree-structured sampling and step-level reward estimation with geometric consistency constraints. Extensive experiments demonstrate that SpatialDreamer delivers highly competitive results across multiple challenging benchmarks, signifying a critical advancement in human-like active spatial mental simulation for MLLMs.",
    "authors": [
      "Meng Cao",
      "Xingyu Li",
      "Xue Liu",
      "Ian Reid",
      "Xiaodan Liang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07733v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07733v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.48
  },
  {
    "arxiv_id": "2512.07345v1",
    "title": "Debiasing Diffusion Priors via 3D Attention for Consistent Gaussian Splatting",
    "summary": "Versatile 3D tasks (e.g., generation or editing) that distill from Text-to-Image (T2I) diffusion models have attracted significant research interest for not relying on extensive 3D training data. However, T2I models exhibit limitations resulting from prior view bias, which produces conflicting appearances between different views of an object. This bias causes subject-words to preferentially activate prior view features during cross-attention (CA) computation, regardless of the target view condition. To overcome this limitation, we conduct a comprehensive mathematical analysis to reveal the root cause of the prior view bias in T2I models. Moreover, we find different UNet layers show different effects of prior view in CA. Therefore, we propose a novel framework, TD-Attn, which addresses multi-view inconsistency via two key components: (1) the 3D-Aware Attention Guidance Module (3D-AAG) constructs a view-consistent 3D attention Gaussian for subject-words to enforce spatial consistency across attention-focused regions, thereby compensating for the limited spatial information in 2D individual view CA maps; (2) the Hierarchical Attention Modulation Module (HAM) utilizes a Semantic Guidance Tree (SGT) to direct the Semantic Response Profiler (SRP) in localizing and modulating CA layers that are highly responsive to view conditions, where the enhanced CA maps further support the construction of more consistent 3D attention Gaussians. Notably, HAM facilitates semantic-specific interventions, enabling controllable and precise 3D editing. Extensive experiments firmly establish that TD-Attn has the potential to serve as a universal plugin, significantly enhancing multi-view consistency across 3D tasks.",
    "authors": [
      "Shilong Jin",
      "Haoran Duan",
      "Litao Hua",
      "Wentao Huang",
      "Yuan Zhou"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07345v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07345v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.48
  },
  {
    "arxiv_id": "2512.07230v1",
    "title": "STRinGS: Selective Text Refinement in Gaussian Splatting",
    "summary": "Text as signs, labels, or instructions is a critical element of real-world scenes as they can convey important contextual information. 3D representations such as 3D Gaussian Splatting (3DGS) struggle to preserve fine-grained text details, while achieving high visual fidelity. Small errors in textual element reconstruction can lead to significant semantic loss. We propose STRinGS, a text-aware, selective refinement framework to address this issue for 3DGS reconstruction. Our method treats text and non-text regions separately, refining text regions first and merging them with non-text regions later for full-scene optimization. STRinGS produces sharp, readable text even in challenging configurations. We introduce a text readability measure OCR Character Error Rate (CER) to evaluate the efficacy on text regions. STRinGS results in a 63.6% relative improvement over 3DGS at just 7K iterations. We also introduce a curated dataset STRinGS-360 with diverse text scenarios to evaluate text readability in 3D reconstruction. Our method and dataset together push the boundaries of 3D scene understanding in text-rich environments, paving the way for more robust text-aware reconstruction methods.",
    "authors": [
      "Abhinav Raundhal",
      "Gaurav Behera",
      "P J Narayanan",
      "Ravi Kiran Sarvadevabhatla",
      "Makarand Tapaswi"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07230v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07230v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.48
  },
  {
    "arxiv_id": "2512.07747v1",
    "title": "Unison: A Fully Automatic, Task-Universal, and Low-Cost Framework for Unified Understanding and Generation",
    "summary": "Unified understanding and generation is a highly appealing research direction in multimodal learning. There exist two approaches: one trains a transformer via an auto-regressive paradigm, and the other adopts a two-stage scheme connecting pre-trained understanding and generative models for alignment fine-tuning. The former demands massive data and computing resources unaffordable for ordinary researchers. Though the latter requires a lower training cost, existing works often suffer from limited task coverage or poor generation quality. Both approaches lack the ability to parse input meta-information (such as task type, image resolution, video duration, etc.) and require manual parameter configuration that is tedious and non-intelligent. In this paper, we propose Unison which adopts the two-stage scheme while preserving the capabilities of the pre-trained models well. With an extremely low training cost, we cover a variety of multimodal understanding tasks, including text, image, and video understanding, as well as diverse generation tasks, such as text-to-visual content generation, editing, controllable generation, and IP-based reference generation. We also equip our model with the ability to automatically parse user intentions, determine the target task type, and accurately extract the meta-information required for the corresponding task. This enables full automation of various multimodal tasks without human intervention. Experiments demonstrate that, under a low-cost setting of only 500k training samples and 50 GPU hours, our model can accurately and automatically identify tasks and extract relevant parameters, and achieve superior performance across a variety of understanding and generation tasks.",
    "authors": [
      "Shihao Zhao",
      "Yitong Chen",
      "Zeyinzi Jiang",
      "Bojia Zi",
      "Shaozhe Hao",
      "Yu Liu",
      "Chaojie Mao",
      "Kwan-Yee K. Wong"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07747v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07747v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2512.07651v1",
    "title": "Liver Fibrosis Quantification and Analysis: The LiQA Dataset and Baseline Method",
    "summary": "Liver fibrosis represents a significant global health burden, necessitating accurate staging for effective clinical management. This report introduces the LiQA (Liver Fibrosis Quantification and Analysis) dataset, established as part of the CARE 2024 challenge. Comprising $440$ patients with multi-phase, multi-center MRI scans, the dataset is curated to benchmark algorithms for Liver Segmentation (LiSeg) and Liver Fibrosis Staging (LiFS) under complex real-world conditions, including domain shifts, missing modalities, and spatial misalignment. We further describe the challenge's top-performing methodology, which integrates a semi-supervised learning framework with external data for robust segmentation, and utilizes a multi-view consensus approach with Class Activation Map (CAM)-based regularization for staging. Evaluation of this baseline demonstrates that leveraging multi-source data and anatomical constraints significantly enhances model robustness in clinical settings.",
    "authors": [
      "Yuanye Liu",
      "Hanxiao Zhang",
      "Nannan Shi",
      "Yuxin Shi",
      "Arif Mahmood",
      "Murtaza Taj",
      "Xiahai Zhuang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07651v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07651v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2512.07596v1",
    "title": "More than Segmentation: Benchmarking SAM 3 for Segmentation, 3D Perception, and Reconstruction in Robotic Surgery",
    "summary": "The recent Segment Anything Model (SAM) 3 has introduced significant advancements over its predecessor, SAM 2, particularly with the integration of language-based segmentation and enhanced 3D perception capabilities. SAM 3 supports zero-shot segmentation across a wide range of prompts, including point, bounding box, and language-based prompts, allowing for more flexible and intuitive interactions with the model. In this empirical evaluation, we assess the performance of SAM 3 in robot-assisted surgery, benchmarking its zero-shot segmentation with point and bounding box prompts and exploring its effectiveness in dynamic video tracking, alongside its newly introduced language prompt segmentation. While language prompts show potential, their performance in the surgical domain is currently suboptimal, highlighting the need for further domain-specific training. Additionally, we investigate SAM 3's 3D reconstruction abilities, demonstrating its capacity to process surgical scene data and reconstruct 3D anatomical structures from 2D images. Through comprehensive testing on the MICCAI EndoVis 2017 and EndoVis 2018 benchmarks, SAM 3 shows clear improvements over SAM and SAM 2 in both image and video segmentation under spatial prompts, while zero-shot evaluations on SCARED, StereoMIS, and EndoNeRF indicate strong monocular depth estimation and realistic 3D instrument reconstruction, yet also reveal remaining limitations in complex, highly dynamic surgical scenes.",
    "authors": [
      "Wenzhen Dong",
      "Jieming Yu",
      "Yiming Huang",
      "Hongqiu Wang",
      "Lei Zhu",
      "Albert C. S. Chung",
      "Hongliang Ren",
      "Long Bai"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07596v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07596v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2512.07574v1",
    "title": "Precise Liver Tumor Segmentation in CT Using a Hybrid Deep Learning-Radiomics Framework",
    "summary": "Accurate three-dimensional delineation of liver tumors on contrast-enhanced CT is a prerequisite for treatment planning, navigation and response assessment, yet manual contouring is slow, observer-dependent and difficult to standardise across centres. Automatic segmentation is complicated by low lesion-parenchyma contrast, blurred or incomplete boundaries, heterogeneous enhancement patterns, and confounding structures such as vessels and adjacent organs. We propose a hybrid framework that couples an attention-enhanced cascaded U-Net with handcrafted radiomics and voxel-wise 3D CNN refinement for joint liver and liver-tumor segmentation. First, a 2.5D two-stage network with a densely connected encoder, sub-pixel convolution decoders and multi-scale attention gates produces initial liver and tumor probability maps from short stacks of axial slices. Inter-slice temporal consistency is then enforced by a simple three-slice refinement rule along the cranio-caudal direction, which restores thin and tiny lesions while suppressing isolated noise. Next, 728 radiomic descriptors spanning intensity, texture, shape, boundary and wavelet feature groups are extracted from candidate lesions and reduced to 20 stable, highly informative features via multi-strategy feature selection; a random forest classifier uses these features to reject false-positive regions. Finally, a compact 3D patch-based CNN derived from AlexNet operates in a narrow band around the tumor boundary to perform voxel-level relabelling and contour smoothing.",
    "authors": [
      "Xuecheng Li",
      "Weikuan Jia",
      "Komildzhon Sharipov",
      "Alimov Ruslan",
      "Lutfuloev Mazbutdzhon",
      "Ismoilov Shuhratjon",
      "Yuanjie Zheng"
    ],
    "categories": [
      "eess.IV",
      "cs.CR",
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07574v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07574v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2512.07397v1",
    "title": "From sparse recovery to plug-and-play priors, understanding trade-offs for stable recovery with generalized projected gradient descent",
    "summary": "We consider the problem of recovering an unknown low-dimensional vector from noisy, underdetermined observations. We focus on the Generalized Projected Gradient Descent (GPGD) framework, which unifies traditional sparse recovery methods and modern approaches using learned deep projective priors. We extend previous convergence results to robustness to model and projection errors. We use these theoretical results to explore ways to better control stability and robustness constants. To reduce recovery errors due to measurement noise, we consider generalized back-projection strategies to adapt GPGD to structured noise, such as sparse outliers. To improve the stability of GPGD, we propose a normalized idempotent regularization for the learning of deep projective priors. We provide numerical experiments in the context of sparse recovery and image inverse problems, highlighting the trade-offs between identifiability and stability that can be achieved with such methods.",
    "authors": [
      "Ali Joundi",
      "Yann Traonmilin",
      "Jean-François Aujol"
    ],
    "categories": [
      "eess.IV",
      "cs.NE",
      "math.OC"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07397v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07397v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2512.07361v1",
    "title": "An Asynchronous Mixed-Signal Resonate-and-Fire Neuron",
    "summary": "Analog computing at the edge is an emerging strategy to limit data storage and transmission requirements, as well as energy consumption, and its practical implementation is in its initial stages of development. Translating properties of biological neurons into hardware offers a pathway towards low-power, real-time edge processing. Specifically, resonator neurons offer selectivity to specific frequencies as a potential solution for temporal signal processing. Here, we show a fabricated Complementary Metal-Oxide-Semiconductor (CMOS) mixed-signal Resonate-and-Fire (R&F) neuron circuit implementation that emulates the behavior of these neural cells responsible for controlling oscillations within the central nervous system. We integrate the design with asynchronous handshake capabilities, perform comprehensive variability analyses, and characterize its frequency detection functionality. Our results demonstrate the feasibility of large-scale integration within neuromorphic systems, thereby advancing the exploitation of bio-inspired circuits for efficient edge temporal signal processing.",
    "authors": [
      "Giuseppe Leo",
      "Paolo Gibertini",
      "Irem Ilter",
      "Erika Covi",
      "Ole Richter",
      "Elisabetta Chicca"
    ],
    "categories": [
      "eess.SP",
      "cs.NE"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07361v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07361v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2512.07348v1",
    "title": "MICo-150K: A Comprehensive Dataset Advancing Multi-Image Composition",
    "summary": "In controllable image generation, synthesizing coherent and consistent images from multiple reference inputs, i.e., Multi-Image Composition (MICo), remains a challenging problem, partly hindered by the lack of high-quality training data. To bridge this gap, we conduct a systematic study of MICo, categorizing it into 7 representative tasks and curate a large-scale collection of high-quality source images and construct diverse MICo prompts. Leveraging powerful proprietary models, we synthesize a rich amount of balanced composite images, followed by human-in-the-loop filtering and refinement, resulting in MICo-150K, a comprehensive dataset for MICo with identity consistency. We further build a Decomposition-and-Recomposition (De&Re) subset, where 11K real-world complex images are decomposed into components and recomposed, enabling both real and synthetic compositions. To enable comprehensive evaluation, we construct MICo-Bench with 100 cases per task and 300 challenging De&Re cases, and further introduce a new metric, Weighted-Ref-VIEScore, specifically tailored for MICo evaluation. Finally, we fine-tune multiple models on MICo-150K and evaluate them on MICo-Bench. The results show that MICo-150K effectively equips models without MICo capability and further enhances those with existing skills. Notably, our baseline model, Qwen-MICo, fine-tuned from Qwen-Image-Edit, matches Qwen-Image-2509 in 3-image composition while supporting arbitrary multi-image inputs beyond the latter's limitation. Our dataset, benchmark, and baseline collectively offer valuable resources for further research on Multi-Image Composition.",
    "authors": [
      "Xinyu Wei",
      "Kangrui Cen",
      "Hongyang Wei",
      "Zhen Guo",
      "Bairui Li",
      "Zeqing Wang",
      "Jinrui Zhang",
      "Lei Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07348v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07348v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2512.07756v1",
    "title": "UltrasODM: A Dual Stream Optical Flow Mamba Network for 3D Freehand Ultrasound Reconstruction",
    "summary": "Clinical ultrasound acquisition is highly operator-dependent, where rapid probe motion and brightness fluctuations often lead to reconstruction errors that reduce trust and clinical utility. We present UltrasODM, a dual-stream framework that assists sonographers during acquisition through calibrated per-frame uncertainty, saliency-based diagnostics, and actionable prompts. UltrasODM integrates (i) a contrastive ranking module that groups frames by motion similarity, (ii) an optical-flow stream fused with Dual-Mamba temporal modules for robust 6-DoF pose estimation, and (iii) a Human-in-the-Loop (HITL) layer combining Bayesian uncertainty, clinician-calibrated thresholds, and saliency maps highlighting regions of low confidence. When uncertainty exceeds the threshold, the system issues unobtrusive alerts suggesting corrective actions such as re-scanning highlighted regions or slowing the sweep. Evaluated on a clinical freehand ultrasound dataset, UltrasODM reduces drift by 15.2%, distance error by 12.1%, and Hausdorff distance by 10.1% relative to UltrasOM, while producing per-frame uncertainty and saliency outputs. By emphasizing transparency and clinician feedback, UltrasODM improves reconstruction reliability and supports safer, more trustworthy clinical workflows. Our code is publicly available at https://github.com/AnandMayank/UltrasODM.",
    "authors": [
      "Mayank Anand",
      "Ujair Alam",
      "Surya Prakash",
      "Priya Shukla",
      "Gora Chand Nandi",
      "Domenec Puig"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07756v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07756v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.46
  },
  {
    "arxiv_id": "2512.07504v1",
    "title": "ControlVP: Interactive Geometric Refinement of AI-Generated Images with Consistent Vanishing Points",
    "summary": "Recent text-to-image models, such as Stable Diffusion, have achieved impressive visual quality, yet they often suffer from geometric inconsistencies that undermine the structural realism of generated scenes. One prominent issue is vanishing point inconsistency, where projections of parallel lines fail to converge correctly in 2D space. This leads to structurally implausible geometry that degrades spatial realism, especially in architectural scenes. We propose ControlVP, a user-guided framework for correcting vanishing point inconsistencies in generated images. Our approach extends a pre-trained diffusion model by incorporating structural guidance derived from building contours. We also introduce geometric constraints that explicitly encourage alignment between image edges and perspective cues. Our method enhances global geometric consistency while maintaining visual fidelity comparable to the baselines. This capability is particularly valuable for applications that require accurate spatial structure, such as image-to-3D reconstruction. The dataset and source code are available at https://github.com/RyotaOkumura/ControlVP .",
    "authors": [
      "Ryota Okumura",
      "Kaede Shiohara",
      "Toshihiko Yamasaki"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07504v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07504v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.46
  },
  {
    "arxiv_id": "2512.07834v1",
    "title": "Voxify3D: Pixel Art Meets Volumetric Rendering",
    "summary": "Voxel art is a distinctive stylization widely used in games and digital media, yet automated generation from 3D meshes remains challenging due to conflicting requirements of geometric abstraction, semantic preservation, and discrete color coherence. Existing methods either over-simplify geometry or fail to achieve the pixel-precise, palette-constrained aesthetics of voxel art. We introduce Voxify3D, a differentiable two-stage framework bridging 3D mesh optimization with 2D pixel art supervision. Our core innovation lies in the synergistic integration of three components: (1) orthographic pixel art supervision that eliminates perspective distortion for precise voxel-pixel alignment; (2) patch-based CLIP alignment that preserves semantics across discretization levels; (3) palette-constrained Gumbel-Softmax quantization enabling differentiable optimization over discrete color spaces with controllable palette strategies. This integration addresses fundamental challenges: semantic preservation under extreme discretization, pixel-art aesthetics through volumetric rendering, and end-to-end discrete optimization. Experiments show superior performance (37.12 CLIP-IQA, 77.90\\% user preference) across diverse characters and controllable abstraction (2-8 colors, 20x-50x resolutions). Project page: https://yichuanh.github.io/Voxify-3D/",
    "authors": [
      "Yi-Chuan Huang",
      "Jiewen Chan",
      "Hao-Jen Chien",
      "Yu-Lun Liu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07834v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07834v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.45
  },
  {
    "arxiv_id": "2512.07712v1",
    "title": "UnCageNet: Tracking and Pose Estimation of Caged Animal",
    "summary": "Animal tracking and pose estimation systems, such as STEP (Simultaneous Tracking and Pose Estimation) and ViTPose, experience substantial performance drops when processing images and videos with cage structures and systematic occlusions. We present a three-stage preprocessing pipeline that addresses this limitation through: (1) cage segmentation using a Gabor-enhanced ResNet-UNet architecture with tunable orientation filters, (2) cage inpainting using CRFill for content-aware reconstruction of occluded regions, and (3) evaluation of pose estimation and tracking on the uncaged frames. Our Gabor-enhanced segmentation model leverages orientation-aware features with 72 directional kernels to accurately identify and segment cage structures that severely impair the performance of existing methods. Experimental validation demonstrates that removing cage occlusions through our pipeline enables pose estimation and tracking performance comparable to that in environments without occlusions. We also observe significant improvements in keypoint detection accuracy and trajectory consistency.",
    "authors": [
      "Sayak Dutta",
      "Harish Katti",
      "Shashikant Verma",
      "Shanmuganathan Raman"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07712v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07712v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.45
  },
  {
    "arxiv_id": "2512.07305v1",
    "title": "Reevaluating Automated Wildlife Species Detection: A Reproducibility Study on a Custom Image Dataset",
    "summary": "This study revisits the findings of Carl et al., who evaluated the pre-trained Google Inception-ResNet-v2 model for automated detection of European wild mammal species in camera trap images. To assess the reproducibility and generalizability of their approach, we reimplemented the experiment from scratch using openly available resources and a different dataset consisting of 900 images spanning 90 species. After minimal preprocessing, we obtained an overall classification accuracy of 62%, closely aligning with the 71% reported in the original work despite differences in datasets. As in the original study, per-class performance varied substantially, as indicated by a macro F1 score of 0.28,highlighting limitations in generalization when labels do not align directly with ImageNet classes. Our results confirm that pretrained convolutional neural networks can provide a practical baseline for wildlife species identification but also reinforce the need for species-specific adaptation or transfer learning to achieve consistent, high-quality predictions.",
    "authors": [
      "Tobias Abraham Haider"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07305v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07305v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.45
  },
  {
    "arxiv_id": "2512.07259v1",
    "title": "Affine Subspace Models and Clustering for Patch-Based Image Denoising",
    "summary": "Image tile-based approaches are popular in many image processing applications such as denoising (e.g., non-local means). A key step in their use is grouping the images into clusters, which usually proceeds iteratively splitting the images into clusters and fitting a model for the images in each cluster. Linear subspaces have emerged as a suitable model for tile clusters; however, they are not well matched to images patches given that images are non-negative and thus not distributed around the origin in the tile vector space. We study the use of affine subspace models for the clusters to better match the geometric structure of the image tile vector space. We also present a simple denoising algorithm that relies on the affine subspace clustering model using least squares projection. We review several algorithmic approaches to solve the affine subspace clustering problem and show experimental results that highlight the performance improvements in clustering and denoising.",
    "authors": [
      "Tharindu Wickremasinghe",
      "Marco F. Duarte"
    ],
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07259v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07259v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.44
  },
  {
    "arxiv_id": "2512.07778v1",
    "title": "Distribution Matching Variational AutoEncoder",
    "summary": "Most visual generative models compress images into a latent space before applying diffusion or autoregressive modelling. Yet, existing approaches such as VAEs and foundation model aligned encoders implicitly constrain the latent space without explicitly shaping its distribution, making it unclear which types of distributions are optimal for modeling. We introduce \\textbf{Distribution-Matching VAE} (\\textbf{DMVAE}), which explicitly aligns the encoder's latent distribution with an arbitrary reference distribution via a distribution matching constraint. This generalizes beyond the Gaussian prior of conventional VAEs, enabling alignment with distributions derived from self-supervised features, diffusion noise, or other prior distributions. With DMVAE, we can systematically investigate which latent distributions are more conducive to modeling, and we find that SSL-derived distributions provide an excellent balance between reconstruction fidelity and modeling efficiency, reaching gFID equals 3.2 on ImageNet with only 64 training epochs. Our results suggest that choosing a suitable latent distribution structure (achieved via distribution-level alignment), rather than relying on fixed priors, is key to bridging the gap between easy-to-model latents and high-fidelity image synthesis. Code is avaliable at https://github.com/sen-ye/dmvae.",
    "authors": [
      "Sen Ye",
      "Jianning Pei",
      "Mengde Xu",
      "Shuyang Gu",
      "Chunyu Wang",
      "Liwei Wang",
      "Han Hu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07778v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07778v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.43
  },
  {
    "arxiv_id": "2512.07514v1",
    "title": "MeshRipple: Structured Autoregressive Generation of Artist-Meshes",
    "summary": "Meshes serve as a primary representation for 3D assets. Autoregressive mesh generators serialize faces into sequences and train on truncated segments with sliding-window inference to cope with memory limits. However, this mismatch breaks long-range geometric dependencies, producing holes and fragmented components. To address this critical limitation, we introduce MeshRipple, which expands a mesh outward from an active generation frontier, akin to a ripple on a surface.MeshRipple rests on three key innovations: a frontier-aware BFS tokenization that aligns the generation order with surface topology; an expansive prediction strategy that maintains coherent, connected surface growth; and a sparse-attention global memory that provides an effectively unbounded receptive field to resolve long-range topological dependencies.This integrated design enables MeshRipple to generate meshes with high surface fidelity and topological completeness, outperforming strong recent baselines.",
    "authors": [
      "Junkai Lin",
      "Hang Long",
      "Huipeng Guo",
      "Jielei Zhang",
      "JiaYi Yang",
      "Tianle Guo",
      "Yang Yang",
      "Jianwen Li",
      "Wenxiao Zhang",
      "Matthias Nießner",
      "Wei Yang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07514v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07514v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.42
  },
  {
    "arxiv_id": "2512.07331v1",
    "title": "The Inductive Bottleneck: Data-Driven Emergence of Representational Sparsity in Vision Transformers",
    "summary": "Vision Transformers (ViTs) lack the hierarchical inductive biases inherent to Convolutional Neural Networks (CNNs), theoretically allowing them to maintain high-dimensional representations throughout all layers. However, recent observations suggest ViTs often spontaneously manifest a \"U-shaped\" entropy profile-compressing information in middle layers before expanding it for the final classification. In this work, we demonstrate that this \"Inductive Bottleneck\" is not an architectural artifact, but a data-dependent adaptation. By analyzing the layer-wise Effective Encoding Dimension (EED) of DINO-trained ViTs across datasets of varying compositional complexity (UC Merced, Tiny ImageNet, and CIFAR-100), we show that the depth of the bottleneck correlates strongly with the semantic abstraction required by the task. We find that while texture-heavy datasets preserve high-rank representations throughout, object-centric datasets drive the network to dampen high-frequency information in middle layers, effectively \"learning\" a bottleneck to isolate semantic features.",
    "authors": [
      "Kanishk Awadhiya"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-12-08",
    "url": "https://arxiv.org/abs/2512.07331v1",
    "pdf_url": "https://arxiv.org/pdf/2512.07331v1.pdf",
    "date": "2025-12-10",
    "source": "arxiv",
    "research_score": 0.42
  }
]