[
  {
    "arxiv_id": "2511.08663v1",
    "title": "3D-TDA -- Topological feature extraction from 3D images for Alzheimer's disease classification",
    "summary": "Now that disease-modifying therapies for Alzheimer disease have been approved by regulatory agencies, the early, objective, and accurate clinical diagnosis of AD based on the lowest-cost measurement modalities possible has become an increasingly urgent need. In this study, we propose a novel feature extraction method using persistent homology to analyze structural MRI of the brain. This approach converts topological features into powerful feature vectors through Betti functions. By integrating these feature vectors with a simple machine learning model like XGBoost, we achieve a computationally efficient machine learning model. Our model outperforms state-of-the-art deep learning models in both binary and three-class classification tasks for ADNI 3D MRI disease diagnosis. Using 10-fold cross-validation, our model achieved an average accuracy of 97.43 percent and sensitivity of 99.09 percent for binary classification. For three-class classification, it achieved an average accuracy of 95.47 percent and sensitivity of 94.98 percent. Unlike many deep learning models, our approach does not require data augmentation or extensive preprocessing, making it particularly suitable for smaller datasets. Topological features differ significantly from those commonly extracted using convolutional filters and other deep learning machinery. Because it provides an entirely different type of information from machine learning models, it has the potential to combine topological features with other models later on.",
    "authors": [
      "Faisal Ahmed",
      "Taymaz Akan",
      "Fatih Gelir",
      "Owen T. Carmichael",
      "Elizabeth A. Disbrow",
      "Steven A. Conrad",
      "Mohammad A. N. Bhuiyan"
    ],
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08663v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08663v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.97
  },
  {
    "arxiv_id": "2511.08939v1",
    "title": "TransactionGPT",
    "summary": "We present TransactionGPT (TGPT), a foundation model for consumer transaction data within one of world's largest payment networks. TGPT is designed to understand and generate transaction trajectories while simultaneously supporting a variety of downstream prediction and classification tasks. We introduce a novel 3D-Transformer architecture specifically tailored for capturing the complex dynamics in payment transaction data. This architecture incorporates design innovations that enhance modality fusion and computational efficiency, while seamlessly enabling joint optimization with downstream objectives. Trained on billion-scale real-world transactions, TGPT significantly improves downstream classification performance against a competitive production model and exhibits advantages over baselines in generating future transactions. We conduct extensive empirical evaluations utilizing a diverse collection of company transaction datasets spanning multiple downstream tasks, thereby enabling a thorough assessment of TGPT's effectiveness and efficiency in comparison to established methodologies. Furthermore, we examine the incorporation of LLM-derived embeddings within TGPT and benchmark its performance against fine-tuned LLMs, demonstrating that TGPT achieves superior predictive accuracy as well as faster training and inference. We anticipate that the architectural innovations and practical guidelines from this work will advance foundation models for transaction-like data and catalyze future research in this emerging field.",
    "authors": [
      "Yingtong Dou",
      "Zhimeng Jiang",
      "Tianyi Zhang",
      "Mingzhi Hu",
      "Zhichao Xu",
      "Shubham Jain",
      "Uday Singh Saini",
      "Xiran Fan",
      "Jiarui Sun",
      "Menghai Pan",
      "Junpeng Wang",
      "Xin Dai",
      "Liang Wang",
      "Chin-Chia Michael Yeh",
      "Yujie Fan",
      "Vineeth Rakesh",
      "Huiyuan Chen",
      "Mangesh Bendre",
      "Zhongfang Zhuang",
      "Xiaoting Li",
      "Prince Aboagye",
      "Vivian Lai",
      "Minghua Xu",
      "Hao Yang",
      "Yiwei Cai",
      "Mahashweta Das",
      "Yuzhong Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08939v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08939v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.93
  },
  {
    "arxiv_id": "2511.08573v1",
    "title": "SENCA-st: Integrating Spatial Transcriptomics and Histopathology with Cross Attention Shared Encoder for Region Identification in Cancer Pathology",
    "summary": "Spatial transcriptomics is an emerging field that enables the identification of functional regions based on the spatial distribution of gene expression. Integrating this functional information present in transcriptomic data with structural data from histopathology images is an active research area with applications in identifying tumor substructures associated with cancer drug resistance. Current histopathology-spatial-transcriptomic region segmentation methods suffer due to either making spatial transcriptomics prominent by using histopathology features just to assist processing spatial transcriptomics data or using vanilla contrastive learning that make histopathology images prominent due to only promoting common features losing functional information. In both extremes, the model gets either lost in the noise of spatial transcriptomics or overly smoothed, losing essential information. Thus, we propose our novel architecture SENCA-st (Shared Encoder with Neighborhood Cross Attention) that preserves the features of both modalities. More importantly, it emphasizes regions that are structurally similar in histopathology but functionally different on spatial transcriptomics using cross-attention. We demonstrate the superior performance of our model that surpasses state-of-the-art methods in detecting tumor heterogeneity and tumor micro-environment regions, a clinically crucial aspect.",
    "authors": [
      "Shanaka Liyanaarachchi",
      "Chathurya Wijethunga",
      "Shihab Aaqil Ahamed",
      "Akthas Absar",
      "Ranga Rodrigo"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08573v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08573v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.92
  },
  {
    "arxiv_id": "2511.08841v1",
    "title": "Enhancing DPSGD via Per-Sample Momentum and Low-Pass Filtering",
    "summary": "Differentially Private Stochastic Gradient Descent (DPSGD) is widely used to train deep neural networks with formal privacy guarantees. However, the addition of differential privacy (DP) often degrades model accuracy by introducing both noise and bias. Existing techniques typically address only one of these issues, as reducing DP noise can exacerbate clipping bias and vice-versa. In this paper, we propose a novel method, \\emph{DP-PMLF}, which integrates per-sample momentum with a low-pass filtering strategy to simultaneously mitigate DP noise and clipping bias. Our approach uses per-sample momentum to smooth gradient estimates prior to clipping, thereby reducing sampling variance. It further employs a post-processing low-pass filter to attenuate high-frequency DP noise without consuming additional privacy budget. We provide a theoretical analysis demonstrating an improved convergence rate under rigorous DP guarantees, and our empirical evaluations reveal that DP-PMLF significantly enhances the privacy-utility trade-off compared to several state-of-the-art DPSGD variants.",
    "authors": [
      "Xincheng Xu",
      "Thilina Ranbaduge",
      "Qing Wang",
      "Thierry Rakotoarivelo",
      "David Smith"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08841v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08841v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.91
  },
  {
    "arxiv_id": "2511.08535v1",
    "title": "Large Sign Language Models: Toward 3D American Sign Language Translation",
    "summary": "We present Large Sign Language Models (LSLM), a novel framework for translating 3D American Sign Language (ASL) by leveraging Large Language Models (LLMs) as the backbone, which can benefit hearing-impaired individuals' virtual communication. Unlike existing sign language recognition methods that rely on 2D video, our approach directly utilizes 3D sign language data to capture rich spatial, gestural, and depth information in 3D scenes. This enables more accurate and resilient translation, enhancing digital communication accessibility for the hearing-impaired community. Beyond the task of ASL translation, our work explores the integration of complex, embodied multimodal languages into the processing capabilities of LLMs, moving beyond purely text-based inputs to broaden their understanding of human communication. We investigate both direct translation from 3D gesture features to text and an instruction-guided setting where translations can be modulated by external prompts, offering greater flexibility. This work provides a foundational step toward inclusive, multimodal intelligent systems capable of understanding diverse forms of language.",
    "authors": [
      "Sen Zhang",
      "Xiaoxiao He",
      "Di Liu",
      "Zhaoyang Xia",
      "Mingyu Zhao",
      "Chaowei Tan",
      "Vivian Li",
      "Bo Liu",
      "Dimitris N. Metaxas",
      "Mubbasir Kapadia"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08535v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08535v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.88
  },
  {
    "arxiv_id": "2511.08747v1",
    "title": "Vector Symbolic Algebras for the Abstraction and Reasoning Corpus",
    "summary": "The Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) is a generative, few-shot fluid intelligence benchmark. Although humans effortlessly solve ARC-AGI, it remains extremely difficult for even the most advanced artificial intelligence systems. Inspired by methods for modelling human intelligence spanning neuroscience to psychology, we propose a cognitively plausible ARC-AGI solver. Our solver integrates System 1 intuitions with System 2 reasoning in an efficient and interpretable process using neurosymbolic methods based on Vector Symbolic Algebras (VSAs). Our solver works by object-centric program synthesis, leveraging VSAs to represent abstract objects, guide solution search, and enable sample-efficient neural learning. Preliminary results indicate success, with our solver scoring 10.8% on ARC-AGI-1-Train and 3.0% on ARC-AGI-1-Eval. Additionally, our solver performs well on simpler benchmarks, scoring 94.5% on Sort-of-ARC and 83.1% on 1D-ARC -- the latter outperforming GPT-4 at a tiny fraction of the computational cost. Importantly, our approach is unique; we believe we are the first to apply VSAs to ARC-AGI and have developed the most cognitively plausible ARC-AGI solver yet. Our code is available at: https://github.com/ijoffe/ARC-VSA-2025.",
    "authors": [
      "Isaac Joffe",
      "Chris Eliasmith"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08747v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08747v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.88
  },
  {
    "arxiv_id": "2511.08402v1",
    "title": "Anatomy-VLM: A Fine-grained Vision-Language Model for Medical Interpretation",
    "summary": "Accurate disease interpretation from radiology remains challenging due to imaging heterogeneity. Achieving expert-level diagnostic decisions requires integration of subtle image features with clinical knowledge. Yet major vision-language models (VLMs) treat images as holistic entities and overlook fine-grained image details that are vital for disease diagnosis. Clinicians analyze images by utilizing their prior medical knowledge and identify anatomical structures as important region of interests (ROIs). Inspired from this human-centric workflow, we introduce Anatomy-VLM, a fine-grained, vision-language model that incorporates multi-scale information. First, we design a model encoder to localize key anatomical features from entire medical images. Second, these regions are enriched with structured knowledge for contextually-aware interpretation. Finally, the model encoder aligns multi-scale medical information to generate clinically-interpretable disease prediction. Anatomy-VLM achieves outstanding performance on both in- and out-of-distribution datasets. We also validate the performance of Anatomy-VLM on downstream image segmentation tasks, suggesting that its fine-grained alignment captures anatomical and pathology-related knowledge. Furthermore, the Anatomy-VLM's encoder facilitates zero-shot anatomy-wise interpretation, providing its strong expert-level clinical interpretation capabilities.",
    "authors": [
      "Difei Gu",
      "Yunhe Gao",
      "Mu Zhou",
      "Dimitris Metaxas"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08402v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08402v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.86
  },
  {
    "arxiv_id": "2511.08098v1",
    "title": "PerspAct: Enhancing LLM Situated Collaboration Skills through Perspective Taking and Active Vision",
    "summary": "Recent advances in Large Language Models (LLMs) and multimodal foundation models have significantly broadened their application in robotics and collaborative systems. However, effective multi-agent interaction necessitates robust perspective-taking capabilities, enabling models to interpret both physical and epistemic viewpoints. Current training paradigms often neglect these interactive contexts, resulting in challenges when models must reason about the subjectivity of individual perspectives or navigate environments with multiple observers. This study evaluates whether explicitly incorporating diverse points of view using the ReAct framework, an approach that integrates reasoning and acting, can enhance an LLM's ability to understand and ground the demands of other agents. We extend the classic Director task by introducing active visual exploration across a suite of seven scenarios of increasing perspective-taking complexity. These scenarios are designed to challenge the agent's capacity to resolve referential ambiguity based on visual access and interaction, under varying state representations and prompting strategies, including ReAct-style reasoning. Our results demonstrate that explicit perspective cues, combined with active exploration strategies, significantly improve the model's interpretative accuracy and collaborative effectiveness. These findings highlight the potential of integrating active perception with perspective-taking mechanisms in advancing LLMs' application in robotics and multi-agent systems, setting a foundation for future research into adaptive and context-aware AI systems.",
    "authors": [
      "Sabrina Patania",
      "Luca Annese",
      "Anita Pellegrini",
      "Silvia Serino",
      "Anna Lambiase",
      "Luca Pallonetto",
      "Silvia Rossi",
      "Simone Colombani",
      "Tom Foulsham",
      "Azzurra Ruggeri",
      "Dimitri Ognibene"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08098v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08098v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.84
  },
  {
    "arxiv_id": "2511.09558v1",
    "title": "IFG: Internet-Scale Guidance for Functional Grasping Generation",
    "summary": "Large Vision Models trained on internet-scale data have demonstrated strong capabilities in segmenting and semantically understanding object parts, even in cluttered, crowded scenes. However, while these models can direct a robot toward the general region of an object, they lack the geometric understanding required to precisely control dexterous robotic hands for 3D grasping. To overcome this, our key insight is to leverage simulation with a force-closure grasping generation pipeline that understands local geometries of the hand and object in the scene. Because this pipeline is slow and requires ground-truth observations, the resulting data is distilled into a diffusion model that operates in real-time on camera point clouds. By combining the global semantic understanding of internet-scale models with the geometric precision of a simulation-based locally-aware force-closure, \\our achieves high-performance semantic grasping without any manually collected training data. For visualizations of this please visit our website at https://ifgrasping.github.io/",
    "authors": [
      "Ray Muxin Liu",
      "Mingxuan Li",
      "Kenneth Shaw",
      "Deepak Pathak"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.GR",
      "cs.LG"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09558v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09558v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.83
  },
  {
    "arxiv_id": "2511.09008v1",
    "title": "A Neurosymbolic Approach to Natural Language Formalization and Verification",
    "summary": "Large Language Models perform well at natural language interpretation and reasoning, but their inherent stochasticity limits their adoption in regulated industries like finance and healthcare that operate under strict policies. To address this limitation, we present a two-stage neurosymbolic framework that (1) uses LLMs with optional human guidance to formalize natural language policies, allowing fine-grained control of the formalization process, and (2) uses inference-time autoformalization to validate logical correctness of natural language statements against those policies. When correctness is paramount, we perform multiple redundant formalization steps at inference time, cross checking the formalizations for semantic equivalence. Our benchmarks demonstrate that our approach exceeds 99% soundness, indicating a near-zero false positive rate in identifying logical validity. Our approach produces auditable logical artifacts that substantiate the verification outcomes and can be used to improve the original text.",
    "authors": [
      "Sam Bayless",
      "Stefano Buliani",
      "Darion Cassel",
      "Byron Cook",
      "Duncan Clough",
      "Rémi Delmas",
      "Nafi Diallo",
      "Ferhat Erata",
      "Nick Feng",
      "Dimitra Giannakopoulou",
      "Aman Goel",
      "Aditya Gokhale",
      "Joe Hendrix",
      "Marc Hudak",
      "Dejan Jovanović",
      "Andrew M. Kent",
      "Benjamin Kiesl-Reiter",
      "Jeffrey J. Kuna",
      "Nadia Labai",
      "Joseph Lilien",
      "Divya Raghunathan",
      "Zvonimir Rakamarić",
      "Niloofar Razavi",
      "Michael Tautschnig",
      "Ali Torkamani",
      "Nathaniel Weir",
      "Michael W. Whalen",
      "Jianan Yao"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09008v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09008v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.08930v1",
    "title": "From Structure to Detail: Hierarchical Distillation for Efficient Diffusion Model",
    "summary": "The inference latency of diffusion models remains a critical barrier to their real-time application. While trajectory-based and distribution-based step distillation methods offer solutions, they present a fundamental trade-off. Trajectory-based methods preserve global structure but act as a \"lossy compressor\", sacrificing high-frequency details. Conversely, distribution-based methods can achieve higher fidelity but often suffer from mode collapse and unstable training. This paper recasts them from independent paradigms into synergistic components within our novel Hierarchical Distillation (HD) framework. We leverage trajectory distillation not as a final generator, but to establish a structural ``sketch\", providing a near-optimal initialization for the subsequent distribution-based refinement stage. This strategy yields an ideal initial distribution that enhances the ceiling of overall performance. To further improve quality, we introduce and refine the adversarial training process. We find standard discriminator structures are ineffective at refining an already high-quality generator. To overcome this, we introduce the Adaptive Weighted Discriminator (AWD), tailored for the HD pipeline. By dynamically allocating token weights, AWD focuses on local imperfections, enabling efficient detail refinement. Our approach demonstrates state-of-the-art performance across diverse tasks. On ImageNet $256\\times256$, our single-step model achieves an FID of 2.26, rivaling its 250-step teacher. It also achieves promising results on the high-resolution text-to-image MJHQ benchmark, proving its generalizability. Our method establishes a robust new paradigm for high-fidelity, single-step diffusion models.",
    "authors": [
      "Hanbo Cheng",
      "Peng Wang",
      "Kaixiang Lei",
      "Qi Li",
      "Zhen Zou",
      "Pengfei Hu",
      "Jun Du"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08930v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08930v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.08003v1",
    "title": "Sharp Eyes and Memory for VideoLLMs: Information-Aware Visual Token Pruning for Efficient and Reliable VideoLLM Reasoning",
    "summary": "Current Video Large Language Models (VideoLLMs) suffer from quadratic computational complexity and key-value cache scaling, due to their reliance on processing excessive redundant visual tokens. To address this problem, we propose SharpV, a minimalist and efficient method for adaptive pruning of visual tokens and KV cache. Different from most uniform compression approaches, SharpV dynamically adjusts pruning ratios based on spatial-temporal information. Remarkably, this adaptive mechanism occasionally achieves performance gains over dense models, offering a novel paradigm for adaptive pruning. During the KV cache pruning stage, based on observations of visual information degradation, SharpV prunes degraded visual features via a self-calibration manner, guided by similarity to original visual features. In this way, SharpV achieves hierarchical cache pruning from the perspective of information bottleneck, offering a new insight into VideoLLMs' information flow. Experiments on multiple public benchmarks demonstrate the superiority of SharpV. Moreover, to the best of our knowledge, SharpV is notably the first two-stage pruning framework that operates without requiring access to exposed attention scores, ensuring full compatibility with hardware acceleration techniques like Flash Attention.",
    "authors": [
      "Jialong Qin",
      "Xin Zou",
      "Di Lu",
      "Yibo Yan",
      "Xuming Hu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08003v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08003v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.09404v1",
    "title": "Spatio-Temporal Graph Unlearning",
    "summary": "Spatio-temporal graphs are widely used in modeling complex dynamic processes such as traffic forecasting, molecular dynamics, and healthcare monitoring. Recently, stringent privacy regulations such as GDPR and CCPA have introduced significant new challenges for existing spatio-temporal graph models, requiring complete unlearning of unauthorized data. Since each node in a spatio-temporal graph diffuses information globally across both spatial and temporal dimensions, existing unlearning methods primarily designed for static graphs and localized data removal cannot efficiently erase a single node without incurring costs nearly equivalent to full model retraining. Therefore, an effective approach for complete spatio-temporal graph unlearning is a pressing need. To address this, we propose CallosumNet, a divide-and-conquer spatio-temporal graph unlearning framework inspired by the corpus callosum structure that facilitates communication between the brain's two hemispheres. CallosumNet incorporates two novel techniques: (1) Enhanced Subgraph Construction (ESC), which adaptively constructs multiple localized subgraphs based on several factors, including biologically-inspired virtual ganglions; and (2) Global Ganglion Bridging (GGB), which reconstructs global spatio-temporal dependencies from these localized subgraphs, effectively restoring the full graph representation. Empirical results on four diverse real-world datasets show that CallosumNet achieves complete unlearning with only 1%-2% relative MAE loss compared to the gold model, significantly outperforming state-of-the-art baselines. Ablation studies verify the effectiveness of both proposed techniques.",
    "authors": [
      "Qiming Guo",
      "Wenbo Sun",
      "Wenlu Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09404v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09404v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.08263v1",
    "title": "ImagebindDC: Compressing Multi-modal Data with Imagebind-based Condensation",
    "summary": "Data condensation techniques aim to synthesize a compact dataset from a larger one to enable efficient model training, yet while successful in unimodal settings, they often fail in multimodal scenarios where preserving intricate inter-modal dependencies is crucial. To address this, we introduce ImageBindDC, a novel data condensation framework operating within the unified feature space of ImageBind. Our approach moves beyond conventional distribution-matching by employing a powerful Characteristic Function (CF) loss, which operates in the Fourier domain to facilitate a more precise statistical alignment via exact infinite moment matching. We design our objective to enforce three critical levels of distributional consistency: (i) uni-modal alignment, which matches the statistical properties of synthetic and real data within each modality; (ii) cross-modal alignment, which preserves pairwise semantics by matching the distributions of hybrid real-synthetic data pairs; and (iii) joint-modal alignment, which captures the complete multivariate data structure by aligning the joint distribution of real data pairs with their synthetic counterparts. Extensive experiments highlight the effectiveness of ImageBindDC: on the NYU-v2 dataset, a model trained on just 5 condensed datapoints per class achieves lossless performance comparable to one trained on the full dataset, achieving a new state-of-the-art with an 8.2\\% absolute improvement over the previous best method and more than 4$\\times$ less condensation time.",
    "authors": [
      "Yue Min",
      "Shaobo Wang",
      "Jiaze Li",
      "Tianle Niu",
      "Junxin Fan",
      "Yongliang Miao",
      "Lijin Yang",
      "Linfeng Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08263v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08263v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2511.08349v1",
    "title": "Hybrid Quantum-Classical Selective State Space Artificial Intelligence",
    "summary": "Hybrid Quantum Classical (HQC) algorithms constitute one of the most effective paradigms for exploiting the computational advantages of quantum systems in large-scale numerical tasks. By operating in high-dimensional Hilbert spaces, quantum circuits enable exponential speed-ups and provide access to richer representations of cost landscapes compared to purely classical methods. These capabilities are particularly relevant for machine learning, where state-of-the-art models especially in Natural Language Processing (NLP) suffer from prohibitive time complexity due to massive matrix multiplications and high-dimensional optimization.   In this manuscript, we propose a Hybrid Quantum Classical selection mechanism for the Mamba architecture, designed specifically for temporal sequence classification problems. Our approach leverages Variational Quantum Circuits (VQCs) as quantum gating modules that both enhance feature extraction and improve suppression of irrelevant information. This integration directly addresses the computational bottlenecks of deep learning architectures by exploiting quantum resources for more efficient representation learning.   We analyze how introducing quantum subroutines into large language models (LLMs) impacts their generalization capability, expressivity, and parameter efficiency. The results highlight the potential of quantum-enhanced gating mechanisms as a path toward scalable, resource-efficient NLP models, in a limited simulation step. Within the first four epochs on a reshaped MNIST dataset with input format (batch, 784, d_model), our hybrid model achieved 24.6% accuracy while using one quantum layer and achieve higher expressivity, compared to 21.6% obtained by a purely classical selection mechanism. we state No founding",
    "authors": [
      "Amin Ebrahimi",
      "Farzan Haddadi"
    ],
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08349v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08349v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.79
  },
  {
    "arxiv_id": "2511.09018v1",
    "title": "Causally-Grounded Dual-Path Attention Intervention for Object Hallucination Mitigation in LVLMs",
    "summary": "Object hallucination remains a critical challenge in Large Vision-Language Models (LVLMs), where models generate content inconsistent with visual inputs. Existing language-decoder based mitigation approaches often regulate visual or textual attention independently, overlooking their interaction as two key causal factors. To address this, we propose Owl (Bi-mOdal attention reWeighting for Layer-wise hallucination mitigation), a causally-grounded framework that models hallucination process via a structural causal graph, treating decomposed visual and textual attentions as mediators. We introduce VTACR (Visual-to-Textual Attention Contribution Ratio), a novel metric that quantifies the modality contribution imbalance during decoding. Our analysis reveals that hallucinations frequently occur in low-VTACR scenarios, where textual priors dominate and visual grounding is weakened. To mitigate this, we design a fine-grained attention intervention mechanism that dynamically adjusts token- and layer-wise attention guided by VTACR signals. Finally, we propose a dual-path contrastive decoding strategy: one path emphasizes visually grounded predictions, while the other amplifies hallucinated ones -- letting visual truth shine and hallucination collapse. Experimental results on the POPE and CHAIR benchmarks show that Owl achieves significant hallucination reduction, setting a new SOTA in faithfulness while preserving vision-language understanding capability. Our code is available at https://github.com/CikZ2023/OWL",
    "authors": [
      "Liu Yu",
      "Zhonghao Chen",
      "Ping Kuang",
      "Zhikun Feng",
      "Fan Zhou",
      "Lan Wang",
      "Gillian Dobbie"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09018v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09018v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2511.08417v1",
    "title": "NeuCLIP: Efficient Large-Scale CLIP Training with Neural Normalizer Optimization",
    "summary": "Accurately estimating the normalization term (also known as the partition function) in the contrastive loss is a central challenge for training Contrastive Language-Image Pre-training (CLIP) models. Conventional methods rely on large batches for approximation, demanding substantial computational resources. To mitigate this issue, prior works introduced per-sample normalizer estimators, which are updated at each epoch in a blockwise coordinate manner to keep track of updated encoders. However, this scheme incurs optimization error that scales with the ratio of dataset size to batch size, limiting effectiveness for large datasets or small batches. To overcome this limitation, we propose NeuCLIP, a novel and elegant optimization framework based on two key ideas: (i) $\\textbf{reformulating}$ the contrastive loss for each sample $\\textbf{via convex analysis}$ into a minimization problem with an auxiliary variable representing its log-normalizer; and (ii) $\\textbf{transforming}$ the resulting minimization over $n$ auxiliary variables (where $n$ is the dataset size) via $\\textbf{variational analysis}$ into the minimization over a compact neural network that predicts the log-normalizers. We design an alternating optimization algorithm that jointly trains the CLIP model and the auxiliary network. By employing a tailored architecture and acceleration techniques for the auxiliary network, NeuCLIP achieves more accurate normalizer estimation, leading to improved performance compared with previous methods. Extensive experiments on large-scale CLIP training, spanning datasets from millions to billions of samples, demonstrate that NeuCLIP outperforms previous methods.",
    "authors": [
      "Xiyuan Wei",
      "Chih-Jen Lin",
      "Tianbao Yang"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08417v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08417v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2511.08043v1",
    "title": "DynaAct: Large Language Model Reasoning with Dynamic Action Spaces",
    "summary": "In modern sequential decision-making systems, the construction of an optimal candidate action space is critical to efficient inference. However, existing approaches either rely on manually defined action spaces that lack scalability or utilize unstructured spaces that render exhaustive search computationally prohibitive. In this paper, we propose a novel framework named \\textsc{DynaAct} for automatically constructing a compact action space to enhance sequential reasoning in complex problem-solving scenarios. Our method first estimates a proxy for the complete action space by extracting general sketches observed in a corpus covering diverse complex reasoning problems using large language models. We then formulate a submodular function that jointly evaluates candidate actions based on their utility to the current state and their diversity, and employ a greedy algorithm to select an optimal candidate set. Extensive experiments on six diverse standard benchmarks demonstrate that our approach significantly improves overall performance, while maintaining efficient inference without introducing substantial latency. The implementation is available at https://github.com/zhaoxlpku/DynaAct.",
    "authors": [
      "Xueliang Zhao",
      "Wei Wu",
      "Jian Guan",
      "Qintong Li",
      "Lingpeng Kong"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08043v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08043v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.77
  },
  {
    "arxiv_id": "2511.08287v1",
    "title": "Dual-Kernel Graph Community Contrastive Learning",
    "summary": "Graph Contrastive Learning (GCL) has emerged as a powerful paradigm for training Graph Neural Networks (GNNs) in the absence of task-specific labels. However, its scalability on large-scale graphs is hindered by the intensive message passing mechanism of GNN and the quadratic computational complexity of contrastive loss over positive and negative node pairs. To address these issues, we propose an efficient GCL framework that transforms the input graph into a compact network of interconnected node sets while preserving structural information across communities. We firstly introduce a kernelized graph community contrastive loss with linear complexity, enabling effective information transfer among node sets to capture hierarchical structural information of the graph. We then incorporate a knowledge distillation technique into the decoupled GNN architecture to accelerate inference while maintaining strong generalization performance. Extensive experiments on sixteen real-world datasets of varying scales demonstrate that our method outperforms state-of-the-art GCL baselines in both effectiveness and scalability.",
    "authors": [
      "Xiang Chen",
      "Kun Yue",
      "Wenjie Liu",
      "Zhenyu Zhang",
      "Liang Duan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08287v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08287v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2511.09148v1",
    "title": "LoopTool: Closing the Data-Training Loop for Robust LLM Tool Calls",
    "summary": "Augmenting Large Language Models (LLMs) with external tools enables them to execute complex, multi-step tasks. However, tool learning is hampered by the static synthetic data pipelines where data generation and model training are executed as two separate, non-interactive processes. This approach fails to adaptively focus on a model's specific weaknesses and allows noisy labels to persist, degrading training efficiency. We introduce LoopTool, a fully automated, model-aware data evolution framework that closes this loop by tightly integrating data synthesis and model training. LoopTool iteratively refines both the data and the model through three synergistic modules: (1) Greedy Capability Probing (GCP) diagnoses the model's mastered and failed capabilities; (2) Judgement-Guided Label Verification (JGLV) uses an open-source judge model to find and correct annotation errors, progressively purifying the dataset; and (3) Error-Driven Data Expansion (EDDE) generates new, challenging samples based on identified failures. This closed-loop process operates within a cost-effective, open-source ecosystem, eliminating dependence on expensive closed-source APIs. Experiments show that our 8B model trained with LoopTool significantly surpasses its 32B data generator and achieves new state-of-the-art results on the BFCL-v3 and ACEBench benchmarks for its scale. Our work demonstrates that closed-loop, self-refining data pipelines can dramatically enhance the tool-use capabilities of LLMs.",
    "authors": [
      "Kangning Zhang",
      "Wenxiang Jiao",
      "Kounianhua Du",
      "Yuan Lu",
      "Weiwen Liu",
      "Weinan Zhang",
      "Lei Zhang",
      "Yong Yu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09148v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09148v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2511.08130v2",
    "title": "Foam Segmentation in Wastewater Treatment Plants: A Federated Learning Approach with Segment Anything Model 2",
    "summary": "Foam formation in Wastewater Treatment Plants (WTPs) is a major challenge that can reduce treatment efficiency and increase costs. The ability to automatically examine changes in real-time with respect to the percentage of foam can be of great benefit to the plant. However, large amounts of labeled data are required to train standard Machine Learning (ML) models. The development of these systems is slow due to the scarcity and heterogeneity of labeled data. Additionally, the development is often hindered by the fact that different WTPs do not share their data due to privacy concerns. This paper proposes a new framework to address these challenges by combining Federated Learning (FL) with the state-of-the-art base model for image segmentation, Segment Anything Model 2 (SAM2). The FL paradigm enables collaborative model training across multiple WTPs without centralizing sensitive operational data, thereby ensuring privacy. The framework accelerates training convergence and improves segmentation performance even with limited local datasets by leveraging SAM2's strong pre-trained weights for initialization. The methodology involves fine-tuning SAM2 on distributed clients (edge nodes) using the Flower framework, where a central Fog server orchestrates the process by aggregating model weights without accessing private data. The model was trained and validated using various data collections, including real-world images captured at a WTPs in Granada, Spain, a synthetically generated foam dataset, and images from publicly available datasets to improve generalization. This research offers a practical, scalable, and privacy-aware solution for automatic foam tracking in WTPs. The findings highlight the significant potential of integrating large-scale foundational models into FL systems to solve real-world industrial challenges characterized by distributed and sensitive data.",
    "authors": [
      "Mehmet Batuhan Duman",
      "Alejandro Carnero",
      "Cristian Martín",
      "Daniel Garrido",
      "Manuel Díaz"
    ],
    "categories": [
      "cs.CV",
      "cs.DC",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08130v2",
    "pdf_url": "https://arxiv.org/pdf/2511.08130v2.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2511.08922v1",
    "title": "Diffusion Policies with Value-Conditional Optimization for Offline Reinforcement Learning",
    "summary": "In offline reinforcement learning, value overestimation caused by out-of-distribution (OOD) actions significantly limits policy performance. Recently, diffusion models have been leveraged for their strong distribution-matching capabilities, enforcing conservatism through behavior policy constraints. However, existing methods often apply indiscriminate regularization to redundant actions in low-quality datasets, resulting in excessive conservatism and an imbalance between the expressiveness and efficiency of diffusion modeling. To address these issues, we propose DIffusion policies with Value-conditional Optimization (DIVO), a novel approach that leverages diffusion models to generate high-quality, broadly covered in-distribution state-action samples while facilitating efficient policy improvement. Specifically, DIVO introduces a binary-weighted mechanism that utilizes the advantage values of actions in the offline dataset to guide diffusion model training. This enables a more precise alignment with the dataset's distribution while selectively expanding the boundaries of high-advantage actions. During policy improvement, DIVO dynamically filters high-return-potential actions from the diffusion model, effectively guiding the learned policy toward better performance. This approach achieves a critical balance between conservatism and explorability in offline RL. We evaluate DIVO on the D4RL benchmark and compare it against state-of-the-art baselines. Empirical results demonstrate that DIVO achieves superior performance, delivering significant improvements in average returns across locomotion tasks and outperforming existing methods in the challenging AntMaze domain, where sparse rewards pose a major difficulty.",
    "authors": [
      "Yunchang Ma",
      "Tenglong Liu",
      "Yixing Lan",
      "Xin Yin",
      "Changxin Zhang",
      "Xinglong Zhang",
      "Xin Xu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08922v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08922v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2511.08360v1",
    "title": "Extreme Model Compression with Structured Sparsity at Low Precision",
    "summary": "Deep neural networks (DNNs) are used in many applications, but their large size and high computational cost make them hard to run on devices with limited resources. Two widely used techniques to address this challenge are weight quantization, which lowers the precision of all weights, and structured sparsity, which removes unimportant weights while retaining the important ones at full precision. Although both are effective individually, they are typically studied in isolation due to their compounded negative impact on model accuracy when combined. In this work, we introduce SLOPE Structured Sparsity at Low Precision), a unified framework, to effectively combine structured sparsity and low-bit quantization in a principled way. We show that naively combining sparsity and quantization severely harms performance due to the compounded impact of both techniques. To address this, we propose a training-time regularization strategy that minimizes the discrepancy between full-precision weights and their sparse, quantized counterparts by promoting angular alignment rather than direct matching. On ResNet-18, SLOPE achieves $\\sim20\\times$ model size reduction while retaining $\\sim$99% of the original accuracy. It consistently outperforms state-of-the-art quantization and structured sparsity methods across classification, detection, and segmentation tasks on models such as ResNet-18, ViT-Small, and Mask R-CNN.",
    "authors": [
      "Dan Liu",
      "Nikita Dvornik",
      "Xue Liu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08360v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08360v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.08339v1",
    "title": "LPPG-RL: Lexicographically Projected Policy Gradient Reinforcement Learning with Subproblem Exploration",
    "summary": "Lexicographic multi-objective problems, which consist of multiple conflicting subtasks with explicit priorities, are common in real-world applications. Despite the advantages of Reinforcement Learning (RL) in single tasks, extending conventional RL methods to prioritized multiple objectives remains challenging. In particular, traditional Safe RL and Multi-Objective RL (MORL) methods have difficulty enforcing priority orderings efficiently. Therefore, Lexicographic Multi-Objective RL (LMORL) methods have been developed to address these challenges. However, existing LMORL methods either rely on heuristic threshold tuning with prior knowledge or are restricted to discrete domains. To overcome these limitations, we propose Lexicographically Projected Policy Gradient RL (LPPG-RL), a novel LMORL framework which leverages sequential gradient projections to identify feasible policy update directions, thereby enabling LPPG-RL broadly compatible with all policy gradient algorithms in continuous spaces. LPPG-RL reformulates the projection step as an optimization problem, and utilizes Dykstra's projection rather than generic solvers to deliver great speedups, especially for small- to medium-scale instances. In addition, LPPG-RL introduces Subproblem Exploration (SE) to prevent gradient vanishing, accelerate convergence and enhance stability. We provide theoretical guarantees for convergence and establish a lower bound on policy improvement. Finally, through extensive experiments in a 2D navigation environment, we demonstrate the effectiveness of LPPG-RL, showing that it outperforms existing state-of-the-art continuous LMORL methods.",
    "authors": [
      "Ruiyu Qiu",
      "Rui Wang",
      "Guanghui Yang",
      "Xiang Li",
      "Zhijiang Shao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08339v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08339v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.08340v1",
    "title": "HN-MVTS: HyperNetwork-based Multivariate Time Series Forecasting",
    "summary": "Accurate forecasting of multivariate time series data remains a formidable challenge, particularly due to the growing complexity of temporal dependencies in real-world scenarios. While neural network-based models have achieved notable success in this domain, complex channel-dependent models often suffer from performance degradation compared to channel-independent models that do not consider the relationship between components but provide high robustness due to small capacity. In this work, we propose HN-MVTS, a novel architecture that integrates a hypernetwork-based generative prior with an arbitrary neural network forecasting model. The input of this hypernetwork is a learnable embedding matrix of time series components. To restrict the number of new parameters, the hypernetwork learns to generate the weights of the last layer of the target forecasting networks, serving as a data-adaptive regularizer that improves generalization and long-range predictive accuracy. The hypernetwork is used only during the training, so it does not increase the inference time compared to the base forecasting model. Extensive experiments on eight benchmark datasets demonstrate that application of HN-MVTS to the state-of-the-art models (DLinear, PatchTST, TSMixer, etc.) typically improves their performance. Our findings suggest that hypernetwork-driven parameterization offers a promising direction for enhancing existing forecasting techniques in complex scenarios.",
    "authors": [
      "Andrey Savchenko",
      "Oleg Kachan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08340v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08340v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.08133v1",
    "title": "OTSNet: A Neurocognitive-Inspired Observation-Thinking-Spelling Pipeline for Scene Text Recognition",
    "summary": "Scene Text Recognition (STR) remains challenging due to real-world complexities, where decoupled visual-linguistic optimization in existing frameworks amplifies error propagation through cross-modal misalignment. Visual encoders exhibit attention bias toward background distractors, while decoders suffer from spatial misalignment when parsing geometrically deformed text-collectively degrading recognition accuracy for irregular patterns. Inspired by the hierarchical cognitive processes in human visual perception, we propose OTSNet, a novel three-stage network embodying a neurocognitive-inspired Observation-Thinking-Spelling pipeline for unified STR modeling. The architecture comprises three core components: (1) a Dual Attention Macaron Encoder (DAME) that refines visual features through differential attention maps to suppress irrelevant regions and enhance discriminative focus; (2) a Position-Aware Module (PAM) and Semantic Quantizer (SQ) that jointly integrate spatial context with glyph-level semantic abstraction via adaptive sampling; and (3) a Multi-Modal Collaborative Verifier (MMCV) that enforces self-correction through cross-modal fusion of visual, semantic, and character-level features. Extensive experiments demonstrate that OTSNet achieves state-of-the-art performance, attaining 83.5% average accuracy on the challenging Union14M-L benchmark and 79.1% on the heavily occluded OST dataset-establishing new records across 9 out of 14 evaluation scenarios.",
    "authors": [
      "Lixu Sun",
      "Nurmemet Yolwas",
      "Wushour Silamu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08133v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08133v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.09332v1",
    "title": "Distribution-Based Feature Attribution for Explaining the Predictions of Any Classifier",
    "summary": "The proliferation of complex, black-box AI models has intensified the need for techniques that can explain their decisions. Feature attribution methods have become a popular solution for providing post-hoc explanations, yet the field has historically lacked a formal problem definition. This paper addresses this gap by introducing a formal definition for the problem of feature attribution, which stipulates that explanations be supported by an underlying probability distribution represented by the given dataset. Our analysis reveals that many existing model-agnostic methods fail to meet this criterion, while even those that do often possess other limitations. To overcome these challenges, we propose Distributional Feature Attribution eXplanations (DFAX), a novel, model-agnostic method for feature attribution. DFAX is the first feature attribution method to explain classifier predictions directly based on the data distribution. We show through extensive experiments that DFAX is more effective and efficient than state-of-the-art baselines.",
    "authors": [
      "Xinpeng Li",
      "Kai Ming Ting"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09332v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09332v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.09109v1",
    "title": "Thinking Forward and Backward: Multi-Objective Reinforcement Learning for Retrieval-Augmented Reasoning",
    "summary": "Retrieval-augmented generation (RAG) has proven to be effective in mitigating hallucinations in large language models, yet its effectiveness remains limited in complex, multi-step reasoning scenarios.Recent efforts have incorporated search-based interactions into RAG, enabling iterative reasoning with real-time retrieval. Most approaches rely on outcome-based supervision, offering no explicit guidance for intermediate steps. This often leads to reward hacking and degraded response quality. We propose Bi-RAR, a novel retrieval-augmented reasoning framework that evaluates each intermediate step jointly in both forward and backward directions. To assess the information completeness of each step, we introduce a bidirectional information distance grounded in Kolmogorov complexity, approximated via language model generation probabilities. This quantification measures both how far the current reasoning is from the answer and how well it addresses the question. To optimize reasoning under these bidirectional signals, we adopt a multi-objective reinforcement learning framework with a cascading reward structure that emphasizes early trajectory alignment. Empirical results on seven question answering benchmarks demonstrate that Bi-RAR surpasses previous methods and enables efficient interaction and reasoning with the search engine during training and inference.",
    "authors": [
      "Wenda Wei",
      "Yu-An Liu",
      "Ruqing Zhang",
      "Jiafeng Guo",
      "Lixin Su",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Maarten de Rijke",
      "Xueqi Cheng"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09109v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09109v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.08968v1",
    "title": "Bayesian Mixture of Experts For Large Language Models",
    "summary": "We present Bayesian Mixture of Experts (Bayesian-MoE), a post-hoc uncertainty estimation framework for fine-tuned large language models (LLMs) based on Mixture-of-Experts architectures. Our method applies a structured Laplace approximation to the second linear layer of each expert, enabling calibrated uncertainty estimation without modifying the original training procedure or introducing new parameters. Unlike prior approaches, which apply Bayesian inference to added adapter modules, Bayesian-MoE directly targets the expert pathways already present in MoE models, leveraging their modular design for tractable block-wise posterior estimation. We use Kronecker-factored low-rank approximations to model curvature and derive scalable estimates of predictive uncertainty and marginal likelihood. Experiments on common-sense reasoning benchmarks with Qwen1.5-MoE and DeepSeek-MoE demonstrate that Bayesian-MoE improves both expected calibration error (ECE) and negative log-likelihood (NLL) over baselines, confirming its effectiveness for reliable downstream decision-making.",
    "authors": [
      "Maryam Dialameh",
      "Hossein Rajabzadeh",
      "Weiwei Zhang",
      "Walid Ahmed",
      "Hyock Ju Kwon"
    ],
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08968v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08968v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2511.08379v1",
    "title": "SOM Directions are Better than One: Multi-Directional Refusal Suppression in Language Models",
    "summary": "Refusal refers to the functional behavior enabling safety-aligned language models to reject harmful or unethical prompts. Following the growing scientific interest in mechanistic interpretability, recent work encoded refusal behavior as a single direction in the model's latent space; e.g., computed as the difference between the centroids of harmful and harmless prompt representations. However, emerging evidence suggests that concepts in LLMs often appear to be encoded as a low-dimensional manifold embedded in the high-dimensional latent space. Motivated by these findings, we propose a novel method leveraging Self-Organizing Maps (SOMs) to extract multiple refusal directions. To this end, we first prove that SOMs generalize the prior work's difference-in-means technique. We then train SOMs on harmful prompt representations to identify multiple neurons. By subtracting the centroid of harmless representations from each neuron, we derive a set of multiple directions expressing the refusal concept. We validate our method on an extensive experimental setup, demonstrating that ablating multiple directions from models' internals outperforms not only the single-direction baseline but also specialized jailbreak algorithms, leading to an effective suppression of refusal. Finally, we conclude by analyzing the mechanistic implications of our approach.",
    "authors": [
      "Giorgio Piras",
      "Raffaele Mura",
      "Fabio Brau",
      "Luca Oneto",
      "Fabio Roli",
      "Battista Biggio"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08379v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08379v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2511.08864v1",
    "title": "Transformer-Based Sleep Stage Classification Enhanced by Clinical Information",
    "summary": "Manual sleep staging from polysomnography (PSG) is labor-intensive and prone to inter-scorer variability. While recent deep learning models have advanced automated staging, most rely solely on raw PSG signals and neglect contextual cues used by human experts. We propose a two-stage architecture that combines a Transformer-based per-epoch encoder with a 1D CNN aggregator, and systematically investigates the effect of incorporating explicit context: subject-level clinical metadata (age, sex, BMI) and per-epoch expert event annotations (apneas, desaturations, arousals, periodic breathing). Using the Sleep Heart Health Study (SHHS) cohort (n=8,357), we demonstrate that contextual fusion substantially improves staging accuracy. Compared to a PSG-only baseline (macro-F1 0.7745, micro-F1 0.8774), our final model achieves macro-F1 0.8031 and micro-F1 0.9051, with event annotations contributing the largest gains. Notably, feature fusion outperforms multi-task alternatives that predict the same auxiliary labels. These results highlight that augmenting learned representations with clinically meaningful features enhances both performance and interpretability, without modifying the PSG montage or requiring additional sensors. Our findings support a practical and scalable path toward context-aware, expert-aligned sleep staging systems.",
    "authors": [
      "Woosuk Chung",
      "Seokwoo Hong",
      "Wonhyeok Lee",
      "Sangyoon Bae"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08864v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08864v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2511.08945v1",
    "title": "FGM-HD: Boosting Generation Diversity of Fractal Generative Models through Hausdorff Dimension Induction",
    "summary": "Improving the diversity of generated results while maintaining high visual quality remains a significant challenge in image generation tasks. Fractal Generative Models (FGMs) are efficient in generating high-quality images, but their inherent self-similarity limits the diversity of output images. To address this issue, we propose a novel approach based on the Hausdorff Dimension (HD), a widely recognized concept in fractal geometry used to quantify structural complexity, which aids in enhancing the diversity of generated outputs. To incorporate HD into FGM, we propose a learnable HD estimation method that predicts HD directly from image embeddings, addressing computational cost concerns. However, simply introducing HD into a hybrid loss is insufficient to enhance diversity in FGMs due to: 1) degradation of image quality, and 2) limited improvement in generation diversity. To this end, during training, we adopt an HD-based loss with a monotonic momentum-driven scheduling strategy to progressively optimize the hyperparameters, obtaining optimal diversity without sacrificing visual quality. Moreover, during inference, we employ HD-guided rejection sampling to select geometrically richer outputs. Extensive experiments on the ImageNet dataset demonstrate that our FGM-HD framework yields a 39\\% improvement in output diversity compared to vanilla FGMs, while preserving comparable image quality. To our knowledge, this is the very first work introducing HD into FGM. Our method effectively enhances the diversity of generated outputs while offering a principled theoretical contribution to FGM development.",
    "authors": [
      "Haowei Zhang",
      "Yuanpei Zhao",
      "Jizhe Zhou",
      "Mao Li"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08945v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08945v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2511.08344v2",
    "title": "SASG-DA: Sparse-Aware Semantic-Guided Diffusion Augmentation For Myoelectric Gesture Recognition",
    "summary": "Surface electromyography (sEMG)-based gesture recognition plays a critical role in human-machine interaction (HMI), particularly for rehabilitation and prosthetic control. However, sEMG-based systems often suffer from the scarcity of informative training data, leading to overfitting and poor generalization in deep learning models. Data augmentation offers a promising approach to increasing the size and diversity of training data, where faithfulness and diversity are two critical factors to effectiveness. However, promoting untargeted diversity can result in redundant samples with limited utility. To address these challenges, we propose a novel diffusion-based data augmentation approach, Sparse-Aware Semantic-Guided Diffusion Augmentation (SASG-DA). To enhance generation faithfulness, we introduce the Semantic Representation Guidance (SRG) mechanism by leveraging fine-grained, task-aware semantic representations as generation conditions. To enable flexible and diverse sample generation, we propose a Gaussian Modeling Semantic Sampling (GMSS) strategy, which models the semantic representation distribution and allows stochastic sampling to produce both faithful and diverse samples. To enhance targeted diversity, we further introduce a Sparse-Aware Semantic Sampling (SASS) strategy to explicitly explore underrepresented regions, improving distribution coverage and sample utility. Extensive experiments on benchmark sEMG datasets, Ninapro DB2, DB4, and DB7, demonstrate that SASG-DA significantly outperforms existing augmentation methods. Overall, our proposed data augmentation approach effectively mitigates overfitting and improves recognition performance and generalization by offering both faithful and diverse samples.",
    "authors": [
      "Chen Liu",
      "Can Han",
      "Weishi Xu",
      "Yaqi Wang",
      "Dahong Qian"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08344v2",
    "pdf_url": "https://arxiv.org/pdf/2511.08344v2.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2511.08896v1",
    "title": "Classifying Histopathologic Glioblastoma Sub-regions with EfficientNet",
    "summary": "Glioblastoma (GBM) is the most common aggressive, fast-growing brain tumor, with a grim prognosis. Despite clinical diagnostic advancements, there have not been any substantial improvements to patient prognosis. Histopathological assessment of excised tumors is the first line of clinical diagnostic routine. We hypothesize that automated, robust, and accurate identification of distinct histological sub-regions within GBM could contribute to morphologically understanding this disease at scale. In this study, we designed a four-step deep learning approach to classify six (6) histopathological regions and quantitatively evaluated it on the BraTS-Path 2024 challenge dataset, which includes digitized Hematoxylin \\& Eosin (H\\&E) stained GBM tissue sections annotated for six distinct regions. We used the challenge's publicly available training dataset to develop and evaluate the effectiveness of several variants of EfficientNet architectures (i.e., B0, B1, B2, B3, B4). EfficientNet-B1 and EfficientNet-B4 achieved the best performance, achieving an F1 score of 0.98 in a 5-fold cross-validation configuration using the BraTS-Path training set. The quantitative performance evaluation of our proposed approach with EfficientNet-B1 on the BraTS-Path hold-out validation data and the final hidden testing data yielded F1 scores of 0.546 and 0.517, respectively, for the associated 6-class classification task. The difference in the performance on training, validation, and testing data highlights the challenge of developing models that generalize well to new data, which is crucial for clinical applications. The source code of the proposed approach can be found at the GitHub repository of Indiana University Division of Computational Pathology: https://github.com/IUCompPath/brats-path-2024-enet.",
    "authors": [
      "Sanyukta Adap",
      "Ujjwal Baid",
      "Spyridon Bakas"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08896v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08896v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.08567v1",
    "title": "The Path Not Taken: RLVR Provably Learns Off the Principals",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) reliably improves the reasoning performance of large language models, yet it appears to modify only a small fraction of parameters. We revisit this paradox and show that sparsity is a surface artifact of a model-conditioned optimization bias: for a fixed pretrained model, updates consistently localize to preferred parameter regions, highly consistent across runs and largely invariant to datasets and RL recipes. We mechanistically explain these dynamics with a Three-Gate Theory: Gate I (KL Anchor) imposes a KL-constrained update; Gate II (Model Geometry) steers the step off principal directions into low-curvature, spectrum-preserving subspaces; and Gate III (Precision) hides micro-updates in non-preferred regions, making the off-principal bias appear as sparsity. We then validate this theory and, for the first time, provide a parameter-level characterization of RLVR's learning dynamics: RLVR learns off principal directions in weight space, achieving gains via minimal spectral drift, reduced principal-subspace rotation, and off-principal update alignment. In contrast, SFT targets principal weights, distorts the spectrum, and even lags RLVR.   Together, these results provide the first parameter-space account of RLVR's training dynamics, revealing clear regularities in how parameters evolve. Crucially, we show that RL operates in a distinct optimization regime from SFT, so directly adapting SFT-era parameter-efficient fine-tuning (PEFT) methods can be flawed, as evidenced by our case studies on advanced sparse fine-tuning and LoRA variants. We hope this work charts a path toward a white-box understanding of RLVR and the design of geometry-aware, RLVR-native learning algorithms, rather than repurposed SFT-era heuristics.",
    "authors": [
      "Hanqing Zhu",
      "Zhenyu Zhang",
      "Hanxian Huang",
      "DiJia Su",
      "Zechun Liu",
      "Jiawei Zhao",
      "Igor Fedorov",
      "Hamed Pirsiavash",
      "Zhizhou Sha",
      "Jinwon Lee",
      "David Z. Pan",
      "Zhangyang Wang",
      "Yuandong Tian",
      "Kai Sheng Tai"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08567v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08567v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.07831v1",
    "title": "Distributionally Robust Online Markov Game with Linear Function Approximation",
    "summary": "The sim-to-real gap, where agents trained in a simulator face significant performance degradation during testing, is a fundamental challenge in reinforcement learning. Extansive works adopt the framework of distributionally robust RL, to learn a policy that acts robustly under worst case environment shift. Within this framework, our objective is to devise algorithms that are sample efficient with interactive data collection and large state spaces. By assuming d-rectangularity of environment dynamic shift, we identify a fundamental hardness result for learning in online Markov game, and address it by adopting minimum value assumption. Then, a novel least square value iteration type algorithm, DR-CCE-LSI, with exploration bonus devised specifically for multiple agents, is proposed to find an \\episilon-approximate robust Coarse Correlated Equilibrium(CCE). To obtain sample efficient learning, we find that: when the feature mapping function satisfies certain properties, our algorithm, DR-CCE-LSI, is able to achieve ε-approximate CCE with a regret bound of O{dHmin{H,1/min{σ_i}}\\sqrt{K}}, where K is the number of interacting episodes, H is the horizon length, d is the feature dimension, and \\simga_i represents the uncertainty level of player i. Our work introduces the first sample-efficient algorithm for this setting, matches the best result so far in single agent setting, and achieves minimax optimalsample complexity in terms of the feature dimension d. Meanwhile, we also conduct simulation study to validate the efficacy of our algorithm in learning a robust equilibrium.",
    "authors": [
      "Zewu Zheng",
      "Yuanyuan Lin"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07831v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07831v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2511.08394v1",
    "title": "Interaction Dynamics as a Reward Signal for LLMs",
    "summary": "The alignment of Large Language Models (LLMs) for multi-turn conversations typically relies on reward signals derived from the content of the text. This approach, however, overlooks a rich, complementary source of signal: the dynamics of the interaction itself. This paper introduces TRACE (Trajectory-based Reward for Agent Collaboration Estimation), a novel reward signal derived from the geometric properties of a dialogue's embedding trajectory--a concept we term 'conversational geometry'. Our central finding is that a reward model trained only on these structural signals achieves a pairwise accuracy (68.20%) comparable to a powerful LLM baseline that analyzes the full transcript (70.04%). Furthermore, a hybrid model combining interaction dynamics with textual analysis achieves the highest performance (80.17%), demonstrating their complementary nature. This work provides strong evidence that for interactive settings, how an agent communicates is as powerful a predictor of success as what it says, offering a new, privacy-preserving framework that not only aligns agents but also serves as a diagnostic tool for understanding the distinct interaction patterns that drive successful collaboration.",
    "authors": [
      "Sian Gooding",
      "Edward Grefenstette"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08394v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08394v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07923v1",
    "title": "Exploring the Underwater World Segmentation without Extra Training",
    "summary": "Accurate segmentation of marine organisms is vital for biodiversity monitoring and ecological assessment, yet existing datasets and models remain largely limited to terrestrial scenes. To bridge this gap, we introduce \\textbf{AquaOV255}, the first large-scale and fine-grained underwater segmentation dataset containing 255 categories and over 20K images, covering diverse categories for open-vocabulary (OV) evaluation. Furthermore, we establish the first underwater OV segmentation benchmark, \\textbf{UOVSBench}, by integrating AquaOV255 with five additional underwater datasets to enable comprehensive evaluation. Alongside, we present \\textbf{Earth2Ocean}, a training-free OV segmentation framework that transfers terrestrial vision--language models (VLMs) to underwater domains without any additional underwater training. Earth2Ocean consists of two core components: a Geometric-guided Visual Mask Generator (\\textbf{GMG}) that refines visual features via self-similarity geometric priors for local structure perception, and a Category-visual Semantic Alignment (\\textbf{CSA}) module that enhances text embeddings through multimodal large language model reasoning and scene-aware template construction. Extensive experiments on the UOVSBench benchmark demonstrate that Earth2Ocean achieves significant performance improvement on average while maintaining efficient inference.",
    "authors": [
      "Bingyu Li",
      "Tao Huo",
      "Da Zhang",
      "Zhiyuan Zhao",
      "Junyu Gao",
      "Xuelong Li"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07923v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07923v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.08061v1",
    "title": "Taming Identity Consistency and Prompt Diversity in Diffusion Models via Latent Concatenation and Masked Conditional Flow Matching",
    "summary": "Subject-driven image generation aims to synthesize novel depictions of a specific subject across diverse contexts while preserving its core identity features. Achieving both strong identity consistency and high prompt diversity presents a fundamental trade-off. We propose a LoRA fine-tuned diffusion model employing a latent concatenation strategy, which jointly processes reference and target images, combined with a masked Conditional Flow Matching (CFM) objective. This approach enables robust identity preservation without architectural modifications. To facilitate large-scale training, we introduce a two-stage Distilled Data Curation Framework: the first stage leverages data restoration and VLM-based filtering to create a compact, high-quality seed dataset from diverse sources; the second stage utilizes these curated examples for parameter-efficient fine-tuning, thus scaling the generation capability across various subjects and contexts. Finally, for filtering and quality assessment, we present CHARIS, a fine-grained evaluation framework that performs attribute-level comparisons along five key axes: identity consistency, prompt adherence, region-wise color fidelity, visual quality, and transformation diversity.",
    "authors": [
      "Aditi Singhania",
      "Arushi Jain",
      "Krutik Malani",
      "Riddhi Dhawan",
      "Souymodip Chakraborty",
      "Vineet Batra",
      "Ankit Phogat"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08061v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08061v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.09443v1",
    "title": "BronchOpt : Vision-Based Pose Optimization with Fine-Tuned Foundation Models for Accurate Bronchoscopy Navigation",
    "summary": "Accurate intra-operative localization of the bronchoscope tip relative to patient anatomy remains challenging due to respiratory motion, anatomical variability, and CT-to-body divergence that cause deformation and misalignment between intra-operative views and pre-operative CT. Existing vision-based methods often fail to generalize across domains and patients, leading to residual alignment errors. This work establishes a generalizable foundation for bronchoscopy navigation through a robust vision-based framework and a new synthetic benchmark dataset that enables standardized and reproducible evaluation. We propose a vision-based pose optimization framework for frame-wise 2D-3D registration between intra-operative endoscopic views and pre-operative CT anatomy. A fine-tuned modality- and domain-invariant encoder enables direct similarity computation between real endoscopic RGB frames and CT-rendered depth maps, while a differentiable rendering module iteratively refines camera poses through depth consistency. To enhance reproducibility, we introduce the first public synthetic benchmark dataset for bronchoscopy navigation, addressing the lack of paired CT-endoscopy data. Trained exclusively on synthetic data distinct from the benchmark, our model achieves an average translational error of 2.65 mm and a rotational error of 0.19 rad, demonstrating accurate and stable localization. Qualitative results on real patient data further confirm strong cross-domain generalization, achieving consistent frame-wise 2D-3D alignment without domain-specific adaptation. Overall, the proposed framework achieves robust, domain-invariant localization through iterative vision-based optimization, while the new benchmark provides a foundation for standardized progress in vision-based bronchoscopy navigation.",
    "authors": [
      "Hongchao Shu",
      "Roger D. Soberanis-Mukul",
      "Jiru Xu",
      "Hao Ding",
      "Morgan Ringel",
      "Mali Shen",
      "Saif Iftekar Sayed",
      "Hedyeh Rafii-Tari",
      "Mathias Unberath"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09443v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09443v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.08224v1",
    "title": "2D Representation for Unguided Single-View 3D Super-Resolution in Real-Time",
    "summary": "We introduce 2Dto3D-SR, a versatile framework for real-time single-view 3D super-resolution that eliminates the need for high-resolution RGB guidance. Our framework encodes 3D data from a single viewpoint into a structured 2D representation, enabling the direct application of existing 2D image super-resolution architectures. We utilize the Projected Normalized Coordinate Code (PNCC) to represent 3D geometry from a visible surface as a regular image, thereby circumventing the complexities of 3D point-based or RGB-guided methods. This design supports lightweight and fast models adaptable to various deployment environments. We evaluate 2Dto3D-SR with two implementations: one using Swin Transformers for high accuracy, and another using Vision Mamba for high efficiency. Experiments show the Swin Transformer model achieves state-of-the-art accuracy on standard benchmarks, while the Vision Mamba model delivers competitive results at real-time speeds. This establishes our geometry-guided pipeline as a surprisingly simple yet viable and practical solution for real-world scenarios, especially where high-resolution RGB data is inaccessible.",
    "authors": [
      "Ignasi Mas",
      "Ivan Huerta",
      "Ramon Morros",
      "Javier Ruiz-Hidalgo"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08224v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08224v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.08923v1",
    "title": "TiDAR: Think in Diffusion, Talk in Autoregression",
    "summary": "Diffusion language models hold the promise of fast parallel generation, while autoregressive (AR) models typically excel in quality due to their causal structure aligning naturally with language modeling. This raises a fundamental question: can we achieve a synergy with high throughput, higher GPU utilization, and AR level quality? Existing methods fail to effectively balance these two aspects, either prioritizing AR using a weaker model for sequential drafting (speculative decoding), leading to lower drafting efficiency, or using some form of left-to-right (AR-like) decoding logic for diffusion, which still suffers from quality degradation and forfeits its potential parallelizability. We introduce TiDAR, a sequence-level hybrid architecture that drafts tokens (Thinking) in Diffusion and samples final outputs (Talking) AutoRegressively - all within a single forward pass using specially designed structured attention masks. This design exploits the free GPU compute density, achieving a strong balance between drafting and verification capacity. Moreover, TiDAR is designed to be serving-friendly (low overhead) as a standalone model. We extensively evaluate TiDAR against AR models, speculative decoding, and diffusion variants across generative and likelihood tasks at 1.5B and 8B scales. Thanks to the parallel drafting and sampling as well as exact KV cache support, TiDAR outperforms speculative decoding in measured throughput and surpasses diffusion models like Dream and Llada in both efficiency and quality. Most notably, TiDAR is the first architecture to close the quality gap with AR models while delivering 4.71x to 5.91x more tokens per second.",
    "authors": [
      "Jingyu Liu",
      "Xin Dong",
      "Zhifan Ye",
      "Rishabh Mehta",
      "Yonggan Fu",
      "Vartika Singh",
      "Jan Kautz",
      "Ce Zhang",
      "Pavlo Molchanov"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08923v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08923v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.07904v1",
    "title": "Test-driven Reinforcement Learning",
    "summary": "Reinforcement learning (RL) has been recognized as a powerful tool for robot control tasks. RL typically employs reward functions to define task objectives and guide agent learning. However, since the reward function serves the dual purpose of defining the optimal goal and guiding learning, it is challenging to design the reward function manually, which often results in a suboptimal task representation. To tackle the reward design challenge in RL, inspired by the satisficing theory, we propose a Test-driven Reinforcement Learning (TdRL) framework. In the TdRL framework, multiple test functions are used to represent the task objective rather than a single reward function. Test functions can be categorized as pass-fail tests and indicative tests, each dedicated to defining the optimal objective and guiding the learning process, respectively, thereby making defining tasks easier. Building upon such a task definition, we first prove that if a trajectory return function assigns higher returns to trajectories closer to the optimal trajectory set, maximum entropy policy optimization based on this return function will yield a policy that is closer to the optimal policy set. Then, we introduce a lexicographic heuristic approach to compare the relative distance relationship between trajectories and the optimal trajectory set for learning the trajectory return function. Furthermore, we develop an algorithm implementation of TdRL. Experimental results on the DeepMind Control Suite benchmark demonstrate that TdRL matches or outperforms handcrafted reward methods in policy training, with greater design simplicity and inherent support for multi-objective optimization. We argue that TdRL offers a novel perspective for representing task objectives, which could be helpful in addressing the reward design challenges in RL applications.",
    "authors": [
      "Zhao Yu",
      "Xiuping Wu",
      "Liangjun Ke"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07904v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07904v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.08242v1",
    "title": "Towards Outcome-Oriented, Task-Agnostic Evaluation of AI Agents",
    "summary": "As AI agents proliferate across industries and applications, evaluating their performance based solely on infrastructural metrics such as latency, time-to-first-token, or token throughput is proving insufficient. These metrics fail to capture the quality of an agent's decisions, its operational autonomy, or its ultimate business value. This white paper proposes a novel, comprehensive framework of eleven outcome-based, task-agnostic performance metrics for AI agents that transcend domain boundaries. These metrics are designed to enable organizations to evaluate agents based on the quality of their decisions, their degree of autonomy, their adaptability to new challenges, and the tangible business value they deliver, regardless of the underlying model architecture or specific use case. We introduce metrics such as Goal Completion Rate (GCR), Autonomy Index (AIx), Multi-Step Task Resilience (MTR), and Business Impact Efficiency (BIE). Through a large-scale simulated experiment involving four distinct agent architectures (ReAct, Chain-of-Thought, Tool-Augmented, Hybrid) across five diverse domains (Healthcare, Finance, Marketing, Legal, and Customer Service), we demonstrate the framework's efficacy. Our results reveal significant performance trade-offs between different agent designs, highlighting the Hybrid Agent as the most consistently high-performing model across the majority of our proposed metrics, achieving an average Goal Completion Rate of 88.8\\% and the highest Return on Investment (ROI). This work provides a robust, standardized methodology for the holistic evaluation of AI agents, paving the way for more effective development, deployment, and governance.",
    "authors": [
      "Waseem AlShikh",
      "Muayad Sayed Ali",
      "Brian Kennedy",
      "Dmytro Mozolevskyi"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08242v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08242v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.08152v1",
    "title": "Boomda: Balanced Multi-objective Optimization for Multimodal Domain Adaptation",
    "summary": "Multimodal learning, while contributing to numerous success stories across various fields, faces the challenge of prohibitively expensive manual annotation. To address the scarcity of annotated data, a popular solution is unsupervised domain adaptation, which has been extensively studied in unimodal settings yet remains less explored in multimodal settings. In this paper, we investigate heterogeneous multimodal domain adaptation, where the primary challenge is the varying domain shifts of different modalities from the source to the target domain. We first introduce the information bottleneck method to learn representations for each modality independently, and then match the source and target domains in the representation space with correlation alignment. To balance the domain alignment of all modalities, we formulate the problem as a multi-objective task, aiming for a Pareto optimal solution. By exploiting the properties specific to our model, the problem can be simplified to a quadratic programming problem. Further approximation yields a closed-form solution, leading to an efficient modality-balanced multimodal domain adaptation algorithm. The proposed method features \\textbf{B}alanced multi-\\textbf{o}bjective \\textbf{o}ptimization for \\textbf{m}ultimodal \\textbf{d}omain \\textbf{a}daptation, termed \\textbf{Boomda}. Extensive empirical results showcase the effectiveness of the proposed approach and demonstrate that Boomda outperforms the competing schemes. The code is is available at: https://github.com/sunjunaimer/Boomda.git.",
    "authors": [
      "Jun Sun",
      "Xinxin Zhang",
      "Simin Hong",
      "Jian Zhu",
      "Xiang Gao"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08152v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08152v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.08245v1",
    "title": "Prompt Tuning for Natural Language to SQL with Embedding Fine-Tuning and RAG",
    "summary": "This paper introduces an Error Correction through Prompt Tuning for NL-to-SQL, leveraging the latest advancements in generative pre-training-based LLMs and RAG. Our work addresses the crucial need for efficient and accurate translation of natural language queries into SQL expressions in various settings with the growing use of natural language interfaces. We explore the evolution of NLIDBs from early rule-based systems to advanced neural network-driven approaches. Drawing inspiration from the medical diagnostic process, we propose a novel framework integrating an error correction mechanism that diagnoses error types, identifies their causes, provides fixing instructions, and applies these corrections to SQL queries. This approach is further enriched by embedding fine-tuning and RAG, which harnesses external knowledge bases for improved accuracy and transparency. Through comprehensive experiments, we demonstrate that our framework achieves a significant 12 percent accuracy improvement over existing baselines, highlighting its potential to revolutionize data access and handling in contemporary data-driven environments.",
    "authors": [
      "Jisoo Jang",
      "Tien-Cuong Bui",
      "Yunjun Choi",
      "Wen-Syan Li"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08245v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08245v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2511.08653v1",
    "title": "Accelerating Training Speed of Tiny Recursive Models via Curriculum Guided Adaptive Recursion",
    "summary": "Recursive reasoning models achieve remarkable performance on complex reasoning tasks through iterative refinement, enabling tiny networks to match large language models thousands of times their size. However, training remains computationally expensive, prior work reporting approximately 36 GPU-hours per dataset, limiting broader adoption and research. We propose CGAR, a novel training methodology that applies curriculum learning to architectural depth rather than traditional data ordering. CGAR introduces two synergistic components: Progressive Depth Curriculum dynamically adjusts recursion depth from shallow to deep configurations during training, preventing early overfitting while reducing computational cost, and Hierarchical Supervision Weighting applies exponentially decaying importance to supervision steps, aligning loss weighting with observed gradient magnitude decay. On Sudoku-Extreme with 423,168 test puzzles, CGAR achieves 1.71x training speedup (10.93 to 6.38 hours, 42% cost reduction) with only 0.63% accuracy drop (86.65% to 86.02%). Systematic ablations reveal Progressive Depth Curriculum alone achieves 2.26x speedup with 85.47% accuracy, demonstrating a rare Pareto improvement where architectural curriculum simultaneously enhances training efficiency and solution quality. CGAR-trained models exhibit superior inference efficiency with 100% halting accuracy and 11% fewer reasoning steps. Our work demonstrates that principled curriculum on architectural depth enables efficient training of recursive reasoning models on modest hardware. Code and models: https://github.com/Kaleemullahqasim/CGAR and https://huggingface.co/Kaleemullah/trm-cgar-sudoku",
    "authors": [
      "Kaleem Ullah Qasim",
      "Jiashu Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.NE"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08653v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08653v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.08238v1",
    "title": "Remodeling Semantic Relationships in Vision-Language Fine-Tuning",
    "summary": "Vision-language fine-tuning has emerged as an efficient paradigm for constructing multimodal foundation models. While textual context often highlights semantic relationships within an image, existing fine-tuning methods typically overlook this information when aligning vision and language, thus leading to suboptimal performance. Toward solving this problem, we propose a method that can improve multimodal alignment and fusion based on both semantics and relationships.Specifically, we first extract multilevel semantic features from different vision encoder to capture more visual cues of the relationships. Then, we learn to project the vision features to group related semantics, among which are more likely to have relationships. Finally, we fuse the visual features with the textual by using inheritable cross-attention, where we globally remove the redundant visual relationships by discarding visual-language feature pairs with low correlation. We evaluate our proposed method on eight foundation models and two downstream tasks, visual question answering and image captioning, and show that it outperforms all existing methods.",
    "authors": [
      "Xiangyang Wu",
      "Liu Liu",
      "Baosheng Yu",
      "Jiayan Qiu",
      "Zhenwei Shi"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08238v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08238v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.08904v1",
    "title": "Consistency Change Detection Framework for Unsupervised Remote Sensing Change Detection",
    "summary": "Unsupervised remote sensing change detection aims to monitor and analyze changes from multi-temporal remote sensing images in the same geometric region at different times, without the need for labeled training data. Previous unsupervised methods attempt to achieve style transfer across multi-temporal remote sensing images through reconstruction by a generator network, and then capture the unreconstructable areas as the changed regions. However, it often leads to poor performance due to generator overfitting. In this paper, we propose a novel Consistency Change Detection Framework (CCDF) to address this challenge. Specifically, we introduce a Cycle Consistency (CC) module to reduce the overfitting issues in the generator-based reconstruction. Additionally, we propose a Semantic Consistency (SC) module to enable detail reconstruction. Extensive experiments demonstrate that our method outperforms other state-of-the-art approaches.",
    "authors": [
      "Yating Liu",
      "Yan Lu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08904v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08904v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.09374v1",
    "title": "MTQ-Eval: Multilingual Text Quality Evaluation for Language Models",
    "summary": "The use of large language models (LLMs) for evaluating outputs is becoming an increasingly effective and scalable approach. However, it remains uncertain whether this capability extends beyond task-specific evaluations to more general assessments of text quality, particularly in multilingual contexts. In this study, we introduce, MTQ-Eval, a novel framework for multilingual text quality evaluation that learns from examples of both high- and low-quality texts, adjusting its internal representations. To develop MTQ-Eval, we first automatically generate text quality preference data and then use it to train open-source base LLMs to align with ratings of high- and low-quality text. Our comprehensive evaluation across 115 languages demonstrates the improved performance of the proposed model. Upon further analysis, we find that this enhanced evaluation capability also leads to notable improvements in downstream tasks.",
    "authors": [
      "Rhitabrat Pokharel",
      "Ameeta Agrawal"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09374v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09374v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2511.07755v1",
    "title": "Filtered-ViT: A Robust Defense Against Multiple Adversarial Patch Attacks",
    "summary": "Deep learning vision systems are increasingly deployed in safety-critical domains such as healthcare, yet they remain vulnerable to small adversarial patches that can trigger misclassifications. Most existing defenses assume a single patch and fail when multiple localized disruptions occur, the type of scenario adversaries and real-world artifacts often exploit. We propose Filtered-ViT, a new vision transformer architecture that integrates SMART Vector Median Filtering (SMART-VMF), a spatially adaptive, multi-scale, robustness-aware mechanism that enables selective suppression of corrupted regions while preserving semantic detail. On ImageNet with LaVAN multi-patch attacks, Filtered-ViT achieves 79.8% clean accuracy and 46.3% robust accuracy under four simultaneous 1\\% patches, outperforming existing defenses. Beyond synthetic benchmarks, a real-world case study on radiographic medical imagery shows that Filtered-ViT mitigates natural artifacts such as occlusions and scanner noise without degrading diagnostic content. This establishes Filtered-ViT as the first transformer to demonstrate unified robustness against both adversarial and naturally occurring patch-like disruptions, charting a path toward reliable vision systems in truly high-stakes environments.",
    "authors": [
      "Aja Khanal",
      "Ahmed Faid",
      "Apurva Narayan"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07755v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07755v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07748v1",
    "title": "Auto-US: An Ultrasound Video Diagnosis Agent Using Video Classification Framework and LLMs",
    "summary": "AI-assisted ultrasound video diagnosis presents new opportunities to enhance the efficiency and accuracy of medical imaging analysis. However, existing research remains limited in terms of dataset diversity, diagnostic performance, and clinical applicability. In this study, we propose \\textbf{Auto-US}, an intelligent diagnosis agent that integrates ultrasound video data with clinical diagnostic text. To support this, we constructed \\textbf{CUV Dataset} of 495 ultrasound videos spanning five categories and three organs, aggregated from multiple open-access sources. We developed \\textbf{CTU-Net}, which achieves state-of-the-art performance in ultrasound video classification, reaching an accuracy of 86.73\\% Furthermore, by incorporating large language models, Auto-US is capable of generating clinically meaningful diagnostic suggestions. The final diagnostic scores for each case exceeded 3 out of 5 and were validated by professional clinicians. These results demonstrate the effectiveness and clinical potential of Auto-US in real-world ultrasound applications. Code and data are available at: https://github.com/Bean-Young/Auto-US.",
    "authors": [
      "Yuezhe Yang",
      "Yiyue Guo",
      "Wenjie Cai",
      "Qingqing Ruan",
      "Siying Wang",
      "Xingbo Dong",
      "Zhe Jin",
      "Yong Dai"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07748v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07748v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07743v1",
    "title": "UltraGS: Gaussian Splatting for Ultrasound Novel View Synthesis",
    "summary": "Ultrasound imaging is a cornerstone of non-invasive clinical diagnostics, yet its limited field of view complicates novel view synthesis. We propose \\textbf{UltraGS}, a Gaussian Splatting framework optimized for ultrasound imaging. First, we introduce a depth-aware Gaussian splatting strategy, where each Gaussian is assigned a learnable field of view, enabling accurate depth prediction and precise structural representation. Second, we design SH-DARS, a lightweight rendering function combining low-order spherical harmonics with ultrasound-specific wave physics, including depth attenuation, reflection, and scattering, to model tissue intensity accurately. Third, we contribute the Clinical Ultrasound Examination Dataset, a benchmark capturing diverse anatomical scans under real-world clinical protocols. Extensive experiments on three datasets demonstrate UltraGS's superiority, achieving state-of-the-art results in PSNR (up to 29.55), SSIM (up to 0.89), and MSE (as low as 0.002) while enabling real-time synthesis at 64.69 fps. The code and dataset are open-sourced at: https://github.com/Bean-Young/UltraGS.",
    "authors": [
      "Yuezhe Yang",
      "Wenjie Cai",
      "Dexin Yang",
      "Yufang Dong",
      "Xingbo Dong",
      "Zhe Jin"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07743v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07743v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.08090v1",
    "title": "StableMorph: High-Quality Face Morph Generation with Stable Diffusion",
    "summary": "Face morphing attacks threaten the integrity of biometric identity systems by enabling multiple individuals to share a single identity. To develop and evaluate effective morphing attack detection (MAD) systems, we need access to high-quality, realistic morphed images that reflect the challenges posed in real-world scenarios. However, existing morph generation methods often produce images that are blurry, riddled with artifacts, or poorly constructed making them easy to detect and not representative of the most dangerous attacks. In this work, we introduce StableMorph, a novel approach that generates highly realistic, artifact-free morphed face images using modern diffusion-based image synthesis. Unlike prior methods, StableMorph produces full-head images with sharp details, avoids common visual flaws, and offers unmatched control over visual attributes. Through extensive evaluation, we show that StableMorph images not only rival or exceed the quality of genuine face images but also maintain a strong ability to fool face recognition systems posing a greater challenge to existing MAD solutions and setting a new standard for morph quality in research and operational testing. StableMorph improves the evaluation of biometric security by creating more realistic and effective attacks and supports the development of more robust detection systems.",
    "authors": [
      "Wassim Kabbani",
      "Kiran Raja",
      "Raghavendra Ramachandra",
      "Christoph Busch"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08090v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08090v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.08143v1",
    "title": "Relation as a Prior: A Novel Paradigm for LLM-based Document-level Relation Extraction",
    "summary": "Large Language Models (LLMs) have demonstrated their remarkable capabilities in document understanding. However, recent research reveals that LLMs still exhibit performance gaps in Document-level Relation Extraction (DocRE) as requiring fine-grained comprehension. The commonly adopted \"extract entities then predict relations\" paradigm in LLM-based methods leads to these gaps due to two main reasons: (1) Numerous unrelated entity pairs introduce noise and interfere with the relation prediction for truly related entity pairs. (2) Although LLMs have identified semantic associations between entities, relation labels beyond the predefined set are still treated as prediction errors. To address these challenges, we propose a novel Relation as a Prior (RelPrior) paradigm for LLM-based DocRE. For challenge (1), RelPrior utilizes binary relation as a prior to extract and determine whether two entities are correlated, thereby filtering out irrelevant entity pairs and reducing prediction noise. For challenge (2), RelPrior utilizes predefined relation as a prior to match entities for triples extraction instead of directly predicting relation. Thus, it avoids misjudgment caused by strict predefined relation labeling. Extensive experiments on two benchmarks demonstrate that RelPrior achieves state-of-the-art performance, surpassing existing LLM-based methods.",
    "authors": [
      "Qiankun Pi",
      "Yepeng Sun",
      "Jicang Lu",
      "Qinlong Fan",
      "Ningbo Huang",
      "Shiyu Wang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08143v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08143v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.08853v1",
    "title": "Rethinking Graph Super-resolution: Dual Frameworks for Topological Fidelity",
    "summary": "Graph super-resolution, the task of inferring high-resolution (HR) graphs from low-resolution (LR) counterparts, is an underexplored yet crucial research direction that circumvents the need for costly data acquisition. This makes it especially desirable for resource-constrained fields such as the medical domain. While recent GNN-based approaches show promise, they suffer from two key limitations: (1) matrix-based node super-resolution that disregards graph structure and lacks permutation invariance; and (2) reliance on node representations to infer edge weights, which limits scalability and expressivity. In this work, we propose two GNN-agnostic frameworks to address these issues. First, Bi-SR introduces a bipartite graph connecting LR and HR nodes to enable structure-aware node super-resolution that preserves topology and permutation invariance. Second, DEFEND learns edge representations by mapping HR edges to nodes of a dual graph, allowing edge inference via standard node-based GNNs. We evaluate both frameworks on a real-world brain connectome dataset, where they achieve state-of-the-art performance across seven topological measures. To support generalization, we introduce twelve new simulated datasets that capture diverse topologies and LR-HR relationships. These enable comprehensive benchmarking of graph super-resolution methods.",
    "authors": [
      "Pragya Singh",
      "Islem Rekik"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08853v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08853v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07813v1",
    "title": "Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views",
    "summary": "Recently, large language models (LLMs) have been explored widely for 3D scene understanding. Among them, training-free approaches are gaining attention for their flexibility and generalization over training-based methods. However, they typically struggle with accuracy and efficiency in practical deployment. To address the problems, we propose Sparse3DPR, a novel training-free framework for open-ended scene understanding, which leverages the reasoning capabilities of pre-trained LLMs and requires only sparse-view RGB inputs. Specifically, we introduce a hierarchical plane-enhanced scene graph that supports open vocabulary and adopts dominant planar structures as spatial anchors, which enables clearer reasoning chains and more reliable high-level inferences. Furthermore, we design a task-adaptive subgraph extraction method to filter query-irrelevant information dynamically, reducing contextual noise and improving 3D scene reasoning efficiency and accuracy. Experimental results demonstrate the superiority of Sparse3DPR, which achieves a 28.7% EM@1 improvement and a 78.2% speedup compared with ConceptGraphs on the Space3D-Bench. Moreover, Sparse3DPR obtains comparable performance to training-based methods on ScanQA, with additional real-world experiments confirming its robustness and generalization capability.",
    "authors": [
      "Haida Feng",
      "Hao Wei",
      "Zewen Xu",
      "Haolin Wang",
      "Chade Li",
      "Yihong Wu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07813v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07813v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.08071v1",
    "title": "Radar-APLANC: Unsupervised Radar-based Heartbeat Sensing via Augmented Pseudo-Label and Noise Contrast",
    "summary": "Frequency Modulated Continuous Wave (FMCW) radars can measure subtle chest wall oscillations to enable non-contact heartbeat sensing. However, traditional radar-based heartbeat sensing methods face performance degradation due to noise. Learning-based radar methods achieve better noise robustness but require costly labeled signals for supervised training. To overcome these limitations, we propose the first unsupervised framework for radar-based heartbeat sensing via Augmented Pseudo-Label and Noise Contrast (Radar-APLANC). We propose to use both the heartbeat range and noise range within the radar range matrix to construct the positive and negative samples, respectively, for improved noise robustness. Our Noise-Contrastive Triplet (NCT) loss only utilizes positive samples, negative samples, and pseudo-label signals generated by the traditional radar method, thereby avoiding dependence on expensive ground-truth physiological signals. We further design a pseudo-label augmentation approach featuring adaptive noise-aware label selection to improve pseudo-label signal quality. Extensive experiments on the Equipleth dataset and our collected radar dataset demonstrate that our unsupervised method achieves performance comparable to state-of-the-art supervised methods. Our code, dataset, and supplementary materials can be accessed from https://github.com/RadarHRSensing/Radar-APLANC.",
    "authors": [
      "Ying Wang",
      "Zhaodong Sun",
      "Xu Cheng",
      "Zuxian He",
      "Xiaobai Li"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "eess.SP"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08071v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08071v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07738v1",
    "title": "From Exploration to Exploitation: A Two-Stage Entropy RLVR Approach for Noise-Tolerant MLLM Training",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) for Multimodal Large Language Models (MLLMs) is highly dependent on high-quality labeled data, which is often scarce and prone to substantial annotation noise in real-world scenarios. Existing unsupervised RLVR methods, including pure entropy minimization, can overfit to incorrect labels and limit the crucial reward ranking signal for Group-Relative Policy Optimization (GRPO). To address these challenges and enhance noise tolerance, we propose a novel two-stage, token-level entropy optimization method for RLVR. This approach dynamically guides the model from exploration to exploitation during training. In the initial exploration phase, token-level entropy maximization promotes diverse and stochastic output generation, serving as a strong regularizer that prevents premature convergence to noisy labels and ensures sufficient intra-group variation, which enables more reliable reward gradient estimation in GRPO. As training progresses, the method transitions into the exploitation phase, where token-level entropy minimization encourages the model to produce confident and deterministic outputs, thereby consolidating acquired knowledge and refining prediction accuracy. Empirically, across three MLLM backbones - Qwen2-VL-2B, Qwen2-VL-7B, and Qwen2.5-VL-3B - spanning diverse noise settings and multiple tasks, our phased strategy consistently outperforms prior approaches by unifying and enhancing external, internal, and entropy-based methods, delivering robust and superior performance across the board.",
    "authors": [
      "Donglai Xu",
      "Hongzheng Yang",
      "Yuzhi Zhao",
      "Pingping Zhang",
      "Jinpeng Chen",
      "Wenao Ma",
      "Zhijian Hou",
      "Mengyang Wu",
      "Xiaolei Li",
      "Senkang Hu",
      "Ziyi Guan",
      "Jason Chun Lok Li",
      "Lai Man Po"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07738v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07738v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.08955v1",
    "title": "MicroEvoEval: A Systematic Evaluation Framework for Image-Based Microstructure Evolution Prediction",
    "summary": "Simulating microstructure evolution (MicroEvo) is vital for materials design but demands high numerical accuracy, efficiency, and physical fidelity. Although recent studies on deep learning (DL) offer a promising alternative to traditional solvers, the field lacks standardized benchmarks. Existing studies are flawed due to a lack of comparing specialized MicroEvo DL models with state-of-the-art spatio-temporal architectures, an overemphasis on numerical accuracy over physical fidelity, and a failure to analyze error propagation over time. To address these gaps, we introduce MicroEvoEval, the first comprehensive benchmark for image-based microstructure evolution prediction. We evaluate 14 models, encompassing both domain-specific and general-purpose architectures, across four representative MicroEvo tasks with datasets specifically structured for both short- and long-term assessment. Our multi-faceted evaluation framework goes beyond numerical accuracy and computational cost, incorporating a curated set of structure-preserving metrics to assess physical fidelity. Our extensive evaluations yield several key insights. Notably, we find that modern architectures (e.g., VMamba), not only achieve superior long-term stability and physical fidelity but also operate with an order-of-magnitude greater computational efficiency. The results highlight the necessity of holistic evaluation and identify these modern architectures as a highly promising direction for developing efficient and reliable surrogate models in data-driven materials science.",
    "authors": [
      "Qinyi Zhang",
      "Duanyu Feng",
      "Ronghui Han",
      "Yangshuai Wang",
      "Hao Wang"
    ],
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08955v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08955v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07982v1",
    "title": "NOTAM-Evolve: A Knowledge-Guided Self-Evolving Optimization Framework with LLMs for NOTAM Interpretation",
    "summary": "Accurate interpretation of Notices to Airmen (NOTAMs) is critical for aviation safety, yet their condensed and cryptic language poses significant challenges to both manual and automated processing. Existing automated systems are typically limited to shallow parsing, failing to extract the actionable intelligence needed for operational decisions. We formalize the complete interpretation task as deep parsing, a dual-reasoning challenge requiring both dynamic knowledge grounding (linking the NOTAM to evolving real-world aeronautical data) and schema-based inference (applying static domain rules to deduce operational status). To tackle this challenge, we propose NOTAM-Evolve, a self-evolving framework that enables a large language model (LLM) to autonomously master complex NOTAM interpretation. Leveraging a knowledge graph-enhanced retrieval module for data grounding, the framework introduces a closed-loop learning process where the LLM progressively improves from its own outputs, minimizing the need for extensive human-annotated reasoning traces. In conjunction with this framework, we introduce a new benchmark dataset of 10,000 expert-annotated NOTAMs. Our experiments demonstrate that NOTAM-Evolve achieves a 30.4% absolute accuracy improvement over the base LLM, establishing a new state of the art on the task of structured NOTAM interpretation.",
    "authors": [
      "Maoqi Liu",
      "Quan Fang",
      "Yuhao Wu",
      "Can Zhao",
      "Yang Yang",
      "Kaiquan Cai"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07982v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07982v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.07734v1",
    "title": "Global Optimization on Graph-Structured Data via Gaussian Processes with Spectral Representations",
    "summary": "Bayesian optimization (BO) is a powerful framework for optimizing expensive black-box objectives, yet extending it to graph-structured domains remains challenging due to the discrete and combinatorial nature of graphs. Existing approaches often rely on either full graph topology-impractical for large or partially observed graphs-or incremental exploration, which can lead to slow convergence. We introduce a scalable framework for global optimization over graphs that employs low-rank spectral representations to build Gaussian process (GP) surrogates from sparse structural observations. The method jointly infers graph structure and node representations through learnable embeddings, enabling efficient global search and principled uncertainty estimation even with limited data. We also provide theoretical analysis establishing conditions for accurate recovery of underlying graph structure under different sampling regimes. Experiments on synthetic and real-world datasets demonstrate that our approach achieves faster convergence and improved optimization performance compared to prior methods.",
    "authors": [
      "Shu Hong",
      "Yongsheng Mei",
      "Mahdi Imani",
      "Tian Lan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI",
      "eess.SP"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07734v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07734v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2511.08500v1",
    "title": "SPEAR-MM: Selective Parameter Evaluation and Restoration via Model Merging for Efficient Financial LLM Adaptation",
    "summary": "Large language models (LLMs) adapted to financial domains often suffer from catastrophic forgetting of general reasoning capabilities essential for customer interactions and complex financial analysis. We introduce Selective Parameter Evaluation and Restoration via Model Merging (SPEAR-MM), a practical framework that preserves critical capabilities while enabling domain adaptation. Our method approximates layer-wise impact on external benchmarks through post-hoc analysis, then selectively freezes or restores transformer layers via spherical interpolation merging. Applied to LLaMA-3.1-8B for financial tasks, SPEAR-MM achieves 91.2% retention of general capabilities versus 69.7% for standard continual pretraining, while maintaining 94% of domain adaptation gains. The approach provides interpretable trade-off control and reduces computational costs by 90% crucial for resource-constrained financial institutions.",
    "authors": [
      "Berkcan Kapusuzoglu",
      "Supriyo Chakraborty",
      "Renkun Ni",
      "Stephen Rawls",
      "Sambit Sahu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "math.SP"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08500v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08500v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.07885v1",
    "title": "Intelligence per Watt: Measuring Intelligence Efficiency of Local AI",
    "summary": "Large language model (LLM) queries are predominantly processed by frontier models in centralized cloud infrastructure. Rapidly growing demand strains this paradigm, and cloud providers struggle to scale infrastructure at pace. Two advances enable us to rethink this paradigm: small LMs (<=20B active parameters) now achieve competitive performance to frontier models on many tasks, and local accelerators (e.g., Apple M4 Max) run these models at interactive latencies. This raises the question: can local inference viably redistribute demand from centralized infrastructure? Answering this requires measuring whether local LMs can accurately answer real-world queries and whether they can do so efficiently enough to be practical on power-constrained devices (i.e., laptops). We propose intelligence per watt (IPW), task accuracy divided by unit of power, as a metric for assessing capability and efficiency of local inference across model-accelerator pairs. We conduct a large-scale empirical study across 20+ state-of-the-art local LMs, 8 accelerators, and a representative subset of LLM traffic: 1M real-world single-turn chat and reasoning queries. For each query, we measure accuracy, energy, latency, and power. Our analysis reveals $3$ findings. First, local LMs can accurately answer 88.7% of single-turn chat and reasoning queries with accuracy varying by domain. Second, from 2023-2025, IPW improved 5.3x and local query coverage rose from 23.2% to 71.3%. Third, local accelerators achieve at least 1.4x lower IPW than cloud accelerators running identical models, revealing significant headroom for optimization. These findings demonstrate that local inference can meaningfully redistribute demand from centralized infrastructure, with IPW serving as the critical metric for tracking this transition. We release our IPW profiling harness for systematic intelligence-per-watt benchmarking.",
    "authors": [
      "Jon Saad-Falcon",
      "Avanika Narayan",
      "Hakki Orhun Akengin",
      "J. Wes Griffin",
      "Herumb Shandilya",
      "Adrian Gamarra Lafuente",
      "Medhya Goel",
      "Rebecca Joseph",
      "Shlok Natarajan",
      "Etash Kumar Guha",
      "Shang Zhu",
      "Ben Athiwaratkun",
      "John Hennessy",
      "Azalia Mirhoseini",
      "Christopher Ré"
    ],
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07885v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07885v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.08319v1",
    "title": "Adaptive Multi-Agent Response Refinement in Conversational Systems",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable success in conversational systems by generating human-like responses. However, they can fall short, especially when required to account for personalization or specific knowledge. In real-life settings, it is impractical to rely on users to detect these errors and request a new response. One way to address this problem is to refine the response before returning it to the user. While existing approaches focus on refining responses within a single LLM, this method struggles to consider diverse aspects needed for effective conversations. In this work, we propose refining responses through a multi-agent framework, where each agent is assigned a specific role for each aspect. We focus on three key aspects crucial to conversational quality: factuality, personalization, and coherence. Each agent is responsible for reviewing and refining one of these aspects, and their feedback is then merged to improve the overall response. To enhance collaboration among them, we introduce a dynamic communication strategy. Instead of following a fixed sequence of agents, our approach adaptively selects and coordinates the most relevant agents based on the specific requirements of each query. We validate our framework on challenging conversational datasets, demonstrating that ours significantly outperforms relevant baselines, particularly in tasks involving knowledge or user's persona, or both.",
    "authors": [
      "Soyeong Jeong",
      "Aparna Elangovan",
      "Emine Yilmaz",
      "Oleg Rokhlenko"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08319v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08319v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.08872v1",
    "title": "SasMamba: A Lightweight Structure-Aware Stride State Space Model for 3D Human Pose Estimation",
    "summary": "Recently, the Mamba architecture based on State Space Models (SSMs) has gained attention in 3D human pose estimation due to its linear complexity and strong global modeling capability. However, existing SSM-based methods typically apply manually designed scan operations to flatten detected 2D pose sequences into purely temporal sequences, either locally or globally. This approach disrupts the inherent spatial structure of human poses and entangles spatial and temporal features, making it difficult to capture complex pose dependencies. To address these limitations, we propose the Skeleton Structure-Aware Stride SSM (SAS-SSM), which first employs a structure-aware spatiotemporal convolution to dynamically capture essential local interactions between joints, and then applies a stride-based scan strategy to construct multi-scale global structural representations. This enables flexible modeling of both local and global pose information while maintaining linear computational complexity. Built upon SAS-SSM, our model SasMamba achieves competitive 3D pose estimation performance with significantly fewer parameters compared to existing hybrid models. The source code is available at https://hucui2022.github.io/sasmamba_proj/.",
    "authors": [
      "Hu Cui",
      "Wenqiang Hua",
      "Renjing Huang",
      "Shurui Jia",
      "Tessai Hayama"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08872v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08872v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.09190v1",
    "title": "Iterated Population Based Training with Task-Agnostic Restarts",
    "summary": "Hyperparameter Optimization (HPO) can lift the burden of tuning hyperparameters (HPs) of neural networks. HPO algorithms from the Population Based Training (PBT) family are efficient thanks to dynamically adjusting HPs every few steps of the weight optimization. Recent results indicate that the number of steps between HP updates is an important meta-HP of all PBT variants that can substantially affect their performance. Yet, no method or intuition is available for efficiently setting its value. We introduce Iterated Population Based Training (IPBT), a novel PBT variant that automatically adjusts this HP via restarts that reuse weight information in a task-agnostic way and leverage time-varying Bayesian optimization to reinitialize HPs. Evaluation on 8 image classification and reinforcement learning tasks shows that, on average, our algorithm matches or outperforms 5 previous PBT variants and other HPO algorithms (random search, ASHA, SMAC3), without requiring a budget increase or any changes to its HPs. The source code is available at https://github.com/AwesomeLemon/IPBT.",
    "authors": [
      "Alexander Chebykin",
      "Tanja Alderliesten",
      "Peter A. N. Bosman"
    ],
    "categories": [
      "cs.LG",
      "cs.NE"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09190v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09190v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.08465v1",
    "title": "Generalizable Blood Cell Detection via Unified Dataset and Faster R-CNN",
    "summary": "This paper presents a comprehensive methodology and comparative performance analysis for the automated classification and object detection of peripheral blood cells (PBCs) in microscopic images. Addressing the critical challenge of data scarcity and heterogeneity, robust data pipeline was first developed to standardize and merge four public datasets (PBC, BCCD, Chula, Sickle Cell) into a unified resource. Then employed a state-of-the-art Faster R-CNN object detection framework, leveraging a ResNet-50-FPN backbone. Comparative training rigorously evaluated a randomly initialized baseline model (Regimen 1) against a Transfer Learning Regimen (Regimen 2), initialized with weights pre-trained on the Microsoft COCO dataset. The results demonstrate that the Transfer Learning approach achieved significantly faster convergence and superior stability, culminating in a final validation loss of 0.08666, a substantial improvement over the baseline. This validated methodology establishes a robust foundation for building high-accuracy, deployable systems for automated hematological diagnosis.",
    "authors": [
      "Siddharth Sahay"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08465v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08465v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.07857v1",
    "title": "A General Method for Proving Networks Universal Approximation Property",
    "summary": "Deep learning architectures are highly diverse. To prove their universal approximation properties, existing works typically rely on model-specific proofs. Generally, they construct a dedicated mathematical formulation for each architecture (e.g., fully connected networks, CNNs, or Transformers) and then prove their universal approximability. However, this approach suffers from two major limitations: first, every newly proposed architecture often requires a completely new proof from scratch; second, these proofs are largely isolated from one another, lacking a common analytical foundation. This not only incurs significant redundancy but also hinders unified theoretical understanding across different network families. To address these issues, this paper proposes a general and modular framework for proving universal approximation. We define a basic building block (comprising one or multiple layers) that possesses the universal approximation property as a Universal Approximation Module (UAM). Under this condition, we show that any deep network composed of such modules inherently retains the universal approximation property. Moreover, the overall approximation process can be interpreted as a progressive refinement across modules. This perspective not only unifies the analysis of diverse architectures but also enables a step-by-step understanding of how expressive power evolves through the network.",
    "authors": [
      "Wei Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07857v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07857v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2511.07943v1",
    "title": "Thinker: Training LLMs in Hierarchical Thinking for Deep Search via Multi-Turn Interaction",
    "summary": "Efficient retrieval of external knowledge bases and web pages is crucial for enhancing the reasoning abilities of LLMs. Previous works on training LLMs to leverage external retrievers for solving complex problems have predominantly employed end-to-end reinforcement learning. However, these approaches neglect supervision over the reasoning process, making it difficult to guarantee logical coherence and rigor. To address these limitations, we propose Thinker, a hierarchical thinking model for deep search through multi-turn interaction, making the reasoning process supervisable and verifiable. It decomposes complex problems into independently solvable sub-problems, each dually represented in both natural language and an equivalent logical function to support knowledge base and web searches. Concurrently, dependencies between sub-problems are passed as parameters via these logical functions, enhancing the logical coherence of the problem-solving process. To avoid unnecessary external searches, we perform knowledge boundary determination to check if a sub-problem is within the LLM's intrinsic knowledge, allowing it to answer directly. Experimental results indicate that with as few as several hundred training samples, the performance of Thinker is competitive with established baselines. Furthermore, when scaled to the full training set, Thinker significantly outperforms these methods across various datasets and model sizes. The source code is available at https://github.com/OpenSPG/KAG-Thinker.",
    "authors": [
      "Jun Xu",
      "Xinkai Du",
      "Yu Ao",
      "Peilong Zhao",
      "Yang Li",
      "Ling Zhong",
      "Lin Yuan",
      "Zhongpu Bo",
      "Xiaorui Wang",
      "Mengshu Sun",
      "Zhengke Gui",
      "Dalong Zhang",
      "Zhaoyang Wang",
      "Qiwei Wang",
      "Yangyang Hou",
      "Zhiying Yin",
      "Haofen Wang",
      "Huajun Chen",
      "Lei Liang",
      "Jun Zhou"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07943v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07943v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.08704v1",
    "title": "Rethinking generative image pretraining: How far are we from scaling up next-pixel prediction?",
    "summary": "This paper investigates the scaling properties of autoregressive next-pixel prediction, a simple, end-to-end yet under-explored framework for unified vision models. Starting with images at resolutions of 32x32, we train a family of Transformers using IsoFlops profiles across compute budgets up to 7e19 FLOPs and evaluate three distinct target metrics: next-pixel prediction objective, ImageNet classification accuracy, and generation quality measured by Fr'echet Distance. First, optimal scaling strategy is critically task-dependent. At a fixed 32x32 resolution alone, the optimal scaling properties for image classification and image generation diverge, where generation optimal setup requires the data size grow three to five times faster than for the classification optimal setup. Second, as image resolution increases, the optimal scaling strategy indicates that the model size must grow much faster than data size. Surprisingly, by projecting our findings, we discover that the primary bottleneck is compute rather than the amount of training data. As compute continues to grow four to five times annually, we forecast the feasibility of pixel-by-pixel modeling of images within the next five years.",
    "authors": [
      "Xinchen Yan",
      "Chen Liang",
      "Lijun Yu",
      "Adams Wei Yu",
      "Yifeng Lu",
      "Quoc V. Le"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08704v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08704v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.08967v1",
    "title": "AuthSig: Safeguarding Scanned Signatures Against Unauthorized Reuse in Paperless Workflows",
    "summary": "With the deepening trend of paperless workflows, signatures as a means of identity authentication are gradually shifting from traditional ink-on-paper to electronic formats.Despite the availability of dynamic pressure-sensitive and PKI-based digital signatures, static scanned signatures remain prevalent in practice due to their convenience. However, these static images, having almost lost their authentication attributes, cannot be reliably verified and are vulnerable to malicious copying and reuse. To address these issues, we propose AuthSig, a novel static electronic signature framework based on generative models and watermark, which binds authentication information to the signature image. Leveraging the human visual system's insensitivity to subtle style variations, AuthSig finely modulates style embeddings during generation to implicitly encode watermark bits-enforcing a One Signature, One Use policy.To overcome the scarcity of handwritten signature data and the limitations of traditional augmentation methods, we introduce a keypoint-driven data augmentation strategy that effectively enhances style diversity to support robust watermark embedding. Experimental results show that AuthSig achieves over 98% extraction accuracy under both digital-domain distortions and signature-specific degradations, and remains effective even in print-scan scenarios.",
    "authors": [
      "RuiQiang Zhang",
      "Zehua Ma",
      "Guanjie Wang",
      "Chang Liu",
      "Hengyi Wang",
      "Weiming Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08967v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08967v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.09179v1",
    "title": "A Hybrid Search for Complex Table Question Answering in Securities Report",
    "summary": "Recently, Large Language Models (LLMs) are gaining increased attention in the domain of Table Question Answering (TQA), particularly for extracting information from tables in documents. However, directly entering entire tables as long text into LLMs often leads to incorrect answers because most LLMs cannot inherently capture complex table structures. In this paper, we propose a cell extraction method for TQA without manual identification, even for complex table headers. Our approach estimates table headers by computing similarities between a given question and individual cells via a hybrid retrieval mechanism that integrates a language model and TF-IDF. We then select as the answer the cells at the intersection of the most relevant row and column. Furthermore, the language model is trained using contrastive learning on a small dataset of question-header pairs to enhance performance. We evaluated our approach in the TQA dataset from the U4 shared task at NTCIR-18. The experimental results show that our pipeline achieves an accuracy of 74.6\\%, outperforming existing LLMs such as GPT-4o mini~(63.9\\%). In the future, although we used traditional encoder models for retrieval in this study, we plan to incorporate more efficient text-search models to improve performance and narrow the gap with human evaluation results.",
    "authors": [
      "Daiki Shirafuji",
      "Koji Tanaka",
      "Tatsuhiko Saito"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09179v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09179v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.08215v1",
    "title": "Evaluating Gemini LLM in Food Image-Based Recipe and Nutrition Description with EfficientNet-B4 Visual Backbone",
    "summary": "The proliferation of digital food applications necessitates robust methods for automated nutritional analysis and culinary guidance. This paper presents a comprehensive comparative evaluation of a decoupled, multimodal pipeline for food recognition. We evaluate a system integrating a specialized visual backbone (EfficientNet-B4) with a powerful generative large language model (Google's Gemini LLM). The core objective is to evaluate the trade-offs between visual classification accuracy, model efficiency, and the quality of generative output (nutritional data and recipes). We benchmark this pipeline against alternative vision backbones (VGG-16, ResNet-50, YOLOv8) and a lightweight LLM (Gemma). We introduce a formalization for \"Semantic Error Propagation\" (SEP) to analyze how classification inaccuracies from the visual module cascade into the generative output. Our analysis is grounded in a new Custom Chinese Food Dataset (CCFD) developed to address cultural bias in public datasets. Experimental results demonstrate that while EfficientNet-B4 (89.0\\% Top-1 Acc.) provides the best balance of accuracy and efficiency, and Gemini (9.2/10 Factual Accuracy) provides superior generative quality, the system's overall utility is fundamentally bottlenecked by the visual front-end's perceptive accuracy. We conduct a detailed per-class analysis, identifying high semantic similarity as the most critical failure mode.",
    "authors": [
      "Rizal Khoirul Anam"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08215v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08215v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.08651v1",
    "title": "RS-Net: Context-Aware Relation Scoring for Dynamic Scene Graph Generation",
    "summary": "Dynamic Scene Graph Generation (DSGG) models how object relations evolve over time in videos. However, existing methods are trained only on annotated object pairs and lack guidance for non-related pairs, making it difficult to identify meaningful relations during inference. In this paper, we propose Relation Scoring Network (RS-Net), a modular framework that scores the contextual importance of object pairs using both spatial interactions and long-range temporal context. RS-Net consists of a spatial context encoder with learnable context tokens and a temporal encoder that aggregates video-level information. The resulting relation scores are integrated into a unified triplet scoring mechanism to enhance relation prediction. RS-Net can be easily integrated into existing DSGG models without architectural changes. Experiments on the Action Genome dataset show that RS-Net consistently improves both Recall and Precision across diverse baselines, with notable gains in mean Recall, highlighting its ability to address the long-tailed distribution of relations. Despite the increased number of parameters, RS-Net maintains competitive efficiency, achieving superior performance over state-of-the-art methods.",
    "authors": [
      "Hae-Won Jo",
      "Yeong-Jun Cho"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08651v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08651v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.07896v1",
    "title": "SparseRM: A Lightweight Preference Modeling with Sparse Autoencoder",
    "summary": "Reward models (RMs) are a core component in the post-training of large language models (LLMs), serving as proxies for human preference evaluation and guiding model alignment. However, training reliable RMs under limited resources remains challenging due to the reliance on large-scale preference annotations and the high cost of fine-tuning LLMs. To address this, we propose SparseRM, which leverages Sparse Autoencoder (SAE) to extract preference-relevant information encoded in model representations, enabling the construction of a lightweight and interpretable reward model. SparseRM first employs SAE to decompose LLM representations into interpretable directions that capture preference-relevant features. The representations are then projected onto these directions to compute alignment scores, which quantify the strength of each preference feature in the representations. A simple reward head aggregates these scores to predict preference scores. Experiments on three preference modeling tasks show that SparseRM achieves superior performance over most mainstream RMs while using less than 1% of trainable parameters. Moreover, it integrates seamlessly into downstream alignment pipelines, highlighting its potential for efficient alignment.",
    "authors": [
      "Dengcan Liu",
      "Jiahao Li",
      "Zheren Fu",
      "Yi Tu",
      "Jiajun Li",
      "Zhendong Mao",
      "Yongdong Zhang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07896v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07896v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.07737v1",
    "title": "TurboSAT: Gradient-Guided Boolean Satisfiability Accelerated on GPU-CPU Hybrid System",
    "summary": "While accelerated computing has transformed many domains of computing, its impact on logical reasoning, specifically Boolean satisfiability (SAT), remains limited. State-of-the-art SAT solvers rely heavily on inherently sequential conflict-driven search algorithms that offer powerful heuristics but limit the amount of parallelism that could otherwise enable significantly more scalable SAT solving. Inspired by neural network training, we formulate the SAT problem as a binarized matrix-matrix multiplication layer that could be optimized using a differentiable objective function. Enabled by this encoding, we combine the strengths of parallel differentiable optimization and sequential search to accelerate SAT on a hybrid GPU-CPU system. In this system, the GPUs leverage parallel differentiable solving to rapidly evaluate SAT clauses and use gradients to stochastically explore the solution space and optimize variable assignments. Promising partial assignments generated by the GPUs are post-processed on many CPU threads which exploit conflict-driven sequential search to further traverse the solution subspaces and identify complete assignments. Prototyping the hybrid solver on an NVIDIA DGX GB200 node, our solver achieves runtime speedups up to over 200x when compared to a state-of-the-art CPU-based solver on public satisfiable benchmark problems from the SAT Competition.",
    "authors": [
      "Steve Dai",
      "Cunxi Yu",
      "Kalyan Krishnamani",
      "Brucek Khailany"
    ],
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.LG",
      "cs.MS"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07737v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07737v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.07935v2",
    "title": "DiffRegCD: Integrated Registration and Change Detection with Diffusion Features",
    "summary": "Change detection (CD) is fundamental to computer vision and remote sensing, supporting applications in environmental monitoring, disaster response, and urban development. Most CD models assume co-registered inputs, yet real-world imagery often exhibits parallax, viewpoint shifts, and long temporal gaps that cause severe misalignment. Traditional two stage methods that first register and then detect, as well as recent joint frameworks (e.g., BiFA, ChangeRD), still struggle under large displacements, relying on regression only flow, global homographies, or synthetic perturbations. We present DiffRegCD, an integrated framework that unifies dense registration and change detection in a single model. DiffRegCD reformulates correspondence estimation as a Gaussian smoothed classification task, achieving sub-pixel accuracy and stable training. It leverages frozen multi-scale features from a pretrained denoising diffusion model, ensuring robustness to illumination and viewpoint variation. Supervision is provided through controlled affine perturbations applied to standard CD datasets, yielding paired ground truth for both flow and change detection without pseudo labels. Extensive experiments on aerial (LEVIR-CD, DSIFN-CD, WHU-CD, SYSU-CD) and ground level (VL-CMU-CD) datasets show that DiffRegCD consistently surpasses recent baselines and remains reliable under wide temporal and geometric variation, establishing diffusion features and classification based correspondence as a strong foundation for unified change detection.",
    "authors": [
      "Seyedehanita Madani",
      "Rama Chellappa",
      "Vishal M. Patel"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07935v2",
    "pdf_url": "https://arxiv.org/pdf/2511.07935v2.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2511.08544v2",
    "title": "LeJEPA: Provable and Scalable Self-Supervised Learning Without the Heuristics",
    "summary": "Learning manipulable representations of the world and its dynamics is central to AI. Joint-Embedding Predictive Architectures (JEPAs) offer a promising blueprint, but lack of practical guidance and theory has led to ad-hoc R&D. We present a comprehensive theory of JEPAs and instantiate it in {\\bf LeJEPA}, a lean, scalable, and theoretically grounded training objective. First, we identify the isotropic Gaussian as the optimal distribution that JEPAs' embeddings should follow to minimize downstream prediction risk. Second, we introduce a novel objective--{\\bf Sketched Isotropic Gaussian Regularization} (SIGReg)--to constrain embeddings to reach that ideal distribution. Combining the JEPA predictive loss with SIGReg yields LeJEPA with numerous theoretical and practical benefits: (i) single trade-off hyperparameter, (ii) linear time and memory complexity, (iii) stability across hyper-parameters, architectures (ResNets, ViTs, ConvNets) and domains, (iv) heuristics-free, e.g., no stop-gradient, no teacher-student, no hyper-parameter schedulers, and (v) distributed training-friendly implementation requiring only $\\approx$50 lines of code. Our empirical validation covers 10+ datasets, 60+ architectures, all with varying scales and domains. As an example, using imagenet-1k for pretraining and linear evaluation with frozen backbone, LeJEPA reaches 79\\% with a ViT-H/14. We hope that the simplicity and theory-friendly ecosystem offered by LeJEPA will reestablish self-supervised pre-training as a core pillar of AI research (\\href{https://github.com/rbalestr-lab/lejepa}{GitHub repo}).",
    "authors": [
      "Randall Balestriero",
      "Yann LeCun"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08544v2",
    "pdf_url": "https://arxiv.org/pdf/2511.08544v2.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07942v1",
    "title": "Balance Equation-based Distributionally Robust Offline Imitation Learning",
    "summary": "Imitation Learning (IL) has proven highly effective for robotic and control tasks where manually designing reward functions or explicit controllers is infeasible. However, standard IL methods implicitly assume that the environment dynamics remain fixed between training and deployment. In practice, this assumption rarely holds where modeling inaccuracies, real-world parameter variations, and adversarial perturbations can all induce shifts in transition dynamics, leading to severe performance degradation. We address this challenge through Balance Equation-based Distributionally Robust Offline Imitation Learning, a framework that learns robust policies solely from expert demonstrations collected under nominal dynamics, without requiring further environment interaction. We formulate the problem as a distributionally robust optimization over an uncertainty set of transition models, seeking a policy that minimizes the imitation loss under the worst-case transition distribution. Importantly, we show that this robust objective can be reformulated entirely in terms of the nominal data distribution, enabling tractable offline learning. Empirical evaluations on continuous-control benchmarks demonstrate that our approach achieves superior robustness and generalization compared to state-of-the-art offline IL baselines, particularly under perturbed or shifted environments.",
    "authors": [
      "Rishabh Agrawal",
      "Yusuf Alvi",
      "Rahul Jain",
      "Ashutosh Nayyar"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07942v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07942v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.08505v1",
    "title": "Structured RAG for Answering Aggregative Questions",
    "summary": "Retrieval-Augmented Generation (RAG) has become the dominant approach for answering questions over large corpora. However, current datasets and methods are highly focused on cases where only a small part of the corpus (usually a few paragraphs) is relevant per query, and fail to capture the rich world of aggregative queries. These require gathering information from a large set of documents and reasoning over them. To address this gap, we propose S-RAG, an approach specifically designed for such queries. At ingestion time, S-RAG constructs a structured representation of the corpus; at inference time, it translates natural-language queries into formal queries over said representation. To validate our approach and promote further research in this area, we introduce two new datasets of aggregative queries: HOTELS and WORLD CUP. Experiments with S-RAG on the newly introduced datasets, as well as on a public benchmark, demonstrate that it substantially outperforms both common RAG systems and long-context LLMs.",
    "authors": [
      "Omri Koshorek",
      "Niv Granot",
      "Aviv Alloni",
      "Shahar Admati",
      "Roee Hendel",
      "Ido Weiss",
      "Alan Arazi",
      "Shay-Nitzan Cohen",
      "Yonatan Belinkov"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08505v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08505v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.07836v2",
    "title": "Hyperellipsoid Density Sampling: Exploitative Sequences to Accelerate High-Dimensional Optimization",
    "summary": "The curse of dimensionality presents a pervasive challenge in optimization problems, with exponential expansion of the search space rapidly causing traditional algorithms to become inefficient or infeasible. An adaptive sampling strategy is presented to accelerate optimization in this domain as an alternative to uniform quasi-Monte Carlo (QMC) methods.   This method, referred to as Hyperellipsoid Density Sampling (HDS), generates its sequences by defining multiple hyperellipsoids throughout the search space. HDS uses three types of unsupervised learning algorithms to circumvent high-dimensional geometric calculations, producing an intelligent, non-uniform sample sequence that exploits statistically promising regions of the parameter space and improves final solution quality in high-dimensional optimization problems.   A key feature of the method is optional Gaussian weights, which may be provided to influence the sample distribution towards known locations of interest. This capability makes HDS versatile for applications beyond optimization, providing a focused, denser sample distribution where models need to concentrate their efforts on specific, non-uniform regions of the parameter space.   The method was evaluated against Sobol, a standard QMC method, using differential evolution (DE) on the 29 CEC2017 benchmark test functions. The results show statistically significant improvements in solution geometric mean error (p < 0.05), with average performance gains ranging from 3% in 30D to 37% in 10D. This paper demonstrates the efficacy of HDS as a robust alternative to QMC sampling for high-dimensional optimization.",
    "authors": [
      "Julian Soltes"
    ],
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NE"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07836v2",
    "pdf_url": "https://arxiv.org/pdf/2511.07836v2.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.08231v1",
    "title": "Real-Time Performance Analysis of Multi-Fidelity Residual Physics-Informed Neural Process-Based State Estimation for Robotic Systems",
    "summary": "Various neural network architectures are used in many of the state-of-the-art approaches for real-time nonlinear state estimation. With the ever-increasing incorporation of these data-driven models into the estimation domain, model predictions with reliable margins of error are a requirement -- especially for safety-critical applications. This paper discusses the application of a novel real-time, data-driven estimation approach based on the multi-fidelity residual physics-informed neural process (MFR-PINP) toward the real-time state estimation of a robotic system. Specifically, we address the model-mismatch issue of selecting an accurate kinematic model by tasking the MFR-PINP to also learn the residuals between simple, low-fidelity predictions and complex, high-fidelity ground-truth dynamics. To account for model uncertainty present in a physical implementation, robust uncertainty guarantees from the split conformal (SC) prediction framework are modeled in the training and inference paradigms. We provide implementation details of our MFR-PINP-based estimator for a hybrid online learning setting to validate our model's usage in real-time applications. Experimental results of our approach's performance in comparison to the state-of-the-art variants of the Kalman filter (i.e. unscented Kalman filter and deep Kalman filter) in estimation scenarios showed promising results for the MFR-PINP model as a viable option in real-time estimation tasks.",
    "authors": [
      "Devin Hunter",
      "Chinwendu Enyioha"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08231v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08231v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.08226v1",
    "title": "The Online Patch Redundancy Eliminator (OPRE): A novel approach to online agnostic continual learning using dataset compression",
    "summary": "In order to achieve Continual Learning (CL), the problem of catastrophic forgetting, one that has plagued neural networks since their inception, must be overcome. The evaluation of continual learning methods relies on splitting a known homogeneous dataset and learning the associated tasks one after the other. We argue that most CL methods introduce a priori information about the data to come and cannot be considered agnostic. We exemplify this point with the case of methods relying on pretrained feature extractors, which are still used in CL. After showing that pretrained feature extractors imply a loss of generality with respect to the data that can be learned by the model, we then discuss other kinds of a priori information introduced in other CL methods. We then present the Online Patch Redundancy Eliminator (OPRE), an online dataset compression algorithm, which, along with the training of a classifier at test time, yields performance on CIFAR-10 and CIFAR-100 superior to a number of other state-of-the-art online continual learning methods. Additionally, OPRE requires only minimal and interpretable hypothesis on the data to come. We suggest that online dataset compression could well be necessary to achieve fully agnostic CL.",
    "authors": [
      "Raphaël Bayle",
      "Martial Mermillod",
      "Robert M. French"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08226v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08226v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.08464v1",
    "title": "Contrastive Integrated Gradients: A Feature Attribution-Based Method for Explaining Whole Slide Image Classification",
    "summary": "Interpretability is essential in Whole Slide Image (WSI) analysis for computational pathology, where understanding model predictions helps build trust in AI-assisted diagnostics. While Integrated Gradients (IG) and related attribution methods have shown promise, applying them directly to WSIs introduces challenges due to their high-resolution nature. These methods capture model decision patterns but may overlook class-discriminative signals that are crucial for distinguishing between tumor subtypes. In this work, we introduce Contrastive Integrated Gradients (CIG), a novel attribution method that enhances interpretability by computing contrastive gradients in logit space. First, CIG highlights class-discriminative regions by comparing feature importance relative to a reference class, offering sharper differentiation between tumor and non-tumor areas. Second, CIG satisfies the axioms of integrated attribution, ensuring consistency and theoretical soundness. Third, we propose two attribution quality metrics, MIL-AIC and MIL-SIC, which measure how predictive information and model confidence evolve with access to salient regions, particularly under weak supervision. We validate CIG across three datasets spanning distinct cancer types: CAMELYON16 (breast cancer metastasis in lymph nodes), TCGA-RCC (renal cell carcinoma), and TCGA-Lung (lung cancer). Experimental results demonstrate that CIG yields more informative attributions both quantitatively, using MIL-AIC and MIL-SIC, and qualitatively, through visualizations that align closely with ground truth tumor regions, underscoring its potential for interpretable and trustworthy WSI-based diagnostics",
    "authors": [
      "Anh Mai Vu",
      "Tuan L. Vo",
      "Ngoc Lam Quang Bui",
      "Nam Nguyen Le Binh",
      "Akash Awasthi",
      "Huy Quoc Vo",
      "Thanh-Huy Nguyen",
      "Zhu Han",
      "Chandra Mohan",
      "Hien Van Nguyen"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08464v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08464v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.09493v1",
    "title": "Consensus Sampling for Safer Generative AI",
    "summary": "Many approaches to AI safety rely on inspecting model outputs or activations, yet certain risks are inherently undetectable by inspection alone. We propose a complementary, architecture-agnostic approach that enhances safety through the aggregation of multiple generative models, with the aggregated model inheriting its safety from the safest subset of a given size among them. Specifically, we present a consensus sampling algorithm that, given $k$ models and a prompt, achieves risk competitive with the average risk of the safest $s$ of the $k$ models, where $s$ is a chosen parameter, while abstaining when there is insufficient agreement between them. The approach leverages the models' ability to compute output probabilities, and we bound the probability of abstention when sufficiently many models are safe and exhibit adequate agreement. The algorithm is inspired by the provable copyright protection algorithm of Vyas et al. (2023). It requires some overlap among safe models, offers no protection when all models are unsafe, and may accumulate risk over repeated use. Nonetheless, our results provide a new, model-agnostic approach for AI safety by amplifying safety guarantees from an unknown subset of models within a collection to that of a single reliable model.",
    "authors": [
      "Adam Tauman Kalai",
      "Yael Tauman Kalai",
      "Or Zamir"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09493v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09493v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.08993v1",
    "title": "Fast $k$-means clustering in Riemannian manifolds via Fréchet maps: Applications to large-dimensional SPD matrices",
    "summary": "We introduce a novel, efficient framework for clustering data on high-dimensional, non-Euclidean manifolds that overcomes the computational challenges associated with standard intrinsic methods. The key innovation is the use of the $p$-Fréchet map $F^p : \\mathcal{M} \\to \\mathbb{R}^\\ell$ -- defined on a generic metric space $\\mathcal{M}$ -- which embeds the manifold data into a lower-dimensional Euclidean space $\\mathbb{R}^\\ell$ using a set of reference points $\\{r_i\\}_{i=1}^\\ell$, $r_i \\in \\mathcal{M}$. Once embedded, we can efficiently and accurately apply standard Euclidean clustering techniques such as k-means. We rigorously analyze the mathematical properties of $F^p$ in the Euclidean space and the challenging manifold of $n \\times n$ symmetric positive definite matrices $\\mathit{SPD}(n)$. Extensive numerical experiments using synthetic and real $\\mathit{SPD}(n)$ data demonstrate significant performance gains: our method reduces runtime by up to two orders of magnitude compared to intrinsic manifold-based approaches, all while maintaining high clustering accuracy, including scenarios where existing alternative methods struggle or fail.",
    "authors": [
      "Ji Shi",
      "Nicolas Charon",
      "Andreas Mang",
      "Demetrio Labate",
      "Robert Azencott"
    ],
    "categories": [
      "cs.LG",
      "cs.CV",
      "math.DG"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08993v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08993v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.08364v1",
    "title": "DPRM: A Dual Implicit Process Reward Model in Multi-Hop Question Answering",
    "summary": "In multi-hop question answering (MHQA) tasks, Chain of Thought (CoT) improves the quality of generation by guiding large language models (LLMs) through multi-step reasoning, and Knowledge Graphs (KGs) reduce hallucinations via semantic matching. Outcome Reward Models (ORMs) provide feedback after generating the final answers but fail to evaluate the process for multi-step reasoning. Traditional Process Reward Models (PRMs) evaluate the reasoning process but require costly human annotations or rollout generation. While implicit PRM is trained only with outcome signals and derives step rewards through reward parameterization without explicit annotations, it is more suitable for multi-step reasoning in MHQA tasks. However, existing implicit PRM has only been explored for plain text scenarios. When adapting to MHQA tasks, it cannot handle the graph structure constraints in KGs and capture the potential inconsistency between CoT and KG paths. To address these limitations, we propose the DPRM (Dual Implicit Process Reward Model). It trains two implicit PRMs for CoT and KG reasoning in MHQA tasks. Both PRMs, namely KG-PRM and CoT-PRM, derive step-level rewards from outcome signals via reward parameterization without additional explicit annotations. Among them, KG-PRM uses preference pairs to learn structural constraints from KGs. DPRM further introduces a consistency constraint between CoT and KG reasoning steps, making the two PRMs mutually verify and collaboratively optimize the reasoning paths. We also provide a theoretical demonstration of the derivation of process rewards. Experimental results show that our method outperforms 13 baselines on multiple datasets with up to 16.6% improvement on Hit@1.",
    "authors": [
      "Xinyi Wang",
      "Yiping Song",
      "Zhiliang Tian",
      "Bo Liu",
      "Tingjin Luo",
      "Minlie Huang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08364v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08364v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.09228v1",
    "title": "Taming Object Hallucinations with Verified Atomic Confidence Estimation",
    "summary": "Multimodal Large Language Models (MLLMs) often suffer from hallucinations, particularly errors in object existence, attributes, or relations, which undermine their reliability. We introduce TACO (Verified Atomic Confidence Estimation), a simple framework that mitigates hallucinations through self-verification and confidence calibration without relying on external vision experts. TACO decomposes responses into atomic queries, paraphrases them to reduce sensitivity to wording, and estimates confidence using self-consistency (black-box) or self-confidence (gray-box) aggregation, before refining answers with a language model. Experiments on five benchmarks (POPE, MME, HallusionBench, AMBER, and MM-Hal Bench) with two MLLMs (\\texttt{LLaVA-1.5-7B} and \\texttt{CogVLM2}) show that TACO consistently outperforms direct prompting and Visual Contrastive Decoding, reduces systematic biases, and improves confidence calibration, demonstrating its effectiveness in enhancing the faithfulness of MLLMs.",
    "authors": [
      "Jiarui Liu",
      "Weihao Xuan",
      "Zhijing Jin",
      "Mona Diab"
    ],
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09228v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09228v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2511.09478v1",
    "title": "AdaCuRL: Adaptive Curriculum Reinforcement Learning with Invalid Sample Mitigation and Historical Revisiting",
    "summary": "Reinforcement learning (RL) has demonstrated considerable potential for enhancing reasoning in large language models (LLMs). However, existing methods suffer from Gradient Starvation and Policy Degradation when training directly on samples with mixed difficulty. To mitigate this, prior approaches leverage Chain-of-Thought (CoT) data, but the construction of high-quality CoT annotations remains labor-intensive. Alternatively, curriculum learning strategies have been explored but frequently encounter challenges, such as difficulty mismatch, reliance on manual curriculum design, and catastrophic forgetting. To address these issues, we propose AdaCuRL, a Adaptive Curriculum Reinforcement Learning framework that integrates coarse-to-fine difficulty estimation with adaptive curriculum scheduling. This approach dynamically aligns data difficulty with model capability and incorporates a data revisitation mechanism to mitigate catastrophic forgetting. Furthermore, AdaCuRL employs adaptive reference and sparse KL strategies to prevent Policy Degradation. Extensive experiments across diverse reasoning benchmarks demonstrate that AdaCuRL consistently achieves significant performance improvements on both LLMs and MLLMs.",
    "authors": [
      "Renda Li",
      "Hailang Huang",
      "Fei Wei",
      "Feng Xiong",
      "Yong Wang",
      "Xiangxiang Chu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09478v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09478v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08579v1",
    "title": "Training Language Models to Explain Their Own Computations",
    "summary": "Can language models (LMs) learn to faithfully describe their internal computations? Are they better able to describe themselves than other models? We study the extent to which LMs' privileged access to their own internals can be leveraged to produce new techniques for explaining their behavior. Using existing interpretability techniques as a source of ground truth, we fine-tune LMs to generate natural language descriptions of (1) the information encoded by LM features, (2) the causal structure of LMs' internal activations, and (3) the influence of specific input tokens on LM outputs. When trained with only tens of thousands of example explanations, explainer models exhibit non-trivial generalization to new queries. This generalization appears partly attributable to explainer models' privileged access to their own internals: using a model to explain its own computations generally works better than using a *different* model to explain its computations (even if the other model is significantly more capable). Our results suggest not only that LMs can learn to reliably explain their internal computations, but that such explanations offer a scalable complement to existing interpretability methods.",
    "authors": [
      "Belinda Z. Li",
      "Zifan Carl Guo",
      "Vincent Huang",
      "Jacob Steinhardt",
      "Jacob Andreas"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08579v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08579v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07820v1",
    "title": "SONIC: Supersizing Motion Tracking for Natural Humanoid Whole-Body Control",
    "summary": "Despite the rise of billion-parameter foundation models trained across thousands of GPUs, similar scaling gains have not been shown for humanoid control. Current neural controllers for humanoids remain modest in size, target a limited behavior set, and are trained on a handful of GPUs over several days. We show that scaling up model capacity, data, and compute yields a generalist humanoid controller capable of creating natural and robust whole-body movements. Specifically, we posit motion tracking as a natural and scalable task for humanoid control, leverageing dense supervision from diverse motion-capture data to acquire human motion priors without manual reward engineering. We build a foundation model for motion tracking by scaling along three axes: network size (from 1.2M to 42M parameters), dataset volume (over 100M frames, 700 hours of high-quality motion data), and compute (9k GPU hours). Beyond demonstrating the benefits of scale, we show the practical utility of our model through two mechanisms: (1) a real-time universal kinematic planner that bridges motion tracking to downstream task execution, enabling natural and interactive control, and (2) a unified token space that supports various motion input interfaces, such as VR teleoperation devices, human videos, and vision-language-action (VLA) models, all using the same policy. Scaling motion tracking exhibits favorable properties: performance improves steadily with increased compute and data diversity, and learned representations generalize to unseen motions, establishing motion tracking at scale as a practical foundation for humanoid control.",
    "authors": [
      "Zhengyi Luo",
      "Ye Yuan",
      "Tingwu Wang",
      "Chenran Li",
      "Sirui Chen",
      "Fernando Castañeda",
      "Zi-Ang Cao",
      "Jiefeng Li",
      "David Minor",
      "Qingwei Ben",
      "Xingye Da",
      "Runyu Ding",
      "Cyrus Hogg",
      "Lina Song",
      "Edy Lim",
      "Eugene Jeong",
      "Tairan He",
      "Haoru Xue",
      "Wenli Xiao",
      "Zi Wang",
      "Simon Yuen",
      "Jan Kautz",
      "Yan Chang",
      "Umar Iqbal",
      "Linxi \"Jim\" Fan",
      "Yuke Zhu"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.GR",
      "eess.SY"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07820v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07820v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08087v1",
    "title": "Beyond the Pixels: VLM-based Evaluation of Identity Preservation in Reference-Guided Synthesis",
    "summary": "Evaluating identity preservation in generative models remains a critical yet unresolved challenge. Existing metrics rely on global embeddings or coarse VLM prompting, failing to capture fine-grained identity changes and providing limited diagnostic insight. We introduce Beyond the Pixels, a hierarchical evaluation framework that decomposes identity assessment into feature-level transformations. Our approach guides VLMs through structured reasoning by (1) hierarchically decomposing subjects into (type, style) -> attribute -> feature decision tree, and (2) prompting for concrete transformations rather than abstract similarity scores. This decomposition grounds VLM analysis in verifiable visual evidence, reducing hallucinations and improving consistency. We validate our framework across four state-of-the-art generative models, demonstrating strong alignment with human judgments in measuring identity consistency. Additionally, we introduce a new benchmark specifically designed to stress-test generative models. It comprises 1,078 image-prompt pairs spanning diverse subject types, including underrepresented categories such as anthropomorphic and animated characters, and captures an average of six to seven transformation axes per prompt.",
    "authors": [
      "Aditi Singhania",
      "Krutik Malani",
      "Riddhi Dhawan",
      "Arushi Jain",
      "Garv Tandon",
      "Nippun Sharma",
      "Souymodip Chakraborty",
      "Vineet Batra",
      "Ankit Phogat"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08087v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08087v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08980v1",
    "title": "A Finite Difference Approximation of Second Order Regularization of Neural-SDFs",
    "summary": "We introduce a finite-difference framework for curvature regularization in neural signed distance field (SDF) learning. Existing approaches enforce curvature priors using full Hessian information obtained via second-order automatic differentiation, which is accurate but computationally expensive. Others reduced this overhead by avoiding explicit Hessian assembly, but still required higher-order differentiation. In contrast, our method replaces these operations with lightweight finite-difference stencils that approximate second derivatives using the well known Taylor expansion with a truncation error of O(h^2), and can serve as drop-in replacements for Gaussian curvature and rank-deficiency losses. Experiments demonstrate that our finite-difference variants achieve reconstruction fidelity comparable to their automatic-differentiation counterparts, while reducing GPU memory usage and training time by up to a factor of two. Additional tests on sparse, incomplete, and non-CAD data confirm that the proposed formulation is robust and general, offering an efficient and scalable alternative for curvature-aware SDF learning.",
    "authors": [
      "Haotian Yin",
      "Aleksander Plocharski",
      "Michal Jan Wlodarczyk",
      "Przemyslaw Musialski"
    ],
    "categories": [
      "cs.GR",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08980v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08980v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08240v1",
    "title": "Hierarchical Direction Perception via Atomic Dot-Product Operators for Rotation-Invariant Point Clouds Learning",
    "summary": "Point cloud processing has become a cornerstone technology in many 3D vision tasks. However, arbitrary rotations introduce variations in point cloud orientations, posing a long-standing challenge for effective representation learning. The core of this issue is the disruption of the point cloud's intrinsic directional characteristics caused by rotational perturbations. Recent methods attempt to implicitly model rotational equivariance and invariance, preserving directional information and propagating it into deep semantic spaces. Yet, they often fall short of fully exploiting the multiscale directional nature of point clouds to enhance feature representations. To address this, we propose the Direction-Perceptive Vector Network (DiPVNet). At its core is an atomic dot-product operator that simultaneously encodes directional selectivity and rotation invariance--endowing the network with both rotational symmetry modeling and adaptive directional perception. At the local level, we introduce a Learnable Local Dot-Product (L2DP) Operator, which enables interactions between a center point and its neighbors to adaptively capture the non-uniform local structures of point clouds. At the global level, we leverage generalized harmonic analysis to prove that the dot-product between point clouds and spherical sampling vectors is equivalent to a direction-aware spherical Fourier transform (DASFT). This leads to the construction of a global directional response spectrum for modeling holistic directional structures. We rigorously prove the rotation invariance of both operators. Extensive experiments on challenging scenarios involving noise and large-angle rotations demonstrate that DiPVNet achieves state-of-the-art performance on point cloud classification and segmentation tasks. Our code is available at https://github.com/wxszreal0/DiPVNet.",
    "authors": [
      "Chenyu Hu",
      "Xiaotong Li",
      "Hao Zhu",
      "Biao Hou"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08240v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08240v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.09294v1",
    "title": "GuardFed: A Trustworthy Federated Learning Framework Against Dual-Facet Attacks",
    "summary": "Federated learning (FL) enables privacy-preserving collaborative model training but remains vulnerable to adversarial behaviors that compromise model utility or fairness across sensitive groups. While extensive studies have examined attacks targeting either objective, strategies that simultaneously degrade both utility and fairness remain largely unexplored. To bridge this gap, we introduce the Dual-Facet Attack (DFA), a novel threat model that concurrently undermines predictive accuracy and group fairness. Two variants, Synchronous DFA (S-DFA) and Split DFA (Sp-DFA), are further proposed to capture distinct real-world collusion scenarios. Experimental results show that existing robust FL defenses, including hybrid aggregation schemes, fail to resist DFAs effectively. To counter these threats, we propose GuardFed, a self-adaptive defense framework that maintains a fairness-aware reference model using a small amount of clean server data augmented with synthetic samples. In each training round, GuardFed computes a dual-perspective trust score for every client by jointly evaluating its utility deviation and fairness degradation, thereby enabling selective aggregation of trustworthy updates. Extensive experiments on real-world datasets demonstrate that GuardFed consistently preserves both accuracy and fairness under diverse non-IID and adversarial conditions, achieving state-of-the-art performance compared with existing robust FL methods.",
    "authors": [
      "Yanli Li",
      "Yanan Zhou",
      "Zhongliang Guo",
      "Nan Yang",
      "Yuning Zhang",
      "Huaming Chen",
      "Dong Yuan",
      "Weiping Ding",
      "Witold Pedrycz"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09294v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09294v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.07941v1",
    "title": "Libra-MIL: Multimodal Prototypes Stereoscopic Infused with Task-specific Language Priors for Few-shot Whole Slide Image Classification",
    "summary": "While Large Language Models (LLMs) are emerging as a promising direction in computational pathology, the substantial computational cost of giga-pixel Whole Slide Images (WSIs) necessitates the use of Multi-Instance Learning (MIL) to enable effective modeling. A key challenge is that pathological tasks typically provide only bag-level labels, while instance-level descriptions generated by LLMs often suffer from bias due to a lack of fine-grained medical knowledge. To address this, we propose that constructing task-specific pathological entity prototypes is crucial for learning generalizable features and enhancing model interpretability. Furthermore, existing vision-language MIL methods often employ unidirectional guidance, limiting cross-modal synergy. In this paper, we introduce a novel approach, Multimodal Prototype-based Multi-Instance Learning, that promotes bidirectional interaction through a balanced information compression scheme. Specifically, we leverage a frozen LLM to generate task-specific pathological entity descriptions, which are learned as text prototypes. Concurrently, the vision branch learns instance-level prototypes to mitigate the model's reliance on redundant data. For the fusion stage, we employ the Stereoscopic Optimal Transport (SOT) algorithm, which is based on a similarity metric, thereby facilitating broader semantic alignment in a higher-dimensional space. We conduct few-shot classification and explainability experiments on three distinct cancer datasets, and the results demonstrate the superior generalization capabilities of our proposed method.",
    "authors": [
      "Zhenfeng Zhuang",
      "Fangyu Zhou",
      "Liansheng Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07941v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07941v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08470v1",
    "title": "Binary Split Categorical feature with Mean Absolute Error Criteria in CART",
    "summary": "In the context of the Classification and Regression Trees (CART) algorithm, the efficient splitting of categorical features using standard criteria like GINI and Entropy is well-established. However, using the Mean Absolute Error (MAE) criterion for categorical features has traditionally relied on various numerical encoding methods. This paper demonstrates that unsupervised numerical encoding methods are not viable for the MAE criteria. Furthermore, we present a novel and efficient splitting algorithm that addresses the challenges of handling categorical features with the MAE criterion. Our findings underscore the limitations of existing approaches and offer a promising solution to enhance the handling of categorical data in CART algorithms.",
    "authors": [
      "Peng Yu",
      "Yike Chen",
      "Chao Xu",
      "Albert Bifet",
      "Jesse Read"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08470v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08470v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08225v1",
    "title": "Benchmarking Educational LLMs with Analytics: A Case Study on Gender Bias in Feedback",
    "summary": "As teachers increasingly turn to GenAI in their educational practice, we need robust methods to benchmark large language models (LLMs) for pedagogical purposes. This article presents an embedding-based benchmarking framework to detect bias in LLMs in the context of formative feedback. Using 600 authentic student essays from the AES 2.0 corpus, we constructed controlled counterfactuals along two dimensions: (i) implicit cues via lexicon-based swaps of gendered terms within essays, and (ii) explicit cues via gendered author background in the prompt. We investigated six representative LLMs (i.e. GPT-5 mini, GPT-4o mini, DeepSeek-R1, DeepSeek-R1-Qwen, Gemini 2.5 Pro, Llama-3-8B). We first quantified the response divergence with cosine and Euclidean distances over sentence embeddings, then assessed significance via permutation tests, and finally, visualised structure using dimensionality reduction. In all models, implicit manipulations reliably induced larger semantic shifts for male-female counterfactuals than for female-male. Only the GPT and Llama models showed sensitivity to explicit gender cues. These findings show that even state-of-the-art LLMs exhibit asymmetric semantic responses to gender substitutions, suggesting persistent gender biases in feedback they provide learners. Qualitative analyses further revealed consistent linguistic differences (e.g., more autonomy-supportive feedback under male cues vs. more controlling feedback under female cues). We discuss implications for fairness auditing of pedagogical GenAI, propose reporting standards for counterfactual evaluation in learning analytics, and outline practical guidance for prompt design and deployment to safeguard equitable feedback.",
    "authors": [
      "Yishan Du",
      "Conrad Borchers",
      "Mutlu Cukurova"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08225v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08225v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.09036v1",
    "title": "FedSDWC: Federated Synergistic Dual-Representation Weak Causal Learning for OOD",
    "summary": "Amid growing demands for data privacy and advances in computational infrastructure, federated learning (FL) has emerged as a prominent distributed learning paradigm. Nevertheless, differences in data distribution (such as covariate and semantic shifts) severely affect its reliability in real-world deployments. To address this issue, we propose FedSDWC, a causal inference method that integrates both invariant and variant features. FedSDWC infers causal semantic representations by modeling the weak causal influence between invariant and variant features, effectively overcoming the limitations of existing invariant learning methods in accurately capturing invariant features and directly constructing causal representations. This approach significantly enhances FL's ability to generalize and detect OOD data. Theoretically, we derive FedSDWC's generalization error bound under specific conditions and, for the first time, establish its relationship with client prior distributions. Moreover, extensive experiments conducted on multiple benchmark datasets validate the superior performance of FedSDWC in handling covariate and semantic shifts. For example, FedSDWC outperforms FedICON, the next best baseline, by an average of 3.04% on CIFAR-10 and 8.11% on CIFAR-100.",
    "authors": [
      "Zhenyuan Huang",
      "Hui Zhang",
      "Wenzhong Tang",
      "Haijun Yang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09036v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09036v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08717v1",
    "title": "Optimal Control of the Future via Prospective Foraging",
    "summary": "Optimal control of the future is the next frontier for AI. Current approaches to this problem are typically rooted in either reinforcement learning or online learning. While powerful, these frameworks for learning are mathematically distinct from Probably Approximately Correct (PAC) learning, which has been the workhorse for the recent technological achievements in AI. We therefore build on the prior work of prospective learning, an extension of PAC learning (without control) in non-stationary environments (De Silva et al., 2023; Silva et al., 2024; Bai et al., 2026). Here, we further extend the PAC learning framework to address learning and control in non-stationary environments. Using this framework, called ''Prospective Control'', we prove that under certain fairly general assumptions, empirical risk minimization (ERM) asymptotically achieves the Bayes optimal policy. We then consider a specific instance of prospective control, foraging, which is a canonical task for any mobile agent, be it natural or artificial. We illustrate that existing reinforcement learning algorithms fail to learn in these non-stationary environments, and even with modifications, they are orders of magnitude less efficient than our prospective foraging agents. Code is available at: https://github.com/neurodata/ProspectiveLearningwithControl.",
    "authors": [
      "Yuxin Bai",
      "Aranyak Acharyya",
      "Ashwin De Silva",
      "Zeyu Shen",
      "James Hassett",
      "Joshua T. Vogelstein"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08717v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08717v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08887v1",
    "title": "FAST-CAD: A Fairness-Aware Framework for Non-Contact Stroke Diagnosis",
    "summary": "Stroke is an acute cerebrovascular disease, and timely diagnosis significantly improves patient survival. However, existing automated diagnosis methods suffer from fairness issues across demographic groups, potentially exacerbating healthcare disparities. In this work we propose FAST-CAD, a theoretically grounded framework that combines domain-adversarial training (DAT) with group distributionally robust optimization (Group-DRO) for fair and accurate non-contact stroke diagnosis. Our approach is built on domain adaptation and minimax fairness theory and provides convergence guarantees and fairness bounds. We curate a multimodal dataset covering 12 demographic subgroups defined by age, gender, and posture. FAST-CAD employs self-supervised encoders with adversarial domain discrimination to learn demographic-invariant representations, while Group-DRO optimizes worst-group risk to ensure robust performance across all subgroups. Extensive experiments show that our method achieves superior diagnostic performance while maintaining fairness across demographic groups, and our theoretical analysis supports the effectiveness of the unified DAT + Group-DRO framework. This work provides both practical advances and theoretical insights for fair medical AI systems.",
    "authors": [
      "Tianming Sha",
      "Zechuan Chen",
      "Zhan Cheng",
      "Haotian Zhai",
      "Xuwei Ding",
      "Junnan Li",
      "Haixiang Tang",
      "Zaoting Sun",
      "Yanchuan Tang",
      "Yongzhe Yi",
      "Yanjie Huang",
      "Anhao Li",
      "Yuan Gao",
      "Keze Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08887v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08887v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08823v1",
    "title": "DT-NVS: Diffusion Transformers for Novel View Synthesis",
    "summary": "Generating novel views of a natural scene, e.g., every-day scenes both indoors and outdoors, from a single view is an under-explored problem, even though it is an organic extension to the object-centric novel view synthesis. Existing diffusion-based approaches focus rather on small camera movements in real scenes or only consider unnatural object-centric scenes, limiting their potential applications in real-world settings. In this paper we move away from these constrained regimes and propose a 3D diffusion model trained with image-only losses on a large-scale dataset of real-world, multi-category, unaligned, and casually acquired videos of everyday scenes. We propose DT-NVS, a 3D-aware diffusion model for generalized novel view synthesis that exploits a transformer-based architecture backbone. We make significant contributions to transformer and self-attention architectures to translate images to 3d representations, and novel camera conditioning strategies to allow training on real-world unaligned datasets. In addition, we introduce a novel training paradigm swapping the role of reference frame between the conditioning image and the sampled noisy input. We evaluate our approach on the 3D task of generalized novel view synthesis from a single input image and show improvements over state-of-the-art 3D aware diffusion models and deterministic approaches, while generating diverse outputs.",
    "authors": [
      "Wonbong Jang",
      "Jonathan Tremblay",
      "Lourdes Agapito"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08823v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08823v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08667v1",
    "title": "TabPFN-2.5: Advancing the State of the Art in Tabular Foundation Models",
    "summary": "The first tabular foundation model, TabPFN, and its successor TabPFNv2 have impacted tabular AI substantially, with dozens of methods building on it and hundreds of applications across different use cases. This report introduces TabPFN-2.5, the next generation of our tabular foundation model, built for datasets with up to 50,000 data points and 2,000 features, a 20x increase in data cells compared to TabPFNv2. TabPFN-2.5 is now the leading method for the industry standard benchmark TabArena (which contains datasets with up to 100,000 training data points), substantially outperforming tuned tree-based models and matching the accuracy of AutoGluon 1.4, a complex four-hour tuned ensemble that even includes the previous TabPFNv2. Remarkably, default TabPFN-2.5 has a 100% win rate against default XGBoost on small to medium-sized classification datasets (<=10,000 data points, 500 features) and a 87% win rate on larger datasets up to 100K samples and 2K features (85% for regression). For production use cases, we introduce a new distillation engine that converts TabPFN-2.5 into a compact MLP or tree ensemble, preserving most of its accuracy while delivering orders-of-magnitude lower latency and plug-and-play deployment. This new release will immediately strengthen the performance of the many applications and methods already built on the TabPFN ecosystem.",
    "authors": [
      "Léo Grinsztajn",
      "Klemens Flöge",
      "Oscar Key",
      "Felix Birkel",
      "Philipp Jund",
      "Brendan Roof",
      "Benjamin Jäger",
      "Dominik Safaric",
      "Simone Alessi",
      "Adrian Hayler",
      "Mihir Manium",
      "Rosen Yu",
      "Felix Jablonski",
      "Shi Bin Hoo",
      "Anurag Garg",
      "Jake Robertson",
      "Magnus Bühler",
      "Vladyslav Moroshan",
      "Lennart Purucker",
      "Clara Cornu",
      "Lilly Charlotte Wehrhahn",
      "Alessandro Bonetto",
      "Bernhard Schölkopf",
      "Sauraj Gambhir",
      "Noah Hollmann",
      "Frank Hutter"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08667v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08667v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08052v1",
    "title": "Dual-Process Scaffold Reasoning for Enhancing LLM Code Debugging",
    "summary": "Recent LLMs have demonstrated sophisticated problem-solving capabilities on various benchmarks through advanced reasoning algorithms. However, the key research question of identifying reasoning steps that balance complexity and computational efficiency remains unsolved. Recent research has increasingly drawn upon psychological theories to explore strategies for optimizing cognitive pathways. The LLM's final outputs and intermediate steps are regarded as System 1 and System 2, respectively. However, an in-depth exploration of the System 2 reasoning is still lacking. Therefore, we propose a novel psychologically backed Scaffold Reasoning framework for code debugging, which encompasses the Scaffold Stream, Analytic Stream, and Integration Stream. The construction of reference code within the Scaffold Stream is integrated with the buggy code analysis results produced by the Analytic Stream through the Integration Stream. Our framework achieves an 88.91% pass rate and an average inference time of 5.36 seconds per-problem on DebugBench, outperforming other reasoning approaches across various LLMs in both reasoning accuracy and efficiency. Further analyses elucidate the advantages and limitations of various cognitive pathways across varying problem difficulties and bug types. Our findings also corroborate the alignment of the proposed Scaffold Reasoning framework with human cognitive processes.",
    "authors": [
      "Po-Chung Hsieh",
      "Chin-Po Chen",
      "Jeng-Lin Li",
      "Ming-Ching Chang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SE"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08052v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08052v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08322v1",
    "title": "Mitigating Negative Flips via Margin Preserving Training",
    "summary": "Minimizing inconsistencies across successive versions of an AI system is as crucial as reducing the overall error. In image classification, such inconsistencies manifest as negative flips, where an updated model misclassifies test samples that were previously classified correctly. This issue becomes increasingly pronounced as the number of training classes grows over time, since adding new categories reduces the margin of each class and may introduce conflicting patterns that undermine their learning process, thereby degrading performance on the original subset. To mitigate negative flips, we propose a novel approach that preserves the margins of the original model while learning an improved one. Our method encourages a larger relative margin between the previously learned and newly introduced classes by introducing an explicit margin-calibration term on the logits. However, overly constraining the logit margin for the new classes can significantly degrade their accuracy compared to a new independently trained model. To address this, we integrate a double-source focal distillation loss with the previous model and a new independently trained model, learning an appropriate decision margin from both old and new data, even under a logit margin calibration. Extensive experiments on image classification benchmarks demonstrate that our approach consistently reduces the negative flip rate with high overall accuracy.",
    "authors": [
      "Simone Ricci",
      "Niccolò Biondi",
      "Federico Pernici",
      "Alberto Del Bimbo"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08322v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08322v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.09426v1",
    "title": "BIG5-TPoT: Predicting BIG Five Personality Traits, Facets, and Items Through Targeted Preselection of Texts",
    "summary": "Predicting an individual's personalities from their generated texts is a challenging task, especially when the text volume is large. In this paper, we introduce a straightforward yet effective novel strategy called targeted preselection of texts (TPoT). This method semantically filters the texts as input to a deep learning model, specifically designed to predict a Big Five personality trait, facet, or item, referred to as the BIG5-TPoT model. By selecting texts that are semantically relevant to a particular trait, facet, or item, this strategy not only addresses the issue of input text limits in large language models but also improves the Mean Absolute Error and accuracy metrics in predictions for the Stream of Consciousness Essays dataset.",
    "authors": [
      "Triet M. Le",
      "Arjun Chandra",
      "C. Anton Rytting",
      "Valerie P. Karuzis",
      "Vladimir Rife",
      "William A. Simpson"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09426v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09426v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2511.08031v1",
    "title": "Multi-modal Deepfake Detection and Localization with FPN-Transformer",
    "summary": "The rapid advancement of generative adversarial networks (GANs) and diffusion models has enabled the creation of highly realistic deepfake content, posing significant threats to digital trust across audio-visual domains. While unimodal detection methods have shown progress in identifying synthetic media, their inability to leverage cross-modal correlations and precisely localize forged segments limits their practicality against sophisticated, fine-grained manipulations. To address this, we introduce a multi-modal deepfake detection and localization framework based on a Feature Pyramid-Transformer (FPN-Transformer), addressing critical gaps in cross-modal generalization and temporal boundary regression. The proposed approach utilizes pre-trained self-supervised models (WavLM for audio, CLIP for video) to extract hierarchical temporal features. A multi-scale feature pyramid is constructed through R-TLM blocks with localized attention mechanisms, enabling joint analysis of cross-context temporal dependencies. The dual-branch prediction head simultaneously predicts forgery probabilities and refines temporal offsets of manipulated segments, achieving frame-level localization precision. We evaluate our approach on the test set of the IJCAI'25 DDL-AV benchmark, showing a good performance with a final score of 0.7535 for cross-modal deepfake detection and localization in challenging environments. Experimental results confirm the effectiveness of our approach and provide a novel way for generalized deepfake detection. Our code is available at https://github.com/Zig-HS/MM-DDL",
    "authors": [
      "Chende Zheng",
      "Ruiqi Suo",
      "Zhoulin Ji",
      "Jingyi Deng",
      "Fangbin Yi",
      "Chenhao Lin",
      "Chao Shen"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08031v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08031v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.08387v1",
    "title": "RAPTR: Radar-based 3D Pose Estimation using Transformer",
    "summary": "Radar-based indoor 3D human pose estimation typically relied on fine-grained 3D keypoint labels, which are costly to obtain especially in complex indoor settings involving clutter, occlusions, or multiple people. In this paper, we propose \\textbf{RAPTR} (RAdar Pose esTimation using tRansformer) under weak supervision, using only 3D BBox and 2D keypoint labels which are considerably easier and more scalable to collect. Our RAPTR is characterized by a two-stage pose decoder architecture with a pseudo-3D deformable attention to enhance (pose/joint) queries with multi-view radar features: a pose decoder estimates initial 3D poses with a 3D template loss designed to utilize the 3D BBox labels and mitigate depth ambiguities; and a joint decoder refines the initial poses with 2D keypoint labels and a 3D gravity loss. Evaluated on two indoor radar datasets, RAPTR outperforms existing methods, reducing joint position error by $34.3\\%$ on HIBER and $76.9\\%$ on MMVR. Our implementation is available at https://github.com/merlresearch/radar-pose-transformer.",
    "authors": [
      "Sorachi Kato",
      "Ryoma Yataka",
      "Pu Perry Wang",
      "Pedro Miraldo",
      "Takuya Fujihashi",
      "Petros Boufounos"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.SP"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08387v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08387v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.08798v1",
    "title": "Structured Uncertainty guided Clarification for LLM Agents",
    "summary": "LLM agents extend large language models with tool-calling capabilities, but ambiguous user instructions often lead to incorrect invocations and task failures. We introduce a principled formulation of structured uncertainty over tool-call parameters, modeling joint tool-argument clarification as a POMDP with Expected Value of Perfect Information (EVPI) objective for optimal question selection and aspect-based cost modeling to prevent redundancy. Our SAGE-Agent leverages this structured uncertainty to achieve superior efficiency: increasing coverage on ambiguous tasks by 7-39\\% while reducing clarification questions by 1.5-2.7$\\times$ compared to strong prompting and uncertainty-based baselines. We present ClarifyBench, the first multi-turn tool-augmented disambiguation benchmark with realistic LLM-based user simulation across diverse domains including document editing, vehicle control, and travel booking. Additionally, we demonstrate that structured uncertainty provides effective training signals for reinforcement learning, boosting When2Call accuracy from 36.5\\% to 65.2\\% (3B model) and 36.7\\% to 62.9\\% (7B model) through uncertainty-weighted GRPO training. These results establish structured uncertainty as a principled, efficient approach for tool-augmented agents, improving both task success and interaction efficiency in real-world scenarios.",
    "authors": [
      "Manan Suri",
      "Puneet Mathur",
      "Nedim Lipka",
      "Franck Dernoncourt",
      "Ryan A. Rossi",
      "Dinesh Manocha"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08798v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08798v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2511.08821v1",
    "title": "BayesQ: Uncertainty-Guided Bayesian Quantization",
    "summary": "We present BayesQ, an uncertainty-guided post-training quantization framework that is the first to optimize quantization under the posterior expected loss. BayesQ fits a lightweight Gaussian posterior over weights (diagonal Laplace by default; optional K-FAC/low-rank), whitens by the posterior covariance, designs codebooks to minimize posterior-expected distortion, and allocates mixed precision via a greedy knapsack that maximizes marginal expected-loss reduction per bit under a global budget. For scalar quantizers, posterior-expected MSE yields closed-form tables; task-aware proxies are handled by short Monte Carlo on a small calibration set. An optional calibration-only distillation aligns the quantized model with the posterior predictive teacher. At matched average bits/weight of 3.0/3.5/4.0, BayesQ improves over strong PTQ baselines on ResNet-50 (ImageNet) and BERT-base (GLUE) e.g., vs. GPTQ by $+1.5/+0.7/+0.3$ top-1 percentage points on RN50 and $+1.1/+0.4/+0.2$ GLUE points on BERT, while requiring one-time preprocessing comparable to a GPTQ pass. BayesQ reframes low-bit quantization as uncertainty-aware risk minimization in a practical, post-training pipeline.",
    "authors": [
      "Ismail Lamaakal",
      "Chaymae Yahyati",
      "Yassine Maleh",
      "Khalid El Makkaoui",
      "Ibrahim Ouahbi"
    ],
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08821v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08821v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.08577v1",
    "title": "Think-at-Hard: Selective Latent Iterations to Improve Reasoning Language Models",
    "summary": "Improving reasoning capabilities of Large Language Models (LLMs), especially under parameter constraints, is crucial for real-world applications. Prior work proposes recurrent transformers, which allocate a fixed number of extra iterations per token to improve generation quality. After the first, standard forward pass, instead of verbalization, last-layer hidden states are fed back as inputs for additional iterations to refine token predictions. Yet we identify a latent overthinking phenomenon: easy token predictions that are already correct after the first pass are sometimes revised into errors in additional iterations. To address this, we propose Think-at-Hard (TaH), a dynamic latent thinking method that iterates deeper only at hard tokens. It employs a lightweight neural decider to trigger latent iterations only at tokens that are likely incorrect after the standard forward pass. During latent iterations, Low-Rank Adaptation (LoRA) modules shift the LLM objective from general next-token prediction to focused hard-token refinement. We further introduce a duo-causal attention mechanism that extends attention from the token sequence dimension to an additional iteration depth dimension. This enables cross-iteration information flow while maintaining full sequential parallelism. Experiments show that TaH boosts LLM reasoning performance across five challenging benchmarks while maintaining the same parameter count. Compared with baselines that iterate twice for all output tokens, TaH delivers 8.1-11.3% accuracy gains while exempting 94% of tokens from the second iteration. Against strong single-iteration Qwen3 models finetuned with the same data, it also delivers 4.0-5.0% accuracy gains. When allowing less than 3% additional parameters from LoRA and the iteration decider, the gains increase to 8.5-12.6% and 5.3-5.4%, respectively. Our code is available at https://github.com/thu-nics/TaH.",
    "authors": [
      "Tianyu Fu",
      "Yichen You",
      "Zekai Chen",
      "Guohao Dai",
      "Huazhong Yang",
      "Yu Wang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08577v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08577v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.09149v1",
    "title": "Enabling Agents to Communicate Entirely in Latent Space",
    "summary": "While natural language is the de facto communication medium for LLM-based agents, it presents a fundamental constraint. The process of downsampling rich, internal latent states into discrete tokens inherently limits the depth and nuance of information that can be transmitted, thereby hindering collaborative problem-solving. Inspired by human mind-reading, we propose Interlat (Inter-agent Latent Space Communication), a paradigm that leverages the last hidden states of an LLM as a representation of its mind for direct transmission (termed latent communication). An additional compression process further compresses latent communication via entirely latent space reasoning. Experiments demonstrate that Interlat outperforms both fine-tuned chain-of-thought (CoT) prompting and single-agent baselines, promoting more exploratory behavior and enabling genuine utilization of latent information. Further compression not only substantially accelerates inference but also maintains competitive performance through an efficient information-preserving mechanism. We position this work as a feasibility study of entirely latent space inter-agent communication, and our results highlight its potential, offering valuable insights for future research.",
    "authors": [
      "Zhuoyun Du",
      "Runze Wang",
      "Huiyu Bai",
      "Zouying Cao",
      "Xiaoyong Zhu",
      "Bo Zheng",
      "Wei Chen",
      "Haochao Ying"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09149v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09149v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.08274v1",
    "title": "Multi-Agent GraphRAG: A Text-to-Cypher Framework for Labeled Property Graphs",
    "summary": "While Retrieval-Augmented Generation (RAG) methods commonly draw information from unstructured documents, the emerging paradigm of GraphRAG aims to leverage structured data such as knowledge graphs. Most existing GraphRAG efforts focus on Resource Description Framework (RDF) knowledge graphs, relying on triple representations and SPARQL queries. However, the potential of Cypher and Labeled Property Graph (LPG) databases to serve as scalable and effective reasoning engines within GraphRAG pipelines remains underexplored in current research literature. To fill this gap, we propose Multi-Agent GraphRAG, a modular LLM agentic system for text-to-Cypher query generation serving as a natural language interface to LPG-based graph data. Our proof-of-concept system features an LLM-based workflow for automated Cypher queries generation and execution, using Memgraph as the graph database backend. Iterative content-aware correction and normalization, reinforced by an aggregated feedback loop, ensures both semantic and syntactic refinement of generated queries. We evaluate our system on the CypherBench graph dataset covering several general domains with diverse types of queries. In addition, we demonstrate performance of the proposed workflow on a property graph derived from the IFC (Industry Foundation Classes) data, representing a digital twin of a building. This highlights how such an approach can bridge AI with real-world applications at scale, enabling industrial digital automation use cases.",
    "authors": [
      "Anton Gusarov",
      "Anastasia Volkova",
      "Valentin Khrulkov",
      "Andrey Kuznetsov",
      "Evgenii Maslov",
      "Ivan Oseledets"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08274v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08274v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.09292v1",
    "title": "C$^3$TG: Conflict-aware, Composite, and Collaborative Controlled Text Generation",
    "summary": "Recent advancements in large language models (LLMs) have demonstrated remarkable text generation capabilities. However, controlling specific attributes of generated text remains challenging without architectural modifications or extensive fine-tuning. Current methods typically toggle a single, basic attribute but struggle with precise multi-attribute control. In scenarios where attribute requirements conflict, existing methods lack coordination mechanisms, causing interference between desired attributes. Furthermore, these methods fail to incorporate iterative optimization processes in the controlled generation pipeline. To address these limitations, we propose Conflict-aware, Composite, and Collaborative Controlled Text Generation (C$^3$TG), a two-phase framework for fine-grained, multi-dimensional text attribute control. During generation, C$^3$TG selectively pairs the LLM with the required attribute classifiers from the 17 available dimensions and employs weighted KL-divergence to adjust token probabilities. The optimization phase then leverages an energy function combining classifier scores and penalty terms to resolve attribute conflicts through iterative feedback, enabling precise control over multiple dimensions simultaneously while preserving natural text flow. Experiments show that C$^3$TG significantly outperforms baselines across multiple metrics including attribute accuracy, linguistic fluency, and output diversity, while simultaneously reducing toxicity. These results establish C$^3$TG as an effective and flexible solution for multi-dimensional text attribute control that requires no costly model modifications.",
    "authors": [
      "Yu Li",
      "Zhe Yang",
      "Yi Huang",
      "Xin Liu",
      "Guilin Qi"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09292v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09292v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.07931v1",
    "title": "SpeechJudge: Towards Human-Level Judgment for Speech Naturalness",
    "summary": "Aligning large generative models with human feedback is a critical challenge. In speech synthesis, this is particularly pronounced due to the lack of a large-scale human preference dataset, which hinders the development of models that truly align with human perception. To address this, we introduce SpeechJudge, a comprehensive suite comprising a dataset, a benchmark, and a reward model centered on naturalness--one of the most fundamental subjective metrics for speech synthesis. First, we present SpeechJudge-Data, a large-scale human feedback corpus of 99K speech pairs. The dataset is constructed using a diverse set of advanced zero-shot text-to-speech (TTS) models across diverse speech styles and multiple languages, with human annotations for both intelligibility and naturalness preference. From this, we establish SpeechJudge-Eval, a challenging benchmark for speech naturalness judgment. Our evaluation reveals that existing metrics and AudioLLMs struggle with this task; the leading model, Gemini-2.5-Flash, achieves less than 70% agreement with human judgment, highlighting a significant gap for improvement. To bridge this gap, we develop SpeechJudge-GRM, a generative reward model (GRM) based on Qwen2.5-Omni-7B. It is trained on SpeechJudge-Data via a two-stage post-training process: Supervised Fine-Tuning (SFT) with Chain-of-Thought rationales followed by Reinforcement Learning (RL) with GRPO on challenging cases. On the SpeechJudge-Eval benchmark, the proposed SpeechJudge-GRM demonstrates superior performance, achieving 77.2% accuracy (and 79.4% after inference-time scaling @10) compared to a classic Bradley-Terry reward model (72.7%). Furthermore, SpeechJudge-GRM can be also employed as a reward function during the post-training of speech generation models to facilitate their alignment with human preferences.",
    "authors": [
      "Xueyao Zhang",
      "Chaoren Wang",
      "Huan Liao",
      "Ziniu Li",
      "Yuancheng Wang",
      "Li Wang",
      "Dongya Jia",
      "Yuanzhe Chen",
      "Xiulin Li",
      "Zhuo Chen",
      "Zhizheng Wu"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07931v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07931v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.08077v1",
    "title": "An Integrated Fusion Framework for Ensemble Learning Leveraging Gradient Boosting and Fuzzy Rule-Based Models",
    "summary": "The integration of different learning paradigms has long been a focus of machine learning research, aimed at overcoming the inherent limitations of individual methods. Fuzzy rule-based models excel in interpretability and have seen widespread application across diverse fields. However, they face challenges such as complex design specifications and scalability issues with large datasets. The fusion of different techniques and strategies, particularly Gradient Boosting, with Fuzzy Rule-Based Models offers a robust solution to these challenges. This paper proposes an Integrated Fusion Framework that merges the strengths of both paradigms to enhance model performance and interpretability. At each iteration, a Fuzzy Rule-Based Model is constructed and controlled by a dynamic factor to optimize its contribution to the overall ensemble. This control factor serves multiple purposes: it prevents model dominance, encourages diversity, acts as a regularization parameter, and provides a mechanism for dynamic tuning based on model performance, thus mitigating the risk of overfitting. Additionally, the framework incorporates a sample-based correction mechanism that allows for adaptive adjustments based on feedback from a validation set. Experimental results substantiate the efficacy of the presented gradient boosting framework for fuzzy rule-based models, demonstrating performance enhancement, especially in terms of mitigating overfitting and complexity typically associated with many rules. By leveraging an optimal factor to govern the contribution of each model, the framework improves performance, maintains interpretability, and simplifies the maintenance and update of the models.",
    "authors": [
      "Jinbo Li",
      "Peng Liu",
      "Long Chen",
      "Witold Pedrycz",
      "Weiping Ding"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08077v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08077v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.09465v1",
    "title": "Branching Flows: Discrete, Continuous, and Manifold Flow Matching with Splits and Deletions",
    "summary": "Diffusion and flow matching approaches to generative modeling have shown promise in domains where the state space is continuous, such as image generation or protein folding & design, and discrete, exemplified by diffusion large language models. They offer a natural fit when the number of elements in a state is fixed in advance (e.g. images), but require ad hoc solutions when, for example, the length of a response from a large language model, or the number of amino acids in a protein chain is not known a priori.   Here we propose Branching Flows, a generative modeling framework that, like diffusion and flow matching approaches, transports a simple distribution to the data distribution. But in Branching Flows, the elements in the state evolve over a forest of binary trees, branching and dying stochastically with rates that are learned by the model. This allows the model to control, during generation, the number of elements in the sequence. We also show that Branching Flows can compose with any flow matching base process on discrete sets, continuous Euclidean spaces, smooth manifolds, and `multimodal' product spaces that mix these components. We demonstrate this in three domains: small molecule generation (multimodal), antibody sequence generation (discrete), and protein backbone generation (multimodal), and show that Branching Flows is a capable distribution learner with a stable learning objective, and that it enables new capabilities.",
    "authors": [
      "Hedwig Nora Nordlinder",
      "Lukas Billera",
      "Jack Collier Ryder",
      "Anton Oresten",
      "Aron Stålmarck",
      "Theodor Mosetti Björk",
      "Ben Murrell"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09465v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09465v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.07989v1",
    "title": "State of the Art in Text Classification for South Slavic Languages: Fine-Tuning or Prompting?",
    "summary": "Until recently, fine-tuned BERT-like models provided state-of-the-art performance on text classification tasks. With the rise of instruction-tuned decoder-only models, commonly known as large language models (LLMs), the field has increasingly moved toward zero-shot and few-shot prompting. However, the performance of LLMs on text classification, particularly on less-resourced languages, remains under-explored. In this paper, we evaluate the performance of current language models on text classification tasks across several South Slavic languages. We compare openly available fine-tuned BERT-like models with a selection of open-source and closed-source LLMs across three tasks in three domains: sentiment classification in parliamentary speeches, topic classification in news articles and parliamentary speeches, and genre identification in web texts. Our results show that LLMs demonstrate strong zero-shot performance, often matching or surpassing fine-tuned BERT-like models. Moreover, when used in a zero-shot setup, LLMs perform comparably in South Slavic languages and English. However, we also point out key drawbacks of LLMs, including less predictable outputs, significantly slower inference, and higher computational costs. Due to these limitations, fine-tuned BERT-like models remain a more practical choice for large-scale automatic text annotation.",
    "authors": [
      "Taja Kuzman Pungeršek",
      "Peter Rupnik",
      "Ivan Porupski",
      "Vuk Dinić",
      "Nikola Ljubešić"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07989v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07989v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2511.07732v1",
    "title": "ViPRA: Video Prediction for Robot Actions",
    "summary": "Can we turn a video prediction model into a robot policy? Videos, including those of humans or teleoperated robots, capture rich physical interactions. However, most of them lack labeled actions, which limits their use in robot learning. We present Video Prediction for Robot Actions (ViPRA), a simple pretraining-finetuning framework that learns continuous robot control from these actionless videos. Instead of directly predicting actions, we train a video-language model to predict both future visual observations and motion-centric latent actions, which serve as intermediate representations of scene dynamics. We train these latent actions using perceptual losses and optical flow consistency to ensure they reflect physically grounded behavior. For downstream control, we introduce a chunked flow matching decoder that maps latent actions to robot-specific continuous action sequences, using only 100 to 200 teleoperated demonstrations. This approach avoids expensive action annotation, supports generalization across embodiments, and enables smooth, high-frequency continuous control upto 22 Hz via chunked action decoding. Unlike prior latent action works that treat pretraining as autoregressive policy learning, explicitly models both what changes and how. Our method outperforms strong baselines, with a 16% gain on the SIMPLER benchmark and a 13% improvement across real world manipulation tasks. We will release models and code at https://vipra-project.github.io",
    "authors": [
      "Sandeep Routray",
      "Hengkai Pan",
      "Unnat Jain",
      "Shikhar Bahl",
      "Deepak Pathak"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07732v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07732v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.07876v1",
    "title": "LoopLLM: Transferable Energy-Latency Attacks in LLMs via Repetitive Generation",
    "summary": "As large language models (LLMs) scale, their inference incurs substantial computational resources, exposing them to energy-latency attacks, where crafted prompts induce high energy and latency cost. Existing attack methods aim to prolong output by delaying the generation of termination symbols. However, as the output grows longer, controlling the termination symbols through input becomes difficult, making these methods less effective. Therefore, we propose LoopLLM, an energy-latency attack framework based on the observation that repetitive generation can trigger low-entropy decoding loops, reliably compelling LLMs to generate until their output limits. LoopLLM introduces (1) a repetition-inducing prompt optimization that exploits autoregressive vulnerabilities to induce repetitive generation, and (2) a token-aligned ensemble optimization that aggregates gradients to improve cross-model transferability. Extensive experiments on 12 open-source and 2 commercial LLMs show that LoopLLM significantly outperforms existing methods, achieving over 90% of the maximum output length, compared to 20% for baselines, and improving transferability by around 40% to DeepSeek-V3 and Gemini 2.5 Flash.",
    "authors": [
      "Xingyu Li",
      "Xiaolei Liu",
      "Cheng Liu",
      "Yixiao Xu",
      "Kangyi Ding",
      "Bangzhou Xin",
      "Jia-Li Yin"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07876v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07876v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.07990v1",
    "title": "Hardware-Aware YOLO Compression for Low-Power Edge AI on STM32U5 for Weeds Detection in Digital Agriculture",
    "summary": "Weeds significantly reduce crop yields worldwide and pose major challenges to sustainable agriculture. Traditional weed management methods, primarily relying on chemical herbicides, risk environmental contamination and lead to the emergence of herbicide-resistant species. Precision weeding, leveraging computer vision and machine learning methods, offers a promising eco-friendly alternative but is often limited by reliance on high-power computational platforms. This work presents an optimized, low-power edge AI system for weeds detection based on the YOLOv8n object detector deployed on the STM32U575ZI microcontroller. Several compression techniques are applied to the detection model, including structured pruning, integer quantization and input image resolution scaling in order to meet strict hardware constraints. The model is trained and evaluated on the CropAndWeed dataset with 74 plant species, achieving a balanced trade-off between detection accuracy and efficiency. Our system supports real-time, in-situ weeds detection with a minimal energy consumption of 51.8mJ per inference, enabling scalable deployment in power-constrained agricultural environments.",
    "authors": [
      "Charalampos S. Kouzinopoulos",
      "Yuri Manna"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07990v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07990v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.09216v1",
    "title": "Controllable protein design through Feynman-Kac steering",
    "summary": "Diffusion-based models have recently enabled the generation of realistic and diverse protein structures, yet they remain limited in their ability to steer outcomes toward specific functional or biochemical objectives, such as binding affinity or sequence composition. Here we extend the Feynman-Kac (FK) steering framework, an inference-time control approach, to diffusion-based protein design. By coupling FK steering with structure generation, the method guides sampling toward desirable structural or energetic features while maintaining the diversity of the underlying diffusion process. To enable simultaneous generation of both sequence and structure properties, rewards are computed on models refined through ProteinMPNN and all-atom relaxation. Applied to binder design, FK steering consistently improves predicted interface energetics across diverse targets with minimal computational overhead. More broadly, this work demonstrates that inference-time FK control generalizes diffusion-based protein design to arbitrary, non-differentiable, and reward-agnostic objectives, providing a unified and model-independent framework for guided molecular generation.",
    "authors": [
      "Erik Hartman",
      "Jonas Wallin",
      "Johan Malmström",
      "Jimmy Olsson"
    ],
    "categories": [
      "cs.LG",
      "q-bio.QM",
      "stat.ML"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09216v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09216v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.08046v1",
    "title": "ProSona: Prompt-Guided Personalization for Multi-Expert Medical Image Segmentation",
    "summary": "Automated medical image segmentation suffers from high inter-observer variability, particularly in tasks such as lung nodule delineation, where experts often disagree. Existing approaches either collapse this variability into a consensus mask or rely on separate model branches for each annotator. We introduce ProSona, a two-stage framework that learns a continuous latent space of annotation styles, enabling controllable personalization via natural language prompts. A probabilistic U-Net backbone captures diverse expert hypotheses, while a prompt-guided projection mechanism navigates this latent space to generate personalized segmentations. A multi-level contrastive objective aligns textual and visual representations, promoting disentangled and interpretable expert styles. Across the LIDC-IDRI lung nodule and multi-institutional prostate MRI datasets, ProSona reduces the Generalized Energy Distance by 17% and improves mean Dice by more than one point compared with DPersona. These results demonstrate that natural-language prompts can provide flexible, accurate, and interpretable control over personalized medical image segmentation. Our implementation is available online 1 .",
    "authors": [
      "Aya Elgebaly",
      "Nikolaos Delopoulos",
      "Juliane Hörner-Rieber",
      "Carolin Rippke",
      "Sebastian Klüter",
      "Luca Boldrini",
      "Lorenzo Placidi",
      "Riccardo Dal Bello",
      "Nicolaus Andratschke",
      "Michael Baumgartl",
      "Claus Belka",
      "Christopher Kurz",
      "Guillaume Landry",
      "Shadi Albarqouni"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08046v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08046v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.08399v1",
    "title": "Aligning by Misaligning: Boundary-aware Curriculum Learning for Multimodal Alignment",
    "summary": "Most multimodal models treat every negative pair alike, ignoring the ambiguous negatives that differ from the positive by only a small detail. We propose Boundary-Aware Curriculum with Local Attention (BACL), a lightweight add-on that turns these borderline cases into a curriculum signal. A Boundary-aware Negative Sampler gradually raises difficulty, while a Contrastive Local Attention loss highlights where the mismatch occurs. The two modules are fully differentiable and work with any off-the-shelf dual encoder. Theory predicts a fast O(1/n) error rate; practice shows up to +32% R@1 over CLIP and new SOTA on four large-scale benchmarks, all without extra labels.",
    "authors": [
      "Hua Ye",
      "Hang Ding",
      "Siyuan Chen",
      "Yiyang Jiang",
      "Changyuan Zhang",
      "Xuan Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08399v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08399v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.09316v1",
    "title": "AdaptDel: Adaptable Deletion Rate Randomized Smoothing for Certified Robustness",
    "summary": "We consider the problem of certified robustness for sequence classification against edit distance perturbations. Naturally occurring inputs of varying lengths (e.g., sentences in natural language processing tasks) present a challenge to current methods that employ fixed-rate deletion mechanisms and lead to suboptimal performance. To this end, we introduce AdaptDel methods with adaptable deletion rates that dynamically adjust based on input properties. We extend the theoretical framework of randomized smoothing to variable-rate deletion, ensuring sound certification with respect to edit distance. We achieve strong empirical results in natural language tasks, observing up to 30 orders of magnitude improvement to median cardinality of the certified region, over state-of-the-art certifications.",
    "authors": [
      "Zhuoqun Huang",
      "Neil G. Marchant",
      "Olga Ohrimenko",
      "Benjamin I. P. Rubinstein"
    ],
    "categories": [
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09316v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09316v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.08507v1",
    "title": "Introducing A Bangla Sentence - Gloss Pair Dataset for Bangla Sign Language Translation and Research",
    "summary": "Bangla Sign Language (BdSL) translation represents a low-resource NLP task due to the lack of large-scale datasets that address sentence-level translation. Correspondingly, existing research in this field has been limited to word and alphabet level detection. In this work, we introduce Bangla-SGP, a novel parallel dataset consisting of 1,000 human-annotated sentence-gloss pairs which was augmented with around 3,000 synthetically generated pairs using syntactic and morphological rules through a rule-based Retrieval-Augmented Generation (RAG) pipeline. The gloss sequences of the spoken Bangla sentences are made up of individual glosses which are Bangla sign supported words and serve as an intermediate representation for a continuous sign. Our dataset consists of 1000 high quality Bangla sentences that are manually annotated into a gloss sequence by a professional signer. The augmentation process incorporates rule-based linguistic strategies and prompt engineering techniques that we have adopted by critically analyzing our human annotated sentence-gloss pairs and by working closely with our professional signer. Furthermore, we fine-tune several transformer-based models such as mBart50, Google mT5, GPT4.1-nano and evaluate their sentence-to-gloss translation performance using BLEU scores, based on these evaluation metrics we compare the model's gloss-translation consistency across our dataset and the RWTH-PHOENIX-2014T benchmark.",
    "authors": [
      "Neelavro Saha",
      "Rafi Shahriyar",
      "Nafis Ashraf Roudra",
      "Saadman Sakib",
      "Annajiat Alim Rasel"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08507v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08507v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.09298v1",
    "title": "DensiCrafter: Physically-Constrained Generation and Fabrication of Self-Supporting Hollow Structures",
    "summary": "The rise of 3D generative models has enabled automatic 3D geometry and texture synthesis from multimodal inputs (e.g., text or images). However, these methods often ignore physical constraints and manufacturability considerations. In this work, we address the challenge of producing 3D designs that are both lightweight and self-supporting. We present DensiCrafter, a framework for generating lightweight, self-supporting 3D hollow structures by optimizing the density field. Starting from coarse voxel grids produced by Trellis, we interpret these as continuous density fields to optimize and introduce three differentiable, physically constrained, and simulation-free loss terms. Additionally, a mass regularization penalizes unnecessary material, while a restricted optimization domain preserves the outer surface. Our method seamlessly integrates with pretrained Trellis-based models (e.g., Trellis, DSO) without any architectural changes. In extensive evaluations, we achieve up to 43% reduction in material mass on the text-to-3D task. Compared to state-of-the-art baselines, our method could improve the stability and maintain high geometric fidelity. Real-world 3D-printing experiments confirm that our hollow designs can be reliably fabricated and could be self-supporting.",
    "authors": [
      "Shengqi Dang",
      "Fu Chai",
      "Jiaxin Li",
      "Chao Yuan",
      "Wei Ye",
      "Nan Cao"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09298v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09298v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2511.09057v1",
    "title": "PAN: A World Model for General, Interactable, and Long-Horizon World Simulation",
    "summary": "A world model enables an intelligent agent to imagine, predict, and reason about how the world evolves in response to its actions, and accordingly to plan and strategize. While recent video generation models produce realistic visual sequences, they typically operate in the prompt-to-full-video manner without causal control, interactivity, or long-horizon consistency required for purposeful reasoning. Existing world modeling efforts, on the other hand, often focus on restricted domains (e.g., physical, game, or 3D-scene dynamics) with limited depth and controllability, and struggle to generalize across diverse environments and interaction formats. In this work, we introduce PAN, a general, interactable, and long-horizon world model that predicts future world states through high-quality video simulation conditioned on history and natural language actions. PAN employs the Generative Latent Prediction (GLP) architecture that combines an autoregressive latent dynamics backbone based on a large language model (LLM), which grounds simulation in extensive text-based knowledge and enables conditioning on language-specified actions, with a video diffusion decoder that reconstructs perceptually detailed and temporally coherent visual observations, to achieve a unification between latent space reasoning (imagination) and realizable world dynamics (reality). Trained on large-scale video-action pairs spanning diverse domains, PAN supports open-domain, action-conditioned simulation with coherent, long-term dynamics. Extensive experiments show that PAN achieves strong performance in action-conditioned world simulation, long-horizon forecasting, and simulative reasoning compared to other video generators and world models, taking a step towards general world models that enable predictive simulation of future world states for reasoning and acting.",
    "authors": [
      " PAN Team",
      "Jiannan Xiang",
      "Yi Gu",
      "Zihan Liu",
      "Zeyu Feng",
      "Qiyue Gao",
      "Yiyan Hu",
      "Benhao Huang",
      "Guangyi Liu",
      "Yichi Yang",
      "Kun Zhou",
      "Davit Abrahamyan",
      "Arif Ahmad",
      "Ganesh Bannur",
      "Junrong Chen",
      "Kimi Chen",
      "Mingkai Deng",
      "Ruobing Han",
      "Xinqi Huang",
      "Haoqiang Kang",
      "Zheqi Li",
      "Enze Ma",
      "Hector Ren",
      "Yashowardhan Shinde",
      "Rohan Shingre",
      "Ramsundar Tanikella",
      "Kaiming Tao",
      "Dequan Yang",
      "Xinle Yu",
      "Cong Zeng",
      "Binglin Zhou",
      "Hector Liu",
      "Zhiting Hu",
      "Eric P. Xing"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09057v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09057v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07976v1",
    "title": "Morphing Through Time: Diffusion-Based Bridging of Temporal Gaps for Robust Alignment in Change Detection",
    "summary": "Remote sensing change detection is often challenged by spatial misalignment between bi-temporal images, especially when acquisitions are separated by long seasonal or multi-year gaps. While modern convolutional and transformer-based models perform well on aligned data, their reliance on precise co-registration limits their robustness in real-world conditions. Existing joint registration-detection frameworks typically require retraining and transfer poorly across domains. We introduce a modular pipeline that improves spatial and temporal robustness without altering existing change detection networks. The framework integrates diffusion-based semantic morphing, dense registration, and residual flow refinement. A diffusion module synthesizes intermediate morphing frames that bridge large appearance gaps, enabling RoMa to estimate stepwise correspondences between consecutive frames. The composed flow is then refined through a lightweight U-Net to produce a high-fidelity warp that co-registers the original image pair. Extensive experiments on LEVIR-CD, WHU-CD, and DSIFN-CD show consistent gains in both registration accuracy and downstream change detection across multiple backbones, demonstrating the generality and effectiveness of the proposed approach.",
    "authors": [
      "Seyedehanita Madani",
      "Vishal M. Patel"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07976v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07976v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.09147v1",
    "title": "PressTrack-HMR: Pressure-Based Top-Down Multi-Person Global Human Mesh Recovery",
    "summary": "Multi-person global human mesh recovery (HMR) is crucial for understanding crowd dynamics and interactions. Traditional vision-based HMR methods sometimes face limitations in real-world scenarios due to mutual occlusions, insufficient lighting, and privacy concerns. Human-floor tactile interactions offer an occlusion-free and privacy-friendly alternative for capturing human motion. Existing research indicates that pressure signals acquired from tactile mats can effectively estimate human pose in single-person scenarios. However, when multiple individuals walk randomly on the mat simultaneously, how to distinguish intermingled pressure signals generated by different persons and subsequently acquire individual temporal pressure data remains a pending challenge for extending pressure-based HMR to the multi-person situation. In this paper, we present \\textbf{PressTrack-HMR}, a top-down pipeline that recovers multi-person global human meshes solely from pressure signals. This pipeline leverages a tracking-by-detection strategy to first identify and segment each individual's pressure signal from the raw pressure data, and subsequently performs HMR for each extracted individual signal. Furthermore, we build a multi-person interaction pressure dataset \\textbf{MIP}, which facilitates further research into pressure-based human motion analysis in multi-person scenarios. Experimental results demonstrate that our method excels in multi-person HMR using pressure data, with 89.2~$mm$ MPJPE and 112.6~$mm$ WA-MPJPE$_{100}$, and these showcase the potential of tactile mats for ubiquitous, privacy-preserving multi-person action recognition. Our dataset \\& code are available at https://github.com/Jiayue-Yuan/PressTrack-HMR.",
    "authors": [
      "Jiayue Yuan",
      "Fangting Xie",
      "Guangwen Ouyang",
      "Changhai Ma",
      "Ziyu Wu",
      "Heyu Ding",
      "Quan Wan",
      "Yi Ke",
      "Yuchen Wu",
      "Xiaohui Cai"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09147v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09147v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07930v1",
    "title": "IBMA: An Imputation-Based Mixup Augmentation Using Self-Supervised Learning for Time Series Data",
    "summary": "Data augmentation in time series forecasting plays a crucial role in enhancing model performance by introducing variability while maintaining the underlying temporal patterns. However, time series data offers fewer augmentation strategies compared to fields such as image or text, with advanced techniques like Mixup rarely being used. In this work, we propose a novel approach, Imputation-Based Mixup Augmentation (IBMA), which combines Imputation-Augmented data with Mixup augmentation to bolster model generalization and improve forecasting performance. We evaluate the effectiveness of this method across several forecasting models, including DLinear (MLP), TimesNet (CNN), and iTrainformer (Transformer), these models represent some of the most recent advances in time series forecasting. Our experiments, conducted on four datasets (ETTh1, ETTh2, ETTm1, ETTm2) and compared against eight other augmentation techniques, demonstrate that IBMA consistently enhances performance, achieving 22 improvements out of 24 instances, with 10 of those being the best performances, particularly with iTrainformer imputation.",
    "authors": [
      "Dang Nha Nguyen",
      "Hai Dang Nguyen",
      "Khoa Tho Anh Nguyen"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07930v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07930v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.09118v1",
    "title": "Learning to Validate Generative Models: a Goodness-of-Fit Approach",
    "summary": "Generative models are increasingly central to scientific workflows, yet their systematic use and interpretation require a proper understanding of their limitations through rigorous validation. Classic approaches struggle with scalability, statistical power, or interpretability when applied to high-dimensional data, making it difficult to certify the reliability of these models in realistic, high-dimensional scientific settings. Here, we propose the use of the New Physics Learning Machine (NPLM), a learning based approach to goodness-of-fit testing inspired by the Neyman-Pearson construction, to test generative networks trained on high-dimensional scientific data. We demonstrate the performance of NPLM for validation in two benchmark cases: generative models trained on mixtures of Gaussian models with increasing dimensionality, and a public end-to-end generator for the Large Hadron Collider called FlashSim, trained on jet data, typical in the field of high-energy physics. We demonstrate that the NPLM can serve as a powerful validation method while also providing a means to diagnose sub-optimally modeled regions of the data.",
    "authors": [
      "Pietro Cappelli",
      "Gaia Grosso",
      "Marco Letizia",
      "Humberto Reyes-González",
      "Marco Zanetti"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "hep-ex",
      "hep-ph"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09118v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09118v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.08080v1",
    "title": "Hierarchical Structure-Property Alignment for Data-Efficient Molecular Generation and Editing",
    "summary": "Property-constrained molecular generation and editing are crucial in AI-driven drug discovery but remain hindered by two factors: (i) capturing the complex relationships between molecular structures and multiple properties remains challenging, and (ii) the narrow coverage and incomplete annotations of molecular properties weaken the effectiveness of property-based models. To tackle these limitations, we propose HSPAG, a data-efficient framework featuring hierarchical structure-property alignment. By treating SMILES and molecular properties as complementary modalities, the model learns their relationships at atom, substructure, and whole-molecule levels. Moreover, we select representative samples through scaffold clustering and hard samples via an auxiliary variational auto-encoder (VAE), substantially reducing the required pre-training data. In addition, we incorporate a property relevance-aware masking mechanism and diversified perturbation strategies to enhance generation quality under sparse annotations. Experiments demonstrate that HSPAG captures fine-grained structure-property relationships and supports controllable generation under multiple property constraints. Two real-world case studies further validate the editing capabilities of HSPAG.",
    "authors": [
      "Ziyu Fan",
      "Zhijian Huang",
      "Yahan Li",
      "Xiaowen Hu",
      "Siyuan Shen",
      "Yunliang Wang",
      "Zeyu Zhong",
      "Shuhong Liu",
      "Shuning Yang",
      "Shangqian Wu",
      "Min Wu",
      "Lei Deng"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08080v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08080v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07897v1",
    "title": "Data Descriptions from Large Language Models with Influence Estimation",
    "summary": "Deep learning models have been successful in many areas but understanding their behaviors still remains a black-box. Most prior explainable AI (XAI) approaches have focused on interpreting and explaining how models make predictions. In contrast, we would like to understand how data can be explained with deep learning model training and propose a novel approach to understand the data via one of the most common media - language - so that humans can easily understand. Our approach proposes a pipeline to generate textual descriptions that can explain the data with large language models by incorporating external knowledge bases. However, generated data descriptions may still include irrelevant information, so we introduce to exploit influence estimation to choose the most informative textual descriptions, along with the CLIP score. Furthermore, based on the phenomenon of cross-modal transferability, we propose a novel benchmark task named cross-modal transfer classification to examine the effectiveness of our textual descriptions. In the experiment of zero-shot setting, we show that our textual descriptions are more effective than other baseline descriptions, and furthermore, we successfully boost the performance of the model trained only on images across all nine image classification datasets. These results are further supported by evaluation using GPT-4o. Through our approach, we may gain insights into the inherent interpretability of the decision-making process of the model.",
    "authors": [
      "Chaeri Kim",
      "Jaeyeon Bae",
      "Taehwan Kim"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07897v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07897v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.08927v1",
    "title": "The Double Contingency Problem: AI Recursion and the Limits of Interspecies Understanding",
    "summary": "Current bioacoustic AI systems achieve impressive cross-species performance by processing animal communication through transformer architectures, foundation model paradigms, and other computational approaches. However, these approaches overlook a fundamental question: what happens when one form of recursive cognition--AI systems with their attention mechanisms, iterative processing, and feedback loops--encounters the recursive communicative processes of other species? Drawing on philosopher Yuk Hui's work on recursivity and contingency, I argue that AI systems are not neutral pattern detectors but recursive cognitive agents whose own information processing may systematically obscure or distort other species' communicative structures. This creates a double contingency problem: each species' communication emerges through contingent ecological and evolutionary conditions, while AI systems process these signals through their own contingent architectural and training conditions. I propose that addressing this challenge requires reconceptualizing bioacoustic AI from universal pattern recognition toward diplomatic encounter between different forms of recursive cognition, with implications for model design, evaluation frameworks, and research methodologies.",
    "authors": [
      "Graham L. Bishop"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08927v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08927v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.08248v1",
    "title": "NERVE: Neighbourhood & Entropy-guided Random-walk for training free open-Vocabulary sEgmentation",
    "summary": "Despite recent advances in Open-Vocabulary Semantic Segmentation (OVSS), existing training-free methods face several limitations: use of computationally expensive affinity refinement strategies, ineffective fusion of transformer attention maps due to equal weighting or reliance on fixed-size Gaussian kernels to reinforce local spatial smoothness, enforcing isotropic neighborhoods. We propose a strong baseline for training-free OVSS termed as NERVE (Neighbourhood \\& Entropy-guided Random-walk for open-Vocabulary sEgmentation), which uniquely integrates global and fine-grained local information, exploiting the neighbourhood structure from the self-attention layer of a stable diffusion model. We also introduce a stochastic random walk for refining the affinity rather than relying on fixed-size Gaussian kernels for local context. This spatial diffusion process encourages propagation across connected and semantically related areas, enabling it to effectively delineate objects with arbitrary shapes. Whereas most existing approaches treat self-attention maps from different transformer heads or layers equally, our method uses entropy-based uncertainty to select the most relevant maps. Notably, our method does not require any conventional post-processing techniques like Conditional Random Fields (CRF) or Pixel-Adaptive Mask Refinement (PAMR). Experiments are performed on 7 popular semantic segmentation benchmarks, yielding an overall state-of-the-art zero-shot segmentation performance, providing an effective approach to open-vocabulary semantic segmentation.",
    "authors": [
      "Kunal Mahatha",
      "Jose Dolz",
      "Christian Desrosiers"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08248v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08248v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2511.07772v1",
    "title": "SALT: Steering Activations towards Leakage-free Thinking in Chain of Thought",
    "summary": "As Large Language Models (LLMs) evolve into personal assistants with access to sensitive user data, they face a critical privacy challenge: while prior work has addressed output-level privacy, recent findings reveal that LLMs often leak private information through their internal reasoning processes, violating contextual privacy expectations. These leaky thoughts occur when models inadvertently expose sensitive details in their reasoning traces, even when final outputs appear safe. The challenge lies in preventing such leakage without compromising the model's reasoning capabilities, requiring a delicate balance between privacy and utility. We introduce Steering Activations towards Leakage-free Thinking (SALT), a lightweight test-time intervention that mitigates privacy leakage in model's Chain of Thought (CoT) by injecting targeted steering vectors into hidden state. We identify the high-leakage layers responsible for this behavior. Through experiments across multiple LLMs, we demonstrate that SALT achieves reductions including $18.2\\%$ reduction in CPL on QwQ-32B, $17.9\\%$ reduction in CPL on Llama-3.1-8B, and $31.2\\%$ reduction in CPL on Deepseek in contextual privacy leakage dataset AirGapAgent-R while maintaining comparable task performance and utility. Our work establishes SALT as a practical approach for test-time privacy protection in reasoning-capable language models, offering a path toward safer deployment of LLM-based personal agents.",
    "authors": [
      "Shourya Batra",
      "Pierce Tillman",
      "Samarth Gaggar",
      "Shashank Kesineni",
      "Kevin Zhu",
      "Sunishchal Dev",
      "Ashwinee Panda",
      "Vasu Sharma",
      "Maheep Chaudhary"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07772v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07772v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.09005v1",
    "title": "AI Founding Fathers: A Case Study of GIS Search in Multi-Agent Pipelines",
    "summary": "Although Large Language Models (LLMs) show exceptional fluency, efforts persist to extract stronger reasoning capabilities from them. Drawing on search-based interpretations of LLM computation, this paper advances a systematic framework for understanding LLM reasoning and optimization. Namely, that enhancing reasoning is best achieved by structuring a multi-agent pipeline to ensure a traversal of the search space in a gradual, incremental, and sequential (GIS) manner. Stated succinctly, high-quality reasoning is a controlled, incremental search. To test this framework, we investigate the efficacy of recursive refinement (RR)--an iterative process of self-criticism, adversarial stress-testing, and integrating critical feedback--as a practical method for implementing GIS search. We designed an experiment comparing a simple, linear pipeline against a complex, explicitly structured pipeline leveraging a recursive refinement layer. The multi-agent models were constructed to reflect the historical personas of three US Founding Fathers (Hamilton, Jefferson, and Madison) using RAG-powered corpora and were prompted to generate responses to three contemporary political issues. Model performance was evaluated using a two-tiered approach: a quantitative score from an LLM arbiter agent and qualitative human judgment. Our results revealed that the complex model consistently outperformed the simple model across all nine test cases with an average arbiter-outputted score of 88.3 versus 71.7. The complex model's arguments were superior in analytical depth, structural nuance, and strategic framing. We conclude that recursive refinement is a robust architectural feature for enhancing LLM reasoning via GIS search.",
    "authors": [
      "Alvin Chauhan"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09005v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09005v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.08512v1",
    "title": "CleverBirds: A Multiple-Choice Benchmark for Fine-grained Human Knowledge Tracing",
    "summary": "Mastering fine-grained visual recognition, essential in many expert domains, can require that specialists undergo years of dedicated training. Modeling the progression of such expertize in humans remains challenging, and accurately inferring a human learner's knowledge state is a key step toward understanding visual learning. We introduce CleverBirds, a large-scale knowledge tracing benchmark for fine-grained bird species recognition. Collected by the citizen-science platform eBird, it offers insight into how individuals acquire expertize in complex fine-grained classification. More than 40,000 participants have engaged in the quiz, answering over 17 million multiple-choice questions spanning over 10,000 bird species, with long-range learning patterns across an average of 400 questions per participant. We release this dataset to support the development and evaluation of new methods for visual knowledge tracing. We show that tracking learners' knowledge is challenging, especially across participant subgroups and question types, with different forms of contextual information offering varying degrees of predictive benefit. CleverBirds is among the largest benchmark of its kind, offering a substantially higher number of learnable concepts. With it, we hope to enable new avenues for studying the development of visual expertize over time and across individuals.",
    "authors": [
      "Leonie Bossemeyer",
      "Samuel Heinrich",
      "Grant Van Horn",
      "Oisin Mac Aodha"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08512v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08512v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.07997v1",
    "title": "PrAda-GAN: A Private Adaptive Generative Adversarial Network with Bayes Network Structure",
    "summary": "We revisit the problem of generating synthetic data under differential privacy. To address the core limitations of marginal-based methods, we propose the Private Adaptive Generative Adversarial Network with Bayes Network Structure (PrAda-GAN), which integrates the strengths of both GAN-based and marginal-based approaches. Our method adopts a sequential generator architecture to capture complex dependencies among variables, while adaptively regularizing the learned structure to promote sparsity in the underlying Bayes network. Theoretically, we establish diminishing bounds on the parameter distance, variable selection error, and Wasserstein distance. Our analysis shows that leveraging dependency sparsity leads to significant improvements in convergence rates. Empirically, experiments on both synthetic and real-world datasets demonstrate that PrAda-GAN outperforms existing tabular data synthesis methods in terms of the privacy-utility trade-off.",
    "authors": [
      "Ke Jia",
      "Yuheng Ma",
      "Yang Li",
      "Feifei Wang"
    ],
    "categories": [
      "stat.ML",
      "cs.CR",
      "cs.LG",
      "stat.ME"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07997v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07997v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.08389v1",
    "title": "Unifying Model and Layer Fusion for Speech Foundation Models",
    "summary": "Speech Foundation Models have gained significant attention recently. Prior works have shown that the fusion of representations from multiple layers of the same model or the fusion of multiple models can improve performance on downstream tasks. We unify these two fusion strategies by proposing an interface module that enables fusion across multiple upstream speech models while integrating information across their layers. We conduct extensive experiments on different self-supervised and supervised models across various speech tasks, including ASR and paralinguistic analysis, and demonstrate that our method outperforms prior fusion approaches. We further analyze its scalability concerning model size and count, highlighting the importance of selecting appropriate upstream models. Our results show that the proposed interface provides an additional performance boost when given a suitable upstream model selection, making it a promising approach for utilizing Speech Foundation Models.",
    "authors": [
      "Yi-Jen Shih",
      "David Harwath"
    ],
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08389v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08389v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.08325v1",
    "title": "AgentPRM: Process Reward Models for LLM Agents via Step-Wise Promise and Progress",
    "summary": "Despite rapid development, large language models (LLMs) still encounter challenges in multi-turn decision-making tasks (i.e., agent tasks) like web shopping and browser navigation, which require making a sequence of intelligent decisions based on environmental feedback. Previous work for LLM agents typically relies on elaborate prompt engineering or fine-tuning with expert trajectories to improve performance. In this work, we take a different perspective: we explore constructing process reward models (PRMs) to evaluate each decision and guide the agent's decision-making process. Unlike LLM reasoning, where each step is scored based on correctness, actions in agent tasks do not have a clear-cut correctness. Instead, they should be evaluated based on their proximity to the goal and the progress they have made. Building on this insight, we propose a re-defined PRM for agent tasks, named AgentPRM, to capture both the interdependence between sequential decisions and their contribution to the final goal. This enables better progress tracking and exploration-exploitation balance. To scalably obtain labeled data for training AgentPRM, we employ a Temporal Difference-based (TD-based) estimation method combined with Generalized Advantage Estimation (GAE), which proves more sample-efficient than prior methods. Extensive experiments across different agentic tasks show that AgentPRM is over $8\\times$ more compute-efficient than baselines, and it demonstrates robust improvement when scaling up test-time compute. Moreover, we perform detailed analyses to show how our method works and offer more insights, e.g., applying AgentPRM to the reinforcement learning of LLM agents.",
    "authors": [
      "Zhiheng Xi",
      "Chenyang Liao",
      "Guanyu Li",
      "Yajie Yang",
      "Wenxiang Chen",
      "Zhihao Zhang",
      "Binghai Wang",
      "Senjie Jin",
      "Yuhao Zhou",
      "Jian Guan",
      "Wei Wu",
      "Tao Ji",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08325v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08325v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2511.09127v1",
    "title": "History-Aware Reasoning for GUI Agents",
    "summary": "Advances in Multimodal Large Language Models have significantly enhanced Graphical User Interface (GUI) automation. Equipping GUI agents with reliable episodic reasoning capabilities is essential for bridging the gap between users' concise task descriptions and the complexities of real-world execution. Current methods integrate Reinforcement Learning (RL) with System-2 Chain-of-Thought, yielding notable gains in reasoning enhancement. For long-horizon GUI tasks, historical interactions connect each screen to the goal-oriented episode chain, and effectively leveraging these clues is crucial for the current decision. However, existing native GUI agents exhibit weak short-term memory in their explicit reasoning, interpreting the chained interactions as discrete screen understanding, i.e., unawareness of the historical interactions within the episode. This history-agnostic reasoning challenges their performance in GUI automation. To alleviate this weakness, we propose a History-Aware Reasoning (HAR) framework, which encourages an agent to reflect on its own errors and acquire episodic reasoning knowledge from them via tailored strategies that enhance short-term memory in long-horizon interaction. The framework mainly comprises constructing a reflective learning scenario, synthesizing tailored correction guidelines, and designing a hybrid RL reward function. Using the HAR framework, we develop a native end-to-end model, HAR-GUI-3B, which alters the inherent reasoning mode from history-agnostic to history-aware, equipping the GUI agent with stable short-term memory and reliable perception of screen details. Comprehensive evaluations across a range of GUI-related benchmarks demonstrate the effectiveness and generalization of our method.",
    "authors": [
      "Ziwei Wang",
      "Leyang Yang",
      "Xiaoxuan Tang",
      "Sheng Zhou",
      "Dajun Chen",
      "Wei Jiang",
      "Yong Li"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09127v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09127v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.07926v1",
    "title": "CNN-Based Automated Parameter Extraction Framework for Modeling Memristive Devices",
    "summary": "Resistive random access memory (RRAM) is a promising candidate for next-generation nonvolatile memory (NVM) and in-memory computing applications. Compact models are essential for analyzing the circuit and system-level performance of experimental RRAM devices. However, most existing RRAM compact models rely on multiple fitting parameters to reproduce the device I-V characteristics, and in most cases, as the parameters are not directly related to measurable quantities, their extraction requires extensive manual tuning, making the process time-consuming and limiting adaptability across different devices. This work presents an automated framework for extracting the fitting parameters of the widely used Stanford RRAM model directly from the device I-V characteristics. The framework employs a convolutional neural network (CNN) trained on a synthetic dataset to generate initial parameter estimates, which are then refined through three heuristic optimization blocks that minimize errors via adaptive binary search in the parameter space. We evaluated the framework using four key NVM metrics: set voltage, reset voltage, hysteresis loop area, and low resistance state (LRS) slope. Benchmarking against RRAM device characteristics derived from previously reported Stanford model fits, other analytical models, and experimental data shows that the framework achieves low error across diverse device characteristics, offering a fast, reliable, and robust solution for RRAM modeling.",
    "authors": [
      "Akif Hamid",
      "Orchi Hassan"
    ],
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07926v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07926v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.08436v1",
    "title": "Understanding Electro-communication and Electro-sensing in Weakly Electric Fish using Multi-Agent Deep Reinforcement Learning",
    "summary": "Weakly electric fish, like Gnathonemus petersii, use a remarkable electrical modality for active sensing and communication, but studying their rich electrosensing and electrocommunication behavior and associated neural activity in naturalistic settings remains experimentally challenging. Here, we present a novel biologically-inspired computational framework to study these behaviors, where recurrent neural network (RNN) based artificial agents trained via multi-agent reinforcement learning (MARL) learn to modulate their electric organ discharges (EODs) and movement patterns to collectively forage in virtual environments. Trained agents demonstrate several emergent features consistent with real fish collectives, including heavy tailed EOD interval distributions, environmental context dependent shifts in EOD interval distributions, and social interaction patterns like freeloading, where agents reduce their EOD rates while benefiting from neighboring agents' active sensing. A minimal two-fish assay further isolates the role of electro-communication, showing that access to conspecific EODs and relative dominance jointly shape foraging success. Notably, these behaviors emerge through evolution-inspired rewards for individual fitness and emergent inter-agent interactions, rather than through rewarding agents explicitly for social interactions. Our work has broad implications for the neuroethology of weakly electric fish, as well as other social, communicating animals in which extensive recordings from multiple individuals, and thus traditional data-driven modeling, are infeasible.",
    "authors": [
      "Satpreet H. Singh",
      "Sonja Johnson-Yu",
      "Zhouyang Lu",
      "Aaron Walsman",
      "Federico Pedraja",
      "Denis Turcu",
      "Pratyusha Sharma",
      "Naomi Saphra",
      "Nathaniel B. Sawtell",
      "Kanaka Rajan"
    ],
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.MA",
      "eess.SY",
      "q-bio.NC"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08436v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08436v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.08151v1",
    "title": "SciAgent: A Unified Multi-Agent System for Generalistic Scientific Reasoning",
    "summary": "Recent advances in large language models have enabled AI systems to achieve expert-level performance on domain-specific scientific tasks, yet these systems remain narrow and handcrafted. We introduce SciAgent, a unified multi-agent system designed for generalistic scientific reasoning-the ability to adapt reasoning strategies across disciplines and difficulty levels. SciAgent organizes problem solving as a hierarchical process: a Coordinator Agent interprets each problem's domain and complexity, dynamically orchestrating specialized Worker Systems, each composed of interacting reasoning Sub-agents for symbolic deduction, conceptual modeling, numerical computation, and verification. These agents collaboratively assemble and refine reasoning pipelines tailored to each task. Across mathematics and physics Olympiads (IMO, IMC, IPhO, CPhO), SciAgent consistently attains or surpasses human gold-medalist performance, demonstrating both domain generality and reasoning adaptability. Additionally, SciAgent has been tested on the International Chemistry Olympiad (IChO) and selected problems from the Humanity's Last Exam (HLE) benchmark, further confirming the system's ability to generalize across diverse scientific domains. This work establishes SciAgent as a concrete step toward generalistic scientific intelligence-AI systems capable of coherent, cross-disciplinary reasoning at expert levels.",
    "authors": [
      "Xuchen Li",
      "Ruitao Wu",
      "Xuanbo Liu",
      "Xukai Wang",
      "Jinbo Hu",
      "Zhixin Bai",
      "Bohan Zeng",
      "Hao Liang",
      "Leheng Chen",
      "Mingrui Chen",
      "Haitian Zhong",
      "Xuanlin Yang",
      "Xu-Yao Zhang",
      "Liu Liu",
      "Jia Li",
      "Kaiqi Huang",
      "Jiahao Xu",
      "Haitao Mi",
      "Wentao Zhang",
      "Bin Dong"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08151v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08151v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.08369v1",
    "title": "Text-based Aerial-Ground Person Retrieval",
    "summary": "This work introduces Text-based Aerial-Ground Person Retrieval (TAG-PR), which aims to retrieve person images from heterogeneous aerial and ground views with textual descriptions. Unlike traditional Text-based Person Retrieval (T-PR), which focuses solely on ground-view images, TAG-PR introduces greater practical significance and presents unique challenges due to the large viewpoint discrepancy across images. To support this task, we contribute: (1) TAG-PEDES dataset, constructed from public benchmarks with automatically generated textual descriptions, enhanced by a diversified text generation paradigm to ensure robustness under view heterogeneity; and (2) TAG-CLIP, a novel retrieval framework that addresses view heterogeneity through a hierarchically-routed mixture of experts module to learn view-specific and view-agnostic features and a viewpoint decoupling strategy to decouple view-specific features for better cross-modal alignment. We evaluate the effectiveness of TAG-CLIP on both the proposed TAG-PEDES dataset and existing T-PR benchmarks. The dataset and code are available at https://github.com/Flame-Chasers/TAG-PR.",
    "authors": [
      "Xinyu Zhou",
      "Yu Wu",
      "Jiayao Ma",
      "Wenhao Wang",
      "Min Cao",
      "Mang Ye"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08369v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08369v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.09287v1",
    "title": "From Model Training to Model Raising -- A call to reform AI model training paradigms from post-hoc alignment to intrinsic, identity-based development",
    "summary": "Current AI training methods align models with human values only after their core capabilities have been established, resulting in models that are easily misaligned and lack deep-rooted value systems. We propose a paradigm shift from \"model training\" to \"model raising\", in which alignment is woven into a model's development from the start. We identify several key components for this paradigm, all centered around redesigning the training corpus: reframing training data from a first-person perspective, recontextualizing information as lived experience, simulating social interactions, and scaffolding the ordering of training data. We expect that this redesign of the training corpus will lead to an early commitment to values from the first training token onward, such that knowledge, skills, and values are intrinsically much harder to separate. In an ecosystem in which large language model capabilities start overtaking human capabilities in many tasks, this seems to us like a critical need.",
    "authors": [
      "Roland Aydin",
      "Christian Cyron",
      "Steve Bachelor",
      "Ashton Anderson",
      "Robert West"
    ],
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09287v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09287v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2511.08082v1",
    "title": "Prudential Reliability of Large Language Models in Reinsurance: Governance, Assurance, and Capital Efficiency",
    "summary": "This paper develops a prudential framework for assessing the reliability of large language models (LLMs) in reinsurance. A five-pillar architecture--governance, data lineage, assurance, resilience, and regulatory alignment--translates supervisory expectations from Solvency II, SR 11-7, and guidance from EIOPA (2025), NAIC (2023), and IAIS (2024) into measurable lifecycle controls. The framework is implemented through the Reinsurance AI Reliability and Assurance Benchmark (RAIRAB), which evaluates whether governance-embedded LLMs meet prudential standards for grounding, transparency, and accountability. Across six task families, retrieval-grounded configurations achieved higher grounding accuracy (0.90), reduced hallucination and interpretive drift by roughly 40%, and nearly doubled transparency. These mechanisms lower informational frictions in risk transfer and capital allocation, showing that existing prudential doctrines already accommodate reliable AI when governance is explicit, data are traceable, and assurance is verifiable.",
    "authors": [
      "Stella C. Dong"
    ],
    "categories": [
      "cs.AI",
      "cs.LG",
      "econ.GN"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08082v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08082v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.09438v1",
    "title": "LLM-Guided Dynamic-UMAP for Personalized Federated Graph Learning",
    "summary": "We propose a method that uses large language models to assist graph machine learning under personalization and privacy constraints. The approach combines data augmentation for sparse graphs, prompt and instruction tuning to adapt foundation models to graph tasks, and in-context learning to supply few-shot graph reasoning signals. These signals parameterize a Dynamic UMAP manifold of client-specific graph embeddings inside a Bayesian variational objective for personalized federated learning. The method supports node classification and link prediction in low-resource settings and aligns language model latent representations with graph structure via a cross-modal regularizer. We outline a convergence argument for the variational aggregation procedure, describe a differential privacy threat model based on a moments accountant, and present applications to knowledge graph completion, recommendation-style link prediction, and citation and product graphs. We also discuss evaluation considerations for benchmarking LLM-assisted graph machine learning.",
    "authors": [
      "Sai Puppala",
      "Ismail Hossain",
      "Md Jahangir Alam",
      "Tanzim Ahad",
      "Sajedul Talukder"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09438v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09438v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.09392v1",
    "title": "Potent but Stealthy: Rethink Profile Pollution against Sequential Recommendation via Bi-level Constrained Reinforcement Paradigm",
    "summary": "Sequential Recommenders, which exploit dynamic user intents through interaction sequences, is vulnerable to adversarial attacks. While existing attacks primarily rely on data poisoning, they require large-scale user access or fake profiles thus lacking practicality. In this paper, we focus on the Profile Pollution Attack that subtly contaminates partial user interactions to induce targeted mispredictions. Previous PPA methods suffer from two limitations, i.e., i) over-reliance on sequence horizon impact restricts fine-grained perturbations on item transitions, and ii) holistic modifications cause detectable distribution shifts. To address these challenges, we propose a constrained reinforcement driven attack CREAT that synergizes a bi-level optimization framework with multi-reward reinforcement learning to balance adversarial efficacy and stealthiness. We first develop a Pattern Balanced Rewarding Policy, which integrates pattern inversion rewards to invert critical patterns and distribution consistency rewards to minimize detectable shifts via unbalanced co-optimal transport. Then we employ a Constrained Group Relative Reinforcement Learning paradigm, enabling step-wise perturbations through dynamic barrier constraints and group-shared experience replay, achieving targeted pollution with minimal detectability. Extensive experiments demonstrate the effectiveness of CREAT.",
    "authors": [
      "Jiajie Su",
      "Zihan Nan",
      "Yunshan Ma",
      "Xiaobo Xia",
      "Xiaohua Feng",
      "Weiming Liu",
      "Xiaolin Zheng",
      "Chaochao Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09392v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09392v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.09381v1",
    "title": "Self-Correcting Large Language Models: Generation vs. Multiple Choice",
    "summary": "Large language models have recently demonstrated remarkable abilities to self-correct their responses through iterative refinement, often referred to as self-consistency or self-reflection. However, the dynamics of this self-correction mechanism may differ substantially depending on whether the model is tasked with open-ended text generation or with selecting the most appropriate response from multiple predefined options. In this paper, we conduct a systematic investigation of these two paradigms by comparing performance trends and error-correction behaviors across various natural language understanding and reasoning tasks, covering language models of different scales and families. Our experimental results reveal distinct patterns of improvement and failure modes:   \\textit{While open-ended generation often benefits from the flexibility of re-interpretation and compositional refinement, multiple-choice selection can leverage clearer solution boundaries but may be limited by the provided options}. This contrast also reflects the dual demands faced by emerging agentic LLM applications: effective agents must not only generate and refine open-ended plans or explanations, but also make reliable discrete choices when operating within constrained action spaces. Our findings, therefore, highlight that the design of self-correction mechanisms should take into account the interaction between task structure and output space, with implications for both knowledge-intensive reasoning and decision-oriented applications of LLMs.",
    "authors": [
      "Hossein A. Rahmani",
      "Satyapriya Krishna",
      "Xi Wang",
      "Mohammadmehdi Naghiaei",
      "Emine Yilmaz"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09381v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09381v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.08314v1",
    "title": "Improving the accuracy and generalizability of molecular property regression models with a substructure-substitution-rule-informed framework",
    "summary": "Artificial Intelligence (AI)-aided drug discovery is an active research field, yet AI models often exhibit poor accuracy in regression tasks for molecular property prediction, and perform catastrophically poorly for out-of-distribution (OOD) molecules. Here, we present MolRuleLoss, a substructure-substitution-rule-informed framework that improves the accuracy and generalizability of multiple molecular property regression models (MPRMs) such as GEM and UniMol for diverse molecular property prediction tasks. MolRuleLoss incorporates partial derivative constraints for substructure substitution rules (SSRs) into an MPRM's loss function. When using GEM models for predicting lipophilicity, water solubility, and solvation-free energy (using lipophilicity, ESOL, and freeSolv datasets from MoleculeNet), the root mean squared error (RMSE) values with and without MolRuleLoss were 0.587 vs. 0.660, 0.777 vs. 0.798, and 1.252 vs. 1.877, respectively, representing 2.6-33.3% performance improvements. We show that both the number and the quality of SSRs contribute to the magnitude of prediction accuracy gains obtained upon adding MolRuleLoss to an MPRM. MolRuleLoss improved the generalizability of MPRMs for \"activity cliff\" molecules in a lipophilicity prediction task and improved the generalizability of MPRMs for OOD molecules in a melting point prediction task. In a molecular weight prediction task for OOD molecules, MolRuleLoss reduced the RMSE value of a GEM model from 29.507 to 0.007. We also provide a formal demonstration that the upper bound of the variation for property change of SSRs is positively correlated with an MPRM's error. Together, we show that using the MolRuleLoss framework as a bolt-on boosts the prediction accuracy and generalizability of multiple MPRMs, supporting diverse applications in areas like cheminformatics and AI-aided drug discovery.",
    "authors": [
      "Xiaoyu Fan",
      "Lin Guo",
      "Ruizhen Jia",
      "Yang Tian",
      "Zhihao Yang",
      "Boxue Tian"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08314v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08314v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.09173v1",
    "title": "Data Fusion-Enhanced Decision Transformer for Stable Cross-Domain Generalization",
    "summary": "Cross-domain shifts present a significant challenge for decision transformer (DT) policies. Existing cross-domain policy adaptation methods typically rely on a single simple filtering criterion to select source trajectory fragments and stitch them together. They match either state structure or action feasibility. However, the selected fragments still have poor stitchability: state structures can misalign, the return-to-go (RTG) becomes incomparable when the reward or horizon changes, and actions may jump at trajectory junctions. As a result, RTG tokens lose continuity, which compromises DT's inference ability. To tackle these challenges, we propose Data Fusion-Enhanced Decision Transformer (DFDT), a compact pipeline that restores stitchability. Particularly, DFDT fuses scarce target data with selectively trusted source fragments via a two-level data filter, maximum mean discrepancy (MMD) mismatch for state-structure alignment, and optimal transport (OT) deviation for action feasibility. It then trains on a feasibility-weighted fusion distribution. Furthermore, DFDT replaces RTG tokens with advantage-conditioned tokens, which improves the continuity of the semantics in the token sequence. It also applies a $Q$-guided regularizer to suppress junction value and action jumps. Theoretically, we provide bounds that tie state value and policy performance gaps to the MMD-mismatch and OT-deviation measures, and show that the bounds tighten as these two measures shrink. We show that DFDT improves return and stability over strong offline RL and sequence-model baselines across gravity, kinematic, and morphology shifts on D4RL-style control tasks, and further corroborate these gains with token-stitching and sequence-semantics stability analyses.",
    "authors": [
      "Guojian Wang",
      "Quinson Hon",
      "Xuyang Chen",
      "Lin Zhao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09173v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09173v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.08207v1",
    "title": "FedPoP: Federated Learning Meets Proof of Participation",
    "summary": "Federated learning (FL) offers privacy preserving, distributed machine learning, allowing clients to contribute to a global model without revealing their local data. As models increasingly serve as monetizable digital assets, the ability to prove participation in their training becomes essential for establishing ownership. In this paper, we address this emerging need by introducing FedPoP, a novel FL framework that allows nonlinkable proof of participation while preserving client anonymity and privacy without requiring either extensive computations or a public ledger. FedPoP is designed to seamlessly integrate with existing secure aggregation protocols to ensure compatibility with real-world FL deployments. We provide a proof of concept implementation and an empirical evaluation under realistic client dropouts. In our prototype, FedPoP introduces 0.97 seconds of per-round overhead atop securely aggregated FL and enables a client to prove its participation/contribution to a model held by a third party in 0.0612 seconds. These results indicate FedPoP is practical for real-world deployments that require auditable participation without sacrificing privacy.",
    "authors": [
      "Devriş İşler",
      "Elina van Kempen",
      "Seoyeon Hwang",
      "Nikolaos Laoutaris"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08207v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08207v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.08085v1",
    "title": "BARD10: A New Benchmark Reveals Significance of Bangla Stop-Words in Authorship Attribution",
    "summary": "This research presents a comprehensive investigation into Bangla authorship attribution, introducing a new balanced benchmark corpus BARD10 (Bangla Authorship Recognition Dataset of 10 authors) and systematically analyzing the impact of stop-word removal across classical and deep learning models to uncover the stylistic significance of Bangla stop-words. BARD10 is a curated corpus of Bangla blog and opinion prose from ten contemporary authors, alongside the methodical assessment of four representative classifiers: SVM (Support Vector Machine), Bangla BERT (Bidirectional Encoder Representations from Transformers), XGBoost, and a MLP (Multilayer Perception), utilizing uniform preprocessing on both BARD10 and the benchmark corpora BAAD16 (Bangla Authorship Attribution Dataset of 16 authors). In all datasets, the classical TF-IDF + SVM baseline outperformed, attaining a macro-F1 score of 0.997 on BAAD16 and 0.921 on BARD10, while Bangla BERT lagged by as much as five points. This study reveals that BARD10 authors are highly sensitive to stop-word pruning, while BAAD16 authors remain comparatively robust highlighting genre-dependent reliance on stop-word signatures. Error analysis revealed that high frequency components transmit authorial signatures that are diminished or reduced by transformer models. Three insights are identified: Bangla stop-words serve as essential stylistic indicators; finely calibrated ML models prove effective within short-text limitations; and BARD10 connects formal literature with contemporary web dialogue, offering a reproducible benchmark for future long-context or domain-adapted transformers.",
    "authors": [
      "Abdullah Muhammad Moosa",
      "Nusrat Sultana",
      "Mahdi Muhammad Moosa",
      "Md. Miraiz Hossain"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08085v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08085v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.07947v1",
    "title": "Class-feature Watermark: A Resilient Black-box Watermark Against Model Extraction Attacks",
    "summary": "Machine learning models constitute valuable intellectual property, yet remain vulnerable to model extraction attacks (MEA), where adversaries replicate their functionality through black-box queries. Model watermarking counters MEAs by embedding forensic markers for ownership verification. Current black-box watermarks prioritize MEA survival through representation entanglement, yet inadequately explore resilience against sequential MEAs and removal attacks. Our study reveals that this risk is underestimated because existing removal methods are weakened by entanglement. To address this gap, we propose Watermark Removal attacK (WRK), which circumvents entanglement constraints by exploiting decision boundaries shaped by prevailing sample-level watermark artifacts. WRK effectively reduces watermark success rates by at least 88.79% across existing watermarking benchmarks.   For robust protection, we propose Class-Feature Watermarks (CFW), which improve resilience by leveraging class-level artifacts. CFW constructs a synthetic class using out-of-domain samples, eliminating vulnerable decision boundaries between original domain samples and their artifact-modified counterparts (watermark samples). CFW concurrently optimizes both MEA transferability and post-MEA stability. Experiments across multiple domains show that CFW consistently outperforms prior methods in resilience, maintaining a watermark success rate of at least 70.15% in extracted models even under the combined MEA and WRK distortion, while preserving the utility of protected models.",
    "authors": [
      "Yaxin Xiao",
      "Qingqing Ye",
      "Zi Liang",
      "Haoyang Li",
      "RongHua Li",
      "Huadi Zheng",
      "Haibo Hu"
    ],
    "categories": [
      "cs.CR",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07947v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07947v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.08835v1",
    "title": "Beyond Task-Oriented and Chitchat Dialogues: Proactive and Transition-Aware Conversational Agents",
    "summary": "Conversational agents have traditionally been developed for either task-oriented dialogue (TOD) or open-ended chitchat, with limited progress in unifying the two. Yet, real-world conversations naturally involve fluid transitions between these modes. To address this gap, we introduce TACT (TOD-And-Chitchat Transition), a dataset designed for transition-aware dialogue modeling that incorporates structurally diverse and integrated mode flows. TACT supports both user- and agent-driven mode switches, enabling robust modeling of complex conversational dynamics. To evaluate an agent's ability to initiate and recover from mode transitions, we propose two new metrics -- Switch and Recovery. Models trained on TACT outperform baselines in both intent detection and mode transition handling. Moreover, applying Direct Preference Optimization (DPO) to TACT-trained models yields additional gains, achieving 75.74\\% joint mode-intent accuracy and a 70.1\\% win rate against GPT-4o in human evaluation. These results demonstrate that pairing structurally diverse data with DPO enhances response quality and transition control, paving the way for more proactive and transition-aware conversational agents.",
    "authors": [
      "Yejin Yoon",
      "Yuri Son",
      "Namyoung So",
      "Minseo Kim",
      "Minsoo Cho",
      "Chanhee Park",
      "Seungshin Lee",
      "Taeuk Kim"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08835v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08835v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.08832v1",
    "title": "TIGER-MARL: Enhancing Multi-Agent Reinforcement Learning with Temporal Information through Graph-based Embeddings and Representations",
    "summary": "In this paper, we propose capturing and utilizing \\textit{Temporal Information through Graph-based Embeddings and Representations} or \\textbf{TIGER} to enhance multi-agent reinforcement learning (MARL). We explicitly model how inter-agent coordination structures evolve over time. While most MARL approaches rely on static or per-step relational graphs, they overlook the temporal evolution of interactions that naturally arise as agents adapt, move, or reorganize cooperation strategies. Capturing such evolving dependencies is key to achieving robust and adaptive coordination. To this end, TIGER constructs dynamic temporal graphs of MARL agents, connecting their current and historical interactions. It then employs a temporal attention-based encoder to aggregate information across these structural and temporal neighborhoods, yielding time-aware agent embeddings that guide cooperative policy learning. Through extensive experiments on two coordination-intensive benchmarks, we show that TIGER consistently outperforms diverse value-decomposition and graph-based MARL baselines in task performance and sample efficiency. Furthermore, we conduct comprehensive ablation studies to isolate the impact of key design parameters in TIGER, revealing how structural and temporal factors can jointly shape effective policy learning in MARL. All codes can be found here: https://github.com/Nikunj-Gupta/tiger-marl.",
    "authors": [
      "Nikunj Gupta",
      "Ludwika Twardecka",
      "James Zachary Hare",
      "Jesse Milzman",
      "Rajgopal Kannan",
      "Viktor Prasanna"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08832v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08832v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2511.08136v1",
    "title": "SafeMIL: Learning Offline Safe Imitation Policy from Non-Preferred Trajectories",
    "summary": "In this work, we study the problem of offline safe imitation learning (IL). In many real-world settings, online interactions can be risky, and accurately specifying the reward and the safety cost information at each timestep can be difficult. However, it is often feasible to collect trajectories reflecting undesirable or risky behavior, implicitly conveying the behavior the agent should avoid. We refer to these trajectories as non-preferred trajectories. Unlike standard IL, which aims to mimic demonstrations, our agent must also learn to avoid risky behavior using non-preferred trajectories. In this paper, we propose a novel approach, SafeMIL, to learn a parameterized cost that predicts if the state-action pair is risky via \\textit{Multiple Instance Learning}. The learned cost is then used to avoid non-preferred behaviors, resulting in a policy that prioritizes safety. We empirically demonstrate that our approach can learn a safer policy that satisfies cost constraints without degrading the reward performance, thereby outperforming several baselines.",
    "authors": [
      "Returaj Burnwal",
      "Nirav Pravinbhai Bhatt",
      "Balaraman Ravindran"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08136v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08136v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.09026v1",
    "title": "DeepVRegulome: DNABERT-based deep-learning framework for predicting the functional impact of short genomic variants on the human regulome",
    "summary": "Whole-genome sequencing (WGS) has revealed numerous non-coding short variants whose functional impacts remain poorly understood. Despite recent advances in deep-learning genomic approaches, accurately predicting and prioritizing clinically relevant mutations in gene regulatory regions remains a major challenge. Here we introduce Deep VRegulome, a deep-learning method for prediction and interpretation of functionally disruptive variants in the human regulome, which combines 700 DNABERT fine-tuned models, trained on vast amounts of ENCODE gene regulatory regions, with variant scoring, motif analysis, attention-based visualization, and survival analysis. We showcase its application on TCGA glioblastoma WGS dataset in prioritizing survival-associated mutations and regulatory regions. The analysis identified 572 splice-disrupting and 9,837 transcription-factor binding site altering mutations occurring in greater than 10% of glioblastoma samples. Survival analysis linked 1352 mutations and 563 disrupted regulatory regions to patient outcomes, enabling stratification via non-coding mutation signatures. All the code, fine-tuned models, and an interactive data portal are publicly available.",
    "authors": [
      "Pratik Dutta",
      "Matthew Obusan",
      "Rekha Sathian",
      "Max Chao",
      "Pallavi Surana",
      "Nimisha Papineni",
      "Yanrong Ji",
      "Zhihan Zhou",
      "Han Liu",
      "Alisa Yurovsky",
      "Ramana V Davuluri"
    ],
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09026v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09026v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2511.08721v1",
    "title": "Benevolent Dictators? On LLM Agent Behavior in Dictator Games",
    "summary": "In behavioral sciences, experiments such as the ultimatum game are conducted to assess preferences for fairness or self-interest of study participants. In the dictator game, a simplified version of the ultimatum game where only one of two players makes a single decision, the dictator unilaterally decides how to split a fixed sum of money between themselves and the other player. Although recent studies have explored behavioral patterns of AI agents based on Large Language Models (LLMs) instructed to adopt different personas, we question the robustness of these results. In particular, many of these studies overlook the role of the system prompt - the underlying instructions that shape the model's behavior - and do not account for how sensitive results can be to slight changes in prompts. However, a robust baseline is essential when studying highly complex behavioral aspects of LLMs. To overcome previous limitations, we propose the LLM agent behavior study (LLM-ABS) framework to (i) explore how different system prompts influence model behavior, (ii) get more reliable insights into agent preferences by using neutral prompt variations, and (iii) analyze linguistic features in responses to open-ended instructions by LLM agents to better understand the reasoning behind their behavior. We found that agents often exhibit a strong preference for fairness, as well as a significant impact of the system prompt on their behavior. From a linguistic perspective, we identify that models express their responses differently. Although prompt sensitivity remains a persistent challenge, our proposed framework demonstrates a robust foundation for LLM agent behavior studies. Our code artifacts are available at https://github.com/andreaseinwiller/LLM-ABS.",
    "authors": [
      "Andreas Einwiller",
      "Kanishka Ghosh Dastidar",
      "Artur Romazanov",
      "Annette Hautli-Janisz",
      "Michael Granitzer",
      "Florian Lemmerich"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08721v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08721v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.07865v1",
    "title": "LLM-Powered Fully Automated Chaos Engineering: Towards Enabling Anyone to Build Resilient Software Systems at Low Cost",
    "summary": "Chaos Engineering (CE) is an engineering technique aimed at improving the resilience of distributed systems. It involves intentionally injecting faults into a system to test its resilience, uncover weaknesses, and address them before they cause failures in production. Recent CE tools automate the execution of predefined CE experiments. However, planning such experiments and improving the system based on the experimental results still remain manual. These processes are labor-intensive and require multi-domain expertise. To address these challenges and enable anyone to build resilient systems at low cost, this paper proposes ChaosEater, a system that automates the entire CE cycle with Large Language Models (LLMs). It predefines an agentic workflow according to a systematic CE cycle and assigns subdivided processes within the workflow to LLMs. ChaosEater targets CE for software systems built on Kubernetes. Therefore, the LLMs in ChaosEater complete CE cycles through software engineering tasks, including requirement definition, code generation, testing, and debugging. We evaluate ChaosEater through case studies on small- and large-scale Kubernetes systems. The results demonstrate that it consistently completes reasonable CE cycles with significantly low time and monetary costs. Its cycles are also qualitatively validated by human engineers and LLMs.",
    "authors": [
      "Daisuke Kikuta",
      "Hiroki Ikeuchi",
      "Kengo Tajiri"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07865v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07865v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.08015v1",
    "title": "Invisible Triggers, Visible Threats! Road-Style Adversarial Creation Attack for Visual 3D Detection in Autonomous Driving",
    "summary": "Modern autonomous driving (AD) systems leverage 3D object detection to perceive foreground objects in 3D environments for subsequent prediction and planning. Visual 3D detection based on RGB cameras provides a cost-effective solution compared to the LiDAR paradigm. While achieving promising detection accuracy, current deep neural network-based models remain highly susceptible to adversarial examples. The underlying safety concerns motivate us to investigate realistic adversarial attacks in AD scenarios. Previous work has demonstrated the feasibility of placing adversarial posters on the road surface to induce hallucinations in the detector. However, the unnatural appearance of the posters makes them easily noticeable by humans, and their fixed content can be readily targeted and defended. To address these limitations, we propose the AdvRoad to generate diverse road-style adversarial posters. The adversaries have naturalistic appearances resembling the road surface while compromising the detector to perceive non-existent objects at the attack locations. We employ a two-stage approach, termed Road-Style Adversary Generation and Scenario-Associated Adaptation, to maximize the attack effectiveness on the input scene while ensuring the natural appearance of the poster, allowing the attack to be carried out stealthily without drawing human attention. Extensive experiments show that AdvRoad generalizes well to different detectors, scenes, and spoofing locations. Moreover, physical attacks further demonstrate the practical threats in real-world environments.",
    "authors": [
      "Jian Wang",
      "Lijun He",
      "Yixing Yong",
      "Haixia Bi",
      "Fan Li"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08015v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08015v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.08708v1",
    "title": "Stabilizing Direct Training of Spiking Neural Networks: Membrane Potential Initialization and Threshold-robust Surrogate Gradient",
    "summary": "Recent advancements in the direct training of Spiking Neural Networks (SNNs) have demonstrated high-quality outputs even at early timesteps, paving the way for novel energy-efficient AI paradigms. However, the inherent non-linearity and temporal dependencies in SNNs introduce persistent challenges, such as temporal covariate shift (TCS) and unstable gradient flow with learnable neuron thresholds. In this paper, we present two key innovations: MP-Init (Membrane Potential Initialization) and TrSG (Threshold-robust Surrogate Gradient). MP-Init addresses TCS by aligning the initial membrane potential with its stationary distribution, while TrSG stabilizes gradient flow with respect to threshold voltage during training. Extensive experiments validate our approach, achieving state-of-the-art accuracy on both static and dynamic image datasets. The code is available at: https://github.com/kookhh0827/SNN-MP-Init-TRSG",
    "authors": [
      "Hyunho Kook",
      "Byeongho Yu",
      "Jeong Min Oh",
      "Eunhyeok Park"
    ],
    "categories": [
      "cs.NE",
      "cs.CV"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08708v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08708v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.08368v1",
    "title": "A Circular Argument : Does RoPE need to be Equivariant for Vision?",
    "summary": "Rotary Positional Encodings (RoPE) have emerged as a highly effective technique for one-dimensional sequences in Natural Language Processing spurring recent progress towards generalizing RoPE to higher-dimensional data such as images and videos. The success of RoPE has been thought to be due to its positional equivariance, i.e. its status as a relative positional encoding. In this paper, we mathematically show RoPE to be one of the most general solutions for equivariant positional embedding in one-dimensional data. Moreover, we show Mixed RoPE to be the analogously general solution for M-dimensional data, if we require commutative generators -- a property necessary for RoPE's equivariance. However, we question whether strict equivariance plays a large role in RoPE's performance. We propose Spherical RoPE, a method analogous to Mixed RoPE, but assumes non-commutative generators. Empirically, we find Spherical RoPE to have the equivalent or better learning behavior compared to its equivariant analogues. This suggests that relative positional embeddings are not as important as is commonly believed, at least within computer vision. We expect this discovery to facilitate future work in positional encodings for vision that can be faster and generalize better by removing the preconception that they must be relative.",
    "authors": [
      "Chase van de Geijn",
      "Timo Lüddecke",
      "Polina Turishcheva",
      "Alexander S. Ecker"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08368v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08368v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.09325v1",
    "title": "Not Everything That Counts Can Be Counted: A Case for Safe Qualitative AI",
    "summary": "Artificial intelligence (AI) and large language models (LLM) are reshaping science, with most recent advances culminating in fully-automated scientific discovery pipelines. But qualitative research has been left behind. Researchers in qualitative methods are hesitant about AI adoption. Yet when they are willing to use AI at all, they have little choice but to rely on general-purpose tools like ChatGPT to assist with interview interpretation, data annotation, and topic modeling - while simultaneously acknowledging these system's well-known limitations of being biased, opaque, irreproducible, and privacy-compromising. This creates a critical gap: while AI has substantially advanced quantitative methods, the qualitative dimensions essential for meaning-making and comprehensive scientific understanding remain poorly integrated. We argue for developing dedicated qualitative AI systems built from the ground up for interpretive research. Such systems must be transparent, reproducible, and privacy-friendly. We review recent literature to show how existing automated discovery pipelines could be enhanced by robust qualitative capabilities, and identify key opportunities where safe qualitative AI could advance multidisciplinary and mixed-methods research.",
    "authors": [
      "Stine Beltoft",
      "Lukas Galke"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09325v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09325v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.08808v1",
    "title": "Effects of label noise on the classification of outlier observations",
    "summary": "This study investigates the impact of adding noise to the training set classes in classification tasks using the BCOPS algorithm (Balanced and Conformal Optimized Prediction Sets), proposed by Guan & Tibshirani (2022). The BCOPS algorithm is an application of conformal prediction combined with a machine learning method to construct prediction sets such that the probability of the true class being included in the prediction set for a test observation meets a specified coverage guarantee. An observation is considered an outlier if its true class is not present in the training set. The study employs both synthetic and real datasets and conducts experiments to evaluate the prediction abstention rate for outlier observations and the model's robustness in this previously untested scenario. The results indicate that the addition of noise, even in small amounts, can have a significant effect on model performance.",
    "authors": [
      "Matheus Vinícius Barreto de Farias",
      "Mario de Castro"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08808v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08808v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2511.09486v1",
    "title": "A general framework for adaptive nonparametric dimensionality reduction",
    "summary": "Dimensionality reduction is a fundamental task in modern data science. Several projection methods specifically tailored to take into account the non-linearity of the data via local embeddings have been proposed. Such methods are often based on local neighbourhood structures and require tuning the number of neighbours that define this local structure, and the dimensionality of the lower-dimensional space onto which the data are projected. Such choices critically influence the quality of the resulting embedding. In this paper, we exploit a recently proposed intrinsic dimension estimator which also returns the optimal locally adaptive neighbourhood sizes according to some desirable criteria. In principle, this adaptive framework can be employed to perform an optimal hyper-parameter tuning of any dimensionality reduction algorithm that relies on local neighbourhood structures. Numerical experiments on both real-world and simulated datasets show that the proposed method can be used to significantly improve well-known projection methods when employed for various learning tasks, with improvements measurable through both quantitative metrics and the quality of low-dimensional visualizations.",
    "authors": [
      "Antonio Di Noia",
      "Federico Ravenda",
      "Antonietta Mira"
    ],
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09486v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09486v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08066v2",
    "title": "Information Capacity: Evaluating the Efficiency of Large Language Models via Text Compression",
    "summary": "Recent years have witnessed the rapid advancements of large language models (LLMs) and their expanding applications, leading to soaring demands for computational resources. The widespread adoption of test-time scaling further aggravates the tension between model capability and resource consumption, highlighting the importance of inference efficiency. However, a unified metric that accurately reflects an LLM's efficiency across different model sizes and architectures remains absent. Motivated by the correlation between compression and intelligence, we introduce information capacity, a measure of model efficiency based on text compression performance relative to computational complexity. Larger models can predict the next token more accurately, achieving greater compression gains but at higher computational costs. Empirical evaluations on mainstream open-source models show that models of varying sizes within a series exhibit consistent information capacity. This metric enables a fair efficiency comparison across model series and accurate performance prediction within a model series. A distinctive feature of information capacity is that it incorporates tokenizer efficiency, which affects both input and output token counts but is often neglected in LLM evaluations. We assess the information capacity of 49 models on 5 heterogeneous datasets and observe consistent results on the influences of tokenizer efficiency, pretraining data, and the mixture-of-experts architecture.",
    "authors": [
      "Cheng Yuan",
      "Jiawei Shao",
      "Chi Zhang",
      "Xuelong Li"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "eess.SP"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08066v2",
    "pdf_url": "https://arxiv.org/pdf/2511.08066v2.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08877v1",
    "title": "Hallucinate or Memorize? The Two Sides of Probabilistic Learning in Large Language Models",
    "summary": "Large language models (LLMs) have been increasingly applied to a wide range of tasks, from natural language understanding to code generation. While they have also been used to assist in citation recommendation, the hallucination of non-existent papers remains a major issue. Building on prior studies, this study hypothesizes that an LLM's ability to correctly produce bibliographic records depends on whether the underlying knowledge is generated or memorized, with highly cited papers (i.e., more frequently appear in the pretraining corpus) showing lower hallucination rates. We therefore assume citation count as a proxy for training data redundancy (i.e., the frequency with which a given bibliographic record appears in the pretraining corpus) and investigate how citation frequency affects hallucinated references in LLM outputs. Using GPT-4.1, we generated and manually verified 100 citations across twenty computer-science domains, and measured factual consistency via cosine similarity between generated and authentic metadata. The results revealed that (i) citation count is strongly correlated with factual accuracy, (ii) bibliographic information becomes almost verbatim memorized beyond roughly 1,000 citations, and (iii) memory interference occurs when multiple highly cited papers share similar content. These findings indicate a threshold where generalization shifts into memorization, with highly cited papers being nearly verbatim retained in the model.",
    "authors": [
      "Junichiro Niimi"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08877v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08877v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.09067v1",
    "title": "MM-CRITIC: A Holistic Evaluation of Large Multimodal Models as Multimodal Critique",
    "summary": "The ability of critique is vital for models to self-improve and serve as reliable AI assistants. While extensively studied in language-only settings, multimodal critique of Large Multimodal Models (LMMs) remains underexplored despite their growing capabilities in tasks like captioning and visual reasoning. In this work, we introduce MM-CRITIC, a holistic benchmark for evaluating the critique ability of LMMs across multiple dimensions: basic, correction, and comparison. Covering 8 main task types and over 500 tasks, MM-CRITIC collects responses from various LMMs with different model sizes and is composed of 4471 samples. To enhance the evaluation reliability, we integrate expert-informed ground answers into scoring rubrics that guide GPT-4o in annotating responses and generating reference critiques, which serve as anchors for trustworthy judgments. Extensive experiments validate the effectiveness of MM-CRITIC and provide a comprehensive assessment of leading LMMs' critique capabilities under multiple dimensions. Further analysis reveals some key insights, including the correlation between response quality and critique, and varying critique difficulty across evaluation dimensions. Our code is available at https://github.com/MichealZeng0420/MM-Critic.",
    "authors": [
      "Gailun Zeng",
      "Ziyang Luo",
      "Hongzhan Lin",
      "Yuchen Tian",
      "Kaixin Li",
      "Ziyang Gong",
      "Jianxiong Guo",
      "Jing Ma"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09067v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09067v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08585v1",
    "title": "Simulating the Visual World with Artificial Intelligence: A Roadmap",
    "summary": "The landscape of video generation is shifting, from a focus on generating visually appealing clips to building virtual environments that support interaction and maintain physical plausibility. These developments point toward the emergence of video foundation models that function not only as visual generators but also as implicit world models, models that simulate the physical dynamics, agent-environment interactions, and task planning that govern real or imagined worlds. This survey provides a systematic overview of this evolution, conceptualizing modern video foundation models as the combination of two core components: an implicit world model and a video renderer. The world model encodes structured knowledge about the world, including physical laws, interaction dynamics, and agent behavior. It serves as a latent simulation engine that enables coherent visual reasoning, long-term temporal consistency, and goal-driven planning. The video renderer transforms this latent simulation into realistic visual observations, effectively producing videos as a \"window\" into the simulated world. We trace the progression of video generation through four generations, in which the core capabilities advance step by step, ultimately culminating in a world model, built upon a video generation model, that embodies intrinsic physical plausibility, real-time multimodal interaction, and planning capabilities spanning multiple spatiotemporal scales. For each generation, we define its core characteristics, highlight representative works, and examine their application domains such as robotics, autonomous driving, and interactive gaming. Finally, we discuss open challenges and design principles for next-generation world models, including the role of agent intelligence in shaping and evaluating these systems. An up-to-date list of related works is maintained at this link.",
    "authors": [
      "Jingtong Yue",
      "Ziqi Huang",
      "Zhaoxi Chen",
      "Xintao Wang",
      "Pengfei Wan",
      "Ziwei Liu"
    ],
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08585v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08585v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.07899v1",
    "title": "Statistically Assuring Safety of Control Systems using Ensembles of Safety Filters and Conformal Prediction",
    "summary": "Safety assurance is a fundamental requirement for deploying learning-enabled autonomous systems. Hamilton-Jacobi (HJ) reachability analysis is a fundamental method for formally verifying safety and generating safe controllers. However, computing the HJ value function that characterizes the backward reachable set (BRS) of a set of user-defined failure states is computationally expensive, especially for high-dimensional systems, motivating the use of reinforcement learning approaches to approximate the value function. Unfortunately, a learned value function and its corresponding safe policy are not guaranteed to be correct. The learned value function evaluated at a given state may not be equal to the actual safety return achieved by following the learned safe policy. To address this challenge, we introduce a conformal prediction-based (CP) framework that bounds such uncertainty. We leverage CP to provide probabilistic safety guarantees when using learned HJ value functions and policies to prevent control systems from reaching failure states. Specifically, we use CP to calibrate the switching between the unsafe nominal controller and the learned HJ-based safe policy and to derive safety guarantees under this switched policy. We also investigate using an ensemble of independently trained HJ value functions as a safety filter and compare this ensemble approach to using individual value functions alone.",
    "authors": [
      "Ihab Tabbara",
      "Yuxuan Yang",
      "Hussein Sibai"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "eess.SY"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07899v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07899v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08307v1",
    "title": "Concentration bounds on response-based vector embeddings of black-box generative models",
    "summary": "Generative models, such as large language models or text-to-image diffusion models, can generate relevant responses to user-given queries. Response-based vector embeddings of generative models facilitate statistical analysis and inference on a given collection of black-box generative models. The Data Kernel Perspective Space embedding is one particular method of obtaining response-based vector embeddings for a given set of generative models, already discussed in the literature. In this paper, under appropriate regularity conditions, we establish high probability concentration bounds on the sample vector embeddings for a given set of generative models, obtained through the method of Data Kernel Perspective Space embedding. Our results tell us the required number of sample responses needed in order to approximate the population-level vector embeddings with a desired level of accuracy. The algebraic tools used to establish our results can be used further for establishing concentration bounds on Classical Multidimensional Scaling embeddings in general, when the dissimilarities are observed with noise.",
    "authors": [
      "Aranyak Acharyya",
      "Joshua Agterberg",
      "Youngser Park",
      "Carey E. Priebe"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08307v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08307v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08275v1",
    "title": "Bi-Objective Evolutionary Optimization for Large-Scale Open Pit Mine Scheduling Problem under Uncertainty with Chance Constraints",
    "summary": "The open-pit mine scheduling problem (OPMSP) is a complex, computationally expensive process in long-term mine planning, constrained by operational and geological dependencies. Traditional deterministic approaches often ignore geological uncertainty, leading to suboptimal and potentially infeasible production schedules. Chance constraints allow modeling of stochastic components by ensuring probabilistic constraints are satisfied with high probability. This paper presents a bi-objective formulation of the OPMSP that simultaneously maximizes expected net present value and minimizes scheduling risk, independent of the confidence level required for the constraint. Solutions are represented using integer encoding, inherently satisfying reserve constraints. We introduce a domain-specific greedy randomized initialization and a precedence-aware period-swap mutation operator. We integrate these operators into three multi-objective evolutionary algorithms: the global simple evolutionary multi-objective optimizer (GSEMO), a mutation-only variant of multi-objective evolutionary algorithm based on decomposition (MOEA/D), and non-dominated sorting genetic algorithm II (NSGA-II). We compare our bi-objective formulation against the single-objective approach, which depends on a specific confidence level, by analyzing mine deposits consisting of up to 112 687 blocks. Results demonstrate that the proposed bi-objective formulation yields more robust and balanced trade-offs between economic value and risk compared to single-objective, confidence-dependent approach.",
    "authors": [
      "Ishara Hewa Pathiranage",
      "Aneta Neumann"
    ],
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08275v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08275v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08570v1",
    "title": "Automatic Grid Updates for Kolmogorov-Arnold Networks using Layer Histograms",
    "summary": "Kolmogorov-Arnold Networks (KANs) are a class of neural networks that have received increased attention in recent literature. In contrast to MLPs, KANs leverage parameterized, trainable activation functions and offer several benefits including improved interpretability and higher accuracy on learning symbolic equations. However, the original KAN architecture requires adjustments to the domain discretization of the network (called the \"domain grid\") during training, creating extra overhead for the user in the training process. Typical KAN layers are not designed with the ability to autonomously update their domains in a data-driven manner informed by the changing output ranges of previous layers. As an added benefit, this histogram algorithm may also be applied towards detecting out-of-distribution (OOD) inputs in a variety of settings. We demonstrate that AdaptKAN exceeds or matches the performance of prior KAN architectures and MLPs on four different tasks: learning scientific equations from the Feynman dataset, image classification from frozen features, learning a control Lyapunov function, and detecting OOD inputs on the OpenOOD v1.5 benchmark.",
    "authors": [
      "Jamison Moody",
      "James Usevitch"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08570v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08570v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08878v1",
    "title": "Covariance Scattering Transforms",
    "summary": "Machine learning and data processing techniques relying on covariance information are widespread as they identify meaningful patterns in unsupervised and unlabeled settings. As a prominent example, Principal Component Analysis (PCA) projects data points onto the eigenvectors of their covariance matrix, capturing the directions of maximum variance. This mapping, however, falls short in two directions: it fails to capture information in low-variance directions, relevant when, e.g., the data contains high-variance noise; and it provides unstable results in low-sample regimes, especially when covariance eigenvalues are close. CoVariance Neural Networks (VNNs), i.e., graph neural networks using the covariance matrix as a graph, show improved stability to estimation errors and learn more expressive functions in the covariance spectrum than PCA, but require training and operate in a labeled setup. To get the benefits of both worlds, we propose Covariance Scattering Transforms (CSTs), deep untrained networks that sequentially apply filters localized in the covariance spectrum to the input data and produce expressive hierarchical representations via nonlinearities. We define the filters as covariance wavelets that capture specific and detailed covariance spectral patterns. We improve CSTs' computational and memory efficiency via a pruning mechanism, and we prove that their error due to finite-sample covariance estimations is less sensitive to close covariance eigenvalues compared to PCA, improving their stability. Our experiments on age prediction from cortical thickness measurements on 4 datasets collecting patients with neurodegenerative diseases show that CSTs produce stable representations in low-data settings, as VNNs but without any training, and lead to comparable or better predictions w.r.t. more complex learning models.",
    "authors": [
      "Andrea Cavallo",
      "Ayushman Raghuvanshi",
      "Sundeep Prabhakar Chepuri",
      "Elvin Isufi"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08878v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08878v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.09105v1",
    "title": "Cost-Minimized Label-Flipping Poisoning Attack to LLM Alignment",
    "summary": "Large language models (LLMs) are increasingly deployed in real-world systems, making it critical to understand their vulnerabilities. While data poisoning attacks during RLHF/DPO alignment have been studied empirically, their theoretical foundations remain unclear. We investigate the minimum-cost poisoning attack required to steer an LLM's policy toward an attacker's target by flipping preference labels during RLHF/DPO, without altering the compared outputs. We formulate this as a convex optimization problem with linear constraints, deriving lower and upper bounds on the minimum attack cost. As a byproduct of this theoretical analysis, we show that any existing label-flipping attack can be post-processed via our proposed method to reduce the number of label flips required while preserving the intended poisoning effect. Empirical results demonstrate that this cost-minimization post-processing can significantly reduce poisoning costs over baselines, particularly when the reward model's feature dimension is small relative to the dataset size. These findings highlight fundamental vulnerabilities in RLHF/DPO pipelines and provide tools to evaluate their robustness against low-cost poisoning attacks.",
    "authors": [
      "Shigeki Kusaka",
      "Keita Saito",
      "Mikoto Kudo",
      "Takumi Tanabe",
      "Akifumi Wachi",
      "Youhei Akimoto"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09105v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09105v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08120v1",
    "title": "A robust methodology for long-term sustainability evaluation of Machine Learning models",
    "summary": "Sustainability and efficiency have become essential considerations in the development and deployment of Artificial Intelligence systems, yet existing regulatory and reporting practices lack standardized, model-agnostic evaluation protocols. Current assessments often measure only short-term experimental resource usage and disproportionately emphasize batch learning settings, failing to reflect real-world, long-term AI lifecycles. In this work, we propose a comprehensive evaluation protocol for assessing the long-term sustainability of ML models, applicable to both batch and streaming learning scenarios. Through experiments on diverse classification tasks using a range of model types, we demonstrate that traditional static train-test evaluations do not reliably capture sustainability under evolving data and repeated model updates. Our results show that long-term sustainability varies significantly across models, and in many cases, higher environmental cost yields little performance benefit.",
    "authors": [
      "Jorge Paz-Ruza",
      "João Gama",
      "Amparo Alonso-Betanzos",
      "Bertha Guijarro-Berdiñas"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08120v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08120v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08702v1",
    "title": "FAIRPLAI: A Human-in-the-Loop Approach to Fair and Private Machine Learning",
    "summary": "As machine learning systems move from theory to practice, they are increasingly tasked with decisions that affect healthcare access, financial opportunities, hiring, and public services. In these contexts, accuracy is only one piece of the puzzle - models must also be fair to different groups, protect individual privacy, and remain accountable to stakeholders. Achieving all three is difficult: differential privacy can unintentionally worsen disparities, fairness interventions often rely on sensitive data that privacy restricts, and automated pipelines ignore that fairness is ultimately a human and contextual judgment. We introduce FAIRPLAI (Fair and Private Learning with Active Human Influence), a practical framework that integrates human oversight into the design and deployment of machine learning systems. FAIRPLAI works in three ways: (1) it constructs privacy-fairness frontiers that make trade-offs between accuracy, privacy guarantees, and group outcomes transparent; (2) it enables interactive stakeholder input, allowing decision-makers to select fairness criteria and operating points that reflect their domain needs; and (3) it embeds a differentially private auditing loop, giving humans the ability to review explanations and edge cases without compromising individual data security. Applied to benchmark datasets, FAIRPLAI consistently preserves strong privacy protections while reducing fairness disparities relative to automated baselines. More importantly, it provides a straightforward, interpretable process for practitioners to manage competing demands of accuracy, privacy, and fairness in socially impactful applications. By embedding human judgment where it matters most, FAIRPLAI offers a pathway to machine learning systems that are effective, responsible, and trustworthy in practice. GitHub: https://github.com/Li1Davey/Fairplai",
    "authors": [
      "David Sanchez",
      "Holly Lopez",
      "Michelle Buraczyk",
      "Anantaa Kotal"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CY"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08702v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08702v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.07787v1",
    "title": "Physical Consistency of Aurora's Encoder: A Quantitative Study",
    "summary": "The high accuracy of large-scale weather forecasting models like Aurora is often accompanied by a lack of transparency, as their internal representations remain largely opaque. This \"black box\" nature hinders their adoption in high-stakes operational settings. In this work, we probe the physical consistency of Aurora's encoder by investigating whether its latent representations align with known physical and meteorological concepts. Using a large-scale dataset of embeddings, we train linear classifiers to identify three distinct concepts: the fundamental land-sea boundary, high-impact extreme temperature events, and atmospheric instability. Our findings provide quantitative evidence that Aurora learns physically consistent features, while also highlighting its limitations in capturing the rarest events. This work underscores the critical need for interpretability methods to validate and build trust in the next generation of Al-driven weather models.",
    "authors": [
      "Benjamin Richards",
      "Pushpa Kumar Balan"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07787v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07787v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08732v1",
    "title": "Intuitive Programming, Adaptive Task Planning, and Dynamic Role Allocation in Human-Robot Collaboration",
    "summary": "Remarkable capabilities have been achieved by robotics and AI, mastering complex tasks and environments. Yet, humans often remain passive observers, fascinated but uncertain how to engage. Robots, in turn, cannot reach their full potential in human-populated environments without effectively modeling human states and intentions and adapting their behavior. To achieve a synergistic human-robot collaboration (HRC), a continuous information flow should be established: humans must intuitively communicate instructions, share expertise, and express needs. In parallel, robots must clearly convey their internal state and forthcoming actions to keep users informed, comfortable, and in control. This review identifies and connects key components enabling intuitive information exchange and skill transfer between humans and robots. We examine the full interaction pipeline: from the human-to-robot communication bridge translating multimodal inputs into robot-understandable representations, through adaptive planning and role allocation, to the control layer and feedback mechanisms to close the loop. Finally, we highlight trends and promising directions toward more adaptive, accessible HRC.",
    "authors": [
      "Marta Lagomarsino",
      "Elena Merlo",
      "Andrea Pupa",
      "Timo Birr",
      "Franziska Krebs",
      "Cristian Secchi",
      "Tamim Asfour",
      "Arash Ajoudani"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08732v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08732v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.09378v1",
    "title": "The 2025 Planning Performance of Frontier Large Language Models",
    "summary": "The capacity of Large Language Models (LLMs) for reasoning remains an active area of research, with the capabilities of frontier models continually advancing. We provide an updated evaluation of the end-to-end planning performance of three frontier LLMs as of 2025, where models are prompted to generate a plan from PDDL domain and task descriptions. We evaluate DeepSeek R1, Gemini 2.5 Pro, GPT-5 and as reference the planner LAMA on a subset of domains from the most recent Learning Track of the International Planning Competition. Our results show that on standard PDDL domains, the performance of GPT-5 in terms of solved tasks is competitive with LAMA. When the PDDL domains and tasks are obfuscated to test for pure reasoning, the performance of all LLMs degrades, though less severely than previously reported for other models. These results show substantial improvements over prior generations of LLMs, reducing the performance gap to planners on a challenging benchmark.",
    "authors": [
      "Augusto B. Corrêa",
      "André G. Pereira",
      "Jendrik Seipp"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09378v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09378v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.08303v1",
    "title": "Semi-Supervised Treatment Effect Estimation with Unlabeled Covariates via Generalized Riesz Regression",
    "summary": "This study investigates treatment effect estimation in the semi-supervised setting, where we can use not only the standard triple of covariates, treatment indicator, and outcome, but also unlabeled auxiliary covariates. For this problem, we develop efficiency bounds and efficient estimators whose asymptotic variance aligns with the efficiency bound. In the analysis, we introduce two different data-generating processes: the one-sample setting and the two-sample setting. The one-sample setting considers the case where we can observe treatment indicators and outcomes for a part of the dataset, which is also called the censoring setting. In contrast, the two-sample setting considers two independent datasets with labeled and unlabeled data, which is also called the case-control setting or the stratified setting. In both settings, we find that by incorporating auxiliary covariates, we can lower the efficiency bound and obtain an estimator with an asymptotic variance smaller than that without such auxiliary covariates.",
    "authors": [
      "Masahiro Kato"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "econ.EM",
      "math.ST",
      "stat.ME"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08303v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08303v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2511.09002v1",
    "title": "Convergence and Stability Analysis of Self-Consuming Generative Models with Heterogeneous Human Curation",
    "summary": "Self-consuming generative models have received significant attention over the last few years. In this paper, we study a self-consuming generative model with heterogeneous preferences that is a generalization of the model in Ferbach et al. (2024). The model is retrained round by round using real data and its previous-round synthetic outputs. The asymptotic behavior of the retraining dynamics is investigated across four regimes using different techniques including the nonlinear Perron--Frobenius theory. Our analyses improve upon that of Ferbach et al. (2024) and provide convergence results in settings where the well-known Banach contraction mapping arguments do not apply. Stability and non-stability results regarding the retraining dynamics are also given.",
    "authors": [
      "Hongru Zhao",
      "Jinwen Fu",
      "Tuan Pham"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09002v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09002v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.07884v1",
    "title": "Meta-cognitive Multi-scale Hierarchical Reasoning for Motor Imagery Decoding",
    "summary": "Brain-computer interface (BCI) aims to decode motor intent from noninvasive neural signals to enable control of external devices, but practical deployment remains limited by noise and variability in motor imagery (MI)-based electroencephalogram (EEG) signals. This work investigates a hierarchical and meta-cognitive decoding framework for four-class MI classification. We introduce a multi-scale hierarchical signal processing module that reorganizes backbone features into temporal multi-scale representations, together with an introspective uncertainty estimation module that assigns per-cycle reliability scores and guides iterative refinement. We instantiate this framework on three standard EEG backbones (EEGNet, ShallowConvNet, and DeepConvNet) and evaluate four-class MI decoding using the BCI Competition IV-2a dataset under a subject-independent setting. Across all backbones, the proposed components improve average classification accuracy and reduce inter-subject variance compared to the corresponding baselines, indicating increased robustness to subject heterogeneity and noisy trials. These results suggest that combining hierarchical multi-scale processing with introspective confidence estimation can enhance the reliability of MI-based BCI systems.",
    "authors": [
      "Si-Hyun Kim",
      "Heon-Gyu Kwak",
      "Byoung-Hee Kwon",
      "Seong-Whan Lee"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.07884v1",
    "pdf_url": "https://arxiv.org/pdf/2511.07884v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.09450v1",
    "title": "How does the Performance of the Data-driven Traffic Flow Forecasting Models deteriorate with Increasing Forecasting Horizon? An Extensive Approach Considering Statistical, Machine Learning and Deep Learning Models",
    "summary": "With rapid urbanization in recent decades, traffic congestion has intensified due to increased movement of people and goods. As planning shifts from demand-based to supply-oriented strategies, Intelligent Transportation Systems (ITS) have become essential for managing traffic within existing infrastructure. A core ITS function is traffic forecasting, enabling proactive measures like ramp metering, signal control, and dynamic routing through platforms such as Google Maps. This study assesses the performance of statistical, machine learning (ML), and deep learning (DL) models in forecasting traffic speed and flow using real-world data from California's Harbor Freeway, sourced from the Caltrans Performance Measurement System (PeMS). Each model was evaluated over 20 forecasting windows (up to 1 hour 40 minutes) using RMSE, MAE, and R-Square metrics. Results show ANFIS-GP performs best at early windows with RMSE of 0.038, MAE of 0.0276, and R-Square of 0.9983, while Bi-LSTM is more robust for medium-term prediction due to its capacity to model long-range temporal dependencies, achieving RMSE of 0.1863, MAE of 0.0833, and R-Square of 0.987 at a forecasting of 20. The degradation in model performance was quantified using logarithmic transformation, with slope values used to measure robustness. Among DL models, Bi-LSTM had the flattest slope (0.0454 RMSE, 0.0545 MAE for flow), whereas ANFIS-GP had 0.1058 for RMSE and 0.1037 for flow MAE. The study concludes by identifying hybrid models as a promising future direction.",
    "authors": [
      "Amanta Sherfenaz",
      "Nazmul Haque",
      "Protiva Sadhukhan Prova",
      "Md Asif Raihan",
      "Md. Hadiuzzaman"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09450v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09450v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.09180v1",
    "title": "FSampler: Training Free Acceleration of Diffusion Sampling via Epsilon Extrapolation",
    "summary": "FSampler is a training free, sampler agnostic execution layer that accelerates diffusion sampling by reducing the number of function evaluations (NFE). FSampler maintains a short history of denoising signals (epsilon) from recent real model calls and extrapolates the next epsilon using finite difference predictors at second order, third order, or fourth order, falling back to lower order when history is insufficient. On selected steps the predicted epsilon substitutes the model call while keeping each sampler's update rule unchanged. Predicted epsilons are validated for finiteness and magnitude; a learning stabilizer rescales predictions on skipped steps to correct drift, and an optional gradient estimation stabilizer compensates local curvature. Protected windows, periodic anchors, and a cap on consecutive skips bound deviation over the trajectory. Operating at the sampler level, FSampler integrates with Euler/DDIM, DPM++ 2M/2S, LMS/AB2, and RES family exponential multistep methods and drops into standard workflows. FLUX.1 dev, Qwen Image, and Wan 2.2, FSampler reduces time by 8 to 22% and model calls by 15 to 25% at high fidelity (Structural Similarity Index (SSIM) 0.95 to 0.99), without altering sampler formulas. With an aggressive adaptive gate, reductions can reach 45 to 50% fewer model calls at lower fidelity (SSIM 0.73 to 0.74).",
    "authors": [
      "Michael A. Vladimir"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09180v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09180v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.09049v1",
    "title": "Break the Tie: Learning Cluster-Customized Category Relationships for Categorical Data Clustering",
    "summary": "Categorical attributes with qualitative values are ubiquitous in cluster analysis of real datasets. Unlike the Euclidean distance of numerical attributes, the categorical attributes lack well-defined relationships of their possible values (also called categories interchangeably), which hampers the exploration of compact categorical data clusters. Although most attempts are made for developing appropriate distance metrics, they typically assume a fixed topological relationship between categories when learning distance metrics, which limits their adaptability to varying cluster structures and often leads to suboptimal clustering performance. This paper, therefore, breaks the intrinsic relationship tie of attribute categories and learns customized distance metrics suitable for flexibly and accurately revealing various cluster distributions. As a result, the fitting ability of the clustering algorithm is significantly enhanced, benefiting from the learnable category relationships. Moreover, the learned category relationships are proved to be Euclidean distance metric-compatible, enabling a seamless extension to mixed datasets that include both numerical and categorical attributes. Comparative experiments on 12 real benchmark datasets with significance tests show the superior clustering accuracy of the proposed method with an average ranking of 1.25, which is significantly higher than the 5.21 ranking of the current best-performing method.",
    "authors": [
      "Mingjie Zhao",
      "Zhanpei Huang",
      "Yang Lu",
      "Mengke Li",
      "Yiqun Zhang",
      "Weifeng Su",
      "Yiu-ming Cheung"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09049v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09049v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.08719v1",
    "title": "Practical considerations when designing an online learning algorithm for an app-based mHealth intervention",
    "summary": "The ubiquitous nature of mobile health (mHealth) technology has expanded opportunities for the integration of reinforcement learning into traditional clinical trial designs, allowing researchers to learn individualized treatment policies during the study. LowSalt4Life 2 (LS4L2) is a recent trial aimed at reducing sodium intake among hypertensive individuals through an app-based intervention. A reinforcement learning algorithm, which was deployed in one of the trial arms, was designed to send reminder notifications to promote app engagement in contexts where the notification would be effective, i.e., when a participant is likely to open the app in the next 30-minute and not when prior data suggested reduced effectiveness. Such an algorithm can improve app-based mHealth interventions by reducing participant burden and more effectively promoting behavior change. We encountered various challenges during the implementation of the learning algorithm, which we present as a template to solving challenges in future trials that deploy reinforcement learning algorithms. We provide template solutions based on LS4L2 for solving the key challenges of (i) defining a relevant reward, (ii) determining a meaningful timescale for optimization, (iii) specifying a robust statistical model that allows for automation, (iv) balancing model flexibility with computational cost, and (v) addressing missing values in gradually collected data.",
    "authors": [
      "Rachel T Gonzalez",
      "Madeline R Abbott",
      "Brahmajee Nallamothu",
      "Scott Hummel",
      "Michael Dorsch",
      "Walter Dempsey"
    ],
    "categories": [
      "stat.ME",
      "cs.LG",
      "stat.AP",
      "stat.ML"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08719v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08719v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2511.08565v1",
    "title": "Moral Susceptibility and Robustness under Persona Role-Play in Large Language Models",
    "summary": "Large language models (LLMs) increasingly operate in social contexts, motivating analysis of how they express and shift moral judgments. In this work, we investigate the moral response of LLMs to persona role-play, prompting a LLM to assume a specific character. Using the Moral Foundations Questionnaire (MFQ), we introduce a benchmark that quantifies two properties: moral susceptibility and moral robustness, defined from the variability of MFQ scores across and within personas, respectively. We find that, for moral robustness, model family accounts for most of the variance, while model size shows no systematic effect. The Claude family is, by a significant margin, the most robust, followed by Gemini and GPT-4 models, with other families exhibiting lower robustness. In contrast, moral susceptibility exhibits a mild family effect but a clear within-family size effect, with larger variants being more susceptible. Moreover, robustness and susceptibility are positively correlated, an association that is more pronounced at the family level. Additionally, we present moral foundation profiles for models without persona role-play and for personas averaged across models. Together, these analyses provide a systematic view of how persona conditioning shapes moral behavior in large language models.",
    "authors": [
      "Davi Bastos Costa",
      "Felippe Alves",
      "Renato Vicente"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08565v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08565v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.08846v1",
    "title": "On topological descriptors for graph products",
    "summary": "Topological descriptors have been increasingly utilized for capturing multiscale structural information in relational data. In this work, we consider various filtrations on the (box) product of graphs and the effect on their outputs on the topological descriptors - the Euler characteristic (EC) and persistent homology (PH). In particular, we establish a complete characterization of the expressive power of EC on general color-based filtrations. We also show that the PH descriptors of (virtual) graph products contain strictly more information than the computation on individual graphs, whereas EC does not. Additionally, we provide algorithms to compute the PH diagrams of the product of vertex- and edge-level filtrations on the graph product. We also substantiate our theoretical analysis with empirical investigations on runtime analysis, expressivity, and graph classification performance. Overall, this work paves way for powerful graph persistent descriptors via product filtrations. Code is available at https://github.com/Aalto-QuML/tda_graph_product.",
    "authors": [
      "Mattie Ji",
      "Amauri H. Souza",
      "Vikas Garg"
    ],
    "categories": [
      "cs.LG",
      "math.AT",
      "stat.ML"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.08846v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08846v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.09425v1",
    "title": "Several Supporting Evidences for the Adaptive Feature Program",
    "summary": "Theoretically exploring the advantages of neural networks might be one of the most challenging problems in the AI era. An adaptive feature program has recently been proposed to analyze the feature learning characteristic property of neural networks in a more abstract way. Motivated by the celebrated Le Cam equivalence, we advocate the over-parametrized sequence models to further simplify the analysis of the training dynamics of adaptive feature program and present several supporting evidences for the adaptive feature program. More precisely, after having introduced the feature error measure (FEM) to characterize the quality of the learned feature, we show that the FEM is decreasing during the training process of several concrete adaptive feature models including linear regression, single/multiple index models, etc. We believe that this hints at the potential successes of the adaptive feature program.",
    "authors": [
      "Yicheng Li",
      "Qian Lin"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-12",
    "url": "https://arxiv.org/abs/2511.09425v1",
    "pdf_url": "https://arxiv.org/pdf/2511.09425v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.08767v1",
    "title": "Hey Pentti, We Did (More of) It!: A Vector-Symbolic Lisp With Residue Arithmetic",
    "summary": "Using Frequency-domain Holographic Reduced Representations (FHRRs), we extend a Vector-Symbolic Architecture (VSA) encoding of Lisp 1.5 with primitives for arithmetic operations using Residue Hyperdimensional Computing (RHC). Encoding a Turing-complete syntax over a high-dimensional vector space increases the expressivity of neural network states, enabling network states to contain arbitrarily structured representations that are inherently interpretable. We discuss the potential applications of the VSA encoding in machine learning tasks, as well as the importance of encoding structured representations and designing neural networks whose behavior is sensitive to the structure of their representations in virtue of attaining more general intelligent agents than exist at present.",
    "authors": [
      "Connor Hanley",
      "Eilene Tomkins-Flanaganm",
      "Mary Alexandria Kelly"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08767v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08767v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.08086v1",
    "title": "Dynamic Sparsity: Challenging Common Sparsity Assumptions for Learning World Models in Robotic Reinforcement Learning Benchmarks",
    "summary": "The use of learned dynamics models, also known as world models, can improve the sample efficiency of reinforcement learning. Recent work suggests that the underlying causal graphs of such dynamics models are sparsely connected, with each of the future state variables depending only on a small subset of the current state variables, and that learning may therefore benefit from sparsity priors. Similarly, temporal sparsity, i.e. sparsely and abruptly changing local dynamics, has also been proposed as a useful inductive bias.   In this work, we critically examine these assumptions by analyzing ground-truth dynamics from a set of robotic reinforcement learning environments in the MuJoCo Playground benchmark suite, aiming to determine whether the proposed notions of state and temporal sparsity actually tend to hold in typical reinforcement learning tasks.   We study (i) whether the causal graphs of environment dynamics are sparse, (ii) whether such sparsity is state-dependent, and (iii) whether local system dynamics change sparsely.   Our results indicate that global sparsity is rare, but instead the tasks show local, state-dependent sparsity in their dynamics and this sparsity exhibits distinct structures, appearing in temporally localized clusters (e.g., during contact events) and affecting specific subsets of state dimensions. These findings challenge common sparsity prior assumptions in dynamics learning, emphasizing the need for grounded inductive biases that reflect the state-dependent sparsity structure of real-world dynamics.",
    "authors": [
      "Muthukumar Pandaram",
      "Jakob Hollenstein",
      "David Drexel",
      "Samuele Tosatto",
      "Antonio Rodríguez-Sánchez",
      "Justus Piater"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08086v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08086v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.08791v1",
    "title": "The Probably Approximately Correct Learning Model in Computational Learning Theory",
    "summary": "This survey paper gives an overview of various known results on learning classes of Boolean functions in Valiant's Probably Approximately Correct (PAC) learning model and its commonly studied variants.",
    "authors": [
      "Rocco A. Servedio"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08791v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08791v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2511.08789v1",
    "title": "A Generalized Bias-Variance Decomposition for Bregman Divergences",
    "summary": "The bias-variance decomposition is a central result in statistics and machine learning, but is typically presented only for the squared error. We present a generalization of the bias-variance decomposition where the prediction error is a Bregman divergence, which is relevant to maximum likelihood estimation with exponential families. While the result is already known, there was not previously a clear, standalone derivation, so we provide one for pedagogical purposes. A version of this note previously appeared on the author's personal website without context. Here we provide additional discussion and references to the relevant prior literature.",
    "authors": [
      "David Pfau"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08789v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08789v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2511.08401v1",
    "title": "Source-Optimal Training is Transfer-Suboptimal",
    "summary": "We prove a fundamental misalignment in transfer learning: the source regularization that minimizes source risk almost never coincides with the regularization maximizing transfer benefit. Through sharp phase boundaries for L2-SP ridge regression, we characterize the transfer-optimal source penalty $τ_0^*$ and show it diverges predictably from task-optimal values, requiring stronger regularization in high-SNR regimes and weaker regularization in low-SNR regimes. Additionally, in isotropic settings the decision to transfer is remarkably independent of target sample size and noise, depending only on task alignment and source characteristics. CIFAR-10 and MNIST experiments confirm this counterintuitive pattern persists in non-linear networks.",
    "authors": [
      "C. Evans Hedges"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST"
    ],
    "published": "2025-11-11",
    "url": "https://arxiv.org/abs/2511.08401v1",
    "pdf_url": "https://arxiv.org/pdf/2511.08401v1.pdf",
    "date": "2025-11-13",
    "source": "arxiv",
    "research_score": 0.5
  }
]