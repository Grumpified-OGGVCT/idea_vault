# Copilot Setup Steps for Idea Vault Development Environment
# This file configures the development environment for GitHub Copilot Workspace

steps:
  - name: Install Node.js 20
    description: Install Node.js 20 LTS for any JavaScript tooling
    commands:
      - curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
      - sudo apt-get install -y nodejs
      - node --version
      - npm --version
    
  - name: Install Ruby and Jekyll
    description: Install Ruby and Jekyll for building the static site
    commands:
      - sudo apt-get update
      - sudo apt-get install -y ruby-full build-essential zlib1g-dev
      - echo '# Install Ruby Gems to ~/gems' >> ~/.bashrc
      - echo 'export GEM_HOME="$HOME/gems"' >> ~/.bashrc
      - echo 'export PATH="$HOME/gems/bin:$PATH"' >> ~/.bashrc
      - source ~/.bashrc
      - gem install jekyll bundler
      - jekyll --version
    
  - name: Install Python Dependencies
    description: Install httpx and beautifulsoup4 for web scraping
    commands:
      - pip install --upgrade pip
      - pip install httpx beautifulsoup4
      - python -c "import httpx; print(f'httpx {httpx.__version__} installed')"
      - python -c "import bs4; print(f'beautifulsoup4 {bs4.__version__} installed')"
    
  - name: Verify Installation
    description: Verify all tools are installed correctly
    commands:
      - echo "Node.js $(node --version)"
      - echo "npm $(npm --version)"
      - echo "Ruby $(ruby --version)"
      - echo "Jekyll $(jekyll --version)"
      - echo "Python $(python --version)"
      - pip list | grep -E '(httpx|beautifulsoup4)'
    
  - name: Test Jekyll Build
    description: Test that Jekyll can build the docs site
    commands:
      - cd docs
      - bundle init
      - bundle add jekyll minima
      - bundle exec jekyll build
      - ls -la _site
    
  - name: Test Scraper Script
    description: Test the scraper script with a sample URL
    commands:
      - export SOURCE_URL="https://example.com"
      - python scripts/scrape_and_clean.py || echo "Script execution completed (may be placeholder)"

environment:
  - SOURCE_URL=https://accidentaljedi.github.io/AI_Research_Daily/

notes: |
  These setup steps prepare the coding agent environment with all necessary tools:
  - Node.js 20 for modern JavaScript tooling
  - Ruby + Jekyll for building the static site
  - Python dependencies (httpx, beautifulsoup4) for web scraping
  
  After running these steps, the agent can:
  - Build and preview the Jekyll site locally
  - Run the scraper script to generate daily reports
  - Test the complete workflow end-to-end
