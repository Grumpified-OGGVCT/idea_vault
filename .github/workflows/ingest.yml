name: AI Net Idea Vault - Research Ingestion

on:
  schedule:
    - cron: '0 * * * *'  # Every hour (like Ollama Pulse)
  workflow_dispatch:  # Manual trigger

permissions:
  contents: write

jobs:
  ingest:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      # Fetch arXiv data immediately after dependency install (minimize firewall impact)
      - name: Pre-fetch arXiv research data
        run: |
          # Run arXiv ingestion with retry logic
          for i in {1..3}; do
            python scripts/ingest_arxiv.py && break || {
              echo "Attempt $i failed, retrying..."
              sleep 5
            }
          done
        continue-on-error: true
          
      - name: Run research ingestion
        run: |
          python scripts/ingest_huggingface.py || echo "Warning: HuggingFace ingestion failed"
          python scripts/ingest_paperswithcode.py || echo "Warning: PapersWithCode ingestion failed"
          python scripts/ingest_official.py || echo "Warning: Official ingestion failed"
          python scripts/ingest_cloud.py || echo "Warning: Cloud ingestion failed"
          python scripts/ingest_community.py || echo "Warning: Community ingestion failed"
          python scripts/ingest_tools.py || echo "Warning: Tools ingestion failed"
          python scripts/ingest_issues.py || echo "Warning: Issues ingestion failed"
          
      - name: Aggregate research data
        run: |
          python scripts/aggregate.py || echo "Warning: Aggregation failed"
        continue-on-error: true
        
      - name: Mine research insights
        run: |
          python scripts/mine_insights.py || echo "Warning: Insights mining failed"
        continue-on-error: true

      - name: Commit and push research data
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add data/
          git diff --quiet && git diff --staged --quiet || (git commit -m "chore(data): research ingestion $(date -u '+%Y-%m-%d %H:%M UTC')" && git push)
  
  # Optional: Deep research tracking for specific topics
  deep-research-scan:
    runs-on: ubuntu-latest
    needs: ingest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Track high-impact papers
        run: |
          # Re-run ingestion with focus on high-scoring papers
          python scripts/ingest_arxiv.py
        continue-on-error: true
      
      - name: Commit additional research data
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add data/
          git diff --quiet && git diff --staged --quiet || (git commit -m "chore(data): deep research scan $(date -u '+%Y-%m-%d %H:%M UTC')" && git push)
        continue-on-error: true

