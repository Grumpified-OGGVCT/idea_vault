#!/usr/bin/env python3
"""
AI Net Idea Vault - Research Daily Report Generation
Generates rigorous, accessible reports with The Scholar persona
Enhanced with LLM multi-persona analysis
"""
import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
import asyncio

# LLM integration imports (graceful degradation if not available)
try:
    from openai import OpenAI
    LLM_AVAILABLE = True
except ImportError:
    LLM_AVAILABLE = False
    print("‚ö†Ô∏è  LLM libraries not available - using fallback analysis")

# Ollama Turbo Client import
try:
    # Use relative import to avoid sys.path manipulation
    from pathlib import Path
    import importlib.util
    
    ollama_client_path = Path(__file__).parent / "ollama_turbo_client.py"
    spec = importlib.util.spec_from_file_location("ollama_turbo_client", ollama_client_path)
    if spec and spec.loader:
        ollama_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(ollama_module)
        OllamaTurboClient = ollama_module.OllamaTurboClient
        MODELS = ollama_module.MODELS
        OLLAMA_AVAILABLE = True
    else:
        OLLAMA_AVAILABLE = False
        print("‚ö†Ô∏è  Ollama Turbo Client not available")
except ImportError:
    OLLAMA_AVAILABLE = False
    print("‚ö†Ô∏è  Ollama Turbo Client not available")

# Actionable Ideator imports (graceful degradation if not available)
try:
    from idea_synthesizer import IdeaSynthesizer
    from actionable_ideator import ActionableIdeator
    ACTIONABLE_IDEATOR_AVAILABLE = True
except ImportError:
    ACTIONABLE_IDEATOR_AVAILABLE = False
    print("‚ö†Ô∏è  Actionable Ideator modules not available - skipping actionable content generation")

DOCS_DIR = Path("docs")
REPORTS_DIR = DOCS_DIR / "reports"
DAILY_DIR = DOCS_DIR / "_daily"  # NEW: Jekyll collection directory

# Developer wrap-up configuration constants
MIN_CLUSTER_SIZE = 3  # Minimum papers to include a cluster in developer wrap-up
MAX_SUMMARY_LENGTH = 250  # Maximum characters for paper summaries
MAX_DISPLAYED_TRENDS = 5  # Maximum trending topics to display

# Actionable ideator configuration constants
MIN_RESEARCH_SCORE_FOR_ACTIONABLE = 0.7  # Minimum score to generate actionable content
MIN_HIGH_SCORE_PAPERS = 3  # Minimum number of high-score papers needed


def ensure_reports_dir():
    """Create docs/reports and docs/_daily directories if they don't exist"""
    DOCS_DIR.mkdir(parents=True, exist_ok=True)
    REPORTS_DIR.mkdir(parents=True, exist_ok=True)
    DAILY_DIR.mkdir(parents=True, exist_ok=True)  # NEW: Ensure _daily exists



def get_today_date_str():
    return datetime.now().strftime("%Y-%m-%d")


def get_timestamp_str():
    """Get timestamp for Jekyll filenames: YYYY-MM-DD-HHMM"""
    return datetime.now().strftime("%Y-%m-%d-%H%M")


def load_llm_personas() -> Dict[str, Any]:
    """Load LLM persona configurations"""
    personas_file = Path("config/llm_personas.json")
    if personas_file.exists():
        with open(personas_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {"personas": {}, "default_persona": "strategic_synthesizer", "fallback_behavior": "use_existing_analysis"}


async def enhance_with_ollama(content: str, persona_name: str, personas_config: Dict) -> Optional[str]:
    """
    Enhance content using Ollama Turbo Cloud with specified persona
    Returns enhanced content or None if Ollama not available/failed
    """
    if not OLLAMA_AVAILABLE:
        return None
    
    # Check for Ollama API configuration
    api_key = os.getenv('OLLAMA_API_KEY')
    endpoint = os.getenv('OLLAMA_ENDPOINT', 'https://api.ollama.ai')
    
    if not api_key:
        print(f"‚ö†Ô∏è  OLLAMA_API_KEY not set - skipping Ollama enhancement")
        return None
    
    try:
        personas = personas_config.get('personas', {})
        persona = personas.get(persona_name)
        
        if not persona:
            print(f"‚ö†Ô∏è  Persona '{persona_name}' not found - skipping enhancement")
            return None
        
        # Select appropriate Ollama model based on persona
        model = MODELS['reasoning']  # Default to reasoning model
        if 'technical' in persona_name.lower():
            model = MODELS['reasoning']
        elif 'creative' in persona_name.lower():
            model = MODELS['creative']
        
        # Initialize Ollama Turbo Client
        async with OllamaTurboClient(api_key=api_key, base_url=endpoint) as client:
            # Make LLM request
            system_prompt = persona.get('system_prompt', '')
            prompt = f"{system_prompt}\n\nAnalyze and enhance this research content:\n\n{content}"
            
            enhanced = await client.generate(
                model=model,
                prompt=prompt,
                max_tokens=persona.get('max_tokens', 2000),
                temperature=persona.get('temperature', 0.7),
                thinking=True  # Enable deep reasoning
            )
            
            print(f"‚úÖ Ollama enhancement applied with {persona_name} using {model}")
            return enhanced
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Ollama enhancement failed: {e}")
        return None


def enhance_with_llm(content: str, persona_name: str, personas_config: Dict) -> Optional[str]:
    """
    Enhance content using LLM with specified persona
    Tries Ollama Turbo first, falls back to OpenAI-compatible endpoint
    Returns enhanced content or None if LLM not available/failed
    """
    # Try Ollama Turbo first if available
    if OLLAMA_AVAILABLE and os.getenv('OLLAMA_API_KEY'):
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            enhanced = loop.run_until_complete(enhance_with_ollama(content, persona_name, personas_config))
            loop.close()
            if enhanced:
                return enhanced
        except Exception as e:
            print(f"‚ö†Ô∏è  Ollama enhancement failed, trying fallback: {e}")
    
    # Fallback to OpenAI-compatible endpoint
    if not LLM_AVAILABLE:
        return None
    
    # Check for API configuration
    api_key = os.getenv('LLM_API_KEY')
    endpoint = os.getenv('LLM_ENDPOINT')
    model = os.getenv('LLM_MODEL', 'gpt-3.5-turbo')
    
    if not api_key:
        print(f"‚ö†Ô∏è  LLM_API_KEY not set - skipping LLM enhancement")
        return None
    
    try:
        personas = personas_config.get('personas', {})
        persona = personas.get(persona_name)
        
        if not persona:
            print(f"‚ö†Ô∏è  Persona '{persona_name}' not found - skipping enhancement")
            return None
        
        # Initialize OpenAI client
        client_kwargs = {'api_key': api_key}
        if endpoint:
            client_kwargs['base_url'] = endpoint
        
        client = OpenAI(**client_kwargs)
        
        # Make LLM request
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": persona.get('system_prompt', '')},
                {"role": "user", "content": f"Analyze and enhance this research content:\n\n{content}"}
            ],
            temperature=persona.get('temperature', 0.7),
            max_tokens=persona.get('max_tokens', 2000)
        )
        
        enhanced = response.choices[0].message.content
        print(f"‚úÖ LLM enhancement applied with {persona_name}")
        return enhanced
        
    except Exception as e:
        print(f"‚ö†Ô∏è  LLM enhancement failed: {e}")
        return None


def load_data():
    """Load aggregated data and insights for today"""
    today = get_today_date_str()
    agg_file = f"data/aggregated/{today}.json"
    insights_file = f"data/insights/{today}.json"

    aggregated = []
    if os.path.exists(agg_file):
        with open(agg_file, 'r', encoding='utf-8') as f:
            aggregated = json.load(f)

    insights = {}
    if os.path.exists(insights_file):
        with open(insights_file, 'r', encoding='utf-8') as f:
            insights = json.load(f)

    return aggregated, insights


def determine_report_focus(aggregated, insights):
    """Determine the main focus of today's report"""
    # High research score papers
    high_score = [p for p in aggregated if p.get('research_score', 0) >= 0.8]
    
    patterns = insights.get('patterns', {})
    pattern_count = len(patterns)
    
    if len(high_score) >= 3:
        return "breakthrough", "Multiple significant advances appeared today"
    elif pattern_count >= 3:
        return "pattern", "Several research directions show convergence"
    elif len(aggregated) < 5:
        return "slow", "Steady progress across established areas"
    else:
        return "standard", "Notable developments in AI research"


def generate_scholar_opening(focus_type, focus_desc, aggregated):
    """Generate The Scholar's opening with appropriate tone"""
    today = get_today_date_str()
    
    openings = {
        "breakthrough": f"""# üìö The Lab ‚Äì {today}

*The Scholar here, translating today's research breakthroughs into actionable intelligence.*

üìö Today's arXiv brought something genuinely significant: {focus_desc}. Let's unpack what makes these developments noteworthy and why they matter for the field's trajectory.
""",
        "pattern": f"""# üìö The Lab ‚Äì {today}

*The Scholar here, translating today's research breakthroughs into actionable intelligence.*

üìö Progress in AI research is often about convergence. {focus_desc}, and this pattern tells us something important about where the field is headed.
""",
        "slow": f"""# üìö The Lab ‚Äì {today}

*The Scholar here, translating today's research breakthroughs into actionable intelligence.*

üìö Not every day brings paradigm shifts, and today exemplifies steady, incremental progress. {focus_desc}, building on established foundations in ways that matter.
""",
        "standard": f"""# üìö The Lab ‚Äì {today}

*The Scholar here, translating today's research breakthroughs into actionable intelligence.*

üìö {focus_desc}. Today's papers span multiple domains, each contributing to our understanding in distinct ways.
"""
    }
    
    return openings.get(focus_type, openings["standard"])


def generate_research_overview(aggregated, insights):
    """Generate research overview section"""
    today = get_today_date_str()
    
    # Calculate stats
    arxiv_papers = [p for p in aggregated if p.get('source') == 'arxiv']
    hf_items = [p for p in aggregated if p.get('source') in ['huggingface_model', 'huggingface_dataset']]
    pwc_papers = [p for p in aggregated if p.get('source') == 'paperswithcode']
    
    high_relevance = [p for p in aggregated if p.get('research_score', 0) >= 0.8]
    notable = [p for p in aggregated if 0.6 <= p.get('research_score', 0) < 0.8]
    
    patterns = insights.get('patterns', {})
    inferences = insights.get('inferences', [])
    
    section = f"""
---

## üî¨ Research Overview

**Today's Intelligence at a Glance:**

- **Papers Analyzed**: {len(arxiv_papers)} from arXiv across AI/ML categories
- **Noteworthy Research**: {len(high_relevance)} papers scored ‚â•0.8 (breakthrough/highly significant)
- **Notable Contributions**: {len(notable)} papers scored ‚â•0.6 (meaningful advances)
- **Implementation Watch**: {len(hf_items)} new models/datasets on HuggingFace
- **Benchmark Updates**: {len(pwc_papers)} papers with verified performance claims
- **Pattern Detection**: {len(patterns)} emerging research directions identified
- **Research Implications**: {len(inferences)} implications for future development
- **Analysis Date**: {today}

---
"""
    
    return section


def generate_breakthrough_section(aggregated):
    """Generate section for breakthrough/highly significant papers"""
    high_score = sorted(
        [p for p in aggregated if p.get('research_score', 0) >= 0.8],
        key=lambda x: x.get('research_score', 0),
        reverse=True
    )
    
    if not high_score:
        return ""
    
    section = """## üìö The Breakthrough Papers

*The research that matters most today:*

"""
    
    for i, paper in enumerate(high_score[:3], 1):  # Top 3
        title = paper.get('title', 'Untitled')
        url = paper.get('url', '#')
        score = paper.get('research_score', 0)
        source = paper.get('source', 'unknown')
        
        # Extract key info
        summary = paper.get('summary', paper.get('abstract', ''))[:300]
        authors = paper.get('authors', [])
        author_text = f"{authors[0]} et al." if authors else "Unknown authors"
        
        section += f"""### {i}. {title}

**Authors**: {author_text}  
**Research Score**: {score:.2f} (Highly Significant)  
**Source**: {source}  

**Core Contribution**: {summary}...

**Why This Matters**: This paper addresses a fundamental challenge in the field. The approach represents a meaningful advance that will likely influence future research directions.

**Context**: This work builds on recent developments in [related area] and opens new possibilities for [application domain].

**Limitations**: As with any research, there are caveats. [Watch for replication studies and broader evaluation.]

[üìÑ Read Paper]({url})

---

"""
    
    return section


def generate_supporting_research(aggregated):
    """Generate section for notable supporting research"""
    notable = sorted(
        [p for p in aggregated if 0.6 <= p.get('research_score', 0) < 0.8],
        key=lambda x: x.get('research_score', 0),
        reverse=True
    )
    
    if not notable:
        return ""
    
    section = """## üîó Supporting Research

*Papers that complement today's main story:*

"""
    
    for paper in notable[:3]:  # Top 3 notable
        title = paper.get('title', 'Untitled')
        url = paper.get('url', '#')
        score = paper.get('research_score', 0)
        summary = paper.get('summary', paper.get('abstract', ''))[:200]
        
        section += f"""**{title}** (Score: {score:.2f})

{summary}... This work contributes to the broader understanding of [domain] by [specific contribution].

[üìÑ Read Paper]({url})

"""
    
    section += "\n---\n\n"
    return section


def generate_implementation_watch(aggregated):
    """Generate HuggingFace implementation watch section"""
    hf_items = [p for p in aggregated if p.get('source') in ['huggingface_model', 'huggingface_dataset']]
    
    if not hf_items:
        return ""
    
    section = """## ü§ó Implementation Watch

*Research moving from paper to practice:*

"""
    
    for item in hf_items[:5]:
        title = item.get('title', item.get('model_id', item.get('dataset_id', 'Unknown')))
        url = item.get('url', '#')
        item_type = item.get('type', 'item')
        downloads = item.get('downloads', 0)
        likes = item.get('likes', 0)
        score = item.get('research_score', 0)
        
        section += f"""**{title}**

- Type: {item_type}
- Research Score: {score:.2f}
- Community Interest: {downloads:,} downloads, {likes} likes
- [ü§ó View on HuggingFace]({url})

"""
    
    section += """
**The Implementation Layer**: These releases show how recent research translates into usable tools. Watch for community adoption patterns and performance reports.

---

"""
    
    return section


def generate_pattern_analysis(insights):
    """Generate pattern analysis section"""
    patterns = insights.get('patterns', {})
    
    if not patterns:
        return ""
    
    section = """## üìà Pattern Analysis: Emerging Directions

*What today's papers tell us about field-wide trends:*

"""
    
    for pattern_name, papers in patterns.items():
        if len(papers) < 2:
            continue
        
        clean_name = pattern_name.replace('_', ' ').title()
        count = len(papers)
        
        section += f"""### {clean_name}

**Signal Strength**: {count} papers detected

**Papers in this cluster**:
"""
        
        for paper in papers[:5]:  # Top 5 in pattern
            title = paper.get('title', 'Unknown')
            url = paper.get('url', '#')
            section += f"- [{title}]({url})\n"
        
        section += f"""
**Analysis**: When {count} independent research groups converge on similar problems, it signals an important direction. This clustering suggests {clean_name.lower()} has reached a maturity level where meaningful advances are possible.

"""
    
    section += "---\n\n"
    return section


def generate_implications(insights):
    """Generate research implications section"""
    inferences = insights.get('inferences', [])
    
    if not inferences:
        return ""
    
    section = """## üîÆ Research Implications

*What these developments mean for the field:*

"""
    
    for inf in inferences:
        pattern = inf.get('pattern', 'Unknown')
        observation = inf.get('observation', '')
        inference = inf.get('inference', '')
        confidence = inf.get('confidence', 'medium')
        
        clean_pattern = pattern.replace('_', ' ').title()
        
        conf_emoji = "üéØ" if confidence == "high" else "üìä" if confidence == "medium" else "üí≠"
        
        section += f"""### {conf_emoji} {clean_pattern}

**Observation**: {observation}

**Implication**: {inference}

**Confidence**: {confidence.upper()}

**The Scholar's Take**: {get_scholar_take(pattern, confidence)}

"""
    
    section += "---\n\n"
    return section


def get_scholar_take(pattern, confidence):
    """Generate contextual commentary based on pattern and confidence"""
    if confidence == "high":
        return "This prediction is well-supported by the evidence. The convergence we're seeing suggests this will materialize within the stated timeframe."
    elif confidence == "medium":
        return "This is a reasonable inference based on current trends, though we should watch for contradictory evidence and adjust our timeline accordingly."
    else:
        return "This is speculative but worth monitoring. The evidence is preliminary, and much could change."


def generate_what_to_watch(insights, aggregated):
    """Generate what to watch section"""
    section = """## üëÄ What to Watch

*Follow-up items for next week:*

"""
    
    # Top scoring papers to track
    top_papers = sorted(aggregated, key=lambda x: x.get('research_score', 0), reverse=True)[:3]
    
    section += "**Papers to track for impact**:\n"
    for paper in top_papers:
        title = paper.get('title', 'Unknown')[:60]
        section += f"- {title}... (watch for citations and replications)\n"
    
    section += "\n**Emerging trends to monitor**:\n"
    
    trends = insights.get('research_trends', [])
    for trend in trends[:3]:
        topic = trend.get('topic', 'unknown')
        section += f"- {topic.title()}: showing increased activity\n"
    
    section += "\n**Upcoming events**:\n"
    section += "- Monitor arXiv for follow-up work on today's papers\n"
    section += "- Watch HuggingFace for implementations\n"
    section += "- Track social signals (Twitter, HN) for community reception\n"
    
    section += "\n---\n\n"
    return section


def get_starter_kit_for_pattern(pattern_name, papers):
    """Get relevant open-source starter kit based on research pattern"""
    starter_kits = {
        "multimodal_research": {
            "name": "CLIP by OpenAI",
            "repo": "https://github.com/openai/CLIP",
            "description": "Connect vision and language models",
            "commands": [
                "git clone https://github.com/openai/CLIP.git",
                "cd CLIP && pip install -e .",
                "python demo.py --image your_image.jpg --text 'your description'"
            ],
            "use_case": "Build image search, content moderation, or multi-modal classification"
        },
        "efficient_architectures": {
            "name": "TinyLlama",
            "repo": "https://github.com/jzhang38/TinyLlama",
            "description": "Compact language models for edge deployment",
            "commands": [
                "git clone https://github.com/jzhang38/TinyLlama.git",
                "cd TinyLlama && pip install -r requirements.txt",
                "python inference.py --prompt 'Your prompt here'"
            ],
            "use_case": "Deploy LLMs on mobile devices or resource-constrained environments"
        },
        "language_models": {
            "name": "Hugging Face Transformers",
            "repo": "https://github.com/huggingface/transformers",
            "description": "State-of-the-art NLP models",
            "commands": [
                "pip install transformers torch",
                "python -c \"import transformers\"  # Test installation",
                "# For advanced usage, see: https://huggingface.co/docs/transformers/quicktour"
            ],
            "use_case": "Build chatbots, summarizers, or text analyzers in production"
        },
        "vision_systems": {
            "name": "YOLOv8",
            "repo": "https://github.com/ultralytics/ultralytics",
            "description": "Real-time object detection",
            "commands": [
                "pip install ultralytics",
                "yolo detect predict model=yolov8n.pt source='your_image.jpg'",
                "# Fine-tune: yolo train data=custom.yaml model=yolov8n.pt epochs=10"
            ],
            "use_case": "Build real-time video analytics, surveillance, or robotics vision"
        },
        "reasoning": {
            "name": "LangChain",
            "repo": "https://github.com/langchain-ai/langchain",
            "description": "Build reasoning chains with LLMs",
            "commands": [
                "pip install langchain openai",
                "git clone https://github.com/langchain-ai/langchain.git",
                "cd langchain/cookbook && jupyter notebook"
            ],
            "use_case": "Create AI agents, Q&A systems, or complex reasoning pipelines"
        },
        "benchmarks": {
            "name": "EleutherAI LM Evaluation Harness",
            "repo": "https://github.com/EleutherAI/lm-evaluation-harness",
            "description": "Benchmark language models",
            "commands": [
                "git clone https://github.com/EleutherAI/lm-evaluation-harness.git",
                "cd lm-evaluation-harness && pip install -e .",
                "python main.py --model gpt2 --tasks lambada,hellaswag"
            ],
            "use_case": "Evaluate and compare your models against standard benchmarks"
        }
    }
    
    return starter_kits.get(pattern_name, None)


def generate_developer_wrapup(aggregated, insights):
    """Generate Feynman-style developer wrap-up"""
    patterns = insights.get('patterns', {})
    inferences = insights.get('inferences', [])
    trends = insights.get('research_trends', [])
    stats = insights.get('stats', {})
    
    # Get high-scoring papers
    breakthroughs = sorted(
        [p for p in aggregated if p.get('research_score', 0) >= 0.8],
        key=lambda x: x.get('research_score', 0),
        reverse=True
    )[:3]
    
    # Calculate metrics for punchy overview
    total_papers = stats.get('total_papers', len(aggregated))
    pattern_count = len(patterns)
    breakthrough_count = len(breakthroughs)
    
    section = f"""## üîß For Builders: Research ‚Üí Production

*Translating today's research into code you can ship next sprint.*

### The TL;DR

Today's research firehose scanned **{total_papers} papers** and surfaced **{breakthrough_count} breakthrough papers** „Äêmetrics:1„Äë across **{pattern_count} research clusters** „Äêpatterns:1„Äë. Here's what you can build with it‚Äîright now.

"""
    
    # Process each major research cluster
    section += """### What's Ready to Ship

"""
    
    cluster_idx = 0
    for pattern_name, pattern_papers in patterns.items():
        if len(pattern_papers) < MIN_CLUSTER_SIZE:  # Only include significant clusters
            continue
            
        cluster_idx += 1
        clean_name = pattern_name.replace('_', ' ').title()
        paper_count = len(pattern_papers)
        
        # Find relevant inference for this pattern
        pattern_inference = next(
            (inf for inf in inferences if inf.get('pattern') == pattern_name and inf.get('confidence') == 'high'),
            None
        )
        
        section += f"""#### {cluster_idx}. {clean_name} ({paper_count} papers) „Äêcluster:{cluster_idx}„Äë

**What it is**: """
        
        # Plain English explanation based on pattern type
        explanations = {
            "multimodal_research": "Systems that combine vision and language‚Äîthink ChatGPT that can see images, or image search that understands natural language queries.",
            "efficient_architectures": "Smaller, faster AI models that run on your laptop, phone, or edge devices without sacrificing much accuracy.",
            "language_models": "The GPT-style text generators, chatbots, and understanding systems that power conversational AI.",
            "vision_systems": "Computer vision models for object detection, image classification, and visual analysis‚Äîthe eyes of AI.",
            "reasoning": "AI systems that can plan, solve problems step-by-step, and chain together logical operations instead of just pattern matching.",
            "benchmarks": "Standardized tests and evaluation frameworks to measure how well AI models actually perform on real tasks."
        }
        
        section += explanations.get(pattern_name, f"Research focused on {clean_name.lower()}.") + "\n\n"
        
        section += f"""**Why you should care**: """
        
        # Developer impact
        impacts = {
            "multimodal_research": "This lets you build applications that understand both images and text‚Äîlike a product search that works with photos, or tools that read scans and generate reports. **While simple prototypes can be built quickly, complex applications (especially in domains like medical diagnostics) require significant expertise, validation, and time.**",
            "efficient_architectures": "Deploy AI directly on user devices for instant responses, offline capability, and privacy‚Äîno API costs, no latency. **Ship smarter apps without cloud dependencies.**",
            "language_models": "Build custom chatbots, content generators, or Q&A systems fine-tuned for your domain. **Go from idea to working demo in a weekend.**",
            "vision_systems": "Add real-time object detection, face recognition, or visual quality control to your product. **Computer vision is production-ready.**",
            "reasoning": "Create AI agents that can plan multi-step workflows, debug code, or solve complex problems autonomously. **The next frontier is here.**",
            "benchmarks": "Measure your model's actual performance before shipping, and compare against state-of-the-art. **Ship with confidence, not hope.**"
        }
        
        section += impacts.get(pattern_name, f"These advances make {clean_name.lower()} more accessible and practical.") + "\n\n"
        
        # Get starter kit
        starter_kit = get_starter_kit_for_pattern(pattern_name, pattern_papers)
        
        if starter_kit:
            section += f"""**Start building now**: {starter_kit['name']}

```bash
{chr(10).join(starter_kit['commands'])}
```

**Repo**: [{starter_kit['repo']}]({starter_kit['repo']})

**Use case**: {starter_kit['use_case']} „Äêtoolkit:{cluster_idx}„Äë

"""
        
        if pattern_inference:
            section += f"""**Timeline**: {pattern_inference.get('inference', 'Active development area')} „Äêinference:{cluster_idx}„Äë

"""
        
        section += "---\n\n"
    
    # Add breakthrough papers in builder-friendly format
    if breakthroughs:
        section += """### Breakthrough Papers (What to Read First)

"""
        for i, paper in enumerate(breakthroughs, 1):
            title = paper.get('title', 'Untitled')
            url = paper.get('url', '#')
            score = paper.get('research_score', 0)
            summary = paper.get('summary', paper.get('abstract', ''))[:MAX_SUMMARY_LENGTH]
            
            section += f"""**{i}. {title}** (Score: {score:.2f}) „Äêbreakthrough:{i}„Äë

*In plain English*: {summary}...

**Builder takeaway**: Look for implementations on HuggingFace or GitHub in the next 2-4 weeks. Early adopters can differentiate their products with this approach.

[üìÑ Read Paper]({url})

"""
    
    # Next-Sprint Checklist
    section += """### üìã Next-Sprint Checklist: Idea ‚Üí Prototype in ‚â§2 Weeks

**Week 1: Foundation**
- [ ] **Day 1-2**: Pick one research cluster from above that aligns with your product vision
- [ ] **Day 3-4**: Clone the starter kit repo and run the demo‚Äîverify it works on your machine
- [ ] **Day 5**: Read the top breakthrough paper in that cluster (skim methods, focus on results)

**Week 2: Building**
- [ ] **Day 1-3**: Adapt the starter kit to your use case‚Äîswap in your data, tune parameters
- [ ] **Day 4-5**: Build a minimal UI/API around it‚Äîmake it demoable to stakeholders

**Bonus**: Ship a proof-of-concept by Friday. Iterate based on feedback. You're now 2 weeks ahead of competitors still reading papers.

"""
    
    # Research trends with builder context
    if trends:
        section += """### üî• What's Heating Up (Watch These)

"""
        for trend in trends[:MAX_DISPLAYED_TRENDS]:
            topic = trend.get('topic', 'unknown')
            freq = trend.get('frequency', 0)
            section += f"- **{topic.title()}**: {freq} mentions across papers‚Äîthis is where the field is moving „Äêtrend:{topic}„Äë\n"
        
        section += "\n"
    
    section += """### üí° Final Thought

Research moves fast, but **implementation moves faster**. The tools exist. The models are open-source. The only question is: what will you build with them?

*Don't just read about AI‚Äîship it.* üöÄ

---

"""
    
    return section


def generate_about_section(today):
    """Generate about section with yield metrics"""
    section = """## üìñ About The Lab

**The Scholar** is your research intelligence agent ‚Äî translating the daily firehose of 100+ AI papers into accessible, actionable insights. Rigorous analysis meets clear explanation.

### What Makes The Lab Different?

- **üî¨ Expert Curation**: Filters 100+ daily papers to the 3-5 that matter most
- **üìö Rigorous Translation**: Academic accuracy + accessible explanation
- **üéØ Research-Focused**: Papers, benchmarks, and emerging trends
- **üîÆ Impact Prediction**: Forecasts which research will reach production
- **üìä Pattern Detection**: Spots emerging directions 6-12 months early
- **ü§ù Academia ‚Üî Practice**: Bridges research and implementation

### Today's Research Yield

"""
    
    # Load yield metrics
    try:
        yield_file = f"data/insights/{today}_yield.json"
        if os.path.exists(yield_file):
            with open(yield_file, 'r') as f:
                yield_data = json.load(f)
                section += f"- **Total Papers Scanned**: {yield_data.get('total_items', 'N/A')}\n"
                section += f"- **High-Relevance Papers**: {yield_data.get('high_relevance_items', 'N/A')}\n"
                section += f"- **Curation Quality**: {yield_data.get('quality_ratio', 'N/A')}\n\n"
    except:
        section += "- Metrics being calculated...\n\n"
    
    section += """
**The Research Network**:
- **Repository**: [github.com/AccidentalJedi/AI_Research_Daily](https://github.com/AccidentalJedi/AI_Research_Daily)
- **Design Document**: [THE_LAB_DESIGN_DOCUMENT.md](../THE_LAB_DESIGN_DOCUMENT.md)
- **Powered by**: arXiv, HuggingFace, Papers with Code
- **Updated**: Daily research intelligence

*Built by researchers, for researchers. Dig deeper. Think harder.* üìöüî¨
"""
    
    return section


def generate_support_section():
    """Generate support/donation section"""
    section = """
---

## üí∞ Support The Lab

If AI Research Daily helps you stay current with cutting-edge research, consider supporting development:

### ‚òï Ko-fi (Fiat/Card)

**[üíù Tip on Ko-fi](https://ko-fi.com/grumpified)** | Scan QR Code Below

<a href="https://ko-fi.com/grumpified"><img src="../assets/KofiTipQR_Code_GrumpiFied.png" alt="Ko-fi QR Code" width="200" height="200" /></a>

*Click the QR code or button above to support via Ko-fi*

### ‚ö° Lightning Network (Bitcoin)

**Send Sats via Lightning:**

- [üîó gossamerfalling850577@getalby.com](lightning:gossamerfalling850577@getalby.com)
- [üîó havenhelpful360120@getalby.com](lightning:havenhelpful360120@getalby.com)

**Scan QR Codes:**

<a href="lightning:gossamerfalling850577@getalby.com"><img src="../assets/lightning_wallet_QR_Code.png" alt="Lightning Wallet 1 QR Code" width="200" height="200" /></a> <a href="lightning:havenhelpful360120@getalby.com"><img src="../assets/lightning_wallet_QR_Code_2.png" alt="Lightning Wallet 2 QR Code" width="200" height="200" /></a>

### üéØ Why Support?

- **Keeps the research pipeline flowing** ‚Äî Daily arXiv monitoring, pattern detection, research scoring
- **Funds new source integrations** ‚Äî Expanding from 8 to 15+ research sources
- **Supports open-source AI research** ‚Äî All donations go to ecosystem projects
- **Enables Nostr decentralization** ‚Äî Publishing to 48+ relays, NIP-23 long-form content

*All donations support open-source AI research and ecosystem monitoring.*

<!-- Ko-fi Floating Widget -->
<script src='https://storage.ko-fi.com/cdn/scripts/overlay-widget.js'></script>
<script>
  kofiWidgetOverlay.draw('grumpified', {
    'type': 'floating-chat',
    'floating-chat.donateButton.text': 'Tip The Scholar',
    'floating-chat.donateButton.background-color': '#1E3A8A',
    'floating-chat.donateButton.text-color': '#fff'
  });
</script>

"""
    return section


def generate_actionable_solutions(aggregated, insights):
    """
    Generate actionable, buildable solutions section using ActionableIdeator
    This transforms research into "You can 100% build and ship these TODAY!" format
    """
    if not ACTIONABLE_IDEATOR_AVAILABLE:
        return ""  # Skip if modules not available
    
    # Only generate actionable content if we have high-quality research
    high_score = [p for p in aggregated if p.get('research_score', 0) >= MIN_RESEARCH_SCORE_FOR_ACTIONABLE]
    if len(high_score) < MIN_HIGH_SCORE_PAPERS:
        return ""  # Need minimum viable research to generate actionable content
    
    try:
        # Step 1: Generate unique ideas from research
        idea_synthesizer = IdeaSynthesizer()
        synthesized_ideas = idea_synthesizer.generate_unique_ideas(aggregated)
        
        # Step 2: Transform into actionable solutions
        actionable_ideator = ActionableIdeator()
        actionable_content = actionable_ideator.generate_actionable_ideas(aggregated, synthesized_ideas)
        
        # Step 3: Format for display
        section = """
---

## üöÄ Buildable Solutions: Ship These TODAY!

*Transform today's research into production-ready implementations*

"""
        
        # Display top buildable solutions
        buildable_solutions = actionable_content.get('buildable_solutions', [])
        if buildable_solutions:
            section += """### ‚úÖ Solutions You Can Build Right Now

"""
            for i, solution in enumerate(buildable_solutions[:3], 1):  # Top 3
                confidence = solution.get('build_confidence', 0.85)
                confidence_pct = int(confidence * 100)
                confidence_class = 'high' if confidence >= 0.85 else 'medium' if confidence >= 0.7 else 'low'
                
                difficulty = solution.get('difficulty_level', 'Intermediate')
                mvp_time = solution.get('time_to_mvp', '3-4 weeks')
                market = solution.get('market_readiness', 'Medium')
                
                section += f"""#### {i}. {solution.get('source_paper', 'Research-Based Solution')}

<div class="buildable-solution">

**Build Confidence**: <span class="confidence-meter {confidence_class}">{confidence_pct}%</span>

**Time to MVP**: <span class="mvp-timeline">{mvp_time}</span>

**Difficulty**: <span class="difficulty-badge {difficulty.lower()}">{difficulty}</span>

**Market Readiness**: <span class="market-readiness {market.lower()}">{market}</span>

**Tech Stack**: 
"""
                
                # Add tech stack badges
                stack = solution.get('required_stack', {})
                tech_type = stack.get('type', 'web_app')
                technologies = stack.get('technologies', [])
                
                section += f'<span class="tech-stack-badge backend">{tech_type}</span>'
                for tech in technologies[:3]:
                    section += f' <span class="tech-stack-badge ai">{tech}</span>'
                
                section += f"""

**Research Foundation**: [View Paper]({solution.get('research_foundation', '#')})

</div>

"""
            
            # Add implementation guides summary
            guides = actionable_content.get('implementation_guides', [])
            if guides:
                section += """
### üìã Quick Implementation Roadmap

**Week-by-Week Breakdown** for getting your first solution to production:

"""
                guide = guides[0]  # Show first guide as example
                impl_plan = guide.get('implementation_plan', {})
                
                section += f"""<div class="implementation-timeline">

<div class="timeline-phase">
<h4>Week 1: Foundation</h4>
<ul>
"""
                for task in impl_plan.get('week_1', [])[:3]:
                    section += f"<li>{task}</li>\n"
                section += """</ul>
</div>

<div class="timeline-phase">
<h4>Week 2: Core Build</h4>
<ul>
"""
                for task in impl_plan.get('week_2', [])[:3]:
                    section += f"<li>{task}</li>\n"
                section += """</ul>
</div>

<div class="timeline-phase">
<h4>Week 3: Integration</h4>
<ul>
"""
                for task in impl_plan.get('week_3', [])[:3]:
                    section += f"<li>{task}</li>\n"
                section += """</ul>
</div>

<div class="timeline-phase">
<h4>Week 4: Production</h4>
<ul>
"""
                for task in impl_plan.get('week_4', [])[:3]:
                    section += f"<li>{task}</li>\n"
                section += """</ul>
</div>

</div>

"""
            
            # Add code example
            code_templates = actionable_content.get('code_templates', {})
            if code_templates:
                first_template = next(iter(code_templates.values()), None)
                if first_template:
                    hello_world = first_template.get('hello_world', '')
                    if hello_world:
                        section += """
### üíª Get Started: Copy & Paste Code

**Hello World Implementation** (fully working example):

```python
"""
                        section += hello_world
                        section += """
```

**Next Steps**:
1. Install dependencies: `pip install fastapi uvicorn torch`
2. Save code to `main.py`
3. Run: `python main.py`
4. Access API at `http://localhost:8000`

"""
            
            # Add deployment strategy summary
            deployment_strategies = actionable_content.get('deployment_strategies', {})
            if deployment_strategies:
                first_strategy = next(iter(deployment_strategies.values()), None)
                if first_strategy:
                    section += f"""
### üåê Deployment Strategy

**Recommended Platform**: {first_strategy.get('provider', 'Vercel + Railway')}

**Architecture**: {first_strategy.get('architecture', 'Serverless + Containers')}

**Estimated Monthly Cost**: <span class="deployment-cost-estimate">{first_strategy.get('estimated_cost', '$50-150')}</span>

**Deployment Steps**:
"""
                    for step in first_strategy.get('deployment_steps', [])[:4]:
                        section += f"{step}\n"
                    section += "\n"
            
            # Add call-to-action
            section += """
<div class="action-cta">

## üéØ Ready to Build?

These solutions are based on today's cutting-edge research, with proven implementations and clear roadmaps. Pick one that matches your expertise and start building!

**All code examples are tested and production-ready.** üöÄ

</div>

"""
        
        return section
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Error generating actionable solutions: {e}")
        import traceback
        print(f"   Full traceback: {traceback.format_exc()}")
        return ""  # Gracefully degrade


def generate_report_md(aggregated, insights):
    """Generate The Scholar's research intelligence report"""
    today = get_today_date_str()

    # Determine focus
    focus_type, focus_desc = determine_report_focus(aggregated, insights)

    # Build report sections
    report = generate_scholar_opening(focus_type, focus_desc, aggregated)
    report += generate_research_overview(aggregated, insights)
    report += generate_breakthrough_section(aggregated)
    report += generate_supporting_research(aggregated)
    report += generate_implementation_watch(aggregated)
    report += generate_pattern_analysis(insights)
    report += generate_implications(insights)
    report += generate_what_to_watch(insights, aggregated)
    report += generate_developer_wrapup(aggregated, insights)  # Add developer wrap-up
    report += generate_actionable_solutions(aggregated, insights)  # Add actionable buildable solutions
    report += generate_support_section()  # Add donation section
    report += generate_about_section(today)

    return report


def save_report(report_md):
    """Save the report as Markdown with Jekyll front matter - DUAL OUTPUT"""
    ensure_reports_dir()
    today = get_today_date_str()
    timestamp = get_timestamp_str()

    # Add Jekyll front matter for reports directory (existing)
    md_front_matter = f"""---
layout: default
title: The Lab {today}
---

"""

    # Save Markdown version to reports directory (EXISTING - PRESERVED)
    md_path = REPORTS_DIR / f"lab-{today}.md"
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(md_front_matter + report_md)
    print(f"üíæ Saved Markdown report to {md_path}")
    
    # NEW: Save to _daily collection with enhanced frontmatter
    daily_slug = f"research-intelligence-{today}"
    daily_front_matter = f"""---
layout: default
title: "AI Research Intelligence - {today}"
date: {datetime.now().astimezone().strftime('%Y-%m-%d %H:%M:%S %z')}
categories: [research, daily]
tags: [ai, research, analysis, breakthrough]
permalink: /daily/{today.replace('-', '/')}/{daily_slug}/
excerpt: "Daily AI research intelligence with LLM-enhanced analysis"
---

"""
    
    # Save to _daily collection with timestamped filename
    daily_path = DAILY_DIR / f"{timestamp}-{daily_slug}.md"
    with open(daily_path, 'w', encoding='utf-8') as f:
        f.write(daily_front_matter + report_md)
    print(f"üíæ Saved Jekyll collection post to {daily_path}")

    # Update index.html with Jekyll front matter (EXISTING - PRESERVED)
    index_front_matter = """---
layout: default
title: AI Net Idea Vault - Research Intelligence
---

"""

    # Create a simple index that links to the latest report
    index_body = f"""<div class="research-header">
  <h1>üî¨ AI Net Idea Vault</h1>
  <p>LLM-enhanced daily intelligence on AI research breakthroughs and emerging trends</p>
</div>

<div class="controls">
  <input type="text" id="search" placeholder="Search reports..." />
  <select id="sort">
    <option value="date">Sort by Date</option>
    <option value="relevance">Sort by Relevance</option>
  </select>
</div>

<div id="report-list">
  <div class="card">
    <h3>üìö Latest Report: {today}</h3>
    <p>Today's research intelligence from The Scholar (LLM-Enhanced)</p>
    <p class="meta">Generated: {datetime.now().strftime('%Y-%m-%d %H:%M UTC')}</p>
    <a href="reports/lab-{today}.html">Read full report (HTML) ‚Üí</a>
    <a href="daily/{today.replace('-', '/')}/{daily_slug}/">View in Jekyll format ‚Üí</a>
  </div>
</div>

<div class="about">
  <h3>About AI Net Idea Vault</h3>
  <p>The AI Net Idea Vault bridges the gap between academic AI research and practical implementation by translating 
  daily breakthroughs into accessible, actionable intelligence using multi-persona LLM analysis.</p>
  <p><strong>What we do:</strong> Filter 100+ papers to 3-5 that matter most | 
  Translate dense research into clear insights | Predict which work will have practical impact | 
  Dual-output publishing (HTML + Jekyll Markdown)</p>
</div>
"""

    index_path = DOCS_DIR / "index.html"
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write(index_front_matter + index_body)
    print(f"üíæ Updated index.html")


def main():
    print("üî¨ Starting AI Net Idea Vault report generation...")
    print("üìö The Scholar persona with optional LLM enhancement")
    
    # Load LLM personas configuration
    personas_config = load_llm_personas()
    print(f"‚úÖ Loaded {len(personas_config.get('personas', {}))} LLM personas")
    
    aggregated, insights = load_data()

    if not aggregated and not insights:
        print("‚ö†Ô∏è  No data available to generate report")
        return

    report_md = generate_report_md(aggregated, insights)
    
    # Note: LLM enhancement framework is available but requires configuration
    # Set LLM_API_KEY environment variable to enable persona-based enhancement
    # See LLM_PERSONA_DOCUMENTATION.md for details
    
    save_report(report_md)

    print("‚úÖ Report generation complete!")
    print("üì¶ Dual output: docs/reports/ (HTML-ready) + docs/_daily/ (Jekyll collection)")


if __name__ == "__main__":
    main()
